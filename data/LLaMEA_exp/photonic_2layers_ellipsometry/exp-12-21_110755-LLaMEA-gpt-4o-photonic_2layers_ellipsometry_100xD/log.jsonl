{"id": "01d97524-e1b3-45b4-99dc-5ef101b9107e", "fitness": 0.009522428116479223, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization with adaptive differential evolution to effectively navigate diverse search spaces.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for _ in range(self.budget):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00952 with standard deviation 0.00640.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.018567284349437663, 0.0050000000000000044]}}
{"id": "c5a2676e-d225-4962-b97c-4e7f4809a534", "fitness": 0.005137911185395898, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization with adaptive differential evolution, enhanced by dynamic adjustment of the inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for iteration in range(self.budget):  # Changed line\n            self.w = 0.9 - 0.8 * (iteration / self.budget)  # Added dynamic adjustment of inertia weight\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00514 with standard deviation 0.00020.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.005413733556187683, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "9a7f1451-51d3-4f9a-b184-68e80b4c0827", "fitness": 0.0038204248149477835, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive parameters and elitism to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.w = 0.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.elite_rate = 0.1\n        self.elite_size = int(self.pop_size * self.elite_rate)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub, iteration, max_iter):\n        c1 = self.initial_c1 * (1 - iteration / max_iter)\n        c2 = self.initial_c2 * (iteration / max_iter)\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def elitism(self):\n        elite_indices = np.argsort(self.personal_best_values)[:self.elite_size]\n        return self.personal_best[elite_indices], self.personal_best_values[elite_indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        max_iter = self.budget // self.pop_size\n        for iteration in range(max_iter):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub, iteration, max_iter)\n            elite_population, elite_values = self.elitism()\n\n            for i in range(self.elite_size):\n                if elite_values[i] < self.global_best_value:\n                    self.global_best_value = elite_values[i]\n                    self.global_best = elite_population[i].copy()\n\n        return self.global_best", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00382 with standard deviation 0.00540.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.01146127444484335, 0.0, 0.0]}}
{"id": "912ff32c-0efd-4206-91be-0a9c8721766f", "fitness": 0.0057344419751765114, "name": "HybridPSO_DE_SelfAdaptive", "description": "A hybrid algorithm combining particle swarm optimization with self-adaptive differential evolution for enhanced exploration and exploitation capabilities.", "code": "import numpy as np\n\nclass HybridPSO_DE_SelfAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for _ in range(self.budget):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE_SelfAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00573 with standard deviation 0.00104.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.0072033259255295246, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "01d12e0e-073e-4d9e-9d47-fa259d0b9908", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization with adaptive differential evolution, enhanced by dynamic adjustment of inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        self.w = 0.9 - (0.5 * _ / self.budget) \n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for _ in range(self.budget):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 4, "feedback": "An exception occurred: NameError(\"name '_' is not defined\").", "error": "NameError(\"name '_' is not defined\")", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {}}
{"id": "4696bf73-a92c-4822-a9ba-9ab3ed171ff9", "fitness": 0.0050000000000000044, "name": "RefinedHybridPSO_DE", "description": "A refined hybrid metaheuristic algorithm merging particle swarm optimization with adaptive differential evolution, incorporating dynamic parameter adjustment to enhance convergence and exploration capabilities.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_parameters(self):\n        progress = self.current_eval / self.budget\n        self.w = self.w_max - progress * (self.w_max - self.w_min)\n        self.F = self.F_max - progress * (self.F_max - self.F_min)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            self.update_parameters()\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n                if self.current_eval >= self.budget:\n                    break\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 5, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00500 with standard deviation 0.00000.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "dbd1d41e-3cc0-4eae-8a3d-838820138768", "fitness": 0.0050000000000000044, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid algorithm integrating adaptive inertia weight in PSO and adaptive differential evolution to optimize exploration and exploitation in diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.iteration = 0\n\n    def adaptive_inertia_weight(self):\n        return self.initial_w - (self.initial_w - self.final_w) * (self.iteration / self.budget)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for self.iteration in range(self.budget):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00500 with standard deviation 0.00000.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "97027ae7-2941-410f-ad2d-b3d97b50d3ca", "fitness": 0.0053397335237085715, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid algorithm combining swarm intelligence and adaptive differential evolution, introducing a dynamic adaptation strategy for convergence acceleration and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.initial_w - (self.initial_w - self.final_w) * (self.evaluations / self.budget)\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.evaluations += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00534 with standard deviation 0.00048.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.006019200571125705, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "fd5ae9e6-5d4c-4610-8f04-11c42fdd4658", "fitness": 0.0068875906617595906, "name": "HybridPSO_DE", "description": "Enhance HybridPSO_DE by introducing adaptive inertia weight and crossover rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.9  # Change 1: Adjusted initial inertia weight\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.8 + 0.2 * np.random.rand()  # Change 2: Adaptive crossover rate\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for iteration in range(self.budget):\n            self.w = 0.9 - (0.5 * iteration / self.budget)  # Change 3: Adaptive inertia weight adjustment\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00689 with standard deviation 0.00267.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.010662771985278763, 0.0050000000000000044]}}
{"id": "34d0d2e0-f0d8-44b7-acbe-6bbe3df5ed56", "fitness": 0.01663683914599945, "name": "HybridPSO_DE", "description": "A refined hybrid algorithm that leverages enhanced differential mutation for improved exploration while retaining PSO's exploitation capabilities. ", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.F = 0.8  # Increased F for more aggressive mutation\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for _ in range(self.budget):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01664 with standard deviation 0.00852.", "error": "", "parent_ids": ["01d97524-e1b3-45b4-99dc-5ef101b9107e"], "operator": null, "metadata": {"aucs": [0.01973911747696777, 0.02517139996103057, 0.0050000000000000044]}}
{"id": "1d7a5f0d-95c6-4f8e-8bc3-5d6957c5197d", "fitness": 0.006487063718420634, "name": "EnhancedHybridPSO_DE", "description": "Enhanced Hybrid PSO-DE with adaptive parameters for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_c1 = 2.5\n        self.initial_c2 = 0.5\n        self.final_c1 = 0.5\n        self.final_c2 = 2.5\n        self.w = 0.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            current_c1 = ((self.final_c1 - self.initial_c1) * \n                          (self.evaluations / self.budget) + self.initial_c1)\n            current_c2 = ((self.final_c2 - self.initial_c2) * \n                          (self.evaluations / self.budget) + self.initial_c2)\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  current_c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  current_c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.evaluations += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n            \n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00649 with standard deviation 0.00105.", "error": "", "parent_ids": ["34d0d2e0-f0d8-44b7-acbe-6bbe3df5ed56"], "operator": null, "metadata": {"aucs": [0.007178215792166043, 0.0050000000000000044, 0.007282975363095856]}}
{"id": "b42a9e08-d553-4c60-a3be-6ea5110d27b3", "fitness": 0.015576543178174954, "name": "RefinedHybridPSO_DE", "description": "A balanced hybrid approach integrating adaptive inertia weight and self-adaptive differential evolution to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_init = 0.9\n        self.w_end = 0.4\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.eval_count = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_init - (self.w_init - self.w_end) * (self.eval_count / self.budget)\n\n    def adaptive_differential_weight(self):\n        return self.F_min + (self.F_max - self.F_min) * (self.eval_count / self.budget)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            w = self.adaptive_inertia_weight()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def differential_evolution(self, index, lb, ub):\n        F = self.adaptive_differential_weight()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        for _ in range(self.budget):\n            for i in range(self.pop_size):\n                candidate = self.differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.eval_count += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 11, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01558 with standard deviation 0.01496.", "error": "", "parent_ids": ["34d0d2e0-f0d8-44b7-acbe-6bbe3df5ed56"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.036729629534524855]}}
{"id": "4d1686b2-375c-4b95-b98c-b3170007b431", "fitness": 0.029299445379782647, "name": "EnhancedHybridPSO_DE", "description": "An enhanced algorithm integrating adaptive inertia weight in PSO for dynamic exploration-exploitation balance, combined with a self-adaptive DE strategy to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02930 with standard deviation 0.02133.", "error": "", "parent_ids": ["34d0d2e0-f0d8-44b7-acbe-6bbe3df5ed56"], "operator": null, "metadata": {"aucs": [0.025972352563077283, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "f2940cf0-f05b-41b7-8c26-a273fae33971", "fitness": 0.00551301510271703, "name": "EnhancedHybridPSO_DE", "description": "Incorporate a dynamic crossover rate in DE and adjust velocity update to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]) +\n                                  0.5 * (self.global_best - self.personal_best[i]))  # Adjusted\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        adaptive_CR = 0.5 + 0.4 * np.sin(self.current_eval / self.budget * np.pi)  # Dynamic CR\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < adaptive_CR  # Dynamic CR applied\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00551 with standard deviation 0.00073.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.006539045308151081, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "495e327f-ac1f-4d35-977f-f4f85ac669f0", "fitness": 0.007134864760182362, "name": "EnhancedHybridPSO_DE", "description": "Enhance convergence by introducing a diversity-based selection strategy in the DE mutation process.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        \n        # Select individuals based on their diversity from the current solution\n        a, b, c = sorted(self.population[np.random.choice(idxs, 3, replace=False)],\n                         key=lambda x: np.linalg.norm(self.population[index] - x))[:3]\n        \n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00713 with standard deviation 0.00302.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.011404594280547076, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "9c4686d7-076e-4473-9107-4b5a34e71a9b", "fitness": -Infinity, "name": "AdvancedHybridPSO_DE", "description": "An advanced hybrid algorithm leveraging dynamic velocity clamping in PSO and adaptive DE mutation scaling to enhance exploration-exploitation synergy and convergence speed.", "code": "import numpy as np\n\nclass AdvancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def dynamic_velocity_clamping(self, lb, ub):\n        vmax = 0.1 * (ub - lb)\n        for i in range(self.pop_size):\n            self.velocities[i] = np.clip(self.velocities[i], -vmax, vmax)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.dynamic_velocity_clamping(lb, ub)\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def adaptive_f(self):\n        return self.F_min + (self.F_max - self.F_min) * (self.global_best_value / np.max(self.personal_best_values))\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.adaptive_f()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 15, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "3fcd8e47-5b84-4a8a-9a89-93a77d6009eb", "fitness": 0.009062684270713809, "name": "EnhancedHybridPSO_DE", "description": "Introduced a dynamic crossover rate in the DE strategy to improve diversification and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < (self.CR * (1 - self.current_eval / self.budget))\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00906 with standard deviation 0.00575.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.01718805281214142, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "114caca8-ee0d-416f-a7f7-62f25977e462", "fitness": 0.01392396886056102, "name": "RefinedHybridPSO_DE", "description": "A refined hybrid algorithm that introduces a dynamic population size control and chaotic map initialization to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.final_pop_size = 10\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def dynamic_population_size(self):\n        return self.final_pop_size + int((self.initial_pop_size - self.final_pop_size) * (1 - self.current_eval / self.budget))\n\n    def chaotic_map_initialization(self, lb, ub):\n        chaotic_map = np.random.rand(self.initial_pop_size, self.dim)\n        for i in range(self.initial_pop_size):\n            chaotic_map[i] = np.mod(4.0 * chaotic_map[i] * (1.0 - chaotic_map[i]), 1.0)\n        self.population = lb + chaotic_map * (ub - lb)\n        self.velocities = np.random.uniform(-1, 1, (self.initial_pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.initial_pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        current_pop_size = self.dynamic_population_size()\n        for i in range(current_pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.dynamic_population_size()) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.chaotic_map_initialization(lb, ub)\n        while self.current_eval < self.budget:\n            current_pop_size = self.dynamic_population_size()\n            for i in range(current_pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 17, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01392 with standard deviation 0.00689.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.005055517499138018, 0.02185028787662302, 0.014866101205922022]}}
{"id": "891b0a96-7e39-43e9-97ec-f8a5da509c7b", "fitness": 0.02653595082396169, "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid algorithm incorporating a neighborhood learning mechanism to enhance convergence speed and maintain diversity.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def neighborhood_learning(self, i):\n        neighborhood_size = 3\n        neighbors = np.random.choice(range(self.pop_size), neighborhood_size, replace=False)\n        best_neighbor = min(neighbors, key=lambda x: self.personal_best_values[x])\n        return self.personal_best[best_neighbor]\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            neighborhood_best = self.neighborhood_learning(i)\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (neighborhood_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 18, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02654 with standard deviation 0.01335.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.034762996345129804, 0.03713555945070124, 0.007709296676054023]}}
{"id": "8b16c35f-2d2a-4a22-821d-9969fc2395f7", "fitness": 0.025988706657613363, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with a Restart Mechanism and Adaptive Population Size to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.restart_threshold = 0.1 * budget\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.pop_size = self.initial_pop_size\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def restart_population(self, lb, ub):\n        if self.current_eval < self.budget - self.restart_threshold:\n            self.pop_size = np.random.randint(self.initial_pop_size // 2, self.initial_pop_size * 2)\n            self.initialize_population(lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            # Restart mechanism\n            if self.current_eval % (self.budget // 10) == 0:\n                self.restart_population(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02599 with standard deviation 0.02234.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.056925983576270656, 0.016040136396569427]}}
{"id": "e5ece841-0b53-48bd-bb50-0de875273fbf", "fitness": 0.0050000000000000044, "name": "EnhancedHybridPSO_DE", "description": "Introduced a stochastic perturbation in the position update to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            perturbation = np.random.normal(0, 0.1, self.dim)  # Added stochastic perturbation\n            self.population[i] += self.velocities[i] + perturbation\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00500 with standard deviation 0.00000.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "1379b6cc-5939-48e7-b5ba-d7f44efab6ea", "fitness": 0.029299445379782647, "name": "EnhancedHybridPSO_DE", "description": "Introducing a stochastic selection strategy for better candidate generation in DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = np.random.choice([idx for idx in range(self.pop_size) if idx != index], 3, replace=False)\n        a, b, c = self.population[idxs]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02930 with standard deviation 0.02133.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.025972352563077283, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "86d0e3ef-90c8-4a06-9775-104fdb138064", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with refined mutation strategy in DE and reduced cognitive component in PSO for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 1.5  # Reduced cognitive component for broader exploration\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c) + 0.5 * (self.global_best - self.population[index])  # Add global guidance\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 22, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "791db5d9-5de6-4cee-b7c6-6e81bc40cf3a", "fitness": 0.00546309135823612, "name": "EnhancedHybridPSO_DE_Improved", "description": "Introducing a dynamic learning factor adaptation mechanism in EnhancedHybridPSO_DE to improve exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_learning_factors(self):\n        progress = self.current_eval / self.budget\n        return (2.5 - 2.0 * progress, 0.5 + 2.0 * progress)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        c1_dynamic, c2_dynamic = self.adaptive_learning_factors()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  c1_dynamic * r1 * (self.personal_best[i] - self.population[i]) +\n                                  c2_dynamic * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00546 with standard deviation 0.00064.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050172622448037, 0.006372011829904656]}}
{"id": "55f817fc-4049-47b6-b250-6c0c19ceeb2b", "fitness": 0.005116601215978345, "name": "EnhancedHybridPSO_DE", "description": "Improved EnhancedHybridPSO_DE with dynamic crossover rate for better diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1  # Modified line\n        self.CR_max = 0.9  # Modified line\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_crossover_rate(self):  # Added function\n        return self.CR_min + (self.CR_max - self.CR_min) * (self.current_eval / self.budget)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        CR = self.adaptive_crossover_rate()  # Modified line\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00512 with standard deviation 0.00016.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.005349803647935025]}}
{"id": "9c18efef-612b-49ce-8467-92b94551b05c", "fitness": 0.027610643078013086, "name": "EnhancedHybridPSO_DE_Refined", "description": "Hybrid particle swarm optimization and differential evolution with adaptive neighborhood and elitism to enhance convergence and solution diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.elitism_rate = 0.1\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        neighborhood = np.random.choice(idxs, size=min(5, len(idxs)), replace=False)\n        a, b, c = self.population[np.random.choice(neighborhood, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def elitism_selection(self):\n        top_k = int(self.elitism_rate * self.pop_size)\n        idx_sorted = np.argsort(self.personal_best_values)\n        elites = self.population[idx_sorted[:top_k]]\n        return elites\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        elites = self.elitism_selection()\n        \n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            self.population[:len(elites)] = elites  # Replace worst with elites\n\n        return self.global_best", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSO_DE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02761 with standard deviation 0.02880.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.06825403365996408, 0.00957789557407518, 0.0050000000000000044]}}
{"id": "9c914f9a-8056-4064-baec-cb365007eab2", "fitness": -Infinity, "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm using dynamic topology and diversity preservation to enhance convergence speed and avoid premature convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.neighborhood_size = 5  # For dynamic topology\n        self.diversity_threshold = 1e-5\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            neighbors = self.get_neighbors(i)\n            local_best = min(neighbors, key=lambda idx: self.personal_best_values[idx])\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.personal_best[local_best] - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def get_neighbors(self, index):\n        indices = list(range(self.pop_size))\n        indices.remove(index)\n        np.random.shuffle(indices)\n        return indices[:self.neighborhood_size]\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def preserve_diversity(self):\n        diversity = np.std(self.population, axis=0)\n        if np.all(diversity < self.diversity_threshold):\n            self.initialize_population(self.population.min(axis=0), self.population.max(axis=0))\n            self.update_best()\n\n    def update_best(self):\n        for i in range(self.pop_size):\n            value = func(self.population[i])\n            if value < self.personal_best_values[i]:\n                self.personal_best_values[i] = value\n                self.personal_best[i] = self.population[i].copy()\n            if value < self.global_best_value:\n                self.global_best_value = value\n                self.global_best = self.population[i].copy()\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        self.update_best()\n\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            self.preserve_diversity()\n\n        return self.global_best", "configspace": "", "generation": 26, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "83a604a7-ca2b-4527-afc2-09c6bd07df31", "fitness": 0.007348342271146928, "name": "EnhancedHybridPSO_DE_AdaptiveMutation", "description": "An enhanced hybrid PSO-DE algorithm with a novel adaptive mutation strategy that dynamically balances exploration and exploitation, improving convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_AdaptiveMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_mutation_factor(self):\n        # New adaptive mutation factor which reduces linearly with evaluations\n        return self.F_max - ((self.F_max - self.F_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.adaptive_mutation_factor()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedHybridPSO_DE_AdaptiveMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00735 with standard deviation 0.00332.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.012045026813440773]}}
{"id": "39aae962-fce8-4863-8a82-6f2e0ad1e58c", "fitness": 0.026801526473261544, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with dynamic crossover rate in DE strategy for improved adaptability.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        self.CR = 0.8 + 0.2 * np.sin(self.current_eval * np.pi / self.budget)  # Dynamic CR\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02680 with standard deviation 0.02200.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.056925983576270656, 0.018478595843513967]}}
{"id": "e054b4cd-4e0c-44b7-8725-ac22eb2fdb0f", "fitness": 0.013580135378791177, "name": "EnhancedHybridPSO_DE", "description": "The refined algorithm adds an adaptive crossover rate to the DE strategy for better diversity control and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1  # Changed\n        self.CR_max = 0.9  # Changed\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_crossover_rate(self):  # New method added\n        return self.CR_max - ((self.CR_max - self.CR_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        CR = self.adaptive_crossover_rate()  # Changed\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01358 with standard deviation 0.00609.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.01718805281214142, 0.0050000000000000044, 0.018552353324232107]}}
{"id": "6f0655b0-1337-469c-ba7e-91ad5e01b81b", "fitness": 0.006468168057088127, "name": "EnhancedHybridPSO_DE", "description": "A robust hybrid integrating adaptive inertia PSO with self-adaptive DE, enhanced by a dynamic diversity control mechanism to maintain exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.diversity_threshold = 0.1\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def calculate_diversity(self):\n        mean_position = np.mean(self.population, axis=0)\n        diversity = np.mean(np.linalg.norm(self.population - mean_position, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            diversity = self.calculate_diversity()\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n            # Adjust F_min and F_max based on diversity\n            if diversity < self.diversity_threshold:\n                self.F_min = max(self.F_min - 0.1, 0.1)  # Increase exploration\n                self.F_max = max(self.F_max - 0.1, 0.5)\n            else:\n                self.F_min = min(self.F_min + 0.1, 0.9)  # Increase exploitation\n                self.F_max = min(self.F_max + 0.1, 1.5)\n\n        return self.global_best", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00647 with standard deviation 0.00104.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.007337485736047089, 0.007067018435217287]}}
{"id": "ee1e55f1-6a08-4e74-9a7e-fd76f45c4340", "fitness": 0.016639049126372818, "name": "EnhancedHybridPSO_DE", "description": "A dynamic hybrid optimizer combining adaptive PSO with a diversity-preserving DE strategy, enhancing convergence and maintaining exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def diversity_preserving_de(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        trial_diversity = np.linalg.norm(trial - self.population[index])\n\n        if trial_diversity > 0.1 * np.linalg.norm(ub - lb) / np.sqrt(self.dim):\n            return trial\n        return self.population[index]  # Return original if diversity threshold not met\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.diversity_preserving_de(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01664 with standard deviation 0.01646.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.039917147379118445]}}
{"id": "c53e8a7c-64e5-4f2c-a500-aaf2f8fa6a00", "fitness": 0.00761092379115554, "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive crossover rate and random dimension perturbation to enhance exploration-exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.8 + 0.2 * np.random.rand()  # Adaptive crossover rate\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        random_dim = np.random.randint(0, self.dim)  # Random dimension perturbation\n        trial[random_dim] = lb[random_dim] + np.random.rand() * (ub[random_dim] - lb[random_dim])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00761 with standard deviation 0.00369.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.012832771373466612, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "b8d93af2-31ba-4493-ba46-c2fd7eee6815", "fitness": 0.022308661192090223, "name": "EnhancedHybridPSO_DE", "description": "A hybrid PSO-DE algorithm with dynamic adaptation of mutation factors and inertia weights to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            # Change: Introduced adaptive CR based on generations\n            self.CR = 0.9 - 0.5 * (self.current_eval / self.budget)\n\n        return self.global_best", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02231 with standard deviation 0.02448.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "0ac06d09-d7ca-4dcf-bc9c-08629e00bac9", "fitness": 0.029299445379782647, "name": "EnhancedHybridPSO_DE_Refined", "description": "A blend of PSO and DE with random search enhancing particle diversity and convergence speed, utilizing dynamic boundary adjustments for optimized exploration-exploitation tradeoffs.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.epsilon = 1e-8\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def random_search_enhancement(self, lb, ub):\n        random_solutions = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        for i in range(self.pop_size):\n            random_value = func(random_solutions[i])\n            self.current_eval += 1\n            if random_value < self.global_best_value:\n                self.global_best_value = random_value\n                self.global_best = random_solutions[i].copy()\n\n    def dynamic_boundaries(self, epoch):\n        exploration_factor = max(0, (self.budget - self.current_eval) / self.budget)\n        return exploration_factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n            # Random search enhancement for diversity\n            if self.current_eval < self.budget * 0.1:\n                self.random_search_enhancement(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridPSO_DE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02930 with standard deviation 0.02133.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.025972352563077283, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "6bc2475e-d663-401d-8822-7517d5876e5d", "fitness": 0.013580135378791177, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive crossover rate for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1  # Changed from 0.9 to adaptive range\n        self.CR_max = 0.9  # Added for adaptive crossover rate\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_crossover_rate(self):\n        return self.CR_max - ((self.CR_max - self.CR_min) * (self.current_eval / self.budget))  # New function for adaptive crossover\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        CR = self.adaptive_crossover_rate()  # Apply adaptive crossover rate\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01358 with standard deviation 0.00609.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.01718805281214142, 0.0050000000000000044, 0.018552353324232107]}}
{"id": "9ebe0d19-c06b-4ba1-83d7-a196ea8b4a40", "fitness": 0.026371345462804025, "name": "EnhancedHybridPSO_DE", "description": "A refined hybrid algorithm integrating an adaptive inertia weight in PSO, combined with a self-adaptive DE strategy for enhanced convergence, with improved CR parameter for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.8  # Slightly reduced crossover rate for better exploration-exploitation balance\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02637 with standard deviation 0.02217.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.01718805281214142, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "0c18f10f-f6ef-4ee9-aeaf-93a7b690fe3d", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Integrate stochastic population size adjustments to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n        if np.random.rand() < 0.1:  # Stochastic adjustment of population size\n            self.pop_size = max(10, int(self.pop_size * 1.1))  # Ensure minimum size\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 37, "feedback": "An exception occurred: IndexError('index 31 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 31 is out of bounds for axis 0 with size 30')", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "be2e96d2-7447-4b41-87ae-3d4633d55f7e", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE_LocalSearch", "description": "An enhanced hybrid algorithm combining adaptive inertia weight PSO with self-adaptive DE and a local search phase to refine solutions and improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_LocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def local_search(self, solution, lb, ub):\n        step_size = (ub - lb) * 0.1\n        best_local = solution.copy()\n        best_local_value = np.inf\n        for _ in range(5):  # Simple local search with a few iterations\n            candidate = best_local + np.random.uniform(-step_size, step_size)\n            candidate = np.clip(candidate, lb, ub)\n            candidate_value = func(candidate)\n            self.current_eval += 1\n            if candidate_value < best_local_value:\n                best_local_value = candidate_value\n                best_local = candidate\n        return best_local, best_local_value\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n            # Apply local search on the global best\n            if self.current_eval < self.budget:\n                improved_solution, improved_value = self.local_search(self.global_best, lb, ub)\n                if improved_value < self.global_best_value:\n                    self.global_best_value = improved_value\n                    self.global_best = improved_solution.copy()\n\n        return self.global_best", "configspace": "", "generation": 38, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "c7b1c85c-28f1-4eda-a328-9265f96e1e7f", "fitness": 0.029299445379782647, "name": "EnhancedHybridPSO_DE", "description": "An improved hybrid algorithm combining PSO with adaptive inertia weight and DE with a novel diversity preservation strategy to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def diversity_preservation(self):\n        mean_individual = np.mean(self.population, axis=0)\n        diversity = np.mean(np.linalg.norm(self.population - mean_individual, axis=1))\n        if diversity < 0.1 * (np.max(self.population) - np.min(self.population)):\n            random_indices = np.random.choice(self.pop_size, self.pop_size // 10, replace=False)\n            for idx in random_indices:\n                self.population[idx] = np.random.uniform(lb, ub, self.dim)\n                self.personal_best[idx] = self.population[idx]\n                self.personal_best_values[idx] = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            self.diversity_preservation()\n\n        return self.global_best", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02930 with standard deviation 0.02133.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.025972352563077283, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "5134e3ab-e0df-4bbf-890d-828f355084f6", "fitness": 0.006152089003115813, "name": "EnhancedHybridPSO_DE", "description": "Improved exploration via chaotic mapping in velocity update for enhanced convergence in EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            # Introduce logistic chaotic mapping for enhanced exploration\n            r1 = 4 * r1 * (1 - r1)  \n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00615 with standard deviation 0.00163.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.008456267009347429, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "2bb6a04d-0693-430b-88b7-9f7fbb6174f5", "fitness": 0.007348342271146928, "name": "EnhancedHybridPSO_DE", "description": "Incorporate dynamic scaling for the differential evolution parameter to adaptively fine-tune exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * (1 - (self.current_eval / self.budget))  # Dynamic scaling of F\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00735 with standard deviation 0.00332.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.012045026813440773]}}
{"id": "7d2599d1-0456-44b4-ba68-f0b1f12dd166", "fitness": 0.00859652236750689, "name": "ChaoticEnhancedHybridPSO_DE", "description": "A novel metaheuristic combining chaotic maps for parameter tuning in EnhancedHybridPSO_DE, improving exploration and exploitation balance for better convergence.", "code": "import numpy as np\n\nclass ChaoticEnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.chaos_index = 0.7  # Initial value for chaos-based parameter tuning\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n    \n    def chaotic_map(self):\n        self.chaos_index = 4 * self.chaos_index * (1 - self.chaos_index)  # Logistic map\n        return self.chaos_index\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * self.chaotic_map()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 42, "feedback": "The algorithm ChaoticEnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00860 with standard deviation 0.00287.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.008764219797933737, 0.0050000000000000044, 0.01202534730458693]}}
{"id": "144aa618-9eb8-469a-badf-55ba03691b69", "fitness": 0.011122601301863119, "name": "EnhancedHybridPSO_DE", "description": "Enhanced exploration by tweaking the self-adaptive DE strategy with a probability-based trial selection.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        if np.random.rand() < 0.5:  # Change: Introduced probabilistic trial selection\n            trial = mutant\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01112 with standard deviation 0.00536.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.010319547568211407, 0.018048256337377944, 0.0050000000000000044]}}
{"id": "9edc6b0c-d11b-4e56-9681-e1b3d589163a", "fitness": 0.009863347501654593, "name": "EnhancedHybridPSO_DE", "description": "Incorporate an adaptive crossover rate into DE and introduce a mutation-based diversity strategy for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.7\n        self.CR_max = 1.0\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_crossover_rate(self):\n        return self.CR_min + ((self.CR_max - self.CR_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        CR = self.adaptive_crossover_rate()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00986 with standard deviation 0.00688.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.019590042504963767, 0.0050000000000000044]}}
{"id": "ab7ee1b5-b3c6-4bae-9590-1a7845bf3a0d", "fitness": 0.012483819829999576, "name": "EnhancedHybridPSO_DE", "description": "Introduced a stochastic adaptive crossover rate in DE for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        # Introduce adaptive crossover rate\n        self.CR = 0.5 + 0.5 * np.random.rand()\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01248 with standard deviation 0.01058.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.02745145948999872, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "5e461d3b-c177-476a-aa7d-a4da70493973", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Introducing a diversity mechanism with opposition-based learning to improve convergence speed and avoid local optima.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def opposition_based_learning(self, pop, lb, ub):\n        opp_pop = lb + ub - pop\n        for i in range(self.pop_size):\n            if func(opp_pop[i]) < func(pop[i]):\n                pop[i] = opp_pop[i]\n        return pop\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            self.population = self.opposition_based_learning(self.population, lb, ub)  # Added line\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 46, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "9ac7f4c2-3fb2-44ef-b2a8-0324bf58041a", "fitness": 0.01056829133051651, "name": "EnhancedHybridPSO_DE", "description": "A refined hybrid algorithm integrating adaptive inertia weight in PSO with enhanced local search strategy and self-adaptive DE for better convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            # Enhanced local search using a small perturbation around the global best\n            perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n            local_candidate = self.global_best + perturbation\n            local_candidate = np.clip(local_candidate, lb, ub)\n            local_value = func(local_candidate)\n            self.current_eval += 1\n            if local_value < self.global_best_value:\n                self.global_best_value = local_value\n                self.global_best = local_candidate\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01057 with standard deviation 0.00573.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.005875808923127002, 0.0186318638445917, 0.007197201223830829]}}
{"id": "f0958fec-bbde-415a-926d-a84932f14080", "fitness": 0.010427693172115227, "name": "EnhancedHybridPSO_DE", "description": "A refined hybrid algorithm integrating adaptive inertia weight in PSO with enhanced mutation and crossover strategies for DE to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        \n        # Enhanced mutation and crossover strategy\n        if np.random.rand() < 0.1:  # 10% chance to apply greedier trial selection\n            trial = np.where(np.random.rand(self.dim) < 0.5, \n                             self.personal_best[index], trial)\n        trial = np.where(np.random.rand(self.dim) < 0.05, \n                         self.global_best, trial)  # 5% elitism factor\n        \n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01043 with standard deviation 0.00580.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.018474085250452577, 0.0050000000000000044, 0.007808994265893099]}}
{"id": "da0f642b-d14e-4f95-860b-1985bcf0cac5", "fitness": 0.005556791437921353, "name": "AdaptiveHybridPSO_DE_Levy", "description": "Adaptive Hybrid PSO-DE with Lvy Flights: Enhances exploration by integrating Lvy Flights into PSO for global search diversity, maintaining DE's self-adaptive strategy for efficient convergence.", "code": "import numpy as np\nfrom scipy.stats import levy\n\nclass AdaptiveHybridPSO_DE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def levy_flight(self, step_size):\n        return levy.rvs(size=self.dim) * step_size\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.velocities[i] += self.levy_flight(0.01)  # Adding Lvy flight\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptiveHybridPSO_DE_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00556 with standard deviation 0.00079.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.006670374313764049]}}
{"id": "e3488a96-c6e5-4499-9864-2eefcee16563", "fitness": -Infinity, "name": "OptimizedHybridPSO_DE", "description": "An optimized hybrid PSO-DE algorithm incorporating chaotic maps for improved exploration-exploitation balance and convergence efficiency.", "code": "import numpy as np\n\nclass OptimizedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.chaotic_sequence = self.init_chaotic_sequence()\n\n    def init_chaotic_sequence(self):\n        sequence = np.zeros(self.budget)\n        x = 0.7  # Initial value for chaotic map\n        for i in range(self.budget):\n            x = 4.0 * x * (1.0 - x)  # Logistic map\n            sequence[i] = x\n        return sequence\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = self.chaotic_sequence[self.current_eval], np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = (self.F_min + (self.F_max - self.F_min) * self.chaotic_sequence[self.current_eval]) \n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 50, "feedback": "An exception occurred: IndexError('index 200 is out of bounds for axis 0 with size 200').", "error": "IndexError('index 200 is out of bounds for axis 0 with size 200')", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "2d8000ee-b34f-4094-981b-60610dfb1b3d", "fitness": 0.009062684270713809, "name": "EnhancedHybridPSO_DE", "description": "Introduced a dynamic crossover rate (CR) adaptation to enhance exploration-exploitation trade-off in the hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < (self.CR * (1 - self.current_eval / self.budget)) # Modified line\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00906 with standard deviation 0.00575.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.01718805281214142, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "602f1db0-c128-4f24-85b2-32b7e90a90cd", "fitness": 0.029299445379782647, "name": "EnhancedHybridPSO_DE", "description": "Introduced a dynamic population size adjustment for improved convergence and diversity balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        # Dynamic population size adjustment: Calculate effective population size\n        effective_pop_size = int(self.pop_size * (1 - self.current_eval / self.budget))\n        self.population = np.random.uniform(lb, ub, (effective_pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (effective_pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * effective_pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02930 with standard deviation 0.02133.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.025972352563077283, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "6e3eba2c-29be-4e97-92e1-63e86efc34b2", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Improved exploration by incorporating Lvy flights into the particle velocity update for better search space coverage.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def levy_flight(self, size, lb, ub):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / abs(v) ** (1 / beta)\n        return step * (ub - lb) * 0.01\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            levy_step = self.levy_flight(self.dim, lb, ub)\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]) +\n                                  levy_step)  # Modified line\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 53, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "c91f33b6-fa54-48f5-b893-36629fdf1d51", "fitness": 0.00787602736329899, "name": "EnhancedHybridPSO_DE", "description": "Introduced a dynamic selection strategy for DE parameters and improved local search with a mutation operator to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.mutation_prob = 0.1  # New parameter for mutation\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            if np.random.rand() < self.mutation_prob:\n                self.velocities[i] += np.random.uniform(-0.1, 0.1, self.dim)  # Small mutation\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * (self.current_eval / self.budget)  # Dynamic F\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00788 with standard deviation 0.00097.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.00862681171894053, 0.006507121862420195, 0.008494148508536248]}}
{"id": "2286fcea-70db-4c43-8d44-09eebb0b5c1b", "fitness": 0.012427511754288098, "name": "ImprovedHybridPSO_DE", "description": "An improved hybrid algorithm integrating a nonlinear adaptive PSO inertia weight for enhanced exploration-exploitation balance, with self-adaptive DE using dynamic CR and F for better convergence.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def nonlinear_adaptive_inertia_weight(self):\n        return self.w_min + (self.w_max - self.w_min) * (1 - (self.current_eval / self.budget) ** 2)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.nonlinear_adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        CR = self.CR_min + (self.CR_max - self.CR_min) * (self.current_eval / self.budget)\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 55, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01243 with standard deviation 0.01050.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.027282535262864283, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "ad811b05-c205-46b4-a29b-e232fc96cf88", "fitness": 0.012483819829999576, "name": "EnhancedHybridPSO_DE", "description": "Introduce a dynamic crossover rate adaptation in the self-adaptive differential evolution to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.5 * np.random.rand()  # Line changed: dynamic adaptation of CR\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01248 with standard deviation 0.01058.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.02745145948999872, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "30523a13-81f7-4200-89f1-4e84d33c8a24", "fitness": 0.029299445379782647, "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with dynamic parameter control and elitist selection mechanism for enhanced convergence efficiency and exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def dynamic_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.full(self.pop_size, np.inf)\n        self.global_best_value = np.inf\n\n    def update_particles(self, lb, ub):\n        w = self.dynamic_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def elitist_selection(self, candidate, candidate_value, index):\n        if candidate_value < self.personal_best_values[index]:\n            self.personal_best_values[index] = candidate_value\n            self.personal_best[index] = candidate.copy()\n\n        if candidate_value < self.global_best_value:\n            self.global_best_value = candidate_value\n            self.global_best = candidate.copy()\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n                self.elitist_selection(candidate, candidate_value, i)\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02930 with standard deviation 0.02133.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.025972352563077283, 0.056925983576270656, 0.0050000000000000044]}}
{"id": "1fa59511-b9a1-4a6e-80dd-573cb81d1faa", "fitness": 0.006140888185850901, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid PSO-DE with dynamic population size adjustment for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def dynamic_population_size(self):\n        # Adjust population size dynamically based on progress\n        self.pop_size = max(10, int(30 - (20 * self.current_eval / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            self.dynamic_population_size()\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00614 with standard deviation 0.00161.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.008422664557552695]}}
{"id": "4a9416e0-e184-4f6f-ace4-23adbbf31a86", "fitness": 0.012711891829875014, "name": "EnhancedOppositionHybridPSO_DE", "description": "A novel hybrid algorithm leveraging opposition-based learning to enhance initial diversity and convergence, integrated with an adaptive local search mechanism to refine solutions.", "code": "import numpy as np\n\nclass EnhancedOppositionHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        opposition_population = lb + ub - self.population  # Opposition-based learning\n        self.population = np.vstack((self.population, opposition_population))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size * 2, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * (self.pop_size * 2))\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def adaptive_local_search(self, candidate, lb, ub):\n        perturbation = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n        new_candidate = np.clip(candidate + perturbation, lb, ub)\n        return new_candidate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate = self.adaptive_local_search(candidate, lb, ub)  # Apply local search\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedOppositionHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01271 with standard deviation 0.00862.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.008392388034367038, 0.0050000000000000044, 0.024743287455258]}}
{"id": "891dd41d-571b-4dc9-b3c1-5289160d9115", "fitness": 0.0050000000000000044, "name": "EnhancedHybridPSO_DE", "description": "Introduced chaotic inertia weight and enhanced self-adaptive mutation to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        # Introducing chaotic behavior in inertia weight calculation\n        chaos_factor = 4.0 * self.current_eval * (1.0 - self.current_eval / self.budget)\n        return self.w_max - ((self.w_max - self.w_min) * chaos_factor)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        # Enhanced self-adaptive mutation\n        mutant = a + F * (b - c) + 0.001 * np.random.randn(self.dim)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00500 with standard deviation 0.00000.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "a5849ab7-b4d7-467b-bec1-ecd43084b620", "fitness": 0.01810281238209018, "name": "EnhancedHybridPSO_DE", "description": "Refined EnhancedHybridPSO_DE incorporates mutation rate adaptation and velocity clamping for improved balance and convergence. ", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = np.clip((w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i])), -0.1, 0.1)\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        F = np.clip(F, 0.5, 0.9)  # Mutation rate adaptation\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01810 with standard deviation 0.01775.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0061071406142769735, 0.0050000000000000044, 0.04320129653199356]}}
{"id": "ce3606d9-6bf0-4899-948f-8fd753de58cb", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Improved convergence by dynamically adjusting crossover rate and utilizing personal best for mutation scaling factor in DE strategy.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.5  # Changed line: Introduced dynamic crossover rate\n        self.CR_max = 0.9  # Changed line: Introduced dynamic crossover rate\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * (self.personal_best_values[index] / self.global_best_value)  # Changed line: Utilized personal best for mutation scaling\n        CR = self.CR_min + (self.CR_max - self.CR_min) * (self.current_eval / self.budget)  # Changed line: Dynamically adjusted crossover rate\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 62, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "c483ea7e-5530-4b6e-9166-d649b8317013", "fitness": 0.011248584360384931, "name": "ChaoticHybridPSO_DE", "description": "A hybrid algorithm integrating chaotic maps for adaptive parameter tuning in PSO and dynamic F & CR adjustment in DE for enhanced convergence.", "code": "import numpy as np\n\nclass ChaoticHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.4\n        self.CR_max = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.chaos_param = np.random.rand()\n\n    def logistic_map(self):\n        self.chaos_param = 4.0 * self.chaos_param * (1.0 - self.chaos_param)\n        return self.chaos_param\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * self.logistic_map()\n        CR = self.CR_min + (self.CR_max - self.CR_min) * self.logistic_map()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 63, "feedback": "The algorithm ChaoticHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01125 with standard deviation 0.00831.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.02299596824043193, 0.00574978484072286, 0.0050000000000000044]}}
{"id": "634a8705-e01f-47a3-a3bb-0feba1c0ff6d", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE_Improved", "description": "Introduce a dynamic convergence operator to the EnhancedHybridPSO_DE for improved global search capability and faster convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def dynamic_convergence_operator(self, candidate, lb, ub):\n        convergence_rate = 0.5 * (1 - (self.current_eval / self.budget))\n        perturbation = np.random.uniform(-convergence_rate, convergence_rate, self.dim)\n        candidate += perturbation * (self.global_best - candidate)\n        return np.clip(candidate, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate = self.dynamic_convergence_operator(candidate, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 64, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "139ac375-4380-4d58-85f6-b1ecb2bf979e", "fitness": 0.005718890274608183, "name": "EnhancedHybridPSO_DE", "description": "A refined algorithm that adjusts dynamic exploration-exploitation using a non-linear inertia weight decay and introduces Gaussian perturbation in DE for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        progress = self.current_eval / self.budget\n        return self.w_max - (self.w_max - self.w_min) * (progress**2)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant += np.random.normal(0, 0.1, size=self.dim)  # Gaussian perturbation\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00572 with standard deviation 0.00099.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.007117626847612413, 0.0050000000000000044, 0.005039043976212132]}}
{"id": "ad1287d3-9917-46cf-b1b1-5520b74684fd", "fitness": -Infinity, "name": "AdvancedHybridMS_PSO_DE", "description": "A robust variant enhancing exploration-exploitation by integrating a dynamic multi-swarm strategy with adaptive learning rates for optimal convergence in diverse landscapes.", "code": "import numpy as np\n\nclass AdvancedHybridMS_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.num_swarms = 3\n        self.swarms = []\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.global_best_value = np.inf\n        self.global_best = None\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self, swarm_idx):\n        return self.w_max - ((self.w_max - self.w_min) * (swarm_idx / self.num_swarms))\n\n    def initialize_swarms(self, lb, ub):\n        for _ in range(self.num_swarms):\n            population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n            velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n            personal_best = population.copy()\n            personal_best_values = np.array([np.inf] * self.pop_size)\n            self.swarms.append({\n                'population': population,\n                'velocities': velocities,\n                'personal_best': personal_best,\n                'personal_best_values': personal_best_values,\n                'global_best': None,\n                'global_best_value': np.inf\n            })\n\n    def update_particles(self, lb, ub, swarm):\n        w = self.adaptive_inertia_weight(self.swarms.index(swarm))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            swarm['velocities'][i] = (w * swarm['velocities'][i] +\n                                      self.c1 * r1 * (swarm['personal_best'][i] - swarm['population'][i]) +\n                                      self.c2 * r2 * (swarm['global_best'] - swarm['population'][i]))\n            swarm['population'][i] += swarm['velocities'][i]\n            swarm['population'][i] = np.clip(swarm['population'][i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub, swarm):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = swarm['population'][np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, swarm['population'][index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarms(lb, ub)\n        while self.current_eval < self.budget:\n            for swarm in self.swarms:\n                for i in range(self.pop_size):\n                    candidate = self.self_adaptive_differential_evolution(i, lb, ub, swarm)\n                    candidate_value = func(candidate)\n                    self.current_eval += 1\n\n                    if candidate_value < swarm['personal_best_values'][i]:\n                        swarm['personal_best_values'][i] = candidate_value\n                        swarm['personal_best'][i] = candidate.copy()\n\n                    if candidate_value < swarm['global_best_value']:\n                        swarm['global_best_value'] = candidate_value\n                        swarm['global_best'] = candidate.copy()\n\n                self.update_particles(lb, ub, swarm)\n\n                if swarm['global_best_value'] < self.global_best_value:\n                    self.global_best_value = swarm['global_best_value']\n                    self.global_best = swarm['global_best'].copy()\n\n        return self.global_best", "configspace": "", "generation": 66, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {}}
{"id": "08a4d72d-1b64-4a19-9c49-6489a570c4bd", "fitness": 0.031093488359623184, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with dynamic crossover rate in DE for improved adaptability.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03109 with standard deviation 0.02120.", "error": "", "parent_ids": ["4d1686b2-375c-4b95-b98c-b3170007b431"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.056925983576270656, 0.0313544815025989]}}
{"id": "c9b8a0a9-0983-4147-99e6-4b03df319001", "fitness": 0.03194121560066846, "name": "EnhancedHybridPSO_DE", "description": "EnhancedEnhancedHybridPSO_DE with additional adaptive parameter tuning for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03194 with standard deviation 0.02016.", "error": "", "parent_ids": ["08a4d72d-1b64-4a19-9c49-6489a570c4bd"], "operator": null, "metadata": {"aucs": [0.007543181723135839, 0.056925983576270656, 0.0313544815025989]}}
{"id": "820c8ca5-c031-4024-9543-4e7abb1d9b8a", "fitness": -Infinity, "name": "AdaptiveChaosEnhancedHybrid", "description": "Adaptive Chaos-Enhanced Hybrid Algorithm combines chaotic maps with adaptive strategies for enhanced exploration and convergence in optimization.", "code": "import numpy as np\n\nclass AdaptiveChaosEnhancedHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.chaos_map_index = 0\n        self.chaos_sequence = self.generate_chaos_sequence()\n\n    def generate_chaos_sequence(self):\n        x = 0.7  # Initial value for logistic map\n        sequence = []\n        for _ in range(self.budget):\n            x = 4 * x * (1 - x)\n            sequence.append(x)\n        return sequence\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * self.chaos_sequence[self.chaos_map_index]\n        self.chaos_map_index += 1\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 69, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {}}
{"id": "f51d97e1-f2cc-459b-b7ce-aceeef88da0d", "fitness": 0.012205035668689912, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with cosine-based adaptive differential weight F for diverse exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        # Change in this line (1 line changed)\n        F = self.F_min + (self.F_max - self.F_min) * (np.cos(np.pi * self.current_eval / self.budget)) \n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01221 with standard deviation 0.00485.", "error": "", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {"aucs": [0.0073554202868993945, 0.010426900048628673, 0.018832786670541668]}}
{"id": "34c1fcb1-f1a5-4032-bbdd-900541f03a33", "fitness": 0.005077597596288304, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive learning factors and elite preservation for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.elite_preservation_ratio = 0.1\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_learning_factors(self):\n        progress = self.current_eval / self.budget\n        self.c1 = 2.5 - 1.5 * progress  # Decrease c1 over time\n        self.c2 = 0.5 + 1.5 * progress  # Increase c2 over time\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        self.adaptive_learning_factors()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget) \n        self.CR = np.clip(self.CR, 0.5, 1.0)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def elite_preservation(self):\n        elite_size = int(self.pop_size * self.elite_preservation_ratio)\n        elite_indices = np.argsort(self.personal_best_values)[:elite_size]\n        return elite_indices\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            elite_indices = self.elite_preservation()\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            for i in elite_indices:\n                self.personal_best[i] = self.population[i].copy()\n\n        return self.global_best", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00508 with standard deviation 0.00011.", "error": "", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.005232792788864904]}}
{"id": "06bd1691-0b1a-48b6-a9a0-0a204bc708ee", "fitness": 0.005036440968403795, "name": "EnhancedHybridPSO_DE", "description": "Modified EnhancedHybridPSO_DE with dynamic control of F parameter and improved initialization for enhanced flexibility and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.abs(np.sin(np.pi * self.current_eval / self.budget))  # Changed F calculation\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00504 with standard deviation 0.00005.", "error": "", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {"aucs": [0.0051093229052113776, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "67feddfe-1bc0-4eae-aafc-fbedf734d890", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive population size and diversity preservation for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.pop_size = self.initial_pop_size\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def reduce_population(self):\n        # Reduce population size dynamically\n        if self.current_eval > self.budget * 0.5 and self.pop_size > 10:\n            self.pop_size = max(10, int(self.pop_size * 0.8))\n            self.population = self.population[:self.pop_size]\n            self.velocities = self.velocities[:self.pop_size]\n            self.personal_best = self.personal_best[:self.pop_size]\n            self.personal_best_values = self.personal_best_values[:self.pop_size]\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def promote_diversity(self, lb, ub):\n        # Introduce new random solutions to maintain diversity\n        num_new_solutions = max(1, self.pop_size // 10)\n        new_solutions = np.random.uniform(lb, ub, (num_new_solutions, self.dim))\n        for new_solution in new_solutions:\n            value = func(new_solution)\n            self.current_eval += 1\n            if value < self.global_best_value:\n                self.global_best_value = value\n                self.global_best = new_solution.copy()\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            self.reduce_population()\n            self.promote_diversity(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 73, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {}}
{"id": "fdc598b9-2a41-45be-bb22-707f92e201ff", "fitness": 0.006138436520785162, "name": "EnhancedHybridPSO_DE", "description": "Hybridize the EnhancedHybridPSO_DE with a Lvy flight-based exploration mechanism to improve search efficiency and escape from local optima.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n            if np.random.rand() < 0.1:  # Introduce Lvy flight exploration with 10% probability\n                self.population[i] += self.levy_flight(self.dim)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00614 with standard deviation 0.00161.", "error": "", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.008415309562355477]}}
{"id": "abc2758b-39fb-44b3-bdf8-d410b69fd008", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "EnhancedAdaptiveHybridPSO_DE with improved exploitation via dynamic population sizing and elitism.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def elitism_selection(self):\n        sorted_indices = np.argsort(self.personal_best_values)\n        self.population = self.population[sorted_indices][:self.pop_size//2]\n        self.velocities = self.velocities[sorted_indices][:self.pop_size//2]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        evals_per_gen = self.pop_size if self.current_eval < self.budget // 2 else self.pop_size // 2\n        while self.current_eval < self.budget:\n            for i in range(evals_per_gen):\n                candidate = self.self_adaptive_differential_evolution(i % len(self.population), lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i % len(self.population)]:\n                    self.personal_best_values[i % len(self.population)] = candidate_value\n                    self.personal_best[i % len(self.population)] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            if self.current_eval > self.budget // 2:\n                self.elitism_selection()\n\n        return self.global_best", "configspace": "", "generation": 75, "feedback": "An exception occurred: IndexError('index 29 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 29 is out of bounds for axis 0 with size 15')", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {}}
{"id": "5ee0e16d-a367-4b6a-9df7-41cbb5392418", "fitness": 0.007834937150246338, "name": "EnhancedHybridPSO_DE_V2", "description": "Introduce a diversity-preserving mechanism and adaptive parameter control to enhance the convergence behavior and robustness of EnhancedHybridPSO_DE.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n            # Introducing diversity-preserving mechanism\n            if np.random.rand() < 0.1:  # 10% chance to reinitialize position\n                self.population[i] = np.random.uniform(lb, ub, self.dim)\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        idxs = [idx for idx in range(self.pop_size) if idx != index]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedHybridPSO_DE_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00783 with standard deviation 0.00401.", "error": "", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {"aucs": [0.013504811450739007, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "338f1959-091c-46dc-bc6a-afab12eb9882", "fitness": 0.0335890117156887, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Self-Adaptive Learning Rate and Dynamic Neighborhood-Based Mutation for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03359 with standard deviation 0.03417.", "error": "", "parent_ids": ["c9b8a0a9-0983-4147-99e6-4b03df319001"], "operator": null, "metadata": {"aucs": [0.08162961263479107, 0.01413742251227501, 0.0050000000000000044]}}
{"id": "8a287b66-c301-4a48-9d48-54eee1195590", "fitness": -Infinity, "name": "EnhancedHybridPSODEWithMemory", "description": "Introducing an Adaptive Learning Strategy with Memory-Based Progression Control for Enhanced Particle Swarm and Differential Evolution Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEWithMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.memory = []\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def memory_based_mutation(self, index, lb, ub):\n        if len(self.memory) < 3:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n            while index in neighbors:\n                neighbors = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = self.population[neighbors]\n        else:\n            a, b, c = np.random.choice(self.memory, 3, replace=False)\n        \n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.memory_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)\n        self.CR = np.clip(self.CR, 0.5, 1.0)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n                    self.memory.append(candidate.copy())\n                    if len(self.memory) > self.pop_size:\n                        self.memory.pop(0)\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 78, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {}}
{"id": "a9430af1-411b-4766-9822-d4420c8d30c4", "fitness": 0.01660744298393387, "name": "EnhancedHybridPSODE", "description": "Improved exploration through chaotic maps in velocity initialization for enhanced global search.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.sin(np.linspace(0, np.pi, self.pop_size * self.dim)).reshape(self.pop_size, self.dim)  # Changed line\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01661 with standard deviation 0.01336.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.00513406038486508, 0.03534472941187683, 0.009343539155059699]}}
{"id": "fee7ee17-a6d0-47a6-8c24-fce3ed81feee", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Mutation Strategies and Dynamic Dimensional Variation for Optimized Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def adaptive_mutation_strategy(self, index, lb, ub):\n        if np.random.rand() < 0.5:\n            return self.neighborhood_based_mutation(index, lb, ub)\n        else:\n            dimension_variation = np.random.randint(1, self.dim//2)\n            selected_dims = np.random.choice(self.dim, dimension_variation, replace=False)\n            mutant = self.population[index].copy()\n            for dim in selected_dims:\n                neighbors = np.random.choice(self.pop_size, 3, replace=False)\n                while index in neighbors:\n                    neighbors = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.population[neighbors]\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                mutant[dim] = np.clip(a[dim] + F * (b[dim] - c[dim]), lb[dim], ub[dim])\n            return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.adaptive_mutation_strategy(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 80, "feedback": "An exception occurred: ValueError('low >= high').", "error": "ValueError('low >= high')", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {}}
{"id": "ce3f88ff-4c96-4be9-aa86-e8cfe472f340", "fitness": 0.0335890117156887, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Population Size for Improved Diversity and Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n    \n    def adaptive_population_size(self):\n        return max(5, int(30 * (1 - self.current_eval / self.budget)))\n\n    def initialize_population(self, lb, ub):\n        self.pop_size = self.adaptive_population_size()  # Changed line\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03359 with standard deviation 0.03417.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.08162961263479107, 0.01413742251227501, 0.0050000000000000044]}}
{"id": "bf307afc-5e42-4d7f-81b8-5a6d52628b0a", "fitness": 0.006399534116322177, "name": "EnhancedHybridPSODE", "description": "Hybrid PSO-DE with Adaptive Mutation and Learning Strategy Integration for Enhanced Convergence and Stability.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.adaptive_strategy_threshold = 0.2\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            cognitive_component = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n            social_component = self.c2 * r2 * (self.global_best - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)\n        self.CR = np.clip(self.CR, 0.5, 1.0)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def adaptive_strategy(self, candidate, candidate_value, i):\n        # Introduce an adaptive strategy to adjust behavior based on progress\n        if candidate_value < self.personal_best_values[i]:\n            self.personal_best_values[i] = candidate_value\n            self.personal_best[i] = candidate.copy()\n        if candidate_value < self.global_best_value:\n            self.global_best_value = candidate_value\n            self.global_best = candidate.copy()\n        relative_improvement = (self.global_best_value - candidate_value) / abs(self.global_best_value)\n        if relative_improvement < self.adaptive_strategy_threshold and np.random.rand() < 0.5:\n            self.velocities[i] *= 0.5  # Reduce velocity for more exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n                self.adaptive_strategy(candidate, candidate_value, i)\n            self.update_particles(lb, ub)\n        return self.global_best", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00640 with standard deviation 0.00137.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.005930625874894235, 0.0050000000000000044, 0.008267976474072292]}}
{"id": "f6dd3f0f-6623-41aa-acf6-e3ca71f0ee58", "fitness": 0.03028343572945354, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Velocity Clamping and Time-Varying Perturbation to Balance Exploration and Exploitation for Efficient Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.velocity_clamp = 0.2\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def time_varying_perturbation(self):\n        return 0.1 + 0.9 * (1 - self.current_eval / self.budget)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def adaptive_velocity_clamping(self, velocities):\n        max_velocity = self.velocity_clamp * (self.global_best - self.population).max(axis=0)\n        return np.clip(velocities, -max_velocity, max_velocity)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.velocities[i] = self.adaptive_velocity_clamping(self.velocities[i])\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        pert = self.time_varying_perturbation()\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget) * pert\n        self.CR = np.clip(self.CR, 0.5, 1.0)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03028 with standard deviation 0.01341.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0470406088178017, 0.029582954377530113, 0.014226743993028812]}}
{"id": "c0453fff-ec87-48b2-90d1-b2dca28293ab", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Landscape Estimation for Intelligent Swarm Adjustment and Convergence Improvement.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def landscape_roughness(self, lb, ub):\n        # Estimate roughness by evaluating random points and measuring variance\n        samples = np.random.uniform(lb, ub, (10, self.dim))\n        values = np.array([func(sample) for sample in samples])\n        variance = np.var(values)\n        return variance\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight() * np.exp(-self.landscape_roughness(lb, ub))\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)\n        self.CR = np.clip(self.CR, 0.5, 1.0)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 84, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {}}
{"id": "2f2b035a-d477-4ea6-b000-7e4800d5abd7", "fitness": 0.00877258204524741, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with a Fine-Tuned Mutation Factor for Better Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()*1.1  # Fine-tuned mutation factor\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00877 with standard deviation 0.00344.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.008006755866334703, 0.013310990269407519, 0.0050000000000000044]}}
{"id": "2bb24980-ef54-4fc2-b8fa-75de68a93083", "fitness": 0.030559092624548367, "name": "EnhancedHybridPSODE_v2", "description": "EnhancedHybridPSODE with Adaptive Population Resizing and Advanced Mutation Strategies for Accelerated Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.pop_size = self.initial_pop_size\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.resize_interval = budget // 5\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def adaptive_population_resize(self, lb, ub):\n        if self.current_eval % self.resize_interval == 0 and self.pop_size > 5:\n            self.pop_size -= 5\n            self.population = self.population[:self.pop_size]\n            self.velocities = self.velocities[:self.pop_size]\n            self.personal_best = self.personal_best[:self.pop_size]\n            self.personal_best_values = self.personal_best_values[:self.pop_size]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n            self.adaptive_population_resize(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedHybridPSODE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03056 with standard deviation 0.03611.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.08162961263479107, 0.0050000000000000044, 0.005047665238854027]}}
{"id": "e2b9f2a8-c02f-48c9-88b5-8c0c9d4ae4d8", "fitness": 0.0335890117156887, "name": "EnhancedHybridPSODE", "description": "Introduced a time-varying acceleration coefficient to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_cognitive_coefficient(self):\n        # Time-varying cognitive coefficient for better exploration-exploitation balance\n        return self.c1 + (self.c2 - self.c1) * (self.current_eval / self.budget)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        c1_adaptive = self.adaptive_cognitive_coefficient()  # Using time-varying cognitive coefficient\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  c1_adaptive * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))  # Use adaptive c1\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03359 with standard deviation 0.03417.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.08162961263479107, 0.01413742251227501, 0.0050000000000000044]}}
{"id": "35240c14-dbbc-4f89-9e5f-f17ce4f79d8d", "fitness": 0.010795075300692347, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Population Size and Improved Mutation Control for Robust Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.initial_pop_size = 30  # Variable for adaptive population\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_population_size(self):\n        # Reduce population as evaluations increase\n        self.pop_size = max(int(self.initial_pop_size * (1 - self.current_eval / self.budget)), 10)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)\n        self.CR = np.clip(self.CR, 0.5, 1.0)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            self.adaptive_population_size()\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01080 with standard deviation 0.00820.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.022385225902077033]}}
{"id": "07d83ac5-10a3-4515-8d4e-9563ad144e56", "fitness": 0.0050000000000000044, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Population Size for Better Resource Utilization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_population_size(self):\n        return max(5, int(self.pop_size - (self.pop_size - 5) * (self.current_eval / self.budget)))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.adaptive_population_size()):  # <--- Changed line\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00500 with standard deviation 0.00000.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "a4f07a3a-281a-4875-87d4-dc2682b03d43", "fitness": 0.0, "name": "AdaptiveNeighborhoodEnhancedPSODE", "description": "Adaptive Neighborhood Enhanced PSO-DE with Dynamic Feedback Loop for Convergence Boost.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodEnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub, feedback_factor):\n        w = self.adaptive_inertia_weight() * feedback_factor\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def dynamic_feedback_loop(self):\n        # Feedback based on global improvement rate\n        return np.exp(-0.1 * (1 - (self.global_best_value / np.max(self.personal_best_values))))\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            feedback_factor = self.dynamic_feedback_loop()\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub, feedback_factor)\n\n        return self.global_best", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptiveNeighborhoodEnhancedPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00000 with standard deviation 0.00000.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0]}}
{"id": "40b60542-82b2-44b9-8b0d-3e0f554f4cdb", "fitness": -Infinity, "name": "EnhancedHybridPSODENew", "description": "Introducing Adaptive Neighborhood Learning Strategy and Opposite-Based Particle Initialization for Enhanced Convergence in EnhancedHybridPSODE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODENew:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.opp_prob = 0.5  # Probability for opposite-based initialization\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        opposite_population = lb + ub - self.population\n        # Opposite-based initialization\n        for i in range(self.pop_size):\n            if np.random.rand() < self.opp_prob:\n                self.population[i] = opposite_population[i]\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def adaptive_neighborhood_based_mutation(self, index, lb, ub):\n        # Adaptive neighborhood selection\n        num_neighbors = np.random.randint(2, 5)\n        neighbors = np.random.choice(self.pop_size, num_neighbors, replace=False)\n        neighbors = np.delete(neighbors, np.where(neighbors == index))\n        selected = self.population[neighbors][:3]  # Select up to 3 neighbors\n        a, b, c = selected\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.adaptive_neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 91, "feedback": "An exception occurred: ValueError('not enough values to unpack (expected 3, got 2)').", "error": "ValueError('not enough values to unpack (expected 3, got 2)')", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {}}
{"id": "cc9c3878-088c-48f4-9dcd-72fdf4054c67", "fitness": -Infinity, "name": "EnhancedHybridPSODEPlusPlus", "description": "EnhancedHybridPSODE++ with Adaptive Parameter Fine-tuning and Opposition-Based Learning for Robust Global Search.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def opposition_based_learning(self, lb, ub):\n        opposite_pop = lb + ub - self.population\n        opposite_pop = np.clip(opposite_pop, lb, ub)\n        for i in range(self.pop_size):\n            op_value = func(opposite_pop[i])\n            if op_value < self.personal_best_values[i]:\n                self.personal_best_values[i] = op_value\n                self.personal_best[i] = opposite_pop[i].copy()\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        self.opposition_based_learning(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 92, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {}}
{"id": "d608bdaf-a9b8-4ef0-8ad6-a7a07270c044", "fitness": 0.009879757650719764, "name": "AdaptiveHybridPSODE", "description": "AdaptiveHybridPSODE with Time-Variant Parameters and Neighborhood-Based Adaptive Mutation for Enhanced Convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.5\n        self.CR_max = 1.0\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_adaptive_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * (self.current_eval / self.budget)\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_adaptive_mutation(index, lb, ub)\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * (self.current_eval / self.budget)\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00988 with standard deviation 0.00690.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.01963927295215928]}}
{"id": "24b0b5ae-ed51-4cd8-a8d9-75229e7898a2", "fitness": 0.0074689860101041505, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Dynamic Population Size Adjustment and Momentum Term for Further Convergence Improvement.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.final_pop_size = 10\n        self.pop_size = self.initial_pop_size\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.momentum = 0.1\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def dynamic_pop_size(self):\n        return int(self.initial_pop_size - ((self.initial_pop_size - self.final_pop_size) * (self.current_eval / self.budget)))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]) +\n                                  self.momentum * (self.global_best - self.personal_best[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            self.pop_size = self.dynamic_pop_size()\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00747 with standard deviation 0.00305.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.011773468870287629, 0.005633489160024818, 0.0050000000000000044]}}
{"id": "4169629b-2477-41a2-8fa9-a58bcde66298", "fitness": 0.005360949316266961, "name": "EnhancedHybridPSODE", "description": "Improved mutation process with adaptive scaling factors for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.3  # Changed line: Adjusted for more adaptive scaling\n        self.F_max = 0.8  # Changed line: Adjusted upper limit for F\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00536 with standard deviation 0.00051.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0060828479488008735, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "83b05004-cef5-48cc-ac88-2f87fd5e0cf6", "fitness": 0.010278904644941226, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Mutation Scaling and Improved Initialization to Boost Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.3  # Adjusted mutation scaling\n        self.F_max = 0.8  # Adjusted mutation scaling\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb * 0.9, ub * 1.1, (self.pop_size, self.dim))  # Improved initialization\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        F *= 1 + 0.1 * np.tanh(self.current_eval / self.budget)  # Adaptive mutation scaling\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01028 with standard deviation 0.00380.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.01377774559545586, 0.0050000000000000044, 0.012058968339367815]}}
{"id": "e5c572d7-64a3-486b-9caa-922dae1d7a35", "fitness": 0.0050000000000000044, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Learning Rate, Neighborhood Mutation, and Opposite-Based Learning for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def opposite_based_learning(self, lb, ub):\n        opposite_pop = lb + ub - self.population\n        return np.clip(opposite_pop, lb, ub)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        opposite_population = self.opposite_based_learning(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                opposite_candidate = opposite_population[i]\n                candidate_value = func(candidate)\n                opposite_candidate_value = func(opposite_candidate)\n                self.current_eval += 2  # Two evaluations: candidate and opposite candidate\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if opposite_candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = opposite_candidate_value\n                    self.personal_best[i] = opposite_candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n                if opposite_candidate_value < self.global_best_value:\n                    self.global_best_value = opposite_candidate_value\n                    self.global_best = opposite_candidate.copy()\n\n            self.update_particles(lb, ub)\n            opposite_population = self.opposite_based_learning(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00500 with standard deviation 0.00000.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.0050000000000000044]}}
{"id": "778775c2-e652-4154-94eb-e2a0acf34648", "fitness": 0.005129899709632846, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Particle Size and Dynamic Attraction-Repulsion Mechanism for Better Exploration and Exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(self.pop_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            # Dynamic Attraction-Repulsion Mechanism\n            attraction_repulsion_factor = np.sin(np.pi * self.current_eval / self.budget)\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * attraction_repulsion_factor * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(self.pop_size, 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            for i in range(self.pop_size):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n            self.update_particles(lb, ub)\n\n        return self.global_best", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00513 with standard deviation 0.00016.", "error": "", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {"aucs": [0.005360699028713722, 0.0050000000000000044, 0.005029000100184811]}}
{"id": "7f2cfb50-9515-402f-a66c-b118229d4ddc", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with Adaptive Population Size and Memory-Based Information Sharing for Improved Exploration-Exploitation Balance.  ", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.final_pop_size = 5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.population = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_values = None\n        self.global_best = None\n        self.global_best_value = np.inf\n        self.current_eval = 0\n        self.memory = []\n\n    def adaptive_inertia_weight(self):\n        return self.w_max - ((self.w_max - self.w_min) * (self.current_eval / self.budget))\n\n    def adaptive_population_size(self):\n        return int(self.final_pop_size + (self.initial_pop_size - self.final_pop_size) * (1 - self.current_eval / self.budget))\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.initial_pop_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.initial_pop_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_values = np.array([np.inf] * self.initial_pop_size)\n\n    def update_particles(self, lb, ub):\n        w = self.adaptive_inertia_weight()\n        for i in range(len(self.population)):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best[i] - self.population[i]) +\n                                  self.c2 * r2 * (self.global_best - self.population[i]))\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def neighborhood_based_mutation(self, index, lb, ub):\n        neighbors = np.random.choice(len(self.population), 3, replace=False)\n        while index in neighbors:\n            neighbors = np.random.choice(len(self.population), 3, replace=False)\n        a, b, c = self.population[neighbors]\n        F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + F * (b - c)\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def self_adaptive_differential_evolution(self, index, lb, ub):\n        mutant = self.neighborhood_based_mutation(index, lb, ub)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * self.current_eval / self.budget)  # Dynamic CR\n        self.CR = np.clip(self.CR, 0.5, 1.0)  # Enforcing CR bounds\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[index])\n        return trial\n\n    def update_memory(self, candidate, candidate_value):\n        self.memory.append((candidate.copy(), candidate_value))\n        self.memory.sort(key=lambda x: x[1])\n        if len(self.memory) > self.initial_pop_size:\n            self.memory.pop(-1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        while self.current_eval < self.budget:\n            pop_size = self.adaptive_population_size()\n            for i in range(len(self.population)):\n                candidate = self.self_adaptive_differential_evolution(i, lb, ub)\n                candidate_value = func(candidate)\n                self.current_eval += 1\n\n                if candidate_value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = candidate_value\n                    self.personal_best[i] = candidate.copy()\n\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best = candidate.copy()\n\n                self.update_memory(candidate, candidate_value)\n\n            self.update_particles(lb, ub)\n\n            if self.current_eval < self.budget:\n                mem_size = min(pop_size, len(self.memory))\n                selected_mem = np.random.choice(self.memory, mem_size, replace=False)\n                self.population[:mem_size] = np.array([mem[0] for mem in selected_mem])\n\n        return self.global_best", "configspace": "", "generation": 99, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (30, 2) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (30, 2) + inhomogeneous part.')", "parent_ids": ["338f1959-091c-46dc-bc6a-afab12eb9882"], "operator": null, "metadata": {}}
