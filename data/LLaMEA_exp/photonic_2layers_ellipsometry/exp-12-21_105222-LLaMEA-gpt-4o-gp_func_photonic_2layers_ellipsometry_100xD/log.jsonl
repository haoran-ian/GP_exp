{"id": "f6f5e533-8f46-41a5-8d96-945160ee0865", "fitness": 0.05301709097147979, "name": "NAPSO", "description": "A Novel Adaptive Particle Swarm Optimization (NAPSO) that dynamically adjusts particle velocities and positions based on historical performance to balance exploration and exploitation in a constrained search space.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5  # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub):\n        r1, r2 = np.random.rand(), np.random.rand()\n        for i in range(self.num_particles):\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm NAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.009264657770139295, 0.00927603444725933, 0.009263946184341565, 0.0786363483510858, 0.07874832976635626, 0.07862614594971096, 0.07108595250381877, 0.07117351223993551, 0.0710788915306706]}}
{"id": "fc22de78-5dce-4dac-b59a-e4732177c159", "fitness": -Infinity, "name": "NAPSO", "description": "Enhanced NAPSO by varying inertia dynamically with each iteration to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5  # Inertia weight (initial value)\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub):\n        r1, r2 = np.random.rand(), np.random.rand()\n        self.w = 0.9 - (0.4 * (evaluations / self.budget))  # Dynamic inertia adjustment\n        for i in range(self.num_particles):\n            self.velocities[i] = (self.w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["f6f5e533-8f46-41a5-8d96-945160ee0865"], "operator": null, "metadata": {}}
{"id": "3b1f4fd9-a6a0-43b5-a5b2-4f1e712c4f40", "fitness": 0.053022062730332845, "name": "NAPSO", "description": "Enhanced NAPSO with dynamic inertia weight for adaptive exploration-exploitation balance.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        r1, r2 = np.random.rand(), np.random.rand()\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia\n        for i in range(self.num_particles):\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm NAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["f6f5e533-8f46-41a5-8d96-945160ee0865"], "operator": null, "metadata": {"aucs": [0.00926591585585601, 0.009276107154552293, 0.009264991615683171, 0.07864918801141019, 0.0787490719101912, 0.07863654651888052, 0.07109590059733206, 0.0711740863742224, 0.07108675653486773]}}
{"id": "d0f37ebf-de28-43af-8952-6ed0edda3c6a", "fitness": 0.053022316797734996, "name": "NAPSO", "description": "Introduced adaptive learning rates for cognitive and social components to enhance convergence speed.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        r1, r2 = np.random.rand(), np.random.rand()\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive cognitive component\n        for i in range(self.num_particles):\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm NAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["3b1f4fd9-a6a0-43b5-a5b2-4f1e712c4f40"], "operator": null, "metadata": {"aucs": [0.00926591585585601, 0.009276107154552293, 0.009265111292191985, 0.07864918801141019, 0.0787490719101912, 0.078637765653788, 0.07109590059733206, 0.0711740863742224, 0.07108770433007083]}}
{"id": "99aa9c6b-d36a-4c4e-a4b2-cb2cf5d963c1", "fitness": 0.05302001837991188, "name": "NAPSO", "description": "Introduced adaptive neighborhood topology to enhance exploration and exploitation balance using a dynamic ring topology.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighborhood_size = max(1, self.num_particles // 10)  # Dynamic neighborhood size\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        r1, r2 = np.random.rand(), np.random.rand()\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive cognitive component\n\n        for i in range(self.num_particles):\n            # Determine neighborhood best\n            neighbors = self.get_neighbors(i)\n            neighborhood_best_position = self.personal_best_positions[neighbors[np.argmin(self.personal_best_scores[neighbors])]]\n            \n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (neighborhood_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def get_neighbors(self, index):\n        # Using ring topology for neighbors\n        start = (index - self.neighborhood_size // 2) % self.num_particles\n        return [(start + i) % self.num_particles for i in range(self.neighborhood_size)]\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm NAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["d0f37ebf-de28-43af-8952-6ed0edda3c6a"], "operator": null, "metadata": {"aucs": [0.009259790373390087, 0.009273738826616973, 0.009272427093184654, 0.0785867913607673, 0.07872488715273296, 0.07871337304989279, 0.07104751383889951, 0.07115533856917555, 0.07114630515454712]}}
{"id": "961ead95-764b-4159-b66e-455ad35d8b1a", "fitness": 0.05302201697276668, "name": "NAPSO", "description": "Introduced a velocity decay factor to further refine particle movement and potentially improve convergence.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.velocity_decay = 0.99  # Add velocity decay factor\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        r1, r2 = np.random.rand(), np.random.rand()\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive cognitive component\n        for i in range(self.num_particles):\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n            self.velocities[i] *= self.velocity_decay  # Apply velocity decay here\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm NAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["d0f37ebf-de28-43af-8952-6ed0edda3c6a"], "operator": null, "metadata": {"aucs": [0.0092658836890962, 0.009276097927657267, 0.009265010939633833, 0.07864886005706306, 0.07874897772107459, 0.07863675024718786, 0.07109564741248786, 0.07117401326186401, 0.07108691149883539]}}
{"id": "1e2d88c7-c20d-4808-8d81-0d13df332838", "fitness": 0.05300932327659966, "name": "NAPSO", "description": "Introduced dynamic adjustment of the social coefficient for improved convergence using a linear decay strategy.", "code": "import numpy as np\n\nclass NAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        r1, r2 = np.random.rand(), np.random.rand()\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive cognitive component\n        adapt_c2 = self.c2 * (evaluations / self.budget)  # Newly added: Adaptive social component\n        for i in range(self.num_particles):\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.global_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm NAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05301 with standard deviation 0.03108.", "error": "", "parent_ids": ["d0f37ebf-de28-43af-8952-6ed0edda3c6a"], "operator": null, "metadata": {"aucs": [0.009260354911474034, 0.009274176302490056, 0.009266483856189889, 0.07859253470954197, 0.07872937010242298, 0.07865168271232037, 0.07105196415575665, 0.07115881210299846, 0.07109853063620253]}}
{"id": "3b4adabe-a19e-4ff6-ac21-b86cde2a7ea1", "fitness": 0.053022316797734996, "name": "NAPSO_Diversity", "description": "Introduce a novel particle diversity mechanism by periodically injecting new random particles to escape local optima and enhance global exploration.", "code": "import numpy as np\n\nclass NAPSO_Diversity:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))  # Dynamic choice of particles\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.diversity_interval = max(1, budget // 10)  # Interval for introducing diversity\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        r1, r2 = np.random.rand(), np.random.rand()\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))  # Dynamic inertia\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive cognitive component\n        for i in range(self.num_particles):\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def inject_diversity(self, lb, ub):\n        for i in range(self.num_particles):\n            if np.random.rand() < 0.1:  # 10% probability to replace a particle\n                self.particles[i] = np.random.uniform(lb, ub, self.dim)\n                self.velocities[i] = np.random.uniform(-1, 1, self.dim)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n            if evaluations % self.diversity_interval == 0:\n                self.inject_diversity(lower_bound, upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm NAPSO_Diversity got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["d0f37ebf-de28-43af-8952-6ed0edda3c6a"], "operator": null, "metadata": {"aucs": [0.00926591585585601, 0.009276107154552293, 0.009265111292191985, 0.07864918801141019, 0.0787490719101912, 0.078637765653788, 0.07109590059733206, 0.0711740863742224, 0.07108770433007083]}}
{"id": "09850d93-b74f-412e-b968-908e070afac1", "fitness": 0.05332730356045666, "name": "EnhancedNAPSO", "description": "Introduced stochastic adaptive velocity control and dynamic neighborhood-based learning to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5  # Number of neighbors for neighborhood-based learning\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            # Select a random subset of neighbors\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Adding stochastic variability to velocity\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05333 with standard deviation 0.03128.", "error": "", "parent_ids": ["d0f37ebf-de28-43af-8952-6ed0edda3c6a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009403592410124562, 0.07866246713032199, 0.07875722085550796, 0.08008439515056631, 0.07110619876947122, 0.07118040082324117, 0.07220733277864044]}}
{"id": "255ae2b3-35c4-48b9-b43c-c00c992b92c5", "fitness": 0.05303764302254626, "name": "RefinedEnhancedNAPSO", "description": "Introduced a dynamic inertia weight strategy and a multi-stage adaptive learning factor to further balance exploration and exploitation in EnhancedNAPSO.", "code": "import numpy as np\n\nclass RefinedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_initial = 2.5\n        self.c2_initial = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        # Dynamic inertia weight\n        w = (self.w_max - self.w_min) * np.cos((np.pi / 2) * (evaluations / self.budget)) + self.w_min\n\n        # Multi-stage adaptive learning factors\n        adapt_c1 = self.c1_initial * (0.5 + 0.5 * np.sin((np.pi / 2) * (evaluations / self.budget)))\n        adapt_c2 = self.c2_initial * (1 - 0.5 * np.sin((np.pi / 2) * (evaluations / self.budget)))\n\n        for i in range(self.num_particles):\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.05, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm RefinedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276811061706525, 0.009270350272921224, 0.07866246713032199, 0.07875625339643111, 0.0786908924207188, 0.07110619876947122, 0.07117964993387316, 0.07112894588672036]}}
{"id": "a450e894-d6d4-4185-aeb4-7cbe72d28b56", "fitness": 0.053039828511002834, "name": "EnhancedNAPSOv2", "description": "Introduced adaptive local exploration and a dynamic particle collaboration mechanism to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 1.5  # Reduced cognitive coefficient for more global exploration\n        self.c2 = 2.5  # Increased social coefficient for enhanced collaboration\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * np.log1p(evaluations / self.budget)\n        for i in range(self.num_particles):\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n\n            # Adaptive velocity based on global best, local best, and current position\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]) +\n                                  self.c2 * r3 * (self.global_best_position - self.particles[i]))\n\n            # Stochastic variability enhancement\n            self.velocities[i] += np.random.normal(0, 0.05, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedNAPSOv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267301579585219, 0.009276905795484347, 0.009271200814808034, 0.07866331327151566, 0.07875722085550796, 0.07869958120887466, 0.07110685481994594, 0.07118040082324117, 0.07113567743006255]}}
{"id": "574c697d-2315-414f-abcb-943bbca75858", "fitness": 0.05303822028247564, "name": "EnhancedNAPSOLevy", "description": "Introduced Lévy flight-based random walks to enhance exploration in high-dimensional spaces and utilized adaptive inertia weight clamping for better convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5  # Number of neighbors for neighborhood-based learning\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            # Select a random subset of neighbors\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n            \n            # Adding stochastic variability to velocity\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n            \n            # Incorporating Lévy flight\n            if np.random.rand() < 0.1:\n                self.velocities[i] += self.levy_flight(self.dim)\n            \n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedNAPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.00926710929852903, 0.009276905795484347, 0.009270635766209234, 0.0786613568949377, 0.07875722085550796, 0.07869381376867124, 0.07110533838170596, 0.07118040082324117, 0.07113120095799408]}}
{"id": "f37eba58-f846-4c74-b506-0f30152e420c", "fitness": 0.053050644336239246, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive neighborhood size and chaos-based initialization for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5  # Initial number of neighbors for neighborhood-based learning\n\n    def initialize(self, lb, ub):\n        # Chaos-based initialization\n        self.particles = lb + (ub - lb) * np.mod(np.arange(1, self.num_particles + 1) * 3.56995, 1).reshape(-1, 1)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        dynamic_neighbors = max(1, int(self.neighbors - (self.neighbors - 1) * (evaluations / self.budget)))\n        for i in range(self.num_particles):\n            # Adaptive neighborhood size\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Adding stochastic variability to velocity\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05305 with standard deviation 0.03111.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009273259836770964, 0.009273682868580435, 0.00927383646983726, 0.07872046963457535, 0.07872478302958863, 0.07872633422347808, 0.07115184731341473, 0.07115518964421852, 0.07115639600568924]}}
{"id": "8caf7743-8502-4e6a-808b-ff27c7ad24bd", "fitness": 0.05332730356045666, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive neighborhood size and inertia weight decay for improved dynamic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.initial_neighbors = 5  # Initial number of neighbors for neighborhood-based learning\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        adaptive_neighbors = self.initial_neighbors + int((self.num_particles - self.initial_neighbors) * (evaluations / self.budget))\n        \n        for i in range(self.num_particles):\n            # Select a random subset of neighbors with an adaptive size\n            neighbor_indices = np.random.choice(self.num_particles, adaptive_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Adding stochastic variability to velocity\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05333 with standard deviation 0.03128.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009403592410124562, 0.07866246713032199, 0.07875722085550796, 0.08008439515056631, 0.07110619876947122, 0.07118040082324117, 0.07220733277864044]}}
{"id": "9d0befd6-06cc-4ccc-b069-291ba60dd2c0", "fitness": 0.05302942289940124, "name": "AdvancedMultiSwarmPSO", "description": "Introduced multi-swarm interaction and adaptive inertia weight strategy to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass AdvancedMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.swarm_size = 5  # Number of particles in a sub-swarm\n        self.num_swarms = self.num_particles // self.swarm_size\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for swarm_index in range(self.num_swarms):\n            start_index = swarm_index * self.swarm_size\n            end_index = start_index + self.swarm_size\n            swarm_particles = range(start_index, end_index)\n            local_best_index = min(swarm_particles, key=lambda i: self.personal_best_scores[i])\n            for i in swarm_particles:\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.velocities[i] = (w * self.velocities[i] +\n                                      adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n                # Adding stochastic variability to velocity\n                self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm AdvancedMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009265709318685644, 0.009275938549501594, 0.00926884190531918, 0.07864709325865771, 0.07874735087266682, 0.0786757045310843, 0.07109427438705396, 0.07117275238609433, 0.07111714088554766]}}
{"id": "2b5f18a1-4943-4e5f-89fe-1f6267f92673", "fitness": 0.05303701707238603, "name": "AdaptiveNAPSO", "description": "Introduced adaptive inertia and dynamic social neighborhood selection for enhanced convergence in particle swarm optimization.", "code": "import numpy as np\n\nclass AdaptiveNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2_start = 2.5\n        self.c2_end = 0.5\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_start - ((self.w_start - self.w_end) * (evaluations / self.budget))\n        c2 = self.c2_start - ((self.c2_start - self.c2_end) * (evaluations / self.budget))\n\n        for i in range(self.num_particles):\n            neighbor_indices = np.random.choice(self.num_particles, size=max(2, int(self.num_particles / 10)), replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267092209842231, 0.009276905795484347, 0.009270086024017687, 0.07866118355552543, 0.07875722085550796, 0.07868820735172266, 0.07110520361774375, 0.07118040082324117, 0.07112685341838909]}}
{"id": "59e42fca-60f5-41a6-ad50-4269132442aa", "fitness": 0.05303281524266869, "name": "EnhancedNAPSO", "description": "Enhanced particle diversity by including a chaotic factor into the velocity update process.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5  # Number of neighbors for neighborhood-based learning\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        chaos_factor = 0.8 * (np.sin(evaluations) - 0.5)  # Chaotic factor\n        for i in range(self.num_particles):\n            # Select a random subset of neighbors\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Adding stochastic variability to velocity\n            self.velocities[i] += chaos_factor + np.random.normal(0, 0.1, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009267969639819684, 0.07866246713032199, 0.07875722085550796, 0.07866675374539345, 0.07110619876947122, 0.07118040082324117, 0.07111020209402641]}}
{"id": "b0ebc54f-b98a-4d10-bf91-d8658089e49d", "fitness": 0.05303709785537217, "name": "RefinedEnhancedNAPSO", "description": "EnhancedNAPSO with adaptive inertia weight and large-scale neighborhood crossover for improved convergence in diverse landscapes.", "code": "import numpy as np\n\nclass RefinedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = min(10, self.num_particles // 2)  # Increased neighbors for crossover learning\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = (self.w_max - self.w_min) * np.cos(np.pi * evaluations / (2 * self.budget)) + self.w_min\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            # Select a larger subset of neighbors for more diverse learning\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Adding stochastic variability to velocity\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n            # Cross over with neighbors to introduce diversity\n            crossover_idx = np.random.choice(neighbor_indices)\n            crossover_mask = np.random.rand(self.dim) < 0.5\n            self.particles[i][crossover_mask] = self.particles[crossover_idx][crossover_mask]\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm RefinedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267205104918741, 0.009276633909592102, 0.009270279757566335, 0.07866233206157214, 0.07875444540961907, 0.07869022223590794, 0.07110609393666378, 0.07117824644887338, 0.07112842183363599]}}
{"id": "526d769e-4ab1-4741-a515-173feffa900f", "fitness": 0.05332730356045666, "name": "EnhancedNAPSO", "description": "Introduced dynamic adjustment of the neighborhood size based on the current stage of optimization to enhance adaptive learning.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5  # Number of neighbors for neighborhood-based learning\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        self.neighbors = max(1, int(5 * (1 - evaluations / self.budget)))  # Dynamic adjustment of neighbors\n        for i in range(self.num_particles):\n            # Select a random subset of neighbors\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Adding stochastic variability to velocity\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05333 with standard deviation 0.03128.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009403592410124562, 0.07866246713032199, 0.07875722085550796, 0.08008439515056631, 0.07110619876947122, 0.07118040082324117, 0.07220733277864044]}}
{"id": "dda700f9-cffd-4a38-951b-0044c99b00cd", "fitness": 0.053086914314559364, "name": "EnhancedNAPSO", "description": "Introduced a self-adaptive mutation operator and a dynamic particle clustering mechanism to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1, self.dim)\n            # Self-adaptive mutation operator\n            mutation_prob = 0.1 * (1 - evaluations / self.budget)\n            if np.random.rand() < mutation_prob:\n                self.particles[i] += np.random.normal(0, 0.1, self.dim)  # Introduce mutation\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def cluster_particles(self, evaluations):\n        # Dynamic particle clustering based on evaluations\n        num_clusters = max(2, int(self.num_particles * (1 - evaluations / self.budget)))\n        cluster_assignments = np.random.randint(0, num_clusters, self.num_particles)\n        for k in range(num_clusters):\n            cluster_indices = np.where(cluster_assignments == k)[0]\n            if len(cluster_indices) > 0:\n                cluster_best_idx = cluster_indices[np.argmin(self.personal_best_scores[cluster_indices])]\n                for idx in cluster_indices:\n                    if idx != cluster_best_idx:\n                        self.particles[idx] = self.particles[cluster_best_idx] + np.random.normal(0, 0.1, self.dim)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n            if evaluations % 10 == 0:  # Perform clustering every 10 evaluations\n                self.cluster_particles(evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05309 with standard deviation 0.03113.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.009266713847112973, 0.009276905795484347, 0.009293689462171684, 0.07865733283113574, 0.07875722085550796, 0.07893034117253306, 0.07110221816256157, 0.07118040082324117, 0.07131740588128577]}}
{"id": "4a9dffea-54e3-4923-bb87-7cdb0470269a", "fitness": 0.23946767044675785, "name": "EnhancedNAPSO", "description": "Introduced adaptive neighbor selection and velocity scaling based on convergence progress to improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["09850d93-b74f-412e-b968-908e070afac1"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270221563194903, 0.9119286552736355, 0.07875722085550796, 0.07868958770431278, 0.9112298995541043, 0.07118040082324117, 0.07112792453639172]}}
{"id": "46554d14-4dc4-4aea-b75a-3f559699b639", "fitness": 0.23946767044675785, "name": "EnhancedNAPSO", "description": "Enhanced convergence by introducing inertia weight decay and dynamic neighbor scaling for improved adaptability.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - (0.5 * evaluations / self.budget)))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270221563194903, 0.9119286552736355, 0.07875722085550796, 0.07868958770431278, 0.9112298995541043, 0.07118040082324117, 0.07112792453639172]}}
{"id": "92c20d27-7ea0-4ce0-9aed-59bff07147d6", "fitness": 0.053038101986764695, "name": "EnhancedNAPSO", "description": "Introduced a dynamic inertia weight adjustment and a diversity-enhancing mutation mechanism to improve exploration-exploitation balance and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            mutation_strength = 0.1 * (1 - evaluations / self.budget)\n            if np.random.rand() < 0.1:  # Apply mutation with some probability\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                self.velocities[i] += mutation\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266839968022689, 0.009276905795484347, 0.009270848816502641, 0.07865861640593219, 0.07875722085550796, 0.07869598584597892, 0.07110321331428904, 0.07118040082324117, 0.07113288605592327]}}
{"id": "d8390d4c-8c95-4ac1-a5f3-60780aeea401", "fitness": 0.05303704222987225, "name": "RefinedNAPSO", "description": "Introduced adaptive inertia weight and diversified learning factors to enhance convergence dynamics and balance exploration-exploitation.", "code": "import numpy as np\n\nclass RefinedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_max, self.c1_min = 2.5, 1.5\n        self.c2_max, self.c2_min = 2.5, 1.5\n        self.w_max, self.w_min = 0.95, 0.3\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        progress_ratio = evaluations / self.budget\n        w = self.w_max - ((self.w_max - self.w_min) * progress_ratio)\n        c1 = self.c1_max - ((self.c1_max - self.c1_min) * progress_ratio)\n        c2 = self.c2_min + ((self.c2_max - self.c2_min) * progress_ratio)\n\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - progress_ratio))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - progress_ratio), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm RefinedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276886848046173, 0.009269991457647841, 0.07866246713032199, 0.07875702729249723, 0.07868723423453516, 0.07110619876947122, 0.07118025060248101, 0.07112610540309772]}}
{"id": "19467543-690c-4dcd-9aee-088a3e0e49bb", "fitness": 0.05680578561085549, "name": "RefinedNAPSO", "description": "Introduced stochastic inertia weight adaptation and dynamic local learning to enhance exploration-exploitation balance and prevent premature convergence.", "code": "import numpy as np\n\nclass RefinedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        # Stochastic inertia weight adaptation\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        w += np.random.uniform(-0.1, 0.1)\n        w = np.clip(w, self.w_min, self.w_max)\n\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            # Dynamic local learning\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05681 with standard deviation 0.03411.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267219437154806, 0.009276905795484347, 0.010635525184179762, 0.07866247834768525, 0.07875722085550796, 0.0977716031007041, 0.07110620603782436, 0.07118040082324117, 0.08459451091591763]}}
{"id": "1ec114cc-fa4a-4ce7-b036-15c3638f5df1", "fitness": 0.053038101986764695, "name": "EnhancedNAPSO", "description": "Introduced dynamic inertia weight adjustment and a diversity-enhancing mutation operator to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.mutation_probability = 0.1  # Probability of applying mutation\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Add a diversity-enhancing mutation\n            if np.random.rand() < self.mutation_probability:\n                mutation_strength = 0.1 * (1 - evaluations / self.budget)\n                self.velocities[i] += np.random.normal(0, mutation_strength, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266839968022689, 0.009276905795484347, 0.009270848816502641, 0.07865861640593219, 0.07875722085550796, 0.07869598584597892, 0.07110321331428904, 0.07118040082324117, 0.07113288605592327]}}
{"id": "98a1613f-24e8-4dc3-a1d2-948d6e0bdc7c", "fitness": 0.05301566993385852, "name": "EnhancedNAPSO", "description": "Introduced diversity accentuation through mutation and adaptive control of cognitive and social parameters to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_initial = 2.0\n        self.c2_initial = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def apply_mutation(self, particle, lb, ub, evaluations):\n        mutation_strength = 0.1 * (1 - evaluations / self.budget)\n        mutation = np.random.normal(0, mutation_strength, self.dim)\n        mutated_particle = np.clip(particle + mutation, lb, ub)\n        return mutated_particle\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1_initial * (1 - evaluations / self.budget)\n        adapt_c2 = self.c2_initial * (evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Apply mutation to particles occasionally to maintain diversity\n            if np.random.rand() < 0.1:\n                self.particles[i] = self.apply_mutation(self.particles[i], lb, ub, evaluations)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.00926238763331777, 0.009274174387734702, 0.009267443778593343, 0.07861327689840669, 0.07872934981669166, 0.07866146055557555, 0.07106804884684703, 0.07115879942758818, 0.07110608805997176]}}
{"id": "61cb54f6-bfa5-4cfc-92b8-aee215e9dd56", "fitness": 0.05354509947582975, "name": "EnhancedNAPSO", "description": "Introduced dynamic inertia weight based on swarm diversity and neighborhood informed convergence pressure to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def calculate_diversity(self):\n        centroid = np.mean(self.particles, axis=0)\n        diversity = np.mean(np.linalg.norm(self.particles - centroid, axis=1))\n        return diversity\n\n    def update_particles(self, lb, ub, evaluations):\n        diversity = self.calculate_diversity()\n        w = self.w_min + (self.w_max - self.w_min) * (1 - diversity / (ub - lb).mean())\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05355 with standard deviation 0.03142.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009500562243679789, 0.07866246713032199, 0.07875722085550796, 0.08114080839365145, 0.07110619876947122, 0.07118040082324117, 0.07301411294035787]}}
{"id": "f83fe2ad-bd6f-4135-a686-4ed82a9c5edd", "fitness": 0.05303998380340447, "name": "EnhancedNAPSO", "description": "Introduced dynamic inertia weight adjustment and random walk perturbation to enhance convergence precision.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_min + ((self.w_max - self.w_min) * (1 - (evaluations / self.budget)))  # Changed line\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            self.velocities[i] += np.random.uniform(-0.01, 0.01, self.dim)  # Added line\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267092209842231, 0.009276905795484347, 0.009271483439570183, 0.07866118355552543, 0.07875722085550796, 0.07870245811723242, 0.07110520361774375, 0.07118040082324117, 0.07113790581649271]}}
{"id": "b9b3191d-800c-481b-a046-c42250e5d7e3", "fitness": 0.05306113684917703, "name": "RefinedNAPSO", "description": "Introduced adaptive inertia weight and social learning factor based on particle's convergence rate to enhance global search capabilities.", "code": "import numpy as np\n\nclass RefinedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        for i in range(self.num_particles):\n            convergence_rate = (self.personal_best_scores[i] - self.global_best_score) / (self.personal_best_scores[i] + 1e-9)\n            w = self.w_max - (self.w_max - self.w_min) * convergence_rate\n            adaptive_c2 = self.c2 * (1 + convergence_rate)\n\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adaptive_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm RefinedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05306 with standard deviation 0.03107.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009477618426252832, 0.009276905795484347, 0.009270316768799969, 0.07866246713032199, 0.07875722085550796, 0.07869047150287667, 0.07110619876947122, 0.07118040082324117, 0.07112863157063709]}}
{"id": "514f88e9-c030-4c9d-a8a3-349fcef224aa", "fitness": 0.05303788257539779, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with dynamic inertia weight adjustment using success rate to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.success_count = 0\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        success_rate = self.success_count / max(1, evaluations)\n        w = self.w_max * success_rate + self.w_min * (1 - success_rate)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.success_count = 0\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n                    self.success_count += 1\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270367943908009, 0.07866246713032199, 0.07875722085550796, 0.07869108015786708, 0.07110619876947122, 0.07118040082324117, 0.07112908337202639]}}
{"id": "fefd9b4a-592f-406b-baf9-d5df1a8e5e89", "fitness": 0.05303303531510431, "name": "EnhancedNAPSO", "description": "Introduced non-uniform random number generation to enhance exploration and incorporated a dynamic inertia weight update to improve convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - (self.w_max - self.w_min) * ((evaluations / self.budget) ** 2)  # Non-linear decay\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.beta(2, 5), np.random.beta(2, 5)  # Non-uniform random numbers\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266098755028818, 0.009276528230795278, 0.009269578697649106, 0.07865105713370768, 0.07875336662014942, 0.0786830657557972, 0.07109735689747265, 0.07117740955220397, 0.07112285619313463]}}
{"id": "d1268dc2-ae53-4377-9e8f-588732677dea", "fitness": 0.05303783878276377, "name": "EnhancedNAPSO", "description": "Modified inertia weight decay and adaptive velocity noise for better convergence balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * np.sqrt(evaluations / self.budget))  # Modified line\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Modified line\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270346783595063, 0.07866246713032199, 0.07875722085550796, 0.07869086415449278, 0.07110619876947122, 0.07118040082324117, 0.07112892640200741]}}
{"id": "79dd93c8-d66d-48f0-ab00-f9ce73fa58e6", "fitness": 0.05887101759752908, "name": "AMPSO", "description": "Adaptive Memory Particle Swarm Optimization (AMPSO) integrates a memory-based velocity adjustment and diversity control to enhance exploitation and maintain exploration balance.", "code": "import numpy as np\n\nclass AMPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.memory_factor = 0.5\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        memory_velocity_influence = self.memory_factor * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n            memory_velocity = np.random.uniform(-1, 1, self.dim)\n            \n            if r3 < memory_velocity_influence:\n                self.velocities[i] = (w * self.velocities[i] +\n                                      memory_velocity +\n                                      adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n            else:\n                self.velocities[i] = (w * self.velocities[i] +\n                                      adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm AMPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05887 with standard deviation 0.03633.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.011081897091945514, 0.009276905795484347, 0.009271107123069222, 0.10932944315568915, 0.07875722085550796, 0.0786986183053986, 0.09110863835102634, 0.07118040082324117, 0.07113492687639944]}}
{"id": "02cdd8d8-650f-465b-8c38-4ade6ea4f69c", "fitness": 0.053037778277731436, "name": "EnhancedNAPSO", "description": "Adaptive inertia weight tuning using sigmoid function based on convergence to enhance solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_min + (self.w_max - self.w_min) / (1 + np.exp(-10 * ((self.budget / 2 - evaluations) / self.budget)))  # Changed line\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270318859517346, 0.07866246713032199, 0.07875722085550796, 0.07869057935209833, 0.07110619876947122, 0.07118040082324117, 0.0711286945831886]}}
{"id": "9b9363ea-8ba6-43be-8fd8-e9025c6c7f15", "fitness": 0.05303792019156454, "name": "EnhancedNAPSO", "description": "Enhanced convergence through dynamic inertia adjustment and local search intensification.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * ((evaluations / self.budget) ** 0.5))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270385657226377, 0.07866246713032199, 0.07875722085550796, 0.07869126075974331, 0.07110619876947122, 0.07118040082324117, 0.07112922360233254]}}
{"id": "ec342c20-7f1c-4c46-b4a7-608966d39b7e", "fitness": 0.05332730356045666, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive mutation scaling based on convergence rate to further balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        mutation_scale = 0.1 * (1 - (self.global_best_score - np.min(self.personal_best_scores)) / self.global_best_score)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, mutation_scale, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05333 with standard deviation 0.03128.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009403592410124562, 0.07866246713032199, 0.07875722085550796, 0.08008439515056631, 0.07110619876947122, 0.07118040082324117, 0.07220733277864044]}}
{"id": "544486ce-57f2-47ca-ae6c-6548e5c1fec2", "fitness": 0.05303169461798444, "name": "RefinedNAPSO", "description": "Introduced adaptive inertia weight and dynamic cognitive-social balance to balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass RefinedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_start = 2.5\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.5\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_start - ((self.w_start - self.w_end) * (evaluations / self.budget))\n        c1 = self.c1_start - ((self.c1_start - self.c1_end) * (evaluations / self.budget))\n        c2 = self.c2_start + ((self.c2_end - self.c2_start) * (evaluations / self.budget))\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm RefinedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266119016200114, 0.00927610284586522, 0.009269355503919163, 0.07865126041052628, 0.07874902766470415, 0.07868074473058084, 0.07109751341587023, 0.07117405061652637, 0.0711210773576676]}}
{"id": "31f133af-f3cc-4dc4-9d97-cd2196149a00", "fitness": 0.05303756506798959, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive inertia weight based on both convergence progress and diversity of the swarm for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        diversity = np.mean(np.std(self.particles, axis=0)) / (ub - lb).mean()  # Added line\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget)) * (1 - diversity)  # Modified line\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.00927021842678355, 0.07866246713032199, 0.07875722085550796, 0.07868955575621528, 0.07110619876947122, 0.07118040082324117, 0.0711278997241288]}}
{"id": "3a955152-bbe0-4ec8-86b1-63ff972974bd", "fitness": 0.05303601829629735, "name": "EnhancedNAPSO", "description": "Introduced velocity decay over time and increased population diversity with Gaussian noise to further balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.2 * (1 - evaluations / self.budget), self.dim)  # Increased diversity\n\n            self.particles[i] += self.velocities[i] * (1 - evaluations / self.budget)  # Velocity decay over time\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.00926949043823977, 0.07866246713032199, 0.07875722085550796, 0.07868212563435817, 0.07110619876947122, 0.07118040082324117, 0.07112213688929958]}}
{"id": "a2779569-1fb2-40f0-b9ca-6996085296e8", "fitness": 0.053033741615031986, "name": "EnhancedNAPSO", "description": "Introduced diversity preservation through adaptive mutation and dynamic inertia factors to enhance exploration in the EnhancedNAPSO algorithm.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_min + (self.w_max - self.w_min) * np.exp(-10 * evaluations / self.budget)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        mutation_prob = 0.2 * (1 - evaluations / self.budget)\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            if np.random.rand() < mutation_prob:\n                mutation_strength = 0.1 * (1 - evaluations / self.budget)\n                self.velocities[i] += np.random.normal(0, mutation_strength, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266839968022689, 0.009276905795484347, 0.009268785283105152, 0.07865861640593219, 0.07875722085550796, 0.07867504441486806, 0.07110321331428904, 0.07118040082324117, 0.07111664767483727]}}
{"id": "5873c97b-b396-43f6-81b7-e8e0f63848b2", "fitness": 0.05303768632804874, "name": "EnhancedNAPSO", "description": "Introduce adaptive inertia weight and exponential decay of cognitive coefficients to enhance convergence by dynamically adjusting exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_initial = 2.5\n        self.c2_initial = 2.5\n        self.c1_final = 0.5\n        self.c2_final = 0.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        decay_rate = evaluations / self.budget\n        adapt_c1 = self.c1_initial * np.exp(-decay_rate) + self.c1_final * (1 - np.exp(-decay_rate))\n        adapt_c2 = self.c2_initial * np.exp(-decay_rate) + self.c2_final * (1 - np.exp(-decay_rate))\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.00927027521310464, 0.07866246713032199, 0.07875722085550796, 0.0786901363847684, 0.07110619876947122, 0.07118040082324117, 0.07112835364978698]}}
{"id": "40f241c3-2f1a-477d-88c7-f8780755dc1a", "fitness": 0.05303431384349252, "name": "EnhancedNAPSO", "description": "Introduced mutation operator for particle diversity and improved convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            if evaluations < self.budget * 0.1:  # Line modification 1\n                mutation = np.random.normal(0, 0.1, self.dim)  # Line modification 2\n                self.particles[i] += mutation  # Line modification 3\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266052422016835, 0.009276460471227765, 0.009270295541658036, 0.0786505943369753, 0.07875267749039938, 0.0786903524113911, 0.07109699372366651, 0.07117687851675736, 0.07112851967734035]}}
{"id": "00e48c1d-fdae-4bb3-bc0a-bad8b0fc33ac", "fitness": 0.05302592882118869, "name": "ChaoticEnhancedNAPSO", "description": "Introduce dynamic learning coefficients and chaos-inspired perturbation to enhance exploration-exploitation balance and avoid local minima.", "code": "import numpy as np\n\nclass ChaoticEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def logistic_map(self, x):\n        r = 4.0\n        return r * x * (1 - x)\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        c1 = self.c1_init - ((self.c1_init - 1.5) * (evaluations / self.budget))\n        c2 = self.c2_init + ((2.5 - self.c2_init) * (evaluations / self.budget))\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            chaotic_factor = self.logistic_map(np.random.rand())\n\n            self.velocities[i] = (w * self.velocities[i] +\n                                  c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += chaotic_factor * np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm ChaoticEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03109.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009265253079968394, 0.009275614382450947, 0.009267983341833208, 0.07864245894582977, 0.0787440421659582, 0.07866685221384184, 0.07109067608227149, 0.07117017717721763, 0.07111030200132673]}}
{"id": "8ce17a0d-9564-42cb-b3f1-5938e2a368f6", "fitness": 0.0530398626660806, "name": "EnhancedNAPSO", "description": "Incorporate a dynamically updating inertia weight strategy and leader-based velocity adjustment to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_min + (self.w_max - self.w_min) * ((self.budget - evaluations) / self.budget)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        leader_position = self.personal_best_positions[np.argmin(self.personal_best_scores)]\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n            \n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]) +\n                                  0.5 * r3 * (leader_position - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009271300521413228, 0.07866246713032199, 0.07875722085550796, 0.07870059278353725, 0.07110619876947122, 0.07118040082324117, 0.07113645898499632]}}
{"id": "722abc02-5057-46c6-8ddd-f37819dcc857", "fitness": 0.23896980818879118, "name": "EnhancedNAPSOv2", "description": "Introduced dynamic inertia weight adjustment based on individual particle performance to enhance convergence speed and increase solution accuracy.", "code": "import numpy as np\n\nclass EnhancedNAPSOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w_global = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            \n            # Dynamic inertia weight based on particle's performance\n            personal_improvement = (self.personal_best_scores[i] - self.global_best_score) / self.global_best_score\n            w_personal = self.w_max - (self.w_max - self.w_min) * personal_improvement\n            w = max(w_personal, w_global)  # Use the greater of individual or global inertia\n\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedNAPSOv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23897 with standard deviation 0.36067.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270317444906362, 0.9119286552736355, 0.07875722085550796, 0.07868952818894737, 0.9112298995541043, 0.07118040082324117, 0.07112812743254182]}}
{"id": "9f2538ba-970b-4678-a8c2-c3d134263105", "fitness": 0.053037579553248886, "name": "EnhancedNAPSO", "description": "Enhanced convergence by refining inertia weight and introducing a decay factor to the velocity update rule.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        decay_factor = 0.98  # Introduced decay factor\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (decay_factor * w * self.velocities[i] +  # Applied decay factor here\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270225253113273, 0.07866246713032199, 0.07875722085550796, 0.07868962529264822, 0.07110619876947122, 0.07118040082324117, 0.07112795372869984]}}
{"id": "17787db5-5a64-4d3d-b268-1823604e5207", "fitness": 0.23946765127961622, "name": "EnhancedNAPSO", "description": "Enhanced neighbor selection mechanism by including self-best, and added adaptive inertia for improved balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_min + ((self.w_max - self.w_min) * ((self.budget - evaluations) / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            neighbor_indices = np.append(neighbor_indices, i)  # Include self in neighbor selection\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270212578276649, 0.9119286552736355, 0.07875722085550796, 0.07868949560277938, 0.9112298995541043, 0.07118040082324117, 0.07112785311856906]}}
{"id": "68aebfc7-e709-4f98-a10f-24160c55ff6b", "fitness": 0.05301653474867053, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive global acceleration coefficient for improved convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0  # Original: 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        adapt_c2 = self.c2 * (evaluations / self.budget)  # New line added\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))  # Modified line\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.00926109060100433, 0.009274914566345882, 0.00926842608846612, 0.0786000272984192, 0.07873689959443764, 0.07867127819977615, 0.07105777672696434, 0.07116466045454206, 0.07111373920807906]}}
{"id": "80a87db7-db5c-4539-8d55-5ebe19d9767c", "fitness": 0.05303777291297661, "name": "EnhancedNAPSO", "description": "Enhanced adaptive velocity scaling by incorporating fitness-based inertia weighting to improve convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = (self.w_max - self.w_min) * (self.global_best_score / (self.global_best_score + 1)) + self.w_min\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270316460819994, 0.07866246713032199, 0.07875722085550796, 0.0786905548936665, 0.07110619876947122, 0.07118040082324117, 0.07112867315752436]}}
{"id": "d5bc453e-58f9-4b33-b12b-29f69a13e17c", "fitness": 0.05303099749932257, "name": "EnhancedNAPSOPlus", "description": "Introduced dynamic social adaptability and mutation-based exploration to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSOPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        \n        # Dynamic social learning factor\n        adapt_c2 = self.c2 * (1 - np.exp(-3 * (evaluations / self.budget)))\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Mutation-based exploration\n            self.velocities[i] += np.random.normal(0, 0.2 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedNAPSOPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009264586388877505, 0.009275680461824254, 0.009270982416671902, 0.07863564023085834, 0.0787447181002604, 0.07869733760868058, 0.07108539401709679, 0.07117070840333839, 0.07113392986629496]}}
{"id": "11581ae0-881a-4805-a254-0342a3a4d782", "fitness": 0.05381826792971514, "name": "EnhancedNAPSO", "description": "Introduced dynamic cognitive and social coefficients with opposition-based learning to improve convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def opposition_based_learning(self, particles, lb, ub):\n        opposite_particles = lb + ub - particles\n        return np.clip(opposite_particles, lb, ub)\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        dynamic_c1 = self.c1 * np.sin((np.pi * evaluations) / (2 * self.budget))\n        dynamic_c2 = self.c2 * np.cos((np.pi * evaluations) / (2 * self.budget))\n        \n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  dynamic_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  dynamic_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            opposite_particles = self.opposition_based_learning(self.particles, lower_bound, upper_bound)\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                opposite_score = func(opposite_particles[i])\n                evaluations += 2\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if opposite_score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = opposite_score\n                    self.personal_best_positions[i] = np.copy(opposite_particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if opposite_score < self.global_best_score:\n                    self.global_best_score = opposite_score\n                    self.global_best_position = np.copy(opposite_particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05382 with standard deviation 0.03161.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266152805217476, 0.00963072546646715, 0.009260588451444729, 0.07865058986070184, 0.08266117488084146, 0.07859247398558566, 0.07109720076727133, 0.07415302273997182, 0.07105248240993478]}}
{"id": "94ff17d9-85bd-4b80-b8fa-9c6380f7283e", "fitness": 0.05303629329075332, "name": "EnhancedNAPSO_v2", "description": "Introduced dynamic inertia weight and mutation operator based on evaluation feedback to enhance adaptability and convergence speed.", "code": "import numpy as np\n\nclass EnhancedNAPSO_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Apply mutation operator to escape local optima\n            if np.random.rand() < 0.05 * (1 - evaluations / self.budget):\n                mutation = np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n                self.particles[i] += mutation\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedNAPSO_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009266035898808256, 0.009276905795484347, 0.009270799785478512, 0.07865042787587195, 0.07875722085550796, 0.07869548482043243, 0.07109686602982446, 0.07118040082324117, 0.07113249773213082]}}
{"id": "bd7b73ff-5107-494b-ae9b-5cbac302044a", "fitness": 0.05303930898468042, "name": "EnhancedNAPSOv2", "description": "Introduced dynamic particle neighborhood size with adaptive inertia weight decay and elite reinforcement to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.elite_fraction = 0.1\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        elite_count = max(1, int(self.elite_fraction * self.num_particles))\n        elite_indices = np.argsort(self.personal_best_scores)[:elite_count]\n        elite_best = self.personal_best_positions[elite_indices[np.argmin(self.personal_best_scores[elite_indices])]]\n\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int((self.num_particles / 2) * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]) +\n                                  0.1 * r3 * (elite_best - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedNAPSOv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009271038829964051, 0.07866246713032199, 0.07875722085550796, 0.0786979313606796, 0.07110619876947122, 0.07118040082324117, 0.07113439896670148]}}
{"id": "dfb6654e-b0ca-4432-b590-d7fd8e8878ad", "fitness": 0.2394677792380541, "name": "EnhancedNAPSO", "description": "Enhanced adaptive neighbor selection by incorporating particle diversity to further balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["4a9dffea-54e3-4923-bb87-7cdb0470269a"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270272666765278, 0.9119286552736355, 0.07875722085550796, 0.07869010811622179, 0.9112298995541043, 0.07118040082324117, 0.07112833214257852]}}
{"id": "c984654a-4d76-4cab-baf0-9489648c9b57", "fitness": 0.053037933011468516, "name": "EnhancedNAPSO", "description": "Improved inertia weight adjustment based on dynamic evaluations for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.95  # Changed from 0.9 to 0.95\n        self.w_min = 0.5   # Changed from 0.4 to 0.5\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270391740233919, 0.07866246713032199, 0.07875722085550796, 0.07869132222409514, 0.07110619876947122, 0.07118040082324117, 0.07112927143410896]}}
{"id": "64f307d9-467b-4422-923e-ce1a587cf5e3", "fitness": 0.05303669097024894, "name": "ImprovedEnhancedNAPSO", "description": "Improved EnhancedNAPSO by introducing a dynamic inertia weight strategy and a hybrid search mechanism to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.epsilon = 1e-8  # Small value to prevent division by zero\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.dynamic_inertia_weight(evaluations)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def dynamic_inertia_weight(self, evaluations):\n        # Systematically decay inertia weight based on number of evaluations and diversity\n        diversity = np.std(self.particles, axis=0).mean()\n        return self.w_min + (self.w_max - self.w_min) * np.exp(-evaluations / (self.budget * (diversity + self.epsilon)))\n\n    def hybrid_search(self, func, lb, ub, evaluations):\n        # Introduce hybrid search mechanism\n        if np.random.rand() < 0.1:  # 10% chance for local perturbation\n            i = np.random.randint(0, self.num_particles)\n            perturb = np.random.normal(0, 0.01 * (ub - lb), self.dim)\n            candidate = np.clip(self.particles[i] + perturb, lb, ub)\n            score = func(candidate)\n            evaluations += 1\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = candidate\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = candidate\n        return evaluations\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            evaluations = self.hybrid_search(func, lower_bound, upper_bound, evaluations)\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267219437154806, 0.009276905795484347, 0.009269803701637436, 0.07866247834768525, 0.07875722085550796, 0.07868534453684928, 0.07110620603782436, 0.07118040082324117, 0.07112463919685585]}}
{"id": "e5a26fde-83a4-4e61-8f6e-7f786363a28c", "fitness": 0.053020805887065606, "name": "EnhancedNAPSO", "description": "Improved dynamic neighbor selection by introducing particle clustering based on position similarity.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            similarities = np.linalg.norm(self.particles - self.particles[i], axis=1)  # Changed this line\n            neighbor_indices = np.argsort(similarities)[:dynamic_neighbors]\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009263278446054235, 0.009275315704864062, 0.009267827493062097, 0.0786223404172105, 0.07874099583799066, 0.07866537143938812, 0.07107508022311859, 0.07116783150397765, 0.07110921191792452]}}
{"id": "e6500d98-687a-4a02-82fc-3d35cf78c4c8", "fitness": 0.05303772542575212, "name": "EnhancedNAPSO", "description": "Enhanced adaptive neighbor selection by adjusting inertia weight decay to further balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * ((evaluations / self.budget) ** 0.5))  # Adjusted inertia weight decay\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270294007103108, 0.07866246713032199, 0.07875722085550796, 0.07869032553428368, 0.07110619876947122, 0.07118040082324117, 0.07112849758560369]}}
{"id": "b7292cf8-fd3d-4972-a031-16d9ec480f61", "fitness": 0.053039981846913956, "name": "EnhancedNAPSO", "description": "Introduced dynamic inertia and local exploration boost to enhance convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i] + np.random.uniform(-0.1, 0.1, self.dim)  # Added local exploration boost\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267092209842231, 0.009276905795484347, 0.009271482517145824, 0.07866118355552543, 0.07875722085550796, 0.07870244872586862, 0.07110520361774375, 0.07118040082324117, 0.07113789852186625]}}
{"id": "2e24dc3b-a7cd-4799-a14a-d8810dfdb558", "fitness": 0.0530377305170095, "name": "EnhancedNAPSO", "description": "Enhanced Neighborhood Adaptive PSO with Dynamic Inertia Weight and Gaussian Mutation: Introduces dynamic inertia weight adjustments and Gaussian mutation based on particle diversity to improve exploration-exploitation balance and avoid local optima.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            \n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Introduce Gaussian Mutation to enhance exploration\n            if np.random.rand() < 0.1 * (1 - evaluations / self.budget):\n                mutation_strength = 0.1 * (1 - evaluations / self.budget)\n                self.particles[i] += np.random.normal(0, mutation_strength, self.dim)\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009266713847112973, 0.009276905795484347, 0.009270799785478512, 0.07865733283113574, 0.07875722085550796, 0.07869548482043243, 0.07110221816256157, 0.07118040082324117, 0.07113249773213082]}}
{"id": "6acc7e7d-3588-428a-96c2-d752d6b79162", "fitness": 0.053036784147114324, "name": "EnhancedNAPSO", "description": "Refined EnhancedNAPSO with adaptive velocity scaling based on particle performance to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.num_particles, self.dim))  # Change 1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            performance_factor = 0.5 + 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Change 2\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i])) * performance_factor  # Change 3\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009269817041649198, 0.07866246713032199, 0.07875722085550796, 0.07868586379658471, 0.07110619876947122, 0.07118040082324117, 0.07112496478101638]}}
{"id": "a5f38a65-ae7b-4355-ac40-6fa338e332be", "fitness": 0.05303769227335537, "name": "EnhancedNAPSO", "description": "Improved EnhancedNAPSO by incorporating adaptive inertia weight decay for better convergence speed.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        # Change 1: Updated to use exponential decay for inertia weight\n        w = self.w_max * ((self.w_min/self.w_max) ** (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270278386173114, 0.07866246713032199, 0.07875722085550796, 0.07869016638168946, 0.07110619876947122, 0.07118040082324117, 0.07112837398755711]}}
{"id": "3840a352-1d2e-462f-b106-8b61a97bb958", "fitness": 0.2394677792380541, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with dynamic inertia weighting and adaptive velocity perturbation based on convergence status to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.convergence_threshold = 1e-6\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        \n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            \n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n            \n            if (self.global_best_score - self.personal_best_scores[i]) < self.convergence_threshold:\n                self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270272666765278, 0.9119286552736355, 0.07875722085550796, 0.07869010811622179, 0.9112298995541043, 0.07118040082324117, 0.07112833214257852]}}
{"id": "7b1edaf8-a543-4f4c-9580-a20cead790a1", "fitness": 0.239467733437094, "name": "EnhancedNAPSO", "description": "Dynamic inertia and nonlinear acceleration to further improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * (r1**2) * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i])) # Changed line\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270251135502172, 0.9119286552736355, 0.07875722085550796, 0.07868988814951616, 0.9112298995541043, 0.07118040082324117, 0.07112816143190626]}}
{"id": "ce2ded23-083d-4ec9-a4cf-cee045cac20e", "fitness": 0.05302176358904179, "name": "AdaptiveClusterNAPSO", "description": "Introduce a self-adaptive mechanism to dynamically adjust exploration and exploitation components based on convergence progress and particle clustering.", "code": "import numpy as np\n\nclass AdaptiveClusterNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        cluster_diversity = np.mean(np.std(self.particles, axis=0))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + cluster_diversity)\n        adapt_c2 = self.c2 * (evaluations / self.budget) * (1 + (1 - cluster_diversity))\n        \n        for i in range(self.num_particles):\n            neighbor_indices = np.random.choice(self.num_particles, self.neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveClusterNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009263415795827568, 0.009276048367544365, 0.009267396401085759, 0.07862375898220653, 0.07874847359665693, 0.0786610781078595, 0.07107616847254905, 0.07117361867458638, 0.07110591390305998]}}
{"id": "fce7d9f1-4dc6-4f67-921a-eb40d523d67e", "fitness": 0.05303837600893275, "name": "EnhancedNAPSO", "description": "Enhanced particle diversity with adaptive velocity scaling for improved exploitation-exploration balance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            scale_factor = 1.5 if particle_diversity > 1 else 1.0  # Change\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i])) * scale_factor  # Change\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270599925944367, 0.07866246713032199, 0.07875722085550796, 0.07869344991795901, 0.07110619876947122, 0.07118040082324117, 0.07113092253171271]}}
{"id": "b7fe6854-f206-42de-80f0-8268376d2c95", "fitness": 0.053035597651095806, "name": "EnhancedNAPSO", "description": "Improved particle diversity control for dynamic neighbor selection to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget) * (1 + particle_diversity / 10))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267470572571268, 0.009276715475359798, 0.00926922135259145, 0.07866503427991522, 0.07875527804338578, 0.0786794849834418, 0.07110818907292615, 0.07117889617064976, 0.071120088909021]}}
{"id": "156c3f22-c785-4779-90d3-1e6c23e0c0c2", "fitness": 0.05302628568737137, "name": "EnhancedNAPSO", "description": "Improve particle convergence by introducing adaptive velocity scaling and dynamic particle rejuvenation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            # Change 1: Introduce adaptive velocity scaling\n            self.velocities[i] *= (1 - particle_diversity / self.num_particles)\n            \n            # Change 2: Dynamic particle rejuvenation\n            if evaluations > self.budget * 0.75 and np.random.rand() < 0.05:\n                self.particles[i] = np.random.uniform(lb, ub, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03109.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009266587726203257, 0.00927680959640087, 0.009265613395031513, 0.07865604925633907, 0.07875623947118982, 0.0786427633532556, 0.07110122301083421, 0.07117963989904597, 0.07109164547804203]}}
{"id": "03f6b235-3f73-4ba1-986a-9606ababe0b8", "fitness": 0.0530377305170095, "name": "DEPSO", "description": "Dynamic Evolutionary Particle Swarm Optimizer (DEPSO) utilizes a synergy of evolutionary operators and dynamic neighborhood adaptation to enhance diversity and convergence in complex search spaces.", "code": "import numpy as np\n\nclass DEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.mutation_prob = 0.1\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            if np.random.rand() < self.mutation_prob:\n                mutation_vector = np.random.normal(0, 0.1, self.dim)\n                self.particles[i] += mutation_vector\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm DEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009266713847112973, 0.009276905795484347, 0.009270799785478512, 0.07865733283113574, 0.07875722085550796, 0.07869548482043243, 0.07110221816256157, 0.07118040082324117, 0.07113249773213082]}}
{"id": "555b277d-15c8-408c-9c4d-92acaf912a23", "fitness": 0.2394677792380541, "name": "EnhancedNAPSO", "description": "Introduce a perturbation to the global best particle's position to enhance exploration capabilities.  ", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n            \n            # Introduce a perturbation to the global best position\n            if evaluations % (self.budget // 10) == 0:\n                self.global_best_position += np.random.normal(0, 0.01, self.dim)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270272666765278, 0.9119286552736355, 0.07875722085550796, 0.07869010811622179, 0.9112298995541043, 0.07118040082324117, 0.07112833214257852]}}
{"id": "08989368-5933-4c06-a33c-6bc649bc0779", "fitness": 0.053037593027139, "name": "RefinedEnhancedNAPSO", "description": "Incorporating dynamic velocity scaling and adaptive mutation to better balance exploration and exploitation in EnhancedNAPSO.", "code": "import numpy as np\n\nclass RefinedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.mutation_prob = 0.1\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def adaptive_mutation(self, particle, lb, ub, evaluations):\n        if np.random.rand() < self.mutation_prob * (1 - evaluations / self.budget):\n            mutate_dim = np.random.randint(self.dim)\n            particle[mutate_dim] += np.random.normal(0, 0.1 * (ub[mutate_dim] - lb[mutate_dim]))\n            particle = np.clip(particle, lb, ub)\n        return particle\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            velocity_scale = np.random.uniform(0.5, 1.5)  # Dynamic velocity scaling\n            self.velocities[i] *= velocity_scale\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n            self.particles[i] = self.adaptive_mutation(self.particles[i], lb, ub, evaluations)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm RefinedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009266966088932405, 0.009276905795484347, 0.009270483314722688, 0.07865989998072886, 0.07875722085550796, 0.07869225535352664, 0.0711042084660164, 0.07118040082324117, 0.07112999656609054]}}
{"id": "6656dd32-13f0-4ef4-9fd4-346f60909ada", "fitness": 0.0530379309217195, "name": "EnhancedNAPSO", "description": "Improved velocity update by introducing a dynamic inertia weight adaptation based on global score changes to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Introducing a dynamic inertia weight adaptation based on global score changes\n            if self.global_best_score < float('inf'):\n                w = self.w_max - (self.w_max - self.w_min) * (self.global_best_score / float('inf'))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.00927039075616276, 0.07866246713032199, 0.07875722085550796, 0.07869131219087, 0.07110619876947122, 0.07118040082324117, 0.07112926364366412]}}
{"id": "89bcea89-ada7-4d2d-9bd5-6f265d331bd6", "fitness": 0.06401782427978936, "name": "EnhancedNAPSO", "description": "Introducing a more adaptive acceleration coefficient and a velocity bound check for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (np.std(self.particles, axis=0).sum() / self.dim)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            velocity_limit = (ub - lb) * 0.1  # Added velocity bound check\n            self.velocities[i] = np.clip(self.velocities[i], -velocity_limit, velocity_limit)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06402 with standard deviation 0.04344.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.011816299297081612, 0.009275297623804857, 0.009247801453062032, 0.14225143691617248, 0.0787408058298652, 0.07846220198876241, 0.1042470368410161, 0.07116769337417395, 0.07095184519416564]}}
{"id": "01292910-bba7-4c8f-817d-d1bc68f62ed6", "fitness": 0.0530334795458237, "name": "DynamicNAPSO", "description": "Dynamic Neighborhood Particle Swarm Optimization (D-NAPSO) with Time-Varying Acceleration Coefficients to enhance convergence by optimizing exploration-exploitation balance over time.", "code": "import numpy as np\n\nclass DynamicNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_start, self.c1_end = 2.5, 0.5\n        self.c2_start, self.c2_end = 0.5, 2.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        c1 = self.c1_start - ((self.c1_start - self.c1_end) * (evaluations / self.budget))\n        c2 = self.c2_start + ((self.c2_end - self.c2_start) * (evaluations / self.budget))\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm DynamicNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009266119016200114, 0.009276080582284685, 0.00927021797611316, 0.07865126041052628, 0.07874880077024937, 0.07868954350174573, 0.07109751341587023, 0.07117387101251726, 0.07112790922690648]}}
{"id": "c322b380-f8f1-4154-a544-be54664e79fc", "fitness": 0.2394677792380541, "name": "DNPSO", "description": "Dynamic Neighborhood Particle Swarm Optimization (DNPSO) with adaptive inertia and diversity enhancement for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass DNPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 1.5\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        particle_diversity = np.std(self.particles, axis=0).sum()\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 0.5 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n                                  \n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm DNPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270272666765278, 0.9119286552736355, 0.07875722085550796, 0.07869010811622179, 0.9112298995541043, 0.07118040082324117, 0.07112833214257852]}}
{"id": "3cbe9c51-9c83-4bac-a0e0-eec299e79f76", "fitness": 0.05302106441315349, "name": "ImprovedEnhancedNAPSO", "description": "EnhancedNAPSO with dynamic learning factors and adaptive inertia weight for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def dynamic_learning_factors(self, evaluations):\n        dynamic_c1 = self.c1 * (1 - evaluations / self.budget)\n        dynamic_c2 = self.c2 * (evaluations / self.budget)\n        return dynamic_c1, dynamic_c2\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        dynamic_c1, dynamic_c2 = self.dynamic_learning_factors(evaluations)\n\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  dynamic_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  dynamic_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009261850143845618, 0.00927499349156069, 0.009269722471494823, 0.07860777938161911, 0.07873770569427119, 0.07868450644351965, 0.07106377294039024, 0.07116526659622191, 0.07112398255545815]}}
{"id": "aa3e713d-c6a3-4de3-aadf-2a8e977e4cfc", "fitness": 0.05291428441439646, "name": "EnhancedNAPSOv2", "description": "Introduce adaptive inertia weight scaling and dynamic velocity clamping to further enhance the balance between exploration and exploitation in particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedNAPSOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            \n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            # Dynamic velocity clamping\n            velocity_clamp = np.abs(ub - lb) * 0.1 * (1 - evaluations / self.budget)\n            self.velocities[i] = np.clip(self.velocities[i], -velocity_clamp, velocity_clamp)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedNAPSOv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05291 with standard deviation 0.03103.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009252530355441824, 0.009274032119110598, 0.009229471516669085, 0.07851280245362402, 0.07872788113997797, 0.07827633975217707, 0.07099014370207524, 0.07115771766100953, 0.07080764102948278]}}
{"id": "a0f07a61-f93c-4a91-b29a-0af2e8747a42", "fitness": 0.05303550491187078, "name": "EnhancedNAPSO", "description": "Introducing dynamic inertia weight and velocity scaling based on particle performance for improved adaptability.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n            \n            self.velocities[i] *= (1 + 0.1 * (self.personal_best_scores[i] - self.global_best_score) / abs(self.global_best_score))  # Adjust velocity\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009265704879835135, 0.009276905795484347, 0.009270754639809087, 0.07864706423276302, 0.07875722085550796, 0.07869505881990546, 0.07109425694874227, 0.07118040082324117, 0.07113217721154852]}}
{"id": "da07cf83-6f21-441f-a5ac-4c31c3d88190", "fitness": 0.05303379759382513, "name": "EnhancedNAPSO", "description": "Introducing an adaptive inertia weight decay and dynamic velocity scaling to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max * ((self.budget - evaluations) / self.budget) + self.w_min  # Adaptive inertia weight decay\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i])) \\\n                                  * (0.5 + 0.5 * evaluations / self.budget)  # Dynamic velocity scaling\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267020954157212, 0.009276616878657107, 0.009268927247151892, 0.07866045392038568, 0.078754272312905, 0.07867641279371229, 0.0711046372047438, 0.07117811876225377, 0.07111771827045943]}}
{"id": "8187e5ac-5e99-4adf-8bae-504ae39f983f", "fitness": 0.053037858715958994, "name": "EnhancedNAPSOAdaptive", "description": "Introduce adaptive inertia weight decay and neighborhood mutation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedNAPSOAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Introduce neighborhood mutation to enhance exploration\n            mutation_factor = 0.1 * (1 - evaluations / self.budget)\n            self.velocities[i] += np.random.normal(0, mutation_factor, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedNAPSOAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276852399033086, 0.009270410620590419, 0.07866246713032199, 0.07875667545097553, 0.07869150881030929, 0.07110619876947122, 0.07117997752877503, 0.07112941940340245]}}
{"id": "3c3208a3-e805-4c72-9139-9e7e1622134d", "fitness": 0.05302106441315349, "name": "EnhancedNAPSOPlus", "description": "Incorporate a dynamic inertia weight and adaptive learning factors based on particle performance to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedNAPSOPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1_base = 2.0\n        self.c2_base = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1_base * (1 - evaluations / self.budget)\n        adapt_c2 = self.c2_base * (evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedNAPSOPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009261850143845618, 0.00927499349156069, 0.009269722471494823, 0.07860777938161911, 0.07873770569427119, 0.07868450644351965, 0.07106377294039024, 0.07116526659622191, 0.07112398255545815]}}
{"id": "baa4337e-4ebc-4f5b-9263-1efe35d2eafa", "fitness": 0.23305700118459413, "name": "EnhancedNAPSOPlus", "description": "Introducing a self-adaptive inertia weight and velocity scaling to dynamically adjust exploration and exploitation balance based on convergence progress.", "code": "import numpy as np\n\nclass EnhancedNAPSOPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        progress_ratio = evaluations / self.budget\n        w = 0.4 + 0.5 * (1 - progress_ratio)  # Self-adaptive inertia weight\n        velocity_scale = 0.5 + 0.5 * (1 - progress_ratio)\n        \n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - progress_ratio))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] *= velocity_scale\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - progress_ratio), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedNAPSOPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23306 with standard deviation 0.34637.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.02112696402943115, 0.009276905795484347, 0.009270300339591087, 0.8795238590680624, 0.07875722085550796, 0.07869038986673393, 0.8785584223013686, 0.07118040082324117, 0.07112854758192644]}}
{"id": "b21d7d28-79cb-48cf-bfca-8b7e6a57fda0", "fitness": 0.05303363129575062, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive velocity scaling to improve convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] *= (1 - evaluations / self.budget)  # Change 1: Adaptive velocity scaling\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009265704879835135, 0.009276905795484347, 0.009269872806063506, 0.07864706423276302, 0.07875722085550796, 0.07868606387007293, 0.07109425694874227, 0.07118040082324117, 0.07112519145004526]}}
{"id": "a544b962-bfa3-44dc-88e9-dadfa70e0ba1", "fitness": 0.053037680788810736, "name": "EnhancedNAPSO", "description": "Fine-tuned velocity update and adaptive neighborhood size based on particle improvements to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 0.8 else 0))  # Slightly adjusted threshold\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Reduced noise\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270272974268301, 0.07866246713032199, 0.07875722085550796, 0.07869011124960268, 0.07110619876947122, 0.07118040082324117, 0.07112833117064699]}}
{"id": "bc426cfc-99a5-4116-9078-94d25e04bf3e", "fitness": 0.05503094155906141, "name": "RefinedNAPSO", "description": "Incorporate velocity clamping and adaptive inertia weight for improved exploration-exploitation balance in EnhancedNAPSO.", "code": "import numpy as np\n\nclass RefinedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.max_velocity = None\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n        self.max_velocity = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            # Clamp the velocities to prevent excessive movement\n            self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm RefinedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05503 with standard deviation 0.03254.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009256251755282219, 0.009274922752992465, 0.010058335084838332, 0.0785506879545822, 0.07873697790225231, 0.08875602484271583, 0.07101953731722677, 0.07116472274588292, 0.07846101367577962]}}
{"id": "12425bcf-a4ac-4c86-b414-229c9bbbabba", "fitness": 0.05303643746612078, "name": "EnhancedNAPSO", "description": "Introducing a dynamic inertia weight strategy based on swarm diversity to further enhance exploration-exploitation balance in EnhancedNAPSO.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        particle_diversity = np.std(self.particles, axis=0).mean()\n        w = self.w_min + ((self.w_max - self.w_min) * (1 - particle_diversity))\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget)\n        for i in range(self.num_particles):\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.009266855729513801, 0.00927631366812054, 0.009270637136523763, 0.07865876713455111, 0.07875117571834633, 0.0786938748932613, 0.07110333521072376, 0.07117571000839207, 0.07113126769565437]}}
{"id": "d447a3fc-d354-4262-89c7-e8015e52c5de", "fitness": 0.23946903785978624, "name": "ImprovedEnhancedNAPSO", "description": "Improved EnhancedNAPSO with adaptive inertia weight and neighborhood expansion based on fitness diversity to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["dfb6654e-b0ca-4432-b590-d7fd8e8878ad"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270865543233975, 0.9119286552736355, 0.07875722085550796, 0.07869615615326975, 0.9112298995541043, 0.07118040082324117, 0.07113301882465084]}}
{"id": "54f08531-982d-443e-863d-76a06469f652", "fitness": 0.23946903785978624, "name": "EnhancedDynamicNeighborhoodAdaptivePSO", "description": "Enhanced Dynamic Neighborhood Adaptive PSO (EDNAPSO) with variable particle count and adaptive velocity updates to optimize convergence in diverse solution spaces.", "code": "import numpy as np\n\nclass EnhancedDynamicNeighborhoodAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        self.evaluations = 0\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub):\n        w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - self.evaluations / self.budget) * (1 + fitness_std)\n        \n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - self.evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            \n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedDynamicNeighborhoodAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270865543233975, 0.9119286552736355, 0.07875722085550796, 0.07869615615326975, 0.9112298995541043, 0.07118040082324117, 0.07113301882465084]}}
{"id": "8bd5dea7-6b4e-4766-9b87-4484839db2e9", "fitness": 0.05303927008030128, "name": "ImprovedEnhancedNAPSO", "description": "Improved EnhancedNAPSO with time-varying acceleration coefficients for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.5  # Modified to time-varying\n        self.c2 = 1.5  # Modified to time-varying\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276852399033086, 0.009271075066258128, 0.07866246713032199, 0.07875667545097553, 0.07869829024991948, 0.07110619876947122, 0.07117997752877503, 0.07113467579720512]}}
{"id": "4e8f7bd9-8aa1-4730-ae09-693c0b1cd7c6", "fitness": 0.23946903785978624, "name": "EnhancedAdaptiveNeighborhoodPSO", "description": "Enhanced Adaptive Neighborhood Particle Swarm Optimization (EANPSO) utilizes dynamic learning coefficients with a feedback mechanism based on convergence rate and diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveNeighborhoodPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n        \n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        adapt_c2 = self.c2 * (1 - np.exp(-fitness_std))\n        \n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            \n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptiveNeighborhoodPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270865543233975, 0.9119286552736355, 0.07875722085550796, 0.07869615615326975, 0.9112298995541043, 0.07118040082324117, 0.07113301882465084]}}
{"id": "89636047-80ed-4c0d-8603-62bfa0915e66", "fitness": -Infinity, "name": "EnhancedPSOWithGradient", "description": "Enhanced Particle Swarm Optimization with Adaptive Velocity Perturbation and Gradient-Based Local Search for improved convergence and accuracy.", "code": "import numpy as np\n\nclass EnhancedPSOWithGradient:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def gradient_based_search(self, func, position, lb, ub):\n        # Approximate gradient using finite differences\n        gradient = np.zeros(self.dim)\n        epsilon = 1e-4\n        for i in range(self.dim):\n            dx = np.zeros(self.dim)\n            dx[i] = epsilon\n            grad_approx = (func(position + dx) - func(position - dx)) / (2 * epsilon)\n            gradient[i] = grad_approx\n\n        new_position = position - 0.1 * gradient\n        return np.clip(new_position, lb, ub)\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Apply gradient-based local search\n            if evaluations < self.budget:\n                self.particles[i] = self.gradient_based_search(func, self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {}}
{"id": "6573ce50-93e9-498e-a318-448475c7e2ce", "fitness": 0.23946903785978624, "name": "ImprovedEnhancedNAPSO", "description": "Improved EnhancedNAPSO with adaptive velocity mutation to enhance exploration capabilities while maintaining convergence speed.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270865543233975, 0.9119286552736355, 0.07875722085550796, 0.07869615615326975, 0.9112298995541043, 0.07118040082324117, 0.07113301882465084]}}
{"id": "86546db0-b74d-4187-bb22-7f279278303e", "fitness": 0.23946675719482421, "name": "ImprovedEnhancedNAPSO", "description": "ImprovedEnhancedNAPSO with adaptive personal learning coefficient to balance exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (2 - fitness_std)  # Modified line\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009269791329104438, 0.9119286552736355, 0.07875722085550796, 0.07868519444527378, 0.9112298995541043, 0.07118040082324117, 0.07112452876211817]}}
{"id": "5acd1e35-464e-4c68-a343-96ca4b8883fc", "fitness": 0.05303822537162871, "name": "AdvancedNAPSO", "description": "AdvancedNAPSO incorporates fitness diversity-driven inertia weight adjustment and chaotic perturbations to enhance local exploration and global convergence.  ", "code": "import numpy as np\n\nclass AdvancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n            \n            # Apply chaotic perturbations\n            if evaluations / self.budget < 0.5:  # More exploration in early phases\n                chaotic_factor = self.chaotic_map(np.random.rand())\n                self.velocities[i] *= 1 + chaotic_factor\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm AdvancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.009266407056318426, 0.009276905795484347, 0.009271340000178263, 0.07865420429835923, 0.07875722085550796, 0.07870099462617997, 0.07109978521956195, 0.07118040082324117, 0.07113676966982707]}}
{"id": "5b9cc349-241a-4913-8471-86947de4c6b7", "fitness": 0.06090679660896497, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with adaptive velocity clamping and dynamic learning factor adjustment to balance exploration and exploitation for improved convergence performance.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.vel_max = None\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.vel_max = (ub - lb) * 0.1\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        adapt_c2 = self.c2 * (evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_max, self.vel_max)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06091 with standard deviation 0.03886.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.011483129369327494, 0.009275266805318871, 0.009260736845313033, 0.1213942558863692, 0.07874049117009818, 0.07859321690319632, 0.0971933912894637, 0.07116744376937689, 0.07105323744222103]}}
{"id": "781f263c-9300-4e57-ac1a-5717a2963950", "fitness": 0.053040378594283503, "name": "ImprovedEnhancedNAPSO", "description": "Introduced dynamic velocity scaling to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        dynamic_scale = 1 + fitness_std\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  dynamic_scale * self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.009267470572571268, 0.009276905795484347, 0.009271290716618474, 0.07866503427991522, 0.07875722085550796, 0.078700507639625, 0.07110818907292615, 0.07118040082324117, 0.07113638759266194]}}
{"id": "a46be751-ca73-4b1b-864f-20fb39178a2f", "fitness": 0.053040378594283503, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO with dynamic particle count and fitness-adaptive parameters to improve convergence on diverse optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_num_particles = min(100, int(np.sqrt(budget)))\n        self.num_particles = self.initial_num_particles\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        adapt_c2 = self.c2 * (1 + fitness_std)\n        \n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  adapt_c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def dynamic_particle_adjustment(self, evaluations):\n        if evaluations < self.budget / 2 and self.num_particles < self.initial_num_particles:\n            self.num_particles = min(self.num_particles + 1, self.initial_num_particles)\n        elif evaluations > self.budget / 2 and self.num_particles > 1:\n            self.num_particles = max(self.num_particles - 1, 1)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.dynamic_particle_adjustment(evaluations)\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.009267470572571268, 0.009276905795484347, 0.009271290716618474, 0.07866503427991522, 0.07875722085550796, 0.078700507639625, 0.07110818907292615, 0.07118040082324117, 0.07113638759266194]}}
{"id": "43693ff6-6d6e-41b3-bb8e-9a7da5afae8e", "fitness": 0.23946903785978624, "name": "EnhancedNAPSO", "description": "EnhancedNAPSO using dynamic topology adjustment and adaptive mutation strength to boost exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.initial_neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        mutation_strength = 0.1 * (1 - evaluations / self.budget)\n\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.initial_neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n            \n            self.velocities[i] += np.random.normal(0, mutation_strength, self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23947 with standard deviation 0.36036.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.013748217914947958, 0.009276905795484347, 0.009270865543233975, 0.9119286552736355, 0.07875722085550796, 0.07869615615326975, 0.9112298995541043, 0.07118040082324117, 0.07113301882465084]}}
{"id": "bf5790dc-8efb-4d7f-841c-abf3e19370f2", "fitness": 0.053038755353615005, "name": "ImprovedEnhancedNAPSO", "description": "Refined Improved EnhancedNAPSO by fine-tuning cognitive and social coefficients for better convergence and exploiting dynamic neighborhood strategies.", "code": "import numpy as np\n\nclass ImprovedEnhancedNAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(100, int(np.sqrt(budget)))\n        self.c1 = 1.8  # Adjusted cognitive coefficient\n        self.c2 = 2.2  # Adjusted social coefficient\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.neighbors = 5\n\n    def initialize(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_scores = np.full(self.num_particles, float('inf'))\n\n    def update_particles(self, lb, ub, evaluations):\n        w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n        fitness_std = np.std(self.personal_best_scores)\n        adapt_c1 = self.c1 * (1 - evaluations / self.budget) * (1 + fitness_std)\n        for i in range(self.num_particles):\n            particle_diversity = np.std(self.particles, axis=0).sum()\n            dynamic_neighbors = min(self.num_particles, max(1, int(self.neighbors * (1 - evaluations / self.budget))) + (1 if particle_diversity > 1 else 0))\n            neighbor_indices = np.random.choice(self.num_particles, dynamic_neighbors, replace=False)\n            local_best_index = neighbor_indices[np.argmin(self.personal_best_scores[neighbor_indices])]\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (w * self.velocities[i] +\n                                  adapt_c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                  self.c2 * r2 * (self.personal_best_positions[local_best_index] - self.particles[i]))\n\n            self.velocities[i] += np.random.normal(0, 0.1 * (1 - evaluations / self.budget), self.dim)\n\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n    def __call__(self, func):\n        lower_bound = np.array(func.bounds.lb)\n        upper_bound = np.array(func.bounds.ub)\n        self.initialize(lower_bound, upper_bound)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.particles[i])\n                evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = np.copy(self.particles[i])\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = np.copy(self.particles[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            self.update_particles(lower_bound, upper_bound, evaluations)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm ImprovedEnhancedNAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["d447a3fc-d354-4262-89c7-e8015e52c5de"], "operator": null, "metadata": {"aucs": [0.009267218330751947, 0.009276905795484347, 0.009270778529124613, 0.07866246713032199, 0.07875722085550796, 0.07869527036536739, 0.07110619876947122, 0.07118040082324117, 0.07113233758326443]}}
