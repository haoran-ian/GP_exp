{"id": "d2bcb328-2b71-4622-8d50-070de545529f", "fitness": 0.10306486744971005, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining differential evolution with adaptive local search to efficiently explore and exploit search spaces.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    step_size = (ub - lb) * 0.05\n                    local_trial = population[i] + np.random.uniform(-step_size, step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 0, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10306 with standard deviation 0.00633.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501345563234032, 0.09460976835641577, 0.10423411767082891, 0.10522770214162414, 0.10465487174385812, 0.10928748674036282, 0.11046661979085426, 0.10978359072984367]}}
{"id": "9aa035cf-3604-49bf-9a47-39cb1af40ce4", "fitness": 0.10303218876945844, "name": "HybridMetaheuristic", "description": "Enhance exploration by introducing a dynamic crossover rate adjusted based on search progress, alongside a modified local search strategy.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F = 0.8  # Differential weight\n        # Adjust CR to dynamically decrease over time\n        CR = 0.9\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust crossover probability\n            CR = 0.9 * (1 - evaluations / self.budget) + 0.1\n            \n            for i in range(population_size):\n                # Differential mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    # Enhance local search by reducing step size over time\n                    step_size = (ub - lb) * (0.05 * (1 - evaluations / self.budget))\n                    local_trial = population[i] + np.random.uniform(-step_size, step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 1, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["d2bcb328-2b71-4622-8d50-070de545529f"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501312811299756, 0.09453842634784915, 0.10423411767082891, 0.10522723597023709, 0.10455362182453365, 0.10928748674036282, 0.1104660609831104, 0.10966342703394394]}}
{"id": "3df7bc24-4b61-45ad-83ee-8b587375aa79", "fitness": 0.10303222007602146, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic integrating differential evolution, adaptive local search, and dynamic population resizing to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F = 0.8  # Differential weight\n        CR = 0.9  # Crossover probability\n        local_search_prob = 0.3  # Increased probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential mutation with dynamic scaling factor\n                scaling_factor = F * (1 - evaluations / self.budget)\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + scaling_factor * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive local search with intensified search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    step_size = (ub - lb) * 0.1 * (1 - evaluations / self.budget)\n                    local_trial = population[i] + np.random.uniform(-step_size, step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                # Dynamic population resizing\n                if evaluations % (self.budget // 10) == 0:\n                    population_size = max(5, int(population_size * 0.9))\n                    population = population[:population_size]\n                    fitness = fitness[:population_size]\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["d2bcb328-2b71-4622-8d50-070de545529f"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501319634426564, 0.09453842634784915, 0.10423411767082891, 0.10522733308536947, 0.10455362182453365, 0.10928748674036282, 0.11046617739577713, 0.10966342703394394]}}
{"id": "8f0a0a07-6b8d-416c-82a9-e2b53c760c7b", "fitness": 0.10306509915791531, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic utilizing differential evolution with dynamic adaptive local search and mutation strategies based on population diversity to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adjust mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10307 with standard deviation 0.00633.", "error": "", "parent_ids": ["d2bcb328-2b71-4622-8d50-070de545529f"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501396060381251, 0.09460976835641577, 0.10423411767082891, 0.10522842091533935, 0.10465487174385812, 0.10928748674036282, 0.11046748141951424, 0.10978359072984367]}}
{"id": "f142102b-ba9c-4cc2-9279-aed359e1950b", "fitness": 0.10306467960510989, "name": "RefinedHybridMetaheuristic", "description": "A refined hybrid metaheuristic that integrates adaptive differential evolution with an elite preservation strategy and dynamic local search to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased probability of local search\n        elitism_rate = 0.1  # Rate of elitism for preserving top individuals\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adjust mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Elitism: preserve top individuals\n            elite_count = int(elitism_rate * population_size)\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = population[elite_indices]\n\n            for i in range(population_size):\n                if i in elite_indices:\n                    continue  # Skip mutation for elite individuals\n\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Reinforce population with elite individuals\n            population[:elite_count] = elite_population\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 4, "feedback": "The algorithm RefinedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10306 with standard deviation 0.00633.", "error": "", "parent_ids": ["8f0a0a07-6b8d-416c-82a9-e2b53c760c7b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09460976835641577, 0.10423411767082891, 0.1052271194347918, 0.10465487174385812, 0.10928748674036282, 0.1104659212918101, 0.10978359072984367]}}
{"id": "f5686b41-3f86-4ea1-813d-117c7d2f863d", "fitness": 0.10306486744971005, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic using adaptive multi-strategy mutation and self-adaptive parameters to improve solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # (Changed) Probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adjust mutation and crossover rates based on diversity\n            F = F_base + 0.5 * np.tanh(5 * (0.5 - diversity))  # (Changed) Increased adaption scale\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))  # (Changed) Increased adaption scale\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))  # (Changed) Reduced step size\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10306 with standard deviation 0.00633.", "error": "", "parent_ids": ["8f0a0a07-6b8d-416c-82a9-e2b53c760c7b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501345563234032, 0.09460976835641577, 0.10423411767082891, 0.10522770214162414, 0.10465487174385812, 0.10928748674036282, 0.11046661979085426, 0.10978359072984367]}}
{"id": "4df97bb2-6643-4b28-9fb7-55cc9029acbf", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "A multi-agent adaptive hybrid metaheuristic combining differential evolution and swarm intelligence with dynamically tuned parameters to enhance global exploration and local exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["8f0a0a07-6b8d-416c-82a9-e2b53c760c7b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "5c59bbf9-5fc3-4837-8f36-8720f47d6098", "fitness": 0.1031136345302029, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "An enhanced multi-agent hybrid metaheuristic integrating a diversity-influenced mutation strategy and dynamic local search intensity to improve convergence efficiency and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and diversity influence\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]) + 0.1 * (population.mean(axis=0) - population[i]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search with dynamic intensity\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    intensity = 0.1 + 0.2 * np.exp(-5 * fitness.std() / (fitness.mean() + 1e-12))\n                    adaptive_step_size = (ub - lb) * intensity * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "82beb061-43f3-4dce-82ec-b503baf47f3d", "fitness": 0.10311335815767356, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced adaptive hybrid algorithm combining differential evolution and swarm intelligence with improved local search and dynamic parameters.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.35 * np.tanh(5 * (0.5 - diversity))  # Slightly higher adaptation\n            CR = CR_base - 0.25 * np.tanh(5 * (0.5 - diversity))  # Slightly higher adaptation\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.15 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))  # Increased step size\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465161139599565, 0.10430044169917052, 0.1052524752003805, 0.10471436248387656, 0.10936681863252051, 0.11049628630117425, 0.10985456869691179]}}
{"id": "99b39e27-0cef-4114-a7f0-baebb455e7bd", "fitness": 0.1031136345302029, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "EnhancedAdaptiveMultiAgentHybrid: An improved adaptive hybrid metaheuristic that introduces diversity-driven neighborhood search and memory-based mutation adjustments to better explore the solution space and enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        best_solution = population[np.argmin(fitness)]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Store best solution\n            memory_factor = 0.1\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and memory enhancement\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                memory_vector = memory_factor * (best_solution - population[i])\n                mutant = np.clip(mutant + memory_vector, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[np.argmin(fitness)]:\n                        best_solution = trial\n\n                # Enhanced Adaptive local search with diversity-driven neighborhood search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < fitness[np.argmin(fitness)]:\n                            best_solution = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return best_solution", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "0392360b-e6fa-4b43-8644-4bfe7f80782b", "fitness": 0.1030911896981552, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with non-linear adaptive parameter adjustments for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.35 * np.tanh(5.5 * (0.5 - diversity))  # Changed\n            CR = CR_base - 0.25 * np.tanh(5.5 * (0.5 - diversity))  # Changed\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.6 * np.sin(3 * np.pi * evaluations / self.budget)  # Changed\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.12 * (0.6 + 0.4 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))  # Changed\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10309 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.09434358378390795, 0.09502056891896127, 0.09462278114261657, 0.10428730981622203, 0.10523783155958133, 0.10467332750545355, 0.10935110487624833, 0.11047875035971289, 0.10980544932069292]}}
{"id": "788355a2-8052-489e-999f-3e2d645a7349", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "A refined adaptive hybrid metaheuristic enhancing diversity-driven dynamic parameter tuning and local search efficiency.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.6  # Adjusted base differential weight\n        CR_base = 0.85  # Adjusted base crossover probability\n        local_search_prob = 0.25  # Increased probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.35 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.15 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "8b8ccf68-5446-46bf-a05b-367c44e12c51", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with improved exploration-exploitation balance using diversity-based local search probability and mutation factor adjustment.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            # Dynamic local search probability based on diversity\n            local_search_prob = 0.1 + 0.4 * (1 - diversity)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12)) \n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "7cc1bd6e-711c-4b14-aaa7-3d2a41d0b5d0", "fitness": 0.10310868686638337, "name": "AdaptiveMultiAgentHybrid", "description": "An enhanced adaptive hybrid algorithm integrating rejection-based local search and diversity-driven parameter tuning to optimize exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))  # Adjusted adaptation strategy\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))  # Adjusted adaptation strategy\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search with rejection\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.15 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))  # Adjusted step size\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i] and np.random.rand() < 0.75:  # Added rejection-based acceptance\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.09502066901724504, 0.09465161139599565, 0.10430044169917052, 0.10523797404729474, 0.10471436248387656, 0.10936681863252051, 0.11047892893798839, 0.10985456869691179]}}
{"id": "8707f5b4-ef44-4348-b326-e411e24015f0", "fitness": 0.10311349634393824, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "EnhancedAdaptiveMultiAgentHybrid integrates a feedback loop to dynamically adjust exploration-exploitation balance and utilizes elite opposition-based learning to refine solutions.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        feedback_coefficient = 0.05\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        best_fitness = np.min(fitness)\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Elite opposition-based learning\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    elite_opposition = lb + ub - population[i]\n                    elite_opposition = np.clip(elite_opposition, lb, ub)\n                    elite_fitness = func(elite_opposition)\n                    evaluations += 1\n                    if elite_fitness < trial_fitness:\n                        population[i] = elite_opposition\n                        fitness[i] = elite_fitness\n                        best_fitness = elite_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Feedback loop to adjust local search probability\n            avg_fitness_improvement = best_fitness - np.mean(fitness)\n            local_search_prob = np.clip(local_search_prob + feedback_coefficient * avg_fitness_improvement, 0.1, 0.3)\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.0946519122763636, 0.10430044169917052, 0.1052524752003805, 0.1047147911344245, 0.10936681863252051, 0.11049628630117425, 0.1098550828423781]}}
{"id": "052f5cda-e1a7-4006-b173-bfb320807500", "fitness": 0.10311335815767356, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced multi-agent hybrid metaheuristic with dynamic parameter tuning and nonlinear diversity-driven components to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.6  # Base differential weight\n        CR_base = 0.85  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465161139599565, 0.10430044169917052, 0.1052524752003805, 0.10471436248387656, 0.10936681863252051, 0.11049628630117425, 0.10985456869691179]}}
{"id": "f8c14f17-1255-4325-9008-7d342ae1591b", "fitness": 0.10310681826646056, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "EnhancedAdaptiveMultiAgentHybrid: An improved multi-agent adaptive hybrid metaheuristic integrating a dynamic self-adaptive learning strategy and niching approach to better balance exploration and exploitation for diverse solution landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        # Niching parameters\n        niche_radius = 0.1 * np.linalg.norm(ub - lb) / np.sqrt(self.dim)\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.5 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n\n            # Dynamic self-adaptive learning\n            learning_rate = 0.1 + 0.4 * diversity\n\n            # Adaptive swarm factor\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search with niching\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * learning_rate * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                # Niching mechanism\n                for j in range(population_size):\n                    if i != j and np.linalg.norm(population[i] - population[j]) < niche_radius:\n                        population[j] = lb + np.random.rand(self.dim) * (ub - lb)\n                        fitness[j] = func(population[j])\n                        evaluations += 1\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.09501659829551257, 0.09465161139599565, 0.10430044169917052, 0.10523217759673342, 0.10471436248387656, 0.10936681863252051, 0.11047197871097691, 0.10985456869691179]}}
{"id": "90618bfe-b631-40fc-b56d-5b986e47c3f2", "fitness": 0.10311335815767356, "name": "AdaptiveMultiAgentHybrid", "description": "Improved AdaptiveMultiAgentHybrid with enhanced diversity control and adaptive local search strategies for better convergence.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.35 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.25 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465161139599565, 0.10430044169917052, 0.1052524752003805, 0.10471436248387656, 0.10936681863252051, 0.11049628630117425, 0.10985456869691179]}}
{"id": "459157e1-4cf9-46fc-9969-9d74e30c7b95", "fitness": 0.10307766298127191, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with dynamic swarm factor oscillation and improved local search randomization to boost convergence rate and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Dynamic swarm factor oscillation for improved exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(4 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Improved local search randomization\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * np.abs(np.random.standard_normal(self.dim))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10308 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.09433206239009684, 0.09501311901542753, 0.0946122271059664, 0.1042709087435153, 0.1052272230214154, 0.1046583539111351, 0.10933145071555406, 0.11046604546122474, 0.1097875764671119]}}
{"id": "0560eb68-5334-4fa7-b1e8-970ece9b5a95", "fitness": 0.10310977645420402, "name": "RefinedAdaptiveMultiAgentHybrid", "description": "A hybrid metaheuristic combining adaptive differential evolution and swarm intelligence with stochastic control of parameters and dynamic local search to improve global exploration and convergence efficiency.", "code": "import numpy as np\n\nclass RefinedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates using stochastic control\n            F = F_base + np.random.rand() * 0.2 * (1 - diversity)\n            CR = CR_base - np.random.rand() * 0.1 * diversity\n\n            # Adaptive swarm factor for stochastic search radius\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with stochastic CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search with dynamic step size\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + np.random.rand() * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 19, "feedback": "The algorithm RefinedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.09434348435741025, 0.095030852122585, 0.09465311579783542, 0.1042871768935022, 0.1052524752003805, 0.10471650573661662, 0.10935095225408897, 0.11049628630117425, 0.10985713942424302]}}
{"id": "d37b26ac-b817-472c-87ab-a16f28fe5696", "fitness": 0.10311009030608588, "name": "RefinedAdaptiveHybrid", "description": "A refined adaptive hybrid optimizer enhancing global and local search through dynamic parameter tuning and neighborhood search to improve convergence and solution quality.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Increased probability of performing local search\n        neighborhood_radius = 0.05  # Neighborhood search radius factor\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        \n                # Neighborhood search for local refinement\n                if evaluations < self.budget:\n                    neighborhood_step = neighborhood_radius * (ub - lb)\n                    neighborhood_trial = population[i] + np.random.uniform(-neighborhood_step, neighborhood_step)\n                    neighborhood_trial = np.clip(neighborhood_trial, lb, ub)\n                    neighborhood_fitness = func(neighborhood_trial)\n                    evaluations += 1\n                    if neighborhood_fitness < fitness[i]:\n                        population[i] = neighborhood_trial\n                        fitness[i] = neighborhood_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 20, "feedback": "The algorithm RefinedAdaptiveHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095023729768277, 0.09465161139599565, 0.10430044169917052, 0.10524233289414509, 0.10471436248387656, 0.10936681863252051, 0.11048414029742859, 0.10985456869691179]}}
{"id": "41f7a3ec-253c-4d11-96fe-8201ac68aee0", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "A slightly refined version of a multi-agent hybrid metaheuristic, now with an increased local search probability to enhance local exploitation capability.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Probability of performing local search (increased slightly)\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "6dca82d2-1a14-4a97-b174-a7b28c829dd0", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "An enhanced adaptive hybrid metaheuristic integrating dynamic group topology and modified local search tactics to boost convergence rate and solution precision.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                \n                # Enhanced Adaptive local search with dynamic step size\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "72c72d14-7ba4-46c5-92d8-26b80a7b6040", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "Refined multi-agent adaptive hybrid metaheuristic with enhanced mutation strategy and dynamic local search intensity for improved optimization performance.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Probability of performing local search (changed)\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c] + population[i] - population[a])) # Enhanced mutation strategy (changed)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "855794aa-9098-44c8-aeb8-ad9c90168c35", "fitness": 0.1031136345302029, "name": "AdaptiveMultiAgentHybrid", "description": "Refined adaptive hybrid algorithm enhancing local search through diversity-aware step size and stochastic perturbation.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (1.0 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    stochastic_perturbation = np.random.normal(0, 0.1, self.dim)\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size) + stochastic_perturbation\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "bf84fe29-7ca3-40e9-af57-55adb5134c1a", "fitness": 0.10307989214112402, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with dynamic allocation of local search probability and swarm factor modulation for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Dynamic swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(4 * np.pi * evaluations / self.budget)\n\n            # Dynamic local search probability based on diversity\n            dynamic_local_search_prob = local_search_prob + 0.1 * np.tanh(5 * (0.5 - diversity))\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search with dynamic probability\n                if np.random.rand() < dynamic_local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10308 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.09433206239009684, 0.09501797589630367, 0.0946122271059664, 0.1042709087435153, 0.10523413796093917, 0.1046583539111351, 0.10933145071555406, 0.11047433607949375, 0.1097875764671119]}}
{"id": "cb0c2851-dfd5-44d3-ae64-9c180fd3e43a", "fitness": 0.10310772796961608, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "EnhancedAdaptiveMultiAgentHybrid refines adaptive parameters and introduces chaotic local perturbations to improve exploration while maintaining exploitation efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity)) + 0.1 * np.random.uniform(-1, 1)\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity)) + 0.05 * np.random.uniform(-1, 1)\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search with chaotic perturbation\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    chaotic_factor = np.random.uniform(-1, 1, size=self.dim)\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size) * chaotic_factor\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00633.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.09434348435741025, 0.09502729094543094, 0.09465221315673156, 0.1042871768935022, 0.10524740404726285, 0.10471521978497245, 0.10935095225408897, 0.11049021329930131, 0.1098555969878442]}}
{"id": "41d716b4-4424-4a5c-b713-3fcb1bf55f98", "fitness": 0.1031114130665615, "name": "RefinedAdaptiveHybrid", "description": "A refined adaptive hybrid metaheuristic integrating a diversity-enhanced differential evolution with swarm-inspired dynamic tuning, emphasizing convergence speed and solution precision.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.6  # Adjusted base differential weight for more exploration\n        CR_base = 0.8  # Adjusted crossover probability to improve solution precision\n        local_search_prob = 0.3  # Increased local search probability for finer local tuning\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.1 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.6 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 27, "feedback": "The algorithm RefinedAdaptiveHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.09435150349888843, 0.09502791235366925, 0.09465161139599565, 0.10429858508068324, 0.1052482874403522, 0.10471436248387656, 0.10936459969638634, 0.11049128695229005, 0.10985456869691179]}}
{"id": "3166b612-3180-49fc-9803-e116ddf89f84", "fitness": 0.1031136345302029, "name": "ImprovedAdaptiveMultiAgent", "description": "ImprovedAdaptiveMultiAgent utilizes adaptive learning rates and dynamic population strategies to enhance convergence speed and solution accuracy in complex optimization landscapes.", "code": "import numpy as np\n\nclass ImprovedAdaptiveMultiAgent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        \n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (1 - diversity)\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 28, "feedback": "The algorithm ImprovedAdaptiveMultiAgent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465221315673156, 0.10430044169917052, 0.1052524752003805, 0.10471521978497245, 0.10936681863252051, 0.11049628630117425, 0.1098555969878442]}}
{"id": "ace5a04b-cc75-4e28-9bd1-93e86476b982", "fitness": 0.10311391090273231, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with adaptive population size adjustment to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["4df97bb2-6643-4b28-9fb7-55cc9029acbf"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465281491746746, 0.10430044169917052, 0.1052524752003805, 0.10471607708606856, 0.10936681863252051, 0.11049628630117425, 0.10985662527877671]}}
{"id": "238d4e46-ea88-4338-8ef2-7bb82f706ef9", "fitness": 0.10311391090273231, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "A novel adaptable multi-agent hybrid algorithm that introduces a dynamic local search strategy based on fitness distribution to enhance exploration and convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n            \n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            population_size = min(max(5, int(np.clip(population_size * (1.1 - diversity), 5, 50))), 50)\n            \n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                \n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (1 + np.abs((fitness.mean() - fitness[i]) / (fitness.std() + 1e-12)))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                \n                if evaluations >= self.budget:\n                    break\n        \n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["ace5a04b-cc75-4e28-9bd1-93e86476b982"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465281491746746, 0.10430044169917052, 0.1052524752003805, 0.10471607708606856, 0.10936681863252051, 0.11049628630117425, 0.10985662527877671]}}
{"id": "b02653b5-540b-46f9-a160-1a64873014ea", "fitness": 0.10303215120246646, "name": "EnhancedMultiAgentHybrid", "description": "Improved AdaptiveMultiAgentHybrid with dynamic learning rate adjustments and ensemble mutation strategies for superior exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        # Initialize adaptive learning rate factor\n        learning_rate = 0.1\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + learning_rate * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - learning_rate * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            for i in range(population_size):\n                # Ensemble mutation strategies\n                idx_pool = list(range(population_size))\n                idx_pool.remove(i)\n                a, b, c = np.random.choice(idx_pool, 3, replace=False)\n\n                # Combining different mutation strategies\n                mutant1 = population[a] + F * (population[b] - population[c])\n                mutant2 = population[a] - F * (population[b] - population[c])\n                mutant = np.where(np.random.rand(self.dim) < 0.5, mutant1, mutant2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update learning rate factor based on fitness improvement\n            fitness_improvement = np.abs(fitness[i] - trial_fitness) / (fitness[i] + 1e-12)\n            learning_rate = 0.1 + 0.05 * np.clip(fitness_improvement, 0, 1)\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["ace5a04b-cc75-4e28-9bd1-93e86476b982"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "431af80d-ffd3-4d2f-83d9-5cab2eb6dbdb", "fitness": -Infinity, "name": "AdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with dynamic population size and self-adaptive local search for improved convergence and diversity management.", "code": "import numpy as np\n\nclass AdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        initial_population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(initial_population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = initial_population_size\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt mutation and crossover rates based on diversity\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor to enhance exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size dynamically based on fitness variance\n            fitness_variance = np.var(fitness)\n            population_size = min(max(5, int(initial_population_size * (1 + 0.5 * (fitness_variance / (fitness_variance + 1e-12))))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Self-adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size, self.dim)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        best_index = np.argmin(fitness)\n        return population[best_index]", "configspace": "", "generation": 32, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 14')", "parent_ids": ["ace5a04b-cc75-4e28-9bd1-93e86476b982"], "operator": null, "metadata": {}}
{"id": "dbf4c758-6826-494f-bac0-30f1a607b63b", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced DynamicAdaptiveMultiAgentHybrid with multi-phase adaptation and elite preservation strategy to improve convergence efficiency and exploration robustness.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 33, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["ace5a04b-cc75-4e28-9bd1-93e86476b982"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "1b584a50-f35f-4466-9ef9-4191d2a9e0ee", "fitness": 0.10307462546590301, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced DynamicAdaptiveMultiAgentHybrid with improved local search strategy and adaptive mutation factor for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = 10 + 2 * self.dim\n        F_base = 0.6  # Adjusted base differential weight\n        CR_base = 0.8  # Adjusted base crossover probability\n        local_search_prob = 0.3  # Increased probability of performing local search\n        \n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.25 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.15 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.15 * np.cos(phase_ratio * np.pi)\n\n            swarm_factor = 0.6 + 0.4 * np.sin(3 * np.pi * evaluations / self.budget)\n            \n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.15 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 34, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10307 with standard deviation 0.00633.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09463155820784941, 0.10423411767082891, 0.1052271194347918, 0.10468581069575522, 0.10928748674036282, 0.1104659212918101, 0.10982037467365102]}}
{"id": "12d97f57-1957-4b2e-a908-54673162a31a", "fitness": 0.10311050486487994, "name": "EnhancedAdaptiveSwarmOptimization", "description": "Introducing an Enhanced Adaptive Multi-phase Swarm Optimization Algorithm with Progressive Exploration-Exploitation Balancing and Dynamic Strategy Transitions for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        exploration_prob = 0.3\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Dynamically adjust strategies based on progress and diversity\n            phase_ratio = evaluations / self.budget\n            F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n\n            # Progressive exploration-exploitation balancing\n            exploration_factor = 0.5 + 0.5 * np.sin(2 * np.pi * phase_ratio)\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = exploration_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < exploration_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00633.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095023729768277, 0.0946525140370994, 0.10430044169917052, 0.10524233289414509, 0.10471564843552061, 0.10936681863252051, 0.11048414029742859, 0.10985611113331051]}}
{"id": "a337403e-d75b-42d7-b0a5-3ca3764a5b32", "fitness": 0.10303215120246646, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced DynamicAdaptiveMultiAgentHybrid with an adaptive inertia mechanism and a neighborhood-based strategy to further boost convergence and exploration capabilities.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.25 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.15 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.05 * np.cos(phase_ratio * np.pi)\n            \n            # Adaptive inertia weight mechanism\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = int(population_size * (1.0 + 0.3 * np.sin(2 * np.pi * evaluations / self.budget)))\n            population_size = min(max(5, population_size), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and inertia\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = inertia_weight * population[i] + (1 - inertia_weight) * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Neighborhood-based local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    neighbor_indices = np.random.choice(indices, 2, replace=False)\n                    local_direction = population[neighbor_indices[0]] - population[neighbor_indices[1]]\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size) * local_direction\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 36, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "bccbdca3-f8d4-464d-96be-7d64802af6de", "fitness": 0.103114049088997, "name": "OptimizedDynamicAdaptiveMultiAgentHybrid", "description": "Optimized DynamicAdaptiveMultiAgentHybrid with adaptive clustering and context-aware mutation to enhance exploration-exploitation balance and convergence precision.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass OptimizedDynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        cluster_factor = 5 # Number of clusters for context awareness\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adaptive clustering for context-aware mutation\n            num_clusters = max(2, population_size // cluster_factor)\n            kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(population)\n            cluster_centroids = kmeans.cluster_centers_\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and context awareness\n                cluster_idx = kmeans.labels_[i]\n                local_indices = np.where(kmeans.labels_ == cluster_idx)[0]\n                if len(local_indices) < 3:\n                    local_indices = np.random.choice(range(population_size), 3, replace=False)\n                else:\n                    np.random.shuffle(local_indices)\n\n                a, b, c = local_indices[:3]\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 37, "feedback": "The algorithm OptimizedDynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "92fc8f51-82ea-4715-ac82-c567c7eb0fec", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Introduced DynamicAdaptiveMultiAgentHybrid with adaptive learning rate control and dynamic local search intensification to enhance convergence precision and solution refinement.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        learning_rate = 0.1  # Initial learning rate\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            # Dynamic learning rate control\n            learning_rate = 0.1 + 0.4 * diversity\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search with dynamic intensification\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = learning_rate * (ub - lb) * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 38, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "96543080-affd-4d88-8db7-7f03d64ca6b9", "fitness": 0.10304322249618786, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Advanced DynamicAdaptiveMultiAgentHybrid integrates chaotic map initialization and adaptive restart to enhance global exploration and local exploitation efficiency.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased probability for local search\n        \n        # Chaotic initialization\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        chaos_map = np.random.rand(population_size, self.dim)\n        population = lb + (ub - lb) * chaos_map\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n            \n            # Adaptive restart mechanism\n            if np.random.rand() < 0.05:\n                chaos_map = np.random.rand(population_size, self.dim)\n                population = lb + (ub - lb) * chaos_map\n                fitness = np.array([func(ind) for ind in population])\n                evaluations += population_size\n                elite = population[np.argmin(fitness)]\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 39, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10304 with standard deviation 0.00632.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501361941868647, 0.09456227699663966, 0.10423411767082891, 0.10522793528135943, 0.10458741608837996, 0.10928748674036282, 0.1104668992723814, 0.10970305675578962]}}
{"id": "ff81ddfc-6b34-41ba-93ca-2388a7d2da25", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced mutation strategy with dynamic scaling factor and refined crossover mechanism for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c])) + 0.01 * (population[i] - elite)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 40, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "35704231-1c7a-43c8-887f-8a5bd49da863", "fitness": -Infinity, "name": "AdvancedDynamicAdaptiveMultiAgentHybrid", "description": "AdvancedDynamicAdaptiveMultiAgentHybrid with self-adaptive parameter control and feedback-driven diversification to enhance solution convergence and maintain exploration balance.", "code": "import numpy as np\n\nclass AdvancedDynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Self-adaptive strategies with feedback\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity)) * np.random.uniform(0.8, 1.2)\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity)) * np.random.uniform(0.8, 1.2)\n\n            # Adaptive exploration-exploitation balance\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget) * (1 - phase_ratio)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.2 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 41, "feedback": "An exception occurred: NameError(\"name 'phase_ratio' is not defined\").", "error": "NameError(\"name 'phase_ratio' is not defined\")", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {}}
{"id": "0ee65624-80fb-4acd-b481-674160caae49", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Incorporate adaptive mutation scaling for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                adaptive_F = F * (1 + 0.1 * np.cos(2 * np.pi * evaluations / self.budget))\n                mutant = swarm_factor * (population[a] + adaptive_F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 42, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "dc421d89-478d-4b3e-a8e6-29712bba1d60", "fitness": 0.10311377271646761, "name": "EnhancedDynamicAdaptiveMultiAgentHybrid", "description": "Introduce multi-objective-based dynamic adaptation using fitness diversity and convergence speed to enhance exploration-exploitation balance and improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        prev_best_fitness = min(fitness)\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Calculate convergence speed\n            current_best_fitness = min(fitness)\n            convergence_speed = (prev_best_fitness - current_best_fitness) / (prev_best_fitness + 1e-12)\n            prev_best_fitness = current_best_fitness\n\n            # Multi-objective adaptation based on diversity and convergence speed\n            dynamic_factor = 0.5 * (diversity + np.abs(convergence_speed))\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - dynamic_factor))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - dynamic_factor))\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedDynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.0946525140370994, 0.10430044169917052, 0.1052524752003805, 0.10471564843552061, 0.10936681863252051, 0.11049628630117425, 0.10985611113331051]}}
{"id": "47586037-c378-46e6-82de-de0a33b3ec39", "fitness": 0.10308422874214876, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Augmented DynamicAdaptiveMultiAgentHybrid with enhanced phase-specific adaptation and stochastic local search diversification to improve exploitation-exploration balance and convergence stability.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.25  # Modified for better local exploitation\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n        \n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n            phase_ratio = evaluations / self.budget\n            \n            if phase_ratio < 0.5:\n                F = F_base + 0.4 * np.tanh(4 * (0.5 - diversity))  # Adjusted dynamics\n                CR = CR_base - 0.15 * np.tanh(4 * (0.5 - diversity))\n            else:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.05 * np.cos(phase_ratio * np.pi)\n\n            swarm_factor = 0.5 + 0.6 * np.sin(3 * np.pi * evaluations / self.budget)  # Adjusted frequency\n            population_size = min(max(5, int(population_size * (1.05 - diversity))), 50)\n            \n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n                \n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.08 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size, self.dim)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 44, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10308 with standard deviation 0.00633.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501978563877311, 0.0946457561653622, 0.10423411767082891, 0.10523671615797858, 0.10470602250766825, 0.10928748674036282, 0.11047741288859536, 0.10984456666850717]}}
{"id": "15ecdb99-2c8c-49f8-ab60-8e79f53ca875", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Refined DynamicAdaptiveMultiAgentHybrid with improved adaptation strategy, enhanced local search using gradient direction, and adjusted probabilistic parameters for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.6  # Base differential weight (changed)\n        CR_base = 0.85  # Base crossover probability (changed)\n        local_search_prob = 0.25  # Probability of performing local search (changed)\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(4 * (0.5 - diversity))  # Adjusted factor\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.55 + 0.45 * np.sin(2 * np.pi * evaluations / self.budget)  # Adjusted factor\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    gradient = (population[i] - elite) / (np.linalg.norm(population[i] - elite) + 1e-12)  # New gradient direction\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] - gradient * adaptive_step_size\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 45, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "f3ab8487-cf1d-4027-9ad7-212ee1132841", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhance exploitation by refining trial vector acceptance criteria to consider both fitness improvement and diversity contribution.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i] or (np.random.rand() < diversity):  # Change: consider both fitness improvement and diversity\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 46, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "0d7f652f-d716-430b-90a0-613fde35fe9e", "fitness": 0.10311377271646761, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced DynamicAdaptiveMultiAgentHybrid with hierarchical strategy layers, adaptive local-global balance, and diversity-driven mutation for improved adaptability and performance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Hierarchical strategy layers and adaptive phase control\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.2 * np.exp(-diversity)\n                CR = CR_base - 0.15 * np.exp(-diversity)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Diversity-driven mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 47, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.0946525140370994, 0.10430044169917052, 0.1052524752003805, 0.10471564843552061, 0.10936681863252051, 0.11049628630117425, 0.10985611113331051]}}
{"id": "b4dbc62f-f5fc-491d-a8e3-02b0067b1225", "fitness": 0.10307266850281209, "name": "HybridQuantumInspiredPSO", "description": "Hybrid Quantum-inspired Particle Swarm Optimization with Adaptive Differential Evolution and Elite Reinforcement to enhance convergence dynamics and exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim \n        F_base = 0.5  \n        CR_base = 0.9  \n        quantum_prob = 0.3  \n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        velocities = np.random.rand(population_size, self.dim) * (ub - lb) * 0.1\n        \n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adaptive parameters\n            phase_ratio = evaluations / self.budget\n            F = F_base + 0.2 * np.sin(phase_ratio * np.pi)\n            CR = CR_base - 0.2 * np.sin(phase_ratio * np.pi)\n\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size and add quantum behavior\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n            quantum_indices = np.random.rand(population_size) < quantum_prob\n\n            for i in range(population_size):\n                if quantum_indices[i]:\n                    q_mutant = elite + np.random.randn(self.dim) * (diversity + 0.1)\n                    q_mutant = np.clip(q_mutant, lb, ub)\n                    q_fitness = func(q_mutant)\n                    evaluations += 1\n                    if q_fitness < fitness[i]:\n                        population[i] = q_mutant\n                        fitness[i] = q_fitness\n                        if q_fitness < func(elite):\n                            elite = q_mutant\n                    continue\n\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n            # Update velocities and positions in PSO style\n            personal_best = population[np.argmin(fitness)]\n            velocities = 0.5 * velocities + 0.5 * np.random.rand(population_size, self.dim) * (personal_best - population)\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            if evaluations >= self.budget:\n                break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 48, "feedback": "The algorithm HybridQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10307 with standard deviation 0.00633.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09433115371514966, 0.09502016859112317, 0.09459504634649352, 0.10426962698351017, 0.10523726174102721, 0.1046339977719295, 0.10932996978466814, 0.11047806729555565, 0.10975872429585176]}}
{"id": "30afbb75-0c16-4e7a-b855-aad5ae1213e0", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced exploration by adjusting local search probability based on population diversity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < (local_search_prob + 0.3 * (1 - diversity)) and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 49, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "9b08207e-3a44-4d79-a457-28b2d3cb0de5", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "AdvancedDynamicAdaptiveHybrid: Combines phase-based adaptation with a dynamic neighborhood-based search for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                np.random.shuffle(indices)\n                a, b, c = indices[:3]\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    neighbors = np.random.choice(range(population_size), 3, replace=False)\n                    local_search_step = (population[neighbors[0]] - population[neighbors[1]]) * np.random.rand()\n                    local_trial = population[i] + local_search_step\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 50, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "cd9381cf-bf67-4d6b-8b05-0718715e0ccc", "fitness": 0.1030826300388391, "name": "EnhancedDynamicAdaptiveMultiAgentHybrid", "description": "Introduced multi-modal exploration and dynamic feedback-driven parameter tuning for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Probability of performing local search\n        multi_modality_factor = 0.1\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Dynamic feedback-driven strategy adaptation\n            phase_ratio = evaluations / self.budget\n            feedback = np.tanh(5 * (0.5 - diversity))\n            F = F_base + 0.3 * feedback * (1 - phase_ratio)\n            CR = CR_base - 0.2 * feedback * phase_ratio\n\n            # Adaptive swarm factor considering multi-modal exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            multi_mode_explore = (np.random.rand() < multi_modality_factor)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                # Multi-modal exploration\n                if multi_mode_explore and evaluations < self.budget:\n                    random_shift = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    multi_trial = population[i] + random_shift\n                    multi_trial = np.clip(multi_trial, lb, ub)\n                    multi_fitness = func(multi_trial)\n                    evaluations += 1\n                    if multi_fitness < fitness[i]:\n                        population[i] = multi_trial\n                        fitness[i] = multi_fitness\n                        if multi_fitness < func(elite):\n                            elite = multi_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedDynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10308 with standard deviation 0.00633.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09458430212784352, 0.10430044169917052, 0.1052524752003805, 0.1046187753893667, 0.10936681863252051, 0.11049628630117425, 0.10974091199006364]}}
{"id": "1a083a04-99b6-4f9e-b055-220239cbd085", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Refined mutation mechanism in the Differential Evolution strategy to enhance convergence speed and solution accuracy while maintaining exploration capabilities.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with refined F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]) + 0.1 * (elite - population[i]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 52, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "2b868a93-7a03-4850-a368-970ec3529fc9", "fitness": 0.10303217624712778, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced DynamicAdaptiveMultiAgentHybrid with adaptive learning rate and hybrid mutation strategies to optimize exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.25  # Adjusted local search probability\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            dynamic_factor = np.tanh(5 * (0.5 - diversity))\n            if phase_ratio < 0.5:\n                F = F_base + 0.25 * dynamic_factor\n                CR = CR_base - 0.15 * dynamic_factor\n            else:\n                F = F_base + 0.15 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.15 * np.cos(phase_ratio * np.pi)\n\n            swarm_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Hybrid mutation strategy\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                if np.random.rand() < 0.5:\n                    mutant += np.random.uniform(-F, F, self.dim) * (elite - population[i])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 53, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501310082093684, 0.09453842634784915, 0.10423411767082891, 0.10522719712508866, 0.10455362182453365, 0.10928748674036282, 0.11046601441934367, 0.10966342703394394]}}
{"id": "8c90c960-7ec6-4833-9a63-1e481f24253d", "fitness": 0.10311377271646761, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "DynamicAdaptiveMultiAgentHybrid with Dynamic Parameter Tuning and Adaptive Learning Phase to balance exploration-exploitation and accelerate convergence.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Dynamic parameter tuning\n            phase_ratio = evaluations / self.budget\n            F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adaptive learning phase switch\n            if phase_ratio < 0.3:\n                learning_rate = 0.1 + 0.4 * phase_ratio\n            elif phase_ratio < 0.7:\n                learning_rate = 0.3 + 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                learning_rate = 0.5 * (1 - np.sin(phase_ratio * np.pi))\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * learning_rate * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 54, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.0946525140370994, 0.10430044169917052, 0.1052524752003805, 0.10471564843552061, 0.10936681863252051, 0.11049628630117425, 0.10985611113331051]}}
{"id": "e2fc5503-9c1d-41cc-805d-969d3441b99a", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Adaptive Dynamic Agent Hybrid with phase-based learning rates and enhanced elite selection for improved robustness and convergence.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.4 * np.tanh(6 * (0.4 - diversity))\n                CR = CR_base - 0.3 * np.tanh(4 * (0.6 - diversity))\n            else:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.15 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.6 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.05 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.6 + 0.4 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 55, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "d80623c1-41b3-4a13-aff4-d993a45adb39", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Introduced adaptive learning rate and neighborhood-based selection to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        \n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                # Added: Select neighbors for mutation\n                neighbors = np.random.choice(indices, 5, replace=False)\n                a, b, c = neighbors[:3]\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    # Modified: Adaptive step size based on learning rate\n                    learning_rate = 0.05 + 0.45 * np.exp(-evaluations/self.budget)\n                    adaptive_step_size = (ub - lb) * learning_rate * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 56, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "9d273836-38d1-4c55-ac0f-bcca6a54934c", "fitness": 0.10311335815767356, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced Dynamic Adaptive Multi-Agent Hybrid with an adaptive mutation strategy and fitness-based dynamic population sizing to boost exploitation and exploration balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            F = F_base + (0.3 if phase_ratio < 0.5 else 0.1) * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - (0.2 if phase_ratio < 0.5 else 0.1) * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Dynamic population size based on fitness\n            population_size = min(max(5, int(population_size * (1 + 0.1 * (fitness.std() / (fitness.mean() + 1e-12))))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 57, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465161139599565, 0.10430044169917052, 0.1052524752003805, 0.10471436248387656, 0.10936681863252051, 0.11049628630117425, 0.10985456869691179]}}
{"id": "9871c064-977c-4fcb-8233-e09d58513280", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Introduced dynamic adaptation of local search probability and enhanced adaptive exploration/exploitation based on population convergence metrics.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        # Begin change: line 1\n        local_search_prob = 0.2  # Initial probability of performing local search\n        # End change: line 1\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Begin change: lines 2-3\n            # Dynamic local search probability\n            local_search_prob = 0.1 + 0.4 * (1 - diversity)\n            # End change: lines 2-3\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            # Begin change: line 4\n            population_size = min(max(5, int(population_size * (1.05 - diversity))), 50)  \n            # End change: line 4\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    # Begin change: lines 5-9\n                    adaptive_step_size = (ub - lb) * 0.05 * (1 + np.tanh(fitness.std()))  \n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    # End change: lines 5-9\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 58, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "da8b08e7-e365-46d7-bc42-b2f1bdf98271", "fitness": 0.10311335815767356, "name": "AdvancedHybridOptimizer", "description": "Advanced Hybrid Optimization with Adaptive Resource Allocation and Diversity-Driven Exploitation leveraging feedback loops for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass AdvancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n\n        # Initialize adaptive parameters\n        local_search_base_prob = 0.2\n        exploit_prob = 0.1\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on diversity feedback\n            if diversity < 0.3:\n                F = F_base * 1.2\n                CR = CR_base * 0.8\n                local_search_prob = local_search_base_prob * 1.5\n            else:\n                F = F_base\n                CR = CR_base\n                local_search_prob = local_search_base_prob\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively based on diversity\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search with exploitation feedback\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                # Additional exploitation phase inspired by diversity\n                if np.random.rand() < exploit_prob and evaluations < self.budget:\n                    direction = (elite - population[i])\n                    exploit_step = np.random.rand() * direction\n                    exploit_trial = population[i] + exploit_step\n                    exploit_trial = np.clip(exploit_trial, lb, ub)\n                    exploit_fitness = func(exploit_trial)\n                    evaluations += 1\n                    if exploit_fitness < fitness[i]:\n                        population[i] = exploit_trial\n                        fitness[i] = exploit_fitness\n                        if exploit_fitness < func(elite):\n                            elite = exploit_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465161139599565, 0.10430044169917052, 0.1052524752003805, 0.10471436248387656, 0.10936681863252051, 0.11049628630117425, 0.10985456869691179]}}
{"id": "6f0351df-65fb-47c9-8b18-3f687fc68e4f", "fitness": -Infinity, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Optimized DynamicAdaptiveMultiAgentHybrid using stochastic rank-based selection and diversity preservation to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate diversity metrics\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n            \n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Stochastic rank-based selection\n                rank_indices = np.argsort(fitness)\n                probabilities = np.exp(-np.arange(population_size) / population_size)\n                probabilities /= probabilities.sum()\n                selected_indices = np.random.choice(rank_indices, 3, replace=False, p=probabilities)\n                a, b, c = selected_indices\n\n                # Differential mutation with adaptive F\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 60, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {}}
{"id": "3c7c38dc-dd32-45b6-b806-584450a2e31b", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "An improved DynamicAdaptiveMultiAgentHybrid with dynamic elite acceleration and variable neighborhood search to enhance convergence precision and robustness.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.2\n        elite_accel_factor = 0.05  # Factor to accelerate elite exploration\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n            \n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                # Dynamic elite acceleration\n                if evaluations < self.budget:\n                    elite_trial = elite + np.random.uniform(-elite_accel_factor, elite_accel_factor, size=self.dim) * (ub - lb)\n                    elite_trial = np.clip(elite_trial, lb, ub)\n                    elite_fitness = func(elite_trial)\n                    evaluations += 1\n                    if elite_fitness < func(elite):\n                        elite = elite_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 61, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "8e09e1b7-f315-45b8-9096-9ce542459da2", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Fine-tune differential mutation and crossover using diversity- and fitness-based adaptations to enhance convergence and maintain exploration.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_adapt = F * (1 + 0.2 * (fitness[i] - fitness.min()) / (fitness.max() - fitness.min() + 1e-12))\n                mutant = swarm_factor * (population[a] + F_adapt * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                CR_adapt = CR * (1 - 0.1 * (fitness[i] - fitness.min()) / (fitness.max() - fitness.min() + 1e-12))\n                crossover = np.random.rand(self.dim) < CR_adapt\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 62, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "6509c312-ab9e-4e89-88ec-a99887549637", "fitness": 0.10303215120246646, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Improved DynamicAdaptiveMultiAgentHybrid with enhanced elite exploitation and diversified mutation strategies for better convergence and exploration balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 15 + 3 * self.dim  # Increased population size for diversity\n        F_base = 0.6  # Adjusted differential weight for better exploration\n        CR_base = 0.8  # Adjusted crossover probability for diversity\n        local_search_prob = 0.3  # Increased probability for local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.2 * np.sin(phase_ratio * np.pi)  # Enhanced exploration in later stages\n                CR = CR_base - 0.15 * np.sin(phase_ratio * np.pi)  # Enhanced exploration in later stages\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evaluations / self.budget)  # Adjusted for better balance\n            \n            # Adjust population size adaptively\n            population_size = min(max(10, int(population_size * (1.05 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with more diversified F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.15 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))  # Adjusted local search step size\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 63, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "94e637db-e77c-4dbf-a116-4b16d68a12ff", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Enhanced DynamicAdaptiveMultiAgentHybrid with phase-specific mutation strategies and adaptive crossover scaling to refine global search dynamics and improve convergence accuracy.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased local search probability\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.15 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.15 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.05 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.05 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 64, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "ac05d1dd-5f15-4a61-a346-03342dec9981", "fitness": 0.103114049088997, "name": "EnhancedAdaptiveMultiAgentHybrid", "description": "Enhanced AdaptiveMultiAgentHybrid with diversity-driven operator selection and adaptive phase modulation for improved exploration-exploitation balance and faster convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Diversity-driven selection of operators\n            if diversity > 0.4:\n                swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            else:\n                swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "d881b1fb-0f56-48d3-a7f6-3d32189d0890", "fitness": 0.103114049088997, "name": "DynamicAdaptiveElitePreservingHybrid", "description": "DynamicAdaptiveElitePreservingHybrid with enhanced exploration and dynamic local search to boost convergence and maintain diversity.", "code": "import numpy as np\n\nclass DynamicAdaptiveElitePreservingHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.4:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.15 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.15 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 66, "feedback": "The algorithm DynamicAdaptiveElitePreservingHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "64f02a85-cc80-4088-9cca-295eea149364", "fitness": 0.103114049088997, "name": "HybridEvolutionaryAdaptiveOptimization", "description": "Hybrid Evolutionary Adaptive Optimization with multi-phase strategy and swarm learning for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridEvolutionaryAdaptiveOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        init_population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        elite_preservation_ratio = 0.05  # Ratio of elite individuals preserved\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(init_population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = init_population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.2 * (1 - diversity) * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * (1 - diversity) * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            preserved_elites = int(elite_preservation_ratio * init_population_size)\n            population_size = min(max(5, int(init_population_size * (1.1 - diversity))), 50)\n            population_size = max(population_size, preserved_elites + 2)\n\n            # Preserve top elite individuals\n            elite_indices = np.argsort(fitness)[:preserved_elites]\n            new_population = population[elite_indices].copy()\n            new_fitness = fitness[elite_indices].copy()\n\n            while len(new_population) < population_size:\n                for i in range(len(population) - preserved_elites):\n                    # Differential mutation with adaptive F\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                    mutant = np.clip(mutant, lb, ub)\n\n                    # Crossover with adaptive CR\n                    crossover = np.random.rand(self.dim) < CR\n                    trial = np.where(crossover, mutant, population[i])\n\n                    # Evaluate trial vector\n                    trial_fitness = func(trial)\n                    evaluations += 1\n                    if trial_fitness < fitness[i]:\n                        new_population = np.vstack((new_population, trial))\n                        new_fitness = np.append(new_fitness, trial_fitness)\n                        if trial_fitness < func(elite):\n                            elite = trial\n\n                    # Enhanced Adaptive local search\n                    if np.random.rand() < local_search_prob and evaluations < self.budget:\n                        adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                        local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                        local_trial = np.clip(local_trial, lb, ub)\n                        local_fitness = func(local_trial)\n                        evaluations += 1\n                        if local_fitness < fitness[i]:\n                            new_population = np.vstack((new_population, local_trial))\n                            new_fitness = np.append(new_fitness, local_fitness)\n                            if local_fitness < func(elite):\n                                elite = local_trial\n\n                    if evaluations >= self.budget or len(new_population) >= population_size:\n                        break\n\n            population = new_population\n            fitness = new_fitness\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 67, "feedback": "The algorithm HybridEvolutionaryAdaptiveOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "98a7490d-3a7c-4aeb-9beb-1982f4b73300", "fitness": 0.1030488377534689, "name": "AdaptiveEliteMultiAgentOptimization", "description": "AdaptiveEliteMultiAgentOptimization focuses on enhancing exploration and exploitation balance by introducing an elite guiding mechanism and dynamic parameter adaptation based on current solution quality.", "code": "import numpy as np\n\nclass AdaptiveEliteMultiAgentOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with elite guidance and adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = elite + F * (population[a] - population[b]) + F_base * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with elite influence and adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (1.0 - phase_ratio) * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveEliteMultiAgentOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10305 with standard deviation 0.00632.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09434261292653157, 0.09501304623681539, 0.09453842634784915, 0.10428592403415693, 0.1052271194347918, 0.10455362182453365, 0.10934944065078755, 0.1104659212918101, 0.10966342703394394]}}
{"id": "8b16f384-0612-4fca-9c73-f32f202b6952", "fitness": 0.10311335815767356, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Refined DynamicAdaptiveMultiAgentHybrid with probabilistic self-adaptive mutation and crossover rates, and segment-based local search for enhanced convergence and exploration.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.2  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies using probabilistic self-adaptive rates\n            phase_ratio = evaluations / self.budget\n            F = F_base + np.random.rand() * 0.3 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - np.random.rand() * 0.2 * np.tanh(5 * (0.5 - diversity))\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced segment-based local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    segment_indices = np.random.choice(self.dim, size=max(1, self.dim // 10), replace=False)\n                    local_trial = population[i].copy()\n                    for idx in segment_indices:\n                        adaptive_step_size = (ub[idx] - lb[idx]) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                        local_trial[idx] += np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 69, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465161139599565, 0.10430044169917052, 0.1052524752003805, 0.10471436248387656, 0.10936681863252051, 0.11049628630117425, 0.10985456869691179]}}
{"id": "9c145f91-78f0-46ca-9109-01b0f91a7744", "fitness": 0.103114049088997, "name": "DynamicAdaptiveMultiAgentHybrid", "description": "Improved Elite-Preserving Dynamic Adaptive Multi-Agent Hybrid with augmented exploration and strategic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.25  # Increased local search probability\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.35 * np.tanh(6 * (0.5 - diversity))  # Adjusted factor\n                CR = CR_base - 0.25 * np.tanh(6 * (0.5 - diversity))  # Adjusted factor\n            else:\n                F = F_base + 0.15 * np.cos(phase_ratio * np.pi)  # Adjusted factor\n                CR = CR_base - 0.15 * np.cos(phase_ratio * np.pi)  # Adjusted factor\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evaluations / self.budget)  # Adjusted factor\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.15 - diversity))), 60)  # Adjusted bounds\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.15 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))  # Adjusted step size\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 70, "feedback": "The algorithm DynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "e2af813b-3f66-40ba-aaf3-0378180cb88d", "fitness": 0.103114049088997, "name": "QuantumInspiredDynamicAdaptiveMultiAgentHybrid", "description": "Introducing a Quantum-inspired DynamicAdaptiveMultiAgentHybrid with parallel elite reinforcement and stochastic perturbation for enhanced global and local search balance.", "code": "import numpy as np\n\nclass QuantumInspiredDynamicAdaptiveMultiAgentHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.25  # Increased probability of performing local search\n        quantum_perturbation_prob = 0.1  # Probability of quantum-inspired perturbation\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n        elite_fitness = np.min(fitness)\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt strategies based on phases of the search\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.5:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.2 * np.tanh(5 * (0.5 - diversity))\n            else:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 50)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < elite_fitness:\n                        elite = trial\n                        elite_fitness = trial_fitness\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < elite_fitness:\n                            elite = local_trial\n                            elite_fitness = local_fitness\n\n                # Quantum-inspired perturbation for diversification\n                if np.random.rand() < quantum_perturbation_prob and evaluations < self.budget:\n                    quantum_trial = population[i] + np.random.normal(0, 0.1 * (ub - lb))\n                    quantum_trial = np.clip(quantum_trial, lb, ub)\n                    quantum_fitness = func(quantum_trial)\n                    evaluations += 1\n                    if quantum_fitness < fitness[i]:\n                        population[i] = quantum_trial\n                        fitness[i] = quantum_fitness\n                        if quantum_fitness < elite_fitness:\n                            elite = quantum_trial\n                            elite_fitness = quantum_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 71, "feedback": "The algorithm QuantumInspiredDynamicAdaptiveMultiAgentHybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10311 with standard deviation 0.00634.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.0943528068864472, 0.095030852122585, 0.09465311579783542, 0.10430044169917052, 0.1052524752003805, 0.10471650573661662, 0.10936681863252051, 0.11049628630117425, 0.10985713942424302]}}
{"id": "5305dcf3-01d1-4add-b47d-0dcca47e4983", "fitness": 0.10317808228688191, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Dynamic Phase-Based Synergistic Evolutionary Strategy integrates adaptive multi-agent cooperation with phase-specific mutation strategies to enhance convergence and diversity balance.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 72, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["dbf4c758-6826-494f-bac0-30f1a607b63b"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "a412ffb4-f6d2-4d0c-a8bf-64df9a7182d1", "fitness": 0.10304174764691601, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Refined Adaptive Swarm Factor to Enhance Diversity and Exploration.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)  # Change from np.cos to np.sin\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 73, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10304 with standard deviation 0.00632.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09431551677029937, 0.095023729768277, 0.09453944173221829, 0.10424738247649723, 0.10524233289414509, 0.10455505956498734, 0.10930335311879436, 0.11048414029742859, 0.1096647721995968]}}
{"id": "8f1f1496-87f2-4999-a169-6243c778b517", "fitness": 0.10317808228688191, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Dynamic Phase-Based Synergistic Evolutionary Strategy with slightly increased local search probability to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.32  # Increased probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 74, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "eb6bcb24-4168-4ad7-b981-2e3f7d350d73", "fitness": 0.1030493494857982, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Refined Synergistic Evolutionary Strategy improves phase-specific adaptation by adjusting the local search probability based on convergence status.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob * (1 - phase_ratio) and evaluations < self.budget:  # Adjusted local search probability\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 75, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10305 with standard deviation 0.00632.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.0945761337661164, 0.10423411767082891, 0.1052271194347918, 0.10460714440041574, 0.10928748674036282, 0.1104659212918101, 0.10972698158978034]}}
{"id": "2179b89b-bf9c-446b-968f-30c2748d1bfa", "fitness": 0.10317808228688191, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Introduced adaptive scaling for the differential weight and increased the local search probability to enhance convergence speed.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.4  # Enhanced probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + (F + 0.2 * diversity) * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 76, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "21ba9a87-a00d-4a9a-a3b3-f4fa3e3c1060", "fitness": 0.10317808228688191, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Enhanced Dynamic Phase-Based Synergistic Evolutionary Strategy with a refined local search probability for improved exploration.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.35  # Enhanced probability of performing local search  # Changed from 0.3 to 0.35\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 77, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "99b2d2d4-093d-4362-92ca-9cff6249a0fe", "fitness": 0.10303215120246646, "name": "AdaptiveMultiPhaseSynergisticEvolution", "description": "The Adaptive Multi-Phase Synergistic Evolutionary Strategy enhances dynamic exploration and exploitation by incorporating fitness diversity metrics and phase-specific adaptive strategies for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveMultiPhaseSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 15 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            diversity = np.mean(np.std(population, axis=0) / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.4:\n                F = F_base + 0.5 * np.tanh(6 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(6 * (0.5 - diversity))\n            elif phase_ratio < 0.8:\n                F = F_base + 0.3 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.2 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(6, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 78, "feedback": "The algorithm AdaptiveMultiPhaseSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "cdc9b0c8-1c8d-4102-b176-bfbe7adda5b1", "fitness": -Infinity, "name": "ImprovedDynamicPhaseBasedSynergisticEvolution", "description": "Improved Dynamic Phase-Based Synergistic Evolutionary Strategy incorporating adaptive learning rates and a memory-based archive to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass ImprovedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n        archive_size = population_size // 2\n        \n        # Initialize population and archive\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        archive = np.empty((0, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            \n            if phase_ratio >= 0.7:\n                F = F_base + 0.2 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n            \n            # Adaptive swarm factor\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with archive\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b = np.random.choice(indices, 2, replace=False)\n                c = np.random.choice(archive_size) if archive.size > 0 else np.random.choice(indices)\n                \n                mutant = swarm_factor * (population[a] + F * (population[b] - (archive[c] if archive.size > 0 else population[c])))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    archive = np.vstack((archive, population[i]))\n                    if archive.shape[0] > archive_size:\n                        archive = archive[np.random.choice(archive.shape[0], archive_size, replace=False)]\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 79, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 1').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 1')", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {}}
{"id": "cf8158a4-ef7b-40f8-af1a-769a4c032b00", "fitness": 0.10303215120246646, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Enhanced adaptive local search by adjusting step size based on diversity.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search with diversity-dependent step size\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * diversity)\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 80, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "ba0a67fb-bd41-498b-808a-a4ae722530c3", "fitness": 0.10305986498235847, "name": "EnhancedMultiPhaseAdaptiveEvolution", "description": "Enhanced Multi-Phase Adaptive Evolution integrates novel mutation, crossover, and adaptive learning strategies to improve convergence and solution diversity.  ", "code": "import numpy as np\n\nclass EnhancedMultiPhaseAdaptiveEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.4:\n                F = F_base + 0.5 * np.tanh(6 * (0.5 - diversity))\n                CR = CR_base - 0.4 * np.tanh(6 * (0.5 - diversity))\n            elif phase_ratio < 0.8:\n                F = F_base + 0.3 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.3 * np.sin(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.6 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.2 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.12 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedMultiPhaseAdaptiveEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10306 with standard deviation 0.00633.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.0950160083551207, 0.09459620170647542, 0.10423411767082891, 0.1052313360171695, 0.10463563375970841, 0.10928748674036282, 0.11047097616761103, 0.10976083018268701]}}
{"id": "0af6f20e-5a72-4f92-b99f-bfbe74b5275b", "fitness": 0.10317808228688191, "name": "EnhancedPhaseBasedSynergisticEvolution", "description": "Enhanced Phase-Based Synergistic Evolutionary Strategy integrates dynamic diversity control with adaptive local exploration for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.6 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.5 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.3 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.3 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.2 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "6b32a2a4-0bb9-40f8-8795-545b2d77dd7e", "fitness": 0.10317808228688191, "name": "QuantumInspiredPhaseBasedSynergisticEvolution", "description": "Quantum-Inspired Phase-Based Synergistic Evolutionary Strategy integrates quantum-inspired initialization and entangled phase transitions to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass QuantumInspiredPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n        \n        # Quantum-inspired initialization\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = lb + (ub - lb) * np.random.rand(population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Entangled phase transitions\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 83, "feedback": "The algorithm QuantumInspiredPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "b8a5b003-76e3-4b90-a083-97edbb290855", "fitness": 0.1030493494857982, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Enhanced Dynamic Phase-Based Synergistic Evolutionary Strategy incorporating an adaptive local search probability for improved convergence and diversity balance.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                local_search_prob = 0.3 + 0.2 * np.sin(2 * np.pi * evaluations / self.budget) # Changed line\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 84, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10305 with standard deviation 0.00632.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.0945761337661164, 0.10423411767082891, 0.1052271194347918, 0.10460714440041574, 0.10928748674036282, 0.1104659212918101, 0.10972698158978034]}}
{"id": "694c3c5e-ebe9-4ff7-ae83-76f0bb79e5ee", "fitness": 0.10317808228688191, "name": "DynamicPhaseBasedSynergisticEvolution", "description": "Enhanced Dynamic Phase-Based Synergistic Evolutionary Strategy integrates adaptive multi-agent cooperation with phase-specific mutation strategies and adjusted local search probabilities to improve convergence and diversity balance.", "code": "import numpy as np\n\nclass DynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.35  # Adjusted probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09485411567902813, 0.10423411767082891, 0.1052271194347918, 0.10501079923394718, 0.10928748674036282, 0.1104659212918101, 0.11020394005309042]}}
{"id": "c3f352d0-60f2-4fb0-80d1-1a962d66a2d0", "fitness": 0.10305329869080032, "name": "EnhancedAdaptiveDynamicSynergisticEvolution", "description": "Enhanced Adaptive Dynamic Synergistic Evolutionary Strategy employs phase-specific adaptive mechanisms and intensified local search to boost convergence and maintain diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynamicSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Probability of performing local search\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n\n        # Initialize population\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            diversity = np.mean(np.std(population, axis=0) / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n            CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            if phase_ratio >= 0.3:\n                F *= (1.0 + 0.1 * np.sin(phase_ratio * np.pi))\n                CR *= (1.0 - 0.1 * np.cos(phase_ratio * np.pi))\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.05 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.05 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveDynamicSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10305 with standard deviation 0.00632.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09458483419906272, 0.10423411767082891, 0.1052271194347918, 0.1046194649472646, 0.10928748674036282, 0.1104659212918101, 0.10974150345500422]}}
{"id": "fc267def-1079-424b-b3ce-f5e95cbe83ef", "fitness": 0.10305894398890528, "name": "SynergisticEvolutionaryStrategyWithAdaptiveDiversityControl", "description": "Synergistic Evolutionary Strategy with Adaptive Diversity Control refines phase-specific mutations and integrates population diversity feedback to enhance convergence efficiency.", "code": "import numpy as np\n\nclass SynergisticEvolutionaryStrategyWithAdaptiveDiversityControl:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Probability of performing local search\n        \n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation with diversity feedback\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi) * (1 - diversity)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi) * diversity\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi) * (1 + diversity)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi) * (1 - diversity)\n\n            # Adaptive swarm factor for exploration\n            swarm_factor = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            \n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = swarm_factor * (population[a] + F * (population[b] - population[c]))\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 87, "feedback": "The algorithm SynergisticEvolutionaryStrategyWithAdaptiveDiversityControl got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10306 with standard deviation 0.00633.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09459715694565385, 0.10423411767082891, 0.1052271194347918, 0.10463699337445043, 0.10928748674036282, 0.1104659212918101, 0.10976245996417178]}}
{"id": "a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88", "fitness": 0.10317822005019499, "name": "EnhancedDynamicPhaseBasedSynergisticEvolution", "description": "Enhanced Dynamic Phase-Based Synergistic Evolutionary Strategy introduces stochastic learning and adaptive mutation probability to further enhance exploration and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and stochastic learning\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["5305dcf3-01d1-4add-b47d-0dcca47e4983"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501334647627824, 0.09485411567902813, 0.10423411767082891, 0.10522754678570845, 0.10501079923394718, 0.10928748674036282, 0.1104664335712483, 0.11020394005309042]}}
{"id": "734cd147-2dee-427a-85af-5ce0eb6b9066", "fitness": 0.10303215120246646, "name": "AdaptiveSynergisticEvolutionaryStrategy", "description": "Adaptive Synergistic Evolutionary Strategy with Phase-Based Adaptive Control incorporates hierarchical learning and phase-based parameter adaptation to enhance exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveSynergisticEvolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-based adaptive control\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.1 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.05 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.05 * np.sin(phase_ratio * np.pi)\n\n            # Hierarchical learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 89, "feedback": "The algorithm AdaptiveSynergisticEvolutionaryStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "c656df06-25f0-4c23-8fa8-f2f774c7d3fc", "fitness": 0.10317822005019499, "name": "EnhancedDynamicPhaseBasedSynergisticEvolution", "description": "Slightly increase the base differential weight (F_base) to improve exploration capability.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.55  # Base differential weight increased to improve exploration\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and stochastic learning\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501334647627824, 0.09485411567902813, 0.10423411767082891, 0.10522754678570845, 0.10501079923394718, 0.10928748674036282, 0.1104664335712483, 0.11020394005309042]}}
{"id": "3c28c021-454b-42fb-958c-2f0c6e3a558e", "fitness": 0.1030383724562464, "name": "EnhancedDynamicPhaseBasedSynergisticEvolution", "description": "Adaptive Dynamic Phase Synergistic Evolutionary Strategy with entropy-based diversity control and spatially-aware elite enhancement to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity using entropy\n            diversity = -np.sum([np.log(p + 1e-12) * p for p in np.std(population, axis=0) / (ub - lb)], axis=0)\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and stochastic learning\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search with spatial awareness\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n            # Enhance elite with spatial consideration\n            for _ in range(3): # Three extra trials for the elite to escape local minima\n                spatial_step = np.random.uniform(-0.05 * (ub - lb), 0.05 * (ub - lb))\n                spatial_trial = elite + spatial_step\n                spatial_trial = np.clip(spatial_trial, lb, ub)\n                spatial_fitness = func(spatial_trial)\n                evaluations += 1\n                if spatial_fitness < func(elite):\n                    elite = spatial_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10304 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501313721224558, 0.09455210945119552, 0.10423411767082891, 0.1052272489224576, 0.10457300586715346, 0.10928748674036282, 0.1104660765098805, 0.10968597549083081]}}
{"id": "7c47bbf1-0c8a-41fa-b032-0c6fa9d0d436", "fitness": 0.10303215120246646, "name": "EnhancedDynamicPhaseBasedSynergisticEvolution", "description": "Introduced dynamic scaling of mutation and crossover rates based on elite's fitness to enhance convergence in later stages.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            elite_fitness = func(elite)\n            scaling_factor = 1 + 0.5 * np.tanh(5 * (0.5 - elite_fitness / max(fitness)))\n            \n            if phase_ratio < 0.3:\n                F = F_base + scaling_factor * 0.3 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - scaling_factor * 0.2 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + scaling_factor * 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - scaling_factor * 0.15 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + scaling_factor * 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - scaling_factor * 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and stochastic learning\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "59cc253b-b391-4cc7-b9a9-f544da90beef", "fitness": 0.10303215120246646, "name": "AdaptiveQuantumInspiredSynergisticEvolution", "description": "The Adaptive Quantum-Inspired Synergistic Evolutionary Strategy integrates quantum superposition principles for diversity maintenance and employs phase-specific mechanisms to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Quantum-inspired diversity enhancement\n            quantum_prob = 0.1 + 0.9 * (1 - diversity)\n            if np.random.rand() < quantum_prob:\n                q_population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n                q_fitness = np.array([func(ind) for ind in q_population])\n                evaluations += population_size\n                improved = q_fitness < fitness\n                population[improved] = q_population[improved]\n                fitness[improved] = q_fitness[improved]\n                elite = population[np.argmin(fitness)]\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveQuantumInspiredSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09453842634784915, 0.10423411767082891, 0.1052271194347918, 0.10455362182453365, 0.10928748674036282, 0.1104659212918101, 0.10966342703394394]}}
{"id": "8dc54c1f-c812-4983-814b-0793f3b593e0", "fitness": 0.10317822005019499, "name": "EnhancedDynamicPhaseBasedSynergisticEvolutionWithAdaptiveLifetime", "description": "The Enhanced Dynamic Phase-Based Synergistic Evolutionary Strategy with Adaptive Lifetime introduces a dynamic lifespan for solutions based on fitness performance and integrates an elitist archive to balance exploration and exploitation, enhancing convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolutionWithAdaptiveLifetime:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n        lifespan_scale = 0.1  # Scale for adaptive lifespan\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n        elitist_archive = [elite]\n        lifespans = np.full(population_size, int(self.budget * lifespan_scale))\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and stochastic learning\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    lifespans[i] = int(self.budget * lifespan_scale)  # Reset lifespan\n                    if trial_fitness < func(elite):\n                        elite = trial\n                        elitist_archive.append(elite)\n\n                # Adaptive lifespan decrement\n                lifespans[i] -= 1\n                if lifespans[i] <= 0 and evaluations < self.budget:\n                    # Replace with a random solution when lifespan is over\n                    population[i] = np.random.rand(self.dim) * (ub - lb) + lb\n                    fitness[i] = func(population[i])\n                    evaluations += 1\n                    lifespans[i] = int(self.budget * lifespan_scale)\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n                            elitist_archive.append(elite)\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return min(elitist_archive, key=func)", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolutionWithAdaptiveLifetime got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501334647627824, 0.09485411567902813, 0.10423411767082891, 0.10522754678570845, 0.10501079923394718, 0.10928748674036282, 0.1104664335712483, 0.11020394005309042]}}
{"id": "e61f4941-4d9d-42c2-83b6-92a10c7ba337", "fitness": 0.10317822005019499, "name": "EnhancedDynamicPhaseBasedSynergisticEvolution", "description": "Enhanced Dynamic Phase-Based Synergistic Evolution with adaptive crossover control and diversity-aware mutation strategy for improved convergence and exploration efficiency.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Adaptive crossover control based on diversity\n                CR = CR_base * (1 - np.exp(-diversity))\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return elite", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501334647627824, 0.09485411567902813, 0.10423411767082891, 0.10522754678570845, 0.10501079923394718, 0.10928748674036282, 0.1104664335712483, 0.11020394005309042]}}
{"id": "ef1291ba-af01-4606-9352-1a631930c8e4", "fitness": 0.1030445319332237, "name": "ImprovedAdaptiveSynergisticEvolution", "description": "Improved Adaptive Synergistic Evolution introduces adaptive local search with an elite preservation mechanism for enhanced convergence performance.", "code": "import numpy as np\n\nclass ImprovedAdaptiveSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        elite_preservation_prob = 0.1  # Probability of preserving elite\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Adjust mutation probability based on diversity\n            mutation_prob = 0.3 + 0.7 * (1 - diversity)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = population[a] + F * (population[b] - population[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search with elite preservation\n                if np.random.rand() < elite_preservation_prob and evaluations < self.budget:\n                    local_trial = elite + np.random.uniform(-0.05, 0.05, size=self.dim) * (ub - lb)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < func(elite):\n                        elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 96, "feedback": "The algorithm ImprovedAdaptiveSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10304 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501304623681539, 0.09456562081774356, 0.10423411767082891, 0.1052271194347918, 0.10459219426237909, 0.10928748674036282, 0.1104659212918101, 0.10970908670301927]}}
{"id": "20de9745-3d85-4263-87ad-b5b5e6f16a0f", "fitness": 0.10303237874159268, "name": "EnhancedDynamicPhaseBasedSynergisticEvolution", "description": "Enhanced Dynamic Phase-Based Synergistic Evolutionary Strategy with randomized local search intensification and dynamic learning rates to further improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedDynamicPhaseBasedSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR_base = 0.9  # Base crossover probability\n        local_search_prob = 0.3  # Enhanced probability of performing local search\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.6 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F and stochastic learning\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.15 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedDynamicPhaseBasedSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501354211855806, 0.09453842634784915, 0.10423411767082891, 0.10522782527557484, 0.10455362182453365, 0.10928748674036282, 0.11046676742142036, 0.10966342703394394]}}
{"id": "f9dea64a-8024-4153-95a2-30086842658f", "fitness": 0.10317822005019499, "name": "AdaptiveDiversityControlledSynergisticEvolution", "description": "Adaptive Diversity-Controlled Synergistic Evolutionary Strategy refines exploration and intensification by dynamically adjusting diversity thresholds for enhanced convergence in varying search phases.", "code": "import numpy as np\n\nclass AdaptiveDiversityControlledSynergisticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Adapt diversity thresholds based on phase\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                diversity_target = 0.6\n            elif phase_ratio < 0.7:\n                diversity_target = 0.4\n            else:\n                diversity_target = 0.2\n\n            # Adjust F and CR based on diversity\n            diversity_factor = 1 - np.tanh(2 * (diversity - diversity_target))\n            F = F_base + diversity_factor * 0.3\n            CR = CR_base - diversity_factor * 0.2\n\n            # Stochastic learning for adaptive mutation probability\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Maintain population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 98, "feedback": "The algorithm AdaptiveDiversityControlledSynergisticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10318 with standard deviation 0.00635.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501334647627824, 0.09485411567902813, 0.10423411767082891, 0.10522754678570845, 0.10501079923394718, 0.10928748674036282, 0.1104664335712483, 0.11020394005309042]}}
{"id": "b07d746c-ab96-4976-b262-5304987f9fb3", "fitness": 0.10303221173004151, "name": "AdvancedSynergisticEvolutionaryStrategy", "description": "Advanced Synergistic Evolutionary Strategy with Phase-Specific Diversity Control and Multi-Scale Adaptive Mutation enhances convergence by dynamically adjusting mutation scales and incorporating phase-dependent diversity strategies.", "code": "import numpy as np\n\nclass AdvancedSynergisticEvolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 12 + 2 * self.dim\n        F_base = 0.5\n        CR_base = 0.9\n        local_search_prob = 0.3\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        elite = population[np.argmin(fitness)]\n\n        while evaluations < self.budget:\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (ub - lb))\n\n            # Phase-specific adaptation and diversity control\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < 0.3:\n                F = F_base + 0.4 * np.tanh(5 * (0.5 - diversity))\n                CR = CR_base - 0.3 * np.tanh(5 * (0.5 - diversity))\n                diversity_factor = 1.5\n            elif phase_ratio < 0.7:\n                F = F_base + 0.2 * np.cos(phase_ratio * np.pi)\n                CR = CR_base - 0.2 * np.cos(phase_ratio * np.pi)\n                diversity_factor = 1.0\n            else:\n                F = F_base + 0.1 * np.sin(phase_ratio * np.pi)\n                CR = CR_base - 0.1 * np.sin(phase_ratio * np.pi)\n                diversity_factor = 0.5\n\n            # Adaptive mutation probability based on diversity\n            mutation_prob = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Adjust population size adaptively\n            population_size = min(max(5, int(population_size * (1.1 - diversity))), 60)\n\n            for i in range(population_size):\n                # Differential mutation with adaptive F\n                if np.random.rand() < mutation_prob:\n                    indices = list(range(population_size))\n                    indices.remove(i)\n                    a, b, c = np.random.choice(indices, 3, replace=False)\n                    mutant = population[a] + F * (population[b] - population[c])\n                else:\n                    mutant = np.random.rand(self.dim) * (ub - lb) + lb\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover with adaptive CR\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(elite):\n                        elite = trial\n\n                # Enhanced Adaptive local search\n                if np.random.rand() < local_search_prob and evaluations < self.budget:\n                    adaptive_step_size = (ub - lb) * 0.1 * diversity_factor * (0.5 + 0.5 * (fitness.mean() - fitness[i]) / (fitness.std() + 1e-12))\n                    local_trial = population[i] + np.random.uniform(-adaptive_step_size, adaptive_step_size)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evaluations += 1\n                    if local_fitness < fitness[i]:\n                        population[i] = local_trial\n                        fitness[i] = local_fitness\n                        if local_fitness < func(elite):\n                            elite = local_trial\n\n                if evaluations >= self.budget:\n                    break\n\n        # Return the best found solution\n        return elite", "configspace": "", "generation": 99, "feedback": "The algorithm AdvancedSynergisticEvolutionaryStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10303 with standard deviation 0.00632.", "error": "", "parent_ids": ["a439fd68-1b27-4e38-a5ab-4f1b3cbc4d88"], "operator": null, "metadata": {"aucs": [0.09430619424126241, 0.09501317815295507, 0.09453842634784915, 0.10423411767082891, 0.10522730719548468, 0.10455362182453365, 0.10928748674036282, 0.110466146363153, 0.10966342703394394]}}
