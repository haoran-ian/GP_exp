{"id": "c1d7ddef-0de8-4d6c-9e5c-77e9ec5d5152", "fitness": 0.14911590900931826, "name": "AdaptiveChaoticParticleSwarm", "description": "Leverage adaptively weighted swarm intelligence and chaotic perturbations for enhanced exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveChaoticParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5 + np.random.rand() / 2  # Inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            chaotic_sequence = 0.7 * np.random.rand() * (1.0 - np.random.rand(self.swarm_size, self.dim) ** 2)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          chaotic_sequence)\n\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveChaoticParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14912 with standard deviation 0.01529.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1509984647565984, 0.15227361074895873, 0.1516613167591485, 0.16535485713232245, 0.16747707520663668, 0.1664481450960229, 0.12848858877732872, 0.12980993384082584, 0.12953118876602188]}}
{"id": "bec39632-d249-411c-85df-bfce70688edc", "fitness": 0.14875259594201992, "name": "AdaptiveChaoticParticleSwarm", "description": "Introduce dynamic velocity scaling for enhanced exploration and exploitation balance in adaptive chaotic particle swarm optimization.", "code": "import numpy as np\n\nclass AdaptiveChaoticParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5 + np.random.rand() / 2  # Inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            chaotic_sequence = 0.7 * np.random.rand() * (1.0 - np.random.rand(self.swarm_size, self.dim) ** 2)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          chaotic_sequence)\n\n            # Dynamic velocity scaling\n            scale_factor = (self.budget - self.func_evals) / self.budget\n            velocities *= scale_factor\n\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveChaoticParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14875 with standard deviation 0.01511.", "error": "", "parent_ids": ["c1d7ddef-0de8-4d6c-9e5c-77e9ec5d5152"], "operator": null, "metadata": {"aucs": [0.15024552024816507, 0.15219272304356868, 0.15142429950826242, 0.16408086539101308, 0.16733714029291824, 0.1660407487404726, 0.1282529710828516, 0.1297739221198564, 0.12942517305107104]}}
{"id": "95fc108d-512b-4fd0-8bf8-8e1cb65701aa", "fitness": 0.1492019059004395, "name": "AdaptiveChaoticParticleSwarm", "description": "Introduce dynamic chaotic sequence scaling to enhance search diversity in adaptively weighted swarm intelligence.", "code": "import numpy as np\n\nclass AdaptiveChaoticParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5 + np.random.rand() / 2  # Inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            chaotic_sequence = 0.7 * np.random.rand() * (1.0 - np.random.rand(self.swarm_size, self.dim) ** 2)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          chaotic_sequence * (1.0 - self.func_evals / self.budget))  # Dynamic scaling\n\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveChaoticParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14920 with standard deviation 0.01528.", "error": "", "parent_ids": ["c1d7ddef-0de8-4d6c-9e5c-77e9ec5d5152"], "operator": null, "metadata": {"aucs": [0.1511714761245615, 0.15227361074895873, 0.1516655117573832, 0.16564969822010023, 0.16747707520663668, 0.1664553065913532, 0.12878144566251315, 0.1298099544552891, 0.12953307433715966]}}
{"id": "86cc69ab-e296-4241-881a-b5b2c2949761", "fitness": 0.14930927882451225, "name": "AdaptiveChaoticParticleSwarm", "description": "Incorporate a dynamic adjustment to inertia weight for improved balance in exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveChaoticParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            chaotic_sequence = 0.7 * np.random.rand() * (1.0 - np.random.rand(self.swarm_size, self.dim) ** 2)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          chaotic_sequence * (1.0 - self.func_evals / self.budget))  # Dynamic scaling\n\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveChaoticParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14931 with standard deviation 0.01524.", "error": "", "parent_ids": ["95fc108d-512b-4fd0-8bf8-8e1cb65701aa"], "operator": null, "metadata": {"aucs": [0.1511402258897565, 0.1525330435822072, 0.15157606183704053, 0.1656028987517313, 0.16792333249526759, 0.16630320129532872, 0.1292863797790641, 0.1299258841271309, 0.12949248166308358]}}
{"id": "dffcac16-19b3-43f1-85b5-5defcfbacc67", "fitness": -Infinity, "name": "EnhancedLevyFlightPSO", "description": "Enhance global convergence by incorporating LÃ©vy flight in velocity updates for improved exploration.", "code": "import numpy as np\n\nclass EnhancedLevyFlightPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            levy_steps = self.levy_flight((self.swarm_size, self.dim))\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm)) + levy_steps\n\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["86cc69ab-e296-4241-881a-b5b2c2949761"], "operator": null, "metadata": {}}
{"id": "29238daa-12ad-438e-b8f4-6d7ba3ab18b9", "fitness": 0.14928145426979164, "name": "AdaptiveChaoticParticleSwarm", "description": "Introduce a non-linear dynamic adjustment to inertia weight for more nuanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveChaoticParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.cos(np.pi * self.func_evals / self.budget)  # Non-linear dynamic inertia weight\n            chaotic_sequence = 0.7 * np.random.rand() * (1.0 - np.random.rand(self.swarm_size, self.dim) ** 2)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          chaotic_sequence * (1.0 - self.func_evals / self.budget))  # Dynamic scaling\n\n            swarm = swarm + velocities\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveChaoticParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14928 with standard deviation 0.01522.", "error": "", "parent_ids": ["86cc69ab-e296-4241-881a-b5b2c2949761"], "operator": null, "metadata": {"aucs": [0.15106749035765454, 0.1525287028447032, 0.15157399035334862, 0.16547825885562517, 0.16791578598739199, 0.16629961342803345, 0.12925371906536076, 0.12992396854678812, 0.12949155898921882]}}
{"id": "79a32032-0055-46de-af4a-ed2226df8a73", "fitness": 0.14941153886120515, "name": "EnhancedLevyFlightParticleSwarm", "description": "Integrate a Levy flight mechanism for enhanced exploration and dynamic local search intensification.", "code": "import numpy as np\n\nclass EnhancedLevyFlightParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - self.func_evals / self.budget)  # Levy flight integration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedLevyFlightParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14941 with standard deviation 0.01528.", "error": "", "parent_ids": ["86cc69ab-e296-4241-881a-b5b2c2949761"], "operator": null, "metadata": {"aucs": [0.15121769637368843, 0.1525453417811049, 0.15177730989718208, 0.16573633449314173, 0.1679447146120131, 0.166647263610342, 0.1293209514685285, 0.129931346205292, 0.12958289130955358]}}
{"id": "8ea1b6cb-85ed-4ad0-9e90-cb7bc8b16cb4", "fitness": 0.14940868688205225, "name": "EnhancedLevyFlightParticleSwarm", "description": "Introduce adaptive cognitive and social coefficients to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedLevyFlightParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            progress_ratio = self.func_evals / self.budget\n            self.c1 = 2.5 - 1.0 * progress_ratio  # Adaptive cognitive coefficient\n            self.c2 = 0.5 + 1.5 * progress_ratio  # Adaptive social coefficient\n            \n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - progress_ratio)  # Levy flight integration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedLevyFlightParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14941 with standard deviation 0.01528.", "error": "", "parent_ids": ["79a32032-0055-46de-af4a-ed2226df8a73"], "operator": null, "metadata": {"aucs": [0.15121113386450524, 0.15253600437745296, 0.15178517851758166, 0.16572488986024658, 0.16792846252306803, 0.16666089080015012, 0.12931804773703115, 0.12992721079916092, 0.12958636345927377]}}
{"id": "cb0cf37e-6bdf-40f2-9363-7ce51fad7076", "fitness": 0.1494110492295717, "name": "EnhancedLevyFlightParticleSwarm", "description": "Enhanced exploration and exploitation balance through adaptive parameters and a diversity mechanism.", "code": "import numpy as np\n\nclass EnhancedLevyFlightParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.4 + 0.6 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            random_swarm_idx = np.random.randint(0, self.swarm_size, size=self.swarm_size // 10)\n            swarm[random_swarm_idx] = np.random.uniform(lb, ub, (len(random_swarm_idx), self.dim))  # Diversity mechanism\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - self.func_evals / self.budget)  # Levy flight integration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedLevyFlightParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14941 with standard deviation 0.01528.", "error": "", "parent_ids": ["79a32032-0055-46de-af4a-ed2226df8a73"], "operator": null, "metadata": {"aucs": [0.151216469152758, 0.1525439919405892, 0.15177849350647232, 0.16573420053193821, 0.1679423652004577, 0.16664931353323342, 0.1293204476051677, 0.12993074717779973, 0.12958341441772936]}}
{"id": "06ecd00b-7150-4847-8aba-9df180e644de", "fitness": 0.14940639075027817, "name": "EnhancedLevyFlightParticleSwarm", "description": "Adaptive inertia weight and random exploration boost to enhance global search capability and convergence robustness.", "code": "import numpy as np\n\nclass EnhancedLevyFlightParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.9  # Adjusted initial inertia weight\n        self.c1 = 1.5 + np.random.rand()\n        self.c2 = 1.5 + np.random.rand()\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.7 * (self.func_evals / self.budget)  # Modified dynamic inertia weight adjustment\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - self.func_evals / self.budget)\n            swarm += np.random.uniform(-0.1, 0.1, (self.swarm_size, self.dim))  # Random exploration boost\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedLevyFlightParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14941 with standard deviation 0.01528.", "error": "", "parent_ids": ["79a32032-0055-46de-af4a-ed2226df8a73"], "operator": null, "metadata": {"aucs": [0.15120557547970515, 0.15252860548700586, 0.15179161523640428, 0.16571528526360013, 0.167915611088444, 0.16667206329624729, 0.12931557162290486, 0.12992392639198602, 0.1295892628862061]}}
{"id": "1c6eb748-87dd-499d-8698-95006d161240", "fitness": 0.1493987842248803, "name": "EnhancedLevyFlightParticleSwarm", "description": "Introduce adaptive coefficients and an elite preservation strategy to improve convergence in the Enhanced Levy Flight Particle Swarm algorithm.", "code": "import numpy as np\n\nclass EnhancedLevyFlightParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1_initial = 1.5 + np.random.rand()  # Initial cognitive coefficient\n        self.c2_initial = 1.5 + np.random.rand()  # Initial social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            self.c1 = self.c1_initial * (1 - self.func_evals / self.budget)  # Adaptive cognitive coefficient\n            self.c2 = self.c2_initial * (1 - self.func_evals / self.budget)  # Adaptive social coefficient\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - self.func_evals / self.budget)  # Levy flight integration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedLevyFlightParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14940 with standard deviation 0.01528.", "error": "", "parent_ids": ["79a32032-0055-46de-af4a-ed2226df8a73"], "operator": null, "metadata": {"aucs": [0.15120209147501595, 0.1525234916972924, 0.1517786867847668, 0.16570925388929647, 0.16790673050186888, 0.16664964712721986, 0.12931402332422903, 0.12992160778032047, 0.1295835254439126]}}
{"id": "3a955fc1-ee45-4bf4-8593-c481e5b645f0", "fitness": 0.14832304446956324, "name": "EnhancedLevyFlightParticleSwarm", "description": "Enhance swarm diversity and convergence by introducing chaotic map initialization and adaptive coefficients.", "code": "import numpy as np\n\nclass EnhancedLevyFlightParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        chaotic_map = np.random.rand(self.swarm_size, self.dim)\n        for i in range(1, self.budget//10):\n            chaotic_map = np.sin(np.pi * chaotic_map)\n        swarm = lb + (ub - lb) * chaotic_map  # Chaotic map initialization\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            # Adaptive coefficients\n            c1_dynamic = self.c1 * (1 - self.func_evals / self.budget)\n            c2_dynamic = self.c2 * (self.func_evals / self.budget)\n            \n            velocities = (self.w * velocities +\n                          c1_dynamic * r1 * (personal_best - swarm) +\n                          c2_dynamic * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - self.func_evals / self.budget)  # Levy flight integration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedLevyFlightParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14832 with standard deviation 0.01487.", "error": "", "parent_ids": ["79a32032-0055-46de-af4a-ed2226df8a73"], "operator": null, "metadata": {"aucs": [0.15078150822597913, 0.1523728906596391, 0.14919520309994816, 0.16511113520627418, 0.1676459038955278, 0.1624970385845289, 0.12909223349217902, 0.12985459385223774, 0.12835689320975519]}}
{"id": "c526834b-50f7-41c1-8a46-ea2a2e99cc00", "fitness": 0.1495808982728205, "name": "EnhancedChaoticLevySwarm", "description": "Introduce an adaptive swarm topology and chaotic map initialization for robust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        # Using a logistic map for chaotic sequences\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0  # Logistic map parameter\n        for _ in range(100):  # Iterate to reach chaotic state\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Dynamic inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)  # Adaptive cognitive coefficient\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)  # Adaptive social coefficient\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * (1.0 - self.func_evals / self.budget)  # Levy flight integration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14958 with standard deviation 0.01536.", "error": "", "parent_ids": ["79a32032-0055-46de-af4a-ed2226df8a73"], "operator": null, "metadata": {"aucs": [0.15209710848358937, 0.15258991812398093, 0.15133581520500683, 0.1671973319430975, 0.1680229846513196, 0.1659329371864562, 0.1297256270204905, 0.12995095559193093, 0.12937540624951294]}}
{"id": "2646b3e1-597a-4f8a-92ad-a535680e588b", "fitness": 0.14963047492765857, "name": "EnhancedChaoticLevySwarm", "description": "Introduce a dynamic chaos parameter and adaptive step size scaling for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14963 with standard deviation 0.01538.", "error": "", "parent_ids": ["c526834b-50f7-41c1-8a46-ea2a2e99cc00"], "operator": null, "metadata": {"aucs": [0.15209710848358937, 0.15258991812398093, 0.15147637168455375, 0.1671973319430975, 0.1680229846513196, 0.1661760133441168, 0.1297256270204905, 0.12995095559193093, 0.12943796350584758]}}
{"id": "2e4ad70e-0790-491d-982e-5180ab92c9a0", "fitness": 0.14957653442438557, "name": "EnhancedChaoticLevySwarm", "description": "Integrate non-linear dynamic inertia weight and chaotic perturbation to improve convergence.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.4 * ((self.func_evals / self.budget) ** 2)  # Non-linear inertia weight\n            self.c1 = 2.0 + 1.0 * np.sin(np.pi * self.func_evals / self.budget)  # Modified coefficient\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14958 with standard deviation 0.01536.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.15209710848358937, 0.15258991812398093, 0.15132352791234172, 0.1671973319430975, 0.1680229846513196, 0.16591139594372262, 0.1297256270204905, 0.12995095559193093, 0.12936996014899704]}}
{"id": "52568970-a6b9-4ef4-ad9d-db9ab016b88b", "fitness": 0.14914117549859834, "name": "EnhancedChaoticLevySwarm", "description": "Introduce chaotic inertia weight and adaptive velocity bounds for better convergence.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - np.cos(np.pi * self.func_evals / self.budget))  # Chaotic inertia weight\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            velocities = np.clip(velocities, -0.1, 0.1)  # Adaptive velocity bounds\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14914 with standard deviation 0.01519.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.15206303531970333, 0.1525568025310442, 0.1501449418713806, 0.16713803746519562, 0.16796533131386704, 0.16391971948533313, 0.129710557885373, 0.12993626261705082, 0.12883589099843729]}}
{"id": "7ad4216f-2795-4ce6-a40d-b21ec2e31067", "fitness": 0.14955563308351105, "name": "EnhancedDiverseChaoticLevySwarm", "description": "Introduce a diversity-preserving mechanism using chaotic perturbations and dynamically adjust parameters based on swarm diversity for robustness.", "code": "import numpy as np\n\nclass EnhancedDiverseChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def compute_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            diversity = self.compute_diversity(swarm)\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget) * (diversity / (diversity + 1))\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget) * (1 / (1 + diversity))\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget) * (1 / (1 + diversity))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedDiverseChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14956 with standard deviation 0.01535.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.152061598198036, 0.15258348914927944, 0.15130630854182403, 0.16713551973447593, 0.168011787747138, 0.16588170808278535, 0.12970992327945685, 0.12994810394657674, 0.12936225907202714]}}
{"id": "7e9bc4cd-be5f-47d6-9800-f96c1c99c418", "fitness": 0.14893519679904224, "name": "EnhancedChaoticLevySwarm", "description": "Introduce improved chaos initialization and adaptive chaos parameter for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 3.0 * (self.func_evals / self.budget)  # Adjusted dynamic chaos parameter\n        for _ in range(120):  # Increased iteration count for initialization\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14894 with standard deviation 0.01509.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.15052731409248987, 0.15142600669202133, 0.15216931482701634, 0.16471524413222716, 0.16611838497750697, 0.16732342233708142, 0.1289710777548405, 0.12940832129762758, 0.12975768508056906]}}
{"id": "93d12a2a-0df8-495e-b957-40d34cf9b2df", "fitness": 0.14953525172518067, "name": "EnhancedChaoticLevySwarm", "description": "Enhance swarm diversity by adding chaotic perturbations to the velocity and restrict global best updates to a threshold improvement.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n        self.threshold = 0.01  # Improvement threshold for global best\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * (1 - self.func_evals / self.budget)\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) * np.random.rand(self.swarm_size, self.dim))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score - self.threshold:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14954 with standard deviation 0.01534.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.15204739055167038, 0.1525837126870172, 0.1512614369552544, 0.1671108606523587, 0.1680121769657733, 0.1658084076790235, 0.12970357597418913, 0.12994820311874078, 0.12934150094259866]}}
{"id": "355890e0-2696-44ef-adcf-8f5263c25fe7", "fitness": 0.1494029647059966, "name": "AdaptiveChaoticLevySwarm", "description": "Integrate adaptive inertia weight and self-tuning cognitive and social coefficients for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            inertia_weight = 0.9 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 * (1 - self.func_evals / self.budget)\n            self.c2 = 2.0 * (self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14940 with standard deviation 0.01529.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.1522223585362361, 0.15246224383284712, 0.15082665079829416, 0.16739062489131806, 0.1678059926435026, 0.16510183673665924, 0.12978655422139007, 0.12989328559120727, 0.1291371351025148]}}
{"id": "c9876f5d-69b8-40d5-9030-636b83ca5f0a", "fitness": 0.14963048166460147, "name": "EnhancedChaoticLevySwarm", "description": "Introduce sinusoidal adjustment to the inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14963 with standard deviation 0.01538.", "error": "", "parent_ids": ["2646b3e1-597a-4f8a-92ad-a535680e588b"], "operator": null, "metadata": {"aucs": [0.15209710848358937, 0.15258991812398093, 0.15147639062237173, 0.1671973319430975, 0.1680229846513196, 0.16617604671335928, 0.1297256270204905, 0.12995095559193093, 0.12943797183127326]}}
{"id": "090d55f3-22c6-4bed-ae50-15302966117f", "fitness": 0.14963048166460147, "name": "EnhancedAdaptiveLevySwarm", "description": "Introduce adaptive chaos control and dynamic Levy flight scaling for enhanced exploratory capabilities and convergence precision.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size, scale):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step * scale\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            scale = np.sqrt(1.0 - self.func_evals / self.budget)\n            swarm += self.levy_flight((self.swarm_size, self.dim), scale)  # Dynamic Levy flight scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14963 with standard deviation 0.01538.", "error": "", "parent_ids": ["c9876f5d-69b8-40d5-9030-636b83ca5f0a"], "operator": null, "metadata": {"aucs": [0.15209710848358937, 0.15258991812398093, 0.15147639062237173, 0.1671973319430975, 0.1680229846513196, 0.16617604671335928, 0.1297256270204905, 0.12995095559193093, 0.12943797183127326]}}
{"id": "56e087a2-47c6-40df-b24f-3537f3c3b555", "fitness": 0.149751703619665, "name": "EnhancedChaoticLevySwarm", "description": "Enhance swarm initialization and update strategy to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14975 with standard deviation 0.01544.", "error": "", "parent_ids": ["c9876f5d-69b8-40d5-9030-636b83ca5f0a"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.15170035765989365, 0.1673905116171337, 0.1680423802104587, 0.16653426838052032, 0.12978086679121326, 0.12995605117563236, 0.12954432227854207]}}
{"id": "d4cd4ebc-ba9c-4f93-9cf5-e7b8deebe412", "fitness": 0.1496842200975258, "name": "EnhancedChaoticLevySwarm", "description": "Introduce adaptive velocity scaling and update chaos parameter for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.5 * (self.func_evals / self.budget)  # Updated dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n            velocities *= np.random.uniform(0.8, 1.2, (self.swarm_size, self.dim))  # Adaptive velocity scaling\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14968 with standard deviation 0.01541.", "error": "", "parent_ids": ["56e087a2-47c6-40df-b24f-3537f3c3b555"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.15150816820478852, 0.1673905116171337, 0.1680423802104587, 0.1662053387619682, 0.12978086679121326, 0.12995605117563236, 0.12945808965294636]}}
{"id": "0100990f-ae1f-43a0-8031-53a49a6e4329", "fitness": 0.14946188529531307, "name": "AdaptiveChaoticLevySwarm", "description": "Incorporate adaptive chaotic and Levy-based perturbations with a memory effect to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5\n        self.c1 = 1.5 + np.random.rand()\n        self.c2 = 1.5 + np.random.rand()\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        memory = np.zeros((self.swarm_size, self.dim))\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities + memory\n            memory = self.levy_flight((self.swarm_size, self.dim)) * (0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget))\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14946 with standard deviation 0.01531.", "error": "", "parent_ids": ["56e087a2-47c6-40df-b24f-3537f3c3b555"], "operator": null, "metadata": {"aucs": [0.15209710848358937, 0.15258991812398093, 0.15099568823653942, 0.1671973319430975, 0.1680229846513196, 0.16535565945228825, 0.1297256270204905, 0.12995095559193093, 0.12922169415458118]}}
{"id": "eafdc66e-e9c6-4958-89d2-e63d2f850b68", "fitness": 0.1497391447133893, "name": "EnhancedChaoticLevySwarmV2", "description": "Introduce time-varying chaos and adaptive inertia to improve convergence and maintain diversity in EnhancedChaoticLevySwarm.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarmV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.inertia_weight_range = (0.4, 0.9)  # Adaptive inertia range\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        chaotic_param = 4.0 * (1 - self.func_evals / self.budget)  # Time-varying chaos parameter\n        for _ in range(int(100 * (1 + self.func_evals / self.budget))):  # Adaptive iterations\n            x = chaotic_param * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = (self.inertia_weight_range[0] +\n                      (self.inertia_weight_range[1] - self.inertia_weight_range[0]) *\n                      (1 - self.func_evals / self.budget))  # Adaptive inertia weight\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(1.0 - self.func_evals / self.budget)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedChaoticLevySwarmV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14974 with standard deviation 0.01543.", "error": "", "parent_ids": ["56e087a2-47c6-40df-b24f-3537f3c3b555"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.15166473246507306, 0.1673905116171337, 0.1680423802104587, 0.16647270038038242, 0.12978086679121326, 0.12995605117563236, 0.12952848531701966]}}
{"id": "be1aabf5-ffad-4fdb-92da-05b8bfaac356", "fitness": 0.1497538700933964, "name": "EnhancedChaoticLevySwarm", "description": "Introduce adaptive diversity injection and non-linear convergence control to further enhance search space exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            non_linear_factor = (1 - (self.func_evals / self.budget) ** 2)  # Non-linear convergence control\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(non_linear_factor)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Adaptive diversity injection to escape local optima\n            if np.random.rand() < 0.1 * non_linear_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 5, replace=False)\n                new_positions = self.chaotic_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14975 with standard deviation 0.01544.", "error": "", "parent_ids": ["56e087a2-47c6-40df-b24f-3537f3c3b555"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.15170649284312332, 0.1673905116171337, 0.1680423802104587, 0.16654489973391695, 0.12978086679121326, 0.12995605117563236, 0.1295470540054987]}}
{"id": "4fd048e8-93af-471a-8954-d90d9ab64a0c", "fitness": 0.14971417696517553, "name": "EnhancedChaoticLevySwarm", "description": "Adjust chaotic initialization scaling to slightly increase initial exploration diversity.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.9 * (ub - lb) * x  # Slightly increased scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            non_linear_factor = (1 - (self.func_evals / self.budget) ** 2)  # Non-linear convergence control\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(non_linear_factor)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Adaptive diversity injection to escape local optima\n            if np.random.rand() < 0.1 * non_linear_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 5, replace=False)\n                new_positions = self.chaotic_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14971 with standard deviation 0.01542.", "error": "", "parent_ids": ["be1aabf5-ffad-4fdb-92da-05b8bfaac356"], "operator": null, "metadata": {"aucs": [0.15217812157365052, 0.15259751443867065, 0.1516319711731582, 0.16732934113587805, 0.16803600013014997, 0.1664247819492113, 0.1297635626860021, 0.12995438821799588, 0.12951191138186302]}}
{"id": "d3422674-4480-4529-a1b2-d9bd7bbb0db0", "fitness": 0.1497538700933964, "name": "EnhancedChaoticLevySwarm", "description": "Refine non-linear convergence control for enhanced global search efficacy.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            non_linear_factor = (1 - (self.func_evals / self.budget) ** 1.5)  # Refined non-linear convergence control\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(non_linear_factor)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Adaptive diversity injection to escape local optima\n            if np.random.rand() < 0.1 * non_linear_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 5, replace=False)\n                new_positions = self.chaotic_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14975 with standard deviation 0.01544.", "error": "", "parent_ids": ["be1aabf5-ffad-4fdb-92da-05b8bfaac356"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.15170649284312332, 0.1673905116171337, 0.1680423802104587, 0.16654489973391695, 0.12978086679121326, 0.12995605117563236, 0.1295470540054987]}}
{"id": "8186e194-37f9-4d66-8727-c1fa9f01dc6e", "fitness": 0.14975353008749895, "name": "EnhancedChaoticLevySwarm", "description": "Introduce a dynamic update for the velocity scaling factor to enhance adaptive exploration.", "code": "import numpy as np\n\nclass EnhancedChaoticLevySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            non_linear_factor = (1 - (self.func_evals / self.budget) ** 2)  # Non-linear convergence control\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities * (1 - self.func_evals/self.budget) +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            swarm += self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(non_linear_factor)  # Adaptive step size scaling\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best_scores[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Adaptive diversity injection to escape local optima\n            if np.random.rand() < 0.1 * non_linear_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 5, replace=False)\n                new_positions = self.chaotic_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedChaoticLevySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14975 with standard deviation 0.01544.", "error": "", "parent_ids": ["be1aabf5-ffad-4fdb-92da-05b8bfaac356"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.15170553238257178, 0.1673905116171337, 0.1680423802104587, 0.1665432259741222, 0.12978086679121326, 0.12995605117563236, 0.12954662817276785]}}
{"id": "e2800df3-ff19-49e1-a142-91fd32e637ce", "fitness": 0.14975399178868323, "name": "MultiScaleDynamicSwarm", "description": "Integrate multi-scale perturbation strategies and dynamic learning enhancements to improve convergence robustness and precision.", "code": "import numpy as np\n\nclass MultiScaleDynamicSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            non_linear_factor = (1 - (self.func_evals / self.budget) ** 2)  # Non-linear convergence control\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(non_linear_factor)\n            perturbation *= np.random.choice([0.5, 1.0, 2.0], size=(self.swarm_size, self.dim), p=[0.3, 0.4, 0.3])  # Multi-scale perturbation\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Adaptive diversity injection to escape local optima\n            if np.random.rand() < 0.1 * non_linear_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 5, replace=False)\n                new_positions = self.chaotic_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm MultiScaleDynamicSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14975 with standard deviation 0.01544.", "error": "", "parent_ids": ["be1aabf5-ffad-4fdb-92da-05b8bfaac356"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.1517068369179435, 0.1673905116171337, 0.1680423802104587, 0.16654549813402908, 0.12978086679121326, 0.12995605117563236, 0.1295472067881478]}}
{"id": "57ec6b8f-3d48-4395-931d-1be73025f256", "fitness": 0.1497416877866496, "name": "MultiScaleDynamicSwarm", "description": "Enhance swarm diversity and convergence by integrating a temperature-based perturbation inspired by simulated annealing.", "code": "import numpy as np\n\nclass MultiScaleDynamicSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(40, budget // 3)\n        self.w = 0.5  # Initial inertia weight\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def chaotic_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4.0 - 2.0 * (self.func_evals / self.budget)  # Dynamic chaos parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.85 * (ub - lb) * x  # Slightly modified scaling for initial diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.chaotic_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))  # Reduced initial velocity amplitude\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Sinusoidal inertia weight adjustment\n            self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            non_linear_factor = (1 - (self.func_evals / self.budget) ** 2)  # Non-linear convergence control\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            # Modified perturbation with temperature factor\n            temp_factor = (1 - self.func_evals / self.budget)  # Temperature factor for annealing\n            perturbation = self.levy_flight((self.swarm_size, self.dim)) * np.sqrt(non_linear_factor * temp_factor)\n            perturbation *= np.random.choice([0.5, 1.0, 2.0], size=(self.swarm_size, self.dim), p=[0.3, 0.4, 0.3])\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Adaptive diversity injection to escape local optima\n            if np.random.rand() < 0.1 * non_linear_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 5, replace=False)\n                new_positions = self.chaotic_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm MultiScaleDynamicSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14974 with standard deviation 0.01543.", "error": "", "parent_ids": ["e2800df3-ff19-49e1-a142-91fd32e637ce"], "operator": null, "metadata": {"aucs": [0.1522153432343757, 0.1526012312292151, 0.1516719590186073, 0.1673905116171337, 0.1680423802104587, 0.16648517579158073, 0.12978086679121326, 0.12995605117563236, 0.12953167101162943]}}
{"id": "710a4cc0-eaef-4301-80ea-e1eaad87890b", "fitness": 0.14986815543730753, "name": "AdaptiveCooperativeSwarm", "description": "Hybridize adaptive chaos-driven perturbation and cooperative learning to enhance exploration-exploitation balance and convergence stability.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14987 with standard deviation 0.01549.", "error": "", "parent_ids": ["e2800df3-ff19-49e1-a142-91fd32e637ce"], "operator": null, "metadata": {"aucs": [0.1522856390775491, 0.15271764688131362, 0.15184779863411568, 0.16750683298403968, 0.16824681172459055, 0.16677426826899155, 0.1298133374388053, 0.13000774047386565, 0.12961332345249676]}}
{"id": "79372dff-a2ce-4ec6-9798-8c59309a6e98", "fitness": 0.14982937711225544, "name": "AdaptiveCooperativeSwarm", "description": "Introduce dynamic parameter for enhanced perturbation control, improving convergence stability and diversity.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation * (1.1 - self.func_evals / self.budget)  # Dynamic perturbation factor\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14983 with standard deviation 0.01547.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.1522856390775491, 0.15260845349542174, 0.15184801251003643, 0.16750683298403968, 0.16805479831711367, 0.16677464022047794, 0.1298133374388053, 0.12995926154294324, 0.12961341842391205]}}
{"id": "77d4d1ae-8210-460f-a251-07fa7a63810b", "fitness": 0.14982936062596827, "name": "AdaptiveCooperativeSwarm", "description": "Introduce a random walk mechanism to enhance exploration in adaptive cooperative swarm optimization algorithm.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation\n            swarm += np.random.uniform(-0.1, 0.1, swarm.shape)  # Added random walk for enhanced exploration\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14983 with standard deviation 0.01547.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.1522856390775491, 0.15260845349542174, 0.1518479659259271, 0.16750683298403968, 0.16805479831711367, 0.16677455909157524, 0.1298133374388053, 0.12995926154294324, 0.1296133977603393]}}
{"id": "ad9c1bda-7de0-48d4-b06f-a6788b05da57", "fitness": 0.14979929279574236, "name": "AdaptiveCooperativeSwarm", "description": "Introduce dynamic adjustment for the cognitive and social coefficients based on effective exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 2.0 - np.cos(np.pi * self.func_evals / self.budget)  # Adaptive cognitive coefficient\n            self.c2 = 2.0 - np.sin(np.pi * self.func_evals / self.budget)  # Adaptive social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14980 with standard deviation 0.01545.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.15225679523519964, 0.15258495211760414, 0.15181529548775874, 0.16745662509047965, 0.1680138757183378, 0.16671767863002762, 0.12980058772999303, 0.1299488852566444, 0.12959893989563598]}}
{"id": "422ffcbe-0fd5-434b-9f3a-50cfe20ce280", "fitness": -Infinity, "name": "AdaptiveMetaCooperativeSwarm", "description": "Introduce dynamic learning coefficients and chaotic meta-optimization for enhanced adaptability and faster convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveMetaCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7\n        self.c1 = 1.5 + np.random.rand()\n        self.c2 = 1.5 + np.random.rand()\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x\n\n    def dynamic_coefficients(self):\n        self.w = 0.9 - 0.7 * (self.func_evals / self.budget)\n        self.c1 = 1.5 + 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n        self.c2 = 1.5 + 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n\n    def meta_optimize(self, scores):\n        # Enhance global best using chaotic search around current best\n        min_idx = scores.argmin()\n        perturbation_step = self.chaotic_perturbation((1, self.dim))\n        return scores[min_idx] + perturbation_step\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.dynamic_coefficients()\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            global_best += self.meta_optimize(personal_best_scores)\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 36, "feedback": "An exception occurred: ValueError(\"non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (1,2)\").", "error": "ValueError(\"non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (1,2)\")", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {}}
{"id": "65832578-4c62-4d6d-ab2f-af522b14a8ec", "fitness": 0.1496672286290501, "name": "AdaptiveCooperativeSwarm", "description": "Introducing an adaptive mutation factor to enhance exploitation during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            mutation_factor = 0.01 + 0.04 * (self.func_evals / self.budget)  # Added adaptive mutation factor\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_factor  # Modified here\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14967 with standard deviation 0.01540.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.1522856390775491, 0.15260845349542174, 0.1513863369868812, 0.16750683298403968, 0.16805479831711367, 0.1659840712769043, 0.1298133374388053, 0.12995926154294324, 0.12940632654179274]}}
{"id": "8bca7c7d-1956-45c1-af49-e177832e498c", "fitness": 0.0, "name": "AdaptiveCooperativeSwarm", "description": "Hybridize adaptive chaos-driven perturbation and cooperative learning to enhance exploration-exploitation balance and convergence stability, with improved cooperative dynamic parameter scaling.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2.5 * (1 - (self.func_evals / self.budget) ** 2)  # Improved cooperative dynamic parameter scaling\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00000 with standard deviation 0.00000.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}
{"id": "22356405-ec5b-42e3-b0c4-abfd2069268f", "fitness": 0.14979191037663267, "name": "AdaptiveCooperativeSwarm", "description": "Fine-tune chaotic perturbation and cooperative reinitialization for enhanced swarm dynamics and diversity.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted Levy distribution parameter for more varied step sizes\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 3)  # Adjusted dynamic parameter for initial spread\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.8 * (ub - lb) * x  # Slightly modified scaling for diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * cooperation_factor ** 0.5\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14979 with standard deviation 0.01545.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.15225115756187402, 0.15260488075309264, 0.15177749762427872, 0.16744964715319688, 0.16804865185744633, 0.1666597767036022, 0.12979743119766618, 0.12995768661907214, 0.1295804639194651]}}
{"id": "079a8b27-3905-45ef-a7cf-12fba6f356b8", "fitness": 0.1498292849820716, "name": "AdaptiveCooperativeSwarm", "description": "Introduce a dynamic velocity scaling factor for faster convergence and stability.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (0.9 * (self.w * velocities) +  # Added dynamic velocity scaling\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14983 with standard deviation 0.01547.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.1522856390775491, 0.15260845349542174, 0.15184775205089363, 0.16750683298403968, 0.16805479831711367, 0.16677418714278003, 0.1298133374388053, 0.12995926154294324, 0.12961330278909833]}}
{"id": "021484e7-1e07-4906-8cc7-fb65621ece7d", "fitness": 0.14982975661227269, "name": "AdaptiveCooperativeSwarm", "description": "Introduce stochastic perturbation to enhance solution diversity and robustness against local optima.", "code": "import numpy as np\n\nclass AdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Increased initial inertia weight for better exploration\n        self.c1 = 1.5 + np.random.rand()  # Cognitive coefficient\n        self.c2 = 1.5 + np.random.rand()  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.3  # Slightly adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 2)  # Cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.75 * (ub - lb) * x  # Modified scaling to enhance diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Linear inertia weight adjustment\n            self.c1 = 1.5 + np.cos(np.pi * self.func_evals / self.budget)  # Cooperative cognitive coefficient\n            self.c2 = 1.5 + np.sin(np.pi * self.func_evals / self.budget)  # Cooperative social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * np.sqrt(cooperation_factor)\n\n            if np.random.rand() < 0.1:  # Introduce a small probability for stochastic perturbation\n                perturbation += np.random.normal(0, 0.1, (self.swarm_size, self.dim))  \n\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.05 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14983 with standard deviation 0.01547.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.1522856390775491, 0.15260845349542174, 0.15184908461679714, 0.16750683298403968, 0.16805479831711367, 0.16677650821927847, 0.1298133374388053, 0.12995926154294324, 0.12961389381850597]}}
{"id": "a0003b5f-673b-4152-b5f8-cb12a4e4c1cc", "fitness": 0.14968657183796594, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Enhance interaction between chaotic perturbation and swarm intelligence by integrating dynamic mutation strategies for improved convergence in complex landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.9  # Increased initial inertia weight for enhanced exploration\n        self.c1 = 1.8  # Cognitive coefficient\n        self.c2 = 1.8  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size, step_factor):\n        beta = 1.5  # Adjusted Levy distribution parameter for more aggressive search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = step_factor * (u / np.abs(v) ** (1 / beta))\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 2 + 2 * (1 - (self.func_evals / self.budget) ** 3)  # Enhanced cooperative dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.8 * (ub - lb) * x  # Modified scaling to balance exploration-exploitation\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.6 * (self.func_evals / self.budget)  # Non-linear inertia weight adjustment\n            self.c1 = 1.5 + 0.5 * np.cos(np.pi * self.func_evals / self.budget)  # Dynamic cognitive coefficient\n            self.c2 = 1.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)  # Dynamic social coefficient\n            cooperation_factor = (1 - np.cos(2 * np.pi * self.func_evals / self.budget))\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            step_factor = np.sqrt(cooperation_factor)\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim), step_factor)\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.1 * cooperation_factor:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14969 with standard deviation 0.01541.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.15231648263696784, 0.15252448809084362, 0.15149020448210204, 0.16755075519156715, 0.16791150098958385, 0.1661883298860216, 0.12982903706480597, 0.12992149399243202, 0.12944685420736923]}}
{"id": "3e979832-6736-4a9f-891f-2f3aa4b19b6f", "fitness": 0.14995380477387094, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introduce adaptive mutation strategies and entropy-based diversity preservation to optimize convergence and avoid local optima in swarm behavior.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["710a4cc0-eaef-4301-80ea-e1eaad87890b"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.15258175755761394, 0.15200671378060737, 0.16788882073289257, 0.1680088355857038, 0.16703423212697133, 0.1299166515676472, 0.1299473363188115, 0.12968727582952666]}}
{"id": "707a9c3d-6978-4057-94a8-ff74f4944860", "fitness": 0.14995380477387094, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Enhance swarm movement through dynamic adjustment of mutation rate and velocity direction to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            if self.func_evals > 0.5 * self.budget:  # New condition for improved exploration-exploitation\n                mutation_rate *= 1.5\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.15258175755761394, 0.15200671378060737, 0.16788882073289257, 0.1680088355857038, 0.16703423212697133, 0.1299166515676472, 0.1299473363188115, 0.12968727582952666]}}
{"id": "ceb040ce-08ea-4951-bbc3-b6a73d714b62", "fitness": 0.14993792701906627, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Enhance swarm exploration and convergence by introducing adaptive learning rates and neighborhood-based social interactions.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            neighborhood_best = np.array([personal_best[np.random.choice(self.swarm_size)] for _ in range(self.swarm_size)])  # New line 1\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (neighborhood_best - swarm))  # Modified line 2\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14994 with standard deviation 0.01552.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.1524659964566718, 0.15256311742914064, 0.1520272315925768, 0.16780807114202023, 0.16797637638329255, 0.16706905680533635, 0.1298959169936713, 0.12993906731445437, 0.12969650905443242]}}
{"id": "48ad72af-5f97-4fee-9633-334ad07a1ce5", "fitness": 0.14994643292233756, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introduce a dynamic adjustment to the velocity update mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          0.1 * np.random.rand(self.swarm_size, self.dim))  # Line changed: added random noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01552.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.15249801220847026, 0.15258301532066076, 0.1519991922312125, 0.16786346659839535, 0.16801102604226092, 0.16702118879185723, 0.1299101639505309, 0.12994789423371533, 0.12968393692393465]}}
{"id": "7ad757dd-e0a7-4a40-82ac-32d45f7d2816", "fitness": 0.1499535619087415, "name": "EnhancedAdaptiveCooperativeSwarmV2", "description": "Introduce adaptive learning factors and differential evolution-inspired strategy for enhanced global exploration and local exploitation in swarm optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarmV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.3 * (self.func_evals / self.budget)\n            self.c1 = 2.5 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.5 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += velocities + perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Differential evolution-inspired crossover\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                for idx in random_indexes:\n                    ind1, ind2, ind3 = np.random.choice(self.swarm_size, size=3, replace=False)\n                    mutant = swarm[ind1] + 0.8 * (swarm[ind2] - swarm[ind3])\n                    trial = np.where(np.random.rand(self.dim) < 0.5, mutant, swarm[idx])\n                    trial = np.clip(trial, lb, ub)\n                    trial_score = func(trial)\n                    self.func_evals += 1\n                    if trial_score < scores[idx]:\n                        swarm[idx] = trial\n                        personal_best[idx] = trial\n                        personal_best_scores[idx] = trial_score\n\n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarmV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.15258301532066076, 0.15200476670378937, 0.16788882073289257, 0.16801102604226092, 0.16703085329007483, 0.1299166515676472, 0.12994789423371533, 0.12968640982256852]}}
{"id": "27bbf12f-b018-405b-829e-f1444d92533d", "fitness": 0.1051639654654899, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Enhance swarm diversity by introducing LÃ©vy flight perturbation to improve exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight_perturbation(self, size):\n        beta = 1.5  # LÃ©vy flight parameter\n        return np.random.standard_normal(size) * np.random.standard_normal(size) ** (-1 / beta) \n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.levy_flight_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10516 with standard deviation 0.01632.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.10791538201718232, 0.10797051614274589, 0.10723584336683556, 0.12410624544370918, 0.12420187056996534, 0.12294962085730743, 0.08412606500394071, 0.08415053813096807, 0.08381960765675456]}}
{"id": "a13a155b-6a65-41d1-92e4-d0319741b9cc", "fitness": 0.14995380477387094, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Refined swarm initialization with dynamic scaling for enhanced diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        scaling_factor = 0.5 * (1 + np.sin(np.pi * self.func_evals / self.budget))  # Dynamic scaling\n        return lb + scaling_factor * (ub - lb) * x  # Adjusted scaling factor\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best_scores[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.15258175755761394, 0.15200671378060737, 0.16788882073289257, 0.1680088355857038, 0.16703423212697133, 0.1299166515676472, 0.1299473363188115, 0.12968727582952666]}}
{"id": "753f25ac-3963-441a-8486-71b37b5a2be6", "fitness": 0.14995380477387094, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Enhance convergence by integrating adaptive learning rate and tournament selection for personal best updates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def tournament_selection(self, scores, k=3):\n        \"\"\"Select best individual among 'k' random participants.\"\"\"\n        selected = np.random.choice(len(scores), k, replace=False)\n        best_score_idx = selected[np.argmin(scores[selected])]\n        return best_score_idx\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n                else:  # Tournament selection for personal best update\n                    best_idx = self.tournament_selection(personal_best_scores)\n                    personal_best[i] = personal_best[best_idx]\n                    personal_best_scores[i] = personal_best_scores[best_idx]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.15258175755761394, 0.15200671378060737, 0.16788882073289257, 0.1680088355857038, 0.16703423212697133, 0.1299166515676472, 0.1299473363188115, 0.12968727582952666]}}
{"id": "0fbffbfb-0c34-4194-8f69-1b2b75dffca1", "fitness": -Infinity, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Improve convergence by integrating dynamic swarm size adjustments based on ongoing performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.initial_swarm_size = self.swarm_size  # Added initial swarm size\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.swarm_size = max(10, int(self.initial_swarm_size * (1 - self.func_evals / self.budget)))  # Adjust swarm size dynamically\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,2) (6,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,2) (6,2) ')", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {}}
{"id": "0b9a6521-8870-4ba8-9fba-eecb4c2f607f", "fitness": 0.14995643818259086, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing noise-based velocity adjustment to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["3e979832-6736-4a9f-891f-2f3aa4b19b6f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "d74d5ad2-861f-4045-9dc0-d7daee554833", "fitness": 0.14995643818259086, "name": "RefinedAdaptiveCooperativeSwarm", "description": "Integrating adaptive mutation scaling and diversity-driven leader updates for enhanced swarm exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n            # Adaptive leader update based on diversity\n            diversity = np.mean(np.std(swarm, axis=0))\n            if diversity < 0.1:  # Trigger leader change if diversity is too low\n                new_leader_idx = np.random.choice(self.swarm_size)\n                global_best = swarm[new_leader_idx]\n                global_best_score = scores[new_leader_idx]\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm RefinedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "22e24da2-5cd4-4913-8cc6-b37381e4b974", "fitness": 0.1499510387920262, "name": "EnhancedAdaptiveCooperativeSwarmRefined", "description": "Introducing a dynamic neighborhood-based search and adaptive learning to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarmRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.2 * np.sin(np.pi * self.func_evals / self.budget)  # Dynamic inertia adjustment\n            self.c1 = 2.1 - 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            self.c2 = 1.8 + 0.2 * np.sin(np.pi * self.func_evals / self.budget)\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.15 + 0.25 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            neighborhood = np.random.permutation(self.swarm_size)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (swarm[neighborhood] - swarm) + np.random.normal(0, 0.05, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarmRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01552.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15247693775581384, 0.15256975005964735, 0.1520468801098629, 0.16782684808792792, 0.16798792626961523, 0.16710287424870884, 0.12990080796431935, 0.12994200962087477, 0.12970531501146565]}}
{"id": "854a2d95-faf0-48d0-94a3-e0ffc4c3a3b3", "fitness": 0.14995643818259086, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Incorporating periodic swarm reinitialization to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate or self.func_evals % (self.budget // 10) == 0:  # Change: Added periodic reinitialization\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "b56f35f5-8c60-4ba2-a99c-807169bb61fc", "fitness": 0.14995380477387094, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introduce adaptive learning and memory to enhance swarm intelligence and improve convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n        self.memory = []  # Memory to store best historical positions\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def adaptive_learning(self, velocities, personal_best):\n        # Introduce adaptive learning based on historical memory\n        if self.memory:\n            historical_best = np.mean(self.memory, axis=0)\n            velocities += np.random.normal(0, 0.1, velocities.shape) * (historical_best - personal_best)\n        return velocities\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm))\n            velocities = self.adaptive_learning(velocities, personal_best)\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n                self.memory.append(global_best.copy())\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.15258175755761394, 0.15200671378060737, 0.16788882073289257, 0.1680088355857038, 0.16703423212697133, 0.1299166515676472, 0.1299473363188115, 0.12968727582952666]}}
{"id": "9b1abded-5acf-4532-bb81-7008bda4faa9", "fitness": 0.1499383845636445, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing weighted chaotic perturbation and adaptive mutation based on diversity for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.uniform(-0.15, 0.15, velocities.shape))  # Adjusted noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation * np.abs(velocities)  # Weighted perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14994 with standard deviation 0.01552.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1525009220519784, 0.15258301532066076, 0.15197345770731163, 0.16786850250538576, 0.16801102604226092, 0.1669767458888487, 0.12991145671035853, 0.12994789423371533, 0.12967244061228045]}}
{"id": "1a7edafa-2f76-44b1-8be6-859670f71ef1", "fitness": -Infinity, "name": "AdaptivePopulationCooperativeSwarm", "description": "Introducing adaptive population resizing based on entropy to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptivePopulationCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = min(50, budget // 3)\n        self.swarm_size = self.initial_swarm_size\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub, size):\n        x = np.random.rand(size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def resize_population(self, entropy):\n        \"\"\"Adaptive population resizing based on entropy.\"\"\"\n        max_size = self.initial_swarm_size * 2\n        min_size = max(10, self.initial_swarm_size // 2)\n        normalized_entropy = entropy / np.log(self.swarm_size)\n        self.swarm_size = int(min_size + (max_size - min_size) * normalized_entropy)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub, self.swarm_size)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            self.resize_population(entropy)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub, len(random_indexes))\n                swarm[random_indexes] = new_positions\n\n        return global_best", "configspace": "", "generation": 58, "feedback": "An exception occurred: ValueError('negative dimensions are not allowed').", "error": "ValueError('negative dimensions are not allowed')", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {}}
{"id": "a9ecb2e9-8dd5-401b-9680-1ed02510dad5", "fitness": 0.1487027548769542, "name": "QuantumAdaptiveSwarm", "description": "Integrate adaptive neighborhood-based learning and quantum-inspired perturbation to enhance diversity and convergence.", "code": "import numpy as np\n\nclass QuantumAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.func_evals = 0\n\n    def quantum_perturbation(self, size):\n        delta = 1e-4\n        alpha = np.random.uniform(0, 2 * np.pi, size)\n        return delta * np.tan(alpha)\n\n    def adaptive_neighborhood(self, swarm, scores):\n        adj_matrix = np.zeros((self.swarm_size, self.swarm_size))\n        for i in range(self.swarm_size):\n            distances = np.linalg.norm(swarm - swarm[i], axis=1)\n            nearest_idx = np.argsort(distances)[1:4]\n            adj_matrix[i, nearest_idx] = 1\n        return adj_matrix\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.4 * (np.sin(np.pi * self.func_evals / self.budget))  # Dynamic inertia weight\n            adj_matrix = self.adaptive_neighborhood(swarm, personal_best_scores)\n\n            for i in range(self.swarm_size):\n                if adj_matrix[i].sum() > 0:\n                    local_best_idx = np.argmin(personal_best_scores[adj_matrix[i] == 1])\n                    local_best = personal_best[local_best_idx]\n                else:\n                    local_best = global_best\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n\n                velocities[i] = (self.w * velocities[i] +\n                                self.c1 * r1 * (personal_best[i] - swarm[i]) +\n                                self.c2 * r2 * (local_best - swarm[i]))\n\n            swarm += velocities + self.quantum_perturbation((self.swarm_size, self.dim))\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "The algorithm QuantumAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14870 with standard deviation 0.01498.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1498669289835034, 0.15232111139906634, 0.15132286912747317, 0.16346676151895778, 0.16757117436429636, 0.1658611441851956, 0.12870537662111514, 0.12982838108363703, 0.12938104660934313]}}
{"id": "335eafab-d130-4c07-8ec6-cb692027497e", "fitness": 0.1499262104136917, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing chaos-based velocity update to reinforce exploration while maintaining exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + 0.1 * self.chaotic_perturbation(velocities.shape))  # Replaced noise with chaotic perturbation\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14993 with standard deviation 0.01551.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15240892318082688, 0.15257306637490076, 0.15204128760917113, 0.16770887974427962, 0.16799370121277657, 0.16709315498540145, 0.12987057775907274, 0.1299434807740848, 0.12970282208271122]}}
{"id": "626c3ac3-7e35-4192-a3df-a0bf2107c253", "fitness": 0.14974350236035253, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing dynamic mutation rate based on swarm clustering to enhance exploitation in later stages.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def cluster_swarm(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        distances = np.linalg.norm(swarm - centroid, axis=1)\n        return np.mean(distances)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            clustering = self.cluster_swarm(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - clustering / np.max([clustering, 0.1]))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14974 with standard deviation 0.01543.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1523780469098167, 0.15257258039817878, 0.151553711600233, 0.1676549917007435, 0.16799285291735389, 0.16625411167448756, 0.12985695418261367, 0.1299432821049633, 0.1294849897547824]}}
{"id": "b3eb782a-09cb-4c64-85d8-71c274472005", "fitness": 0.14994690912466627, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing dynamic mutation strategies and enhanced velocity updates to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.7  # Adjusted for even broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.5 + 0.4 * np.random.rand()  # Randomized inertia weight\n            self.c1 = 2.0 - (1.0 * np.sin(np.pi * self.func_evals / self.budget))  # Revised dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.0 * np.cos(np.pi * self.func_evals / self.budget))  # Revised dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01552.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1524893079608679, 0.1525710447227665, 0.1520211997152392, 0.1678484459374564, 0.1679901805157028, 0.16705942209343205, 0.1299062842806592, 0.1299425963944042, 0.12969370050146822]}}
{"id": "04446e9c-44b6-4ddf-ac89-53e59ee897b4", "fitness": 0.149944169732651, "name": "MultiModalAdaptiveSwarm", "description": "Introducing multi-modal adaptive learning to improve diversity and convergence speed in dynamic environments.", "code": "import numpy as np\n\nclass MultiModalAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n        self.modal_switch = 0.05  # Probability of switching modes\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def dynamic_learning_rate(self, current_iter, max_iter):\n        return 0.1 + 0.9 * (1 - current_iter / max_iter)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            if np.random.rand() < self.modal_switch:\n                velocities *= -1  # Reverse directions to explore different regions\n\n            learning_rate = self.dynamic_learning_rate(self.func_evals, self.budget)\n            velocities *= learning_rate\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm MultiModalAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14994 with standard deviation 0.01552.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1524426849524756, 0.1525680919020207, 0.15206325554177091, 0.16776769634658406, 0.1679850387980345, 0.16713136446058152, 0.1298855497066833, 0.12994127404426958, 0.12971257184143892]}}
{"id": "ef427a85-771f-4b89-88e7-814165d65b00", "fitness": 0.14995643818259086, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Leveraging LÃ©vy flights and adaptive learning rates to enhance exploration and convergence in swarm optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.levy_flight((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "fbe80ae7-6571-4f3c-85ea-03ec66f9ed24", "fitness": 0.14995643818259086, "name": "AdaptiveSwarmWithDiversity", "description": "Adaptive Swarm with Diversity Preservation: Introduces entropy-guided mutation and chaos-induced perturbation to maintain diversity and enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveSwarmWithDiversity:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.func_evals = 0\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - 1.5 * np.cos(np.pi * self.func_evals / self.budget)\n            self.c2 = 2.0 - 1.5 * np.sin(np.pi * self.func_evals / self.budget)\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveSwarmWithDiversity got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "c02b1095-d0ea-42cd-b762-ca15bf7d0d9c", "fitness": 0.14974120797526458, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing adaptive learning based on swarm diversity and dynamic chaotic exploration to enhance performance and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.2  # Adjusted for better chaotic behavior\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_diversity(self, swarm):\n        mean_pos = np.mean(swarm, axis=0)\n        diversity = np.mean(np.abs(swarm - mean_pos))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            diversity = self.calculate_diversity(swarm)\n            self.w = 0.7 - 0.3 * (diversity / np.max(diversity))  # Adaptive inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.05, velocities.shape))  # Reduced noise\n\n            swarm = swarm + velocities\n            if np.random.rand() < 0.2:  # Dynamic perturbation based on random chance\n                perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * 0.3\n                swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < 0.2:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14974 with standard deviation 0.01543.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1524307592305385, 0.15256740076076503, 0.15149932562723767, 0.1677469267700088, 0.167983832946636, 0.1661607142916942, 0.12988030111477455, 0.1299409678895188, 0.12946064314620764]}}
{"id": "c78e31f1-beb0-42d9-a9fd-8772e6289ffd", "fitness": 0.14995643818259086, "name": "RefinedAdaptiveCooperativeSwarm", "description": "Integrate a multi-faceted disruption mechanism with adaptive chaos and entropy-driven perturbations to enhance global search capabilities.", "code": "import numpy as np\n\nclass RefinedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n            for i in range(self.swarm_size // 10):\n                idx = np.random.randint(0, self.swarm_size)\n                swarm[idx] = lb + np.random.rand(self.dim) * (ub - lb)  # Random reinitialization for exploration\n\n        return global_best", "configspace": "", "generation": 67, "feedback": "The algorithm RefinedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "906f1a50-2da6-4555-aa19-50c862f77e74", "fitness": -Infinity, "name": "QuantumAdaptiveCooperativeSwarm", "description": "Introducing quantum-inspired exploration and adaptive chaotic perturbation for enhanced convergence and diversity in cooperative swarms.", "code": "import numpy as np\n\nclass QuantumAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def quantum_exploration(self, size):\n        alpha, beta = 0.5, 1.0  # Control parameters for quantum exploration\n        random_walk = np.random.normal(0, 1, size)\n        levy = np.random.standard_cauchy(size) * beta\n        return alpha * random_walk + levy\n\n    def adaptive_chaotic_perturbation(self, size, entropy):\n        beta = 1.5 + 0.5 * (1 - entropy)  # Adjusted dynamically based on entropy\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        return u / np.abs(v) ** (1 / beta)\n    \n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + self.quantum_exploration(velocities.shape))  # Quantum exploration\n\n            swarm = swarm + velocities\n            perturbation = self.adaptive_chaotic_perturbation((self.swarm_size, self.dim), entropy) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "An exception occurred: OverflowError('math range error').", "error": "OverflowError('math range error')", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {}}
{"id": "6c1f5043-9c6b-4cc0-8298-06bd9521d659", "fitness": 0.14995643818259086, "name": "RefinedAdaptiveCooperativeSwarm", "description": "Utilize adaptive chaotic perturbations and diversity-focused population reset to enhance swarm adaptability and exploration.", "code": "import numpy as np\n\nclass RefinedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def diversity_reset(self, swarm, lb, ub):\n        reset_size = self.swarm_size // 4\n        reset_indices = np.random.choice(self.swarm_size, size=reset_size, replace=False)\n        new_positions = self.cooperative_init(lb, ub)\n        swarm[reset_indices] = new_positions[reset_indices]\n        return swarm\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm = np.clip(swarm + perturbation, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                swarm = self.diversity_reset(swarm, lb, ub)\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "86815b69-4973-4012-9342-940ed8efae17", "fitness": 0.14979060401449312, "name": "EnhancedAdaptiveMemorySwarm", "description": "Introducing adaptive memory-based search and dynamic sub-swarm strategies to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n        self.memory_size = 5  # Memory size to store historical bests\n        self.global_memory = []\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def update_memory(self, new_entry):\n        self.global_memory.append(new_entry)\n        if len(self.global_memory) > self.memory_size:\n            self.global_memory.pop(0)\n    \n    def select_from_memory(self):\n        return self.global_memory[np.random.randint(len(self.global_memory))]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        self.update_memory(global_best)\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            mutation_rate = 0.1 + 0.4 * (1 - np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) +\n                          np.random.normal(0, 0.1, velocities.shape))\n\n            if np.random.rand() < 0.5:\n                mem_selection = self.select_from_memory()\n                velocities += np.random.normal(0, 0.1, velocities.shape) * (mem_selection - swarm)\n\n            swarm += velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n                self.update_memory(global_best)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14979 with standard deviation 0.01545.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15237773222576545, 0.15256958026063727, 0.1516905440301075, 0.16765444632603166, 0.1679876278493545, 0.16649088574615656, 0.12985676875487795, 0.1299419596139536, 0.12954589132355365]}}
{"id": "4fcfb843-b6b5-4b9b-a4fd-c6c287f5d1f7", "fitness": 0.14974697128737147, "name": "RefinedAdaptiveCooperativeSwarm", "description": "Incorporating adaptive agents' cooperation and perturbation through dynamic chaos to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.9  # Initial inertia weight, allowing more exploration at start\n        self.c1 = 1.5  # Lower cognitive coefficient for more exploration\n        self.c2 = 2.5  # Higher social coefficient for faster convergence\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def adaptive_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 3.5 - 2.5 * (self.func_evals / self.budget)  # Dynamic parameter\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.adaptive_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.6 * (self.func_evals / self.budget)\n            self.c1 = 1.5 + (1.5 * np.sin(2 * np.pi * self.func_evals / self.budget))\n            self.c2 = 2.5 - (1.0 * np.cos(2 * np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.2 + 0.3 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.adaptive_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm RefinedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14975 with standard deviation 0.01542.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15225913178213912, 0.15209960416192614, 0.15215508081670548, 0.167457262506707, 0.1671824838175432, 0.1672800102378471, 0.12980246321153133, 0.1297311192161752, 0.12975558583576863]}}
{"id": "fb9e96ec-9efa-4540-aaa4-4d09e3182e29", "fitness": 0.14994047297428437, "name": "AdaptiveMultiSwarm", "description": "Adaptive Multi-Swarm with Dynamic Neighborhoods: Implementing multiple interacting swarms with adaptive neighborhood sizes to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveMultiSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3\n        self.swarm_size = min(30, budget // (2 * self.num_swarms))\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        multi_global_best_score = float('inf')\n        multi_global_best = None\n\n        swarms = [self.cooperative_init(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best = [swarm.copy() for swarm in swarms]\n        personal_best_scores = [np.array([func(x) for x in pb]) for pb in personal_best]\n        self.func_evals += self.num_swarms * self.swarm_size\n\n        global_bests = [pb[np.argmin(pbs)] for pb, pbs in zip(personal_best, personal_best_scores)]\n        global_best_scores = [pbs.min() for pbs in personal_best_scores]\n\n        while self.func_evals < self.budget:\n            updates = []\n            for i in range(self.num_swarms):\n                self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n                self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n                self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n                \n                entropy = self.calculate_entropy(swarms[i])\n                mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n                r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - swarms[i]) +\n                                 self.c2 * r2 * (global_bests[i] - swarms[i]) + \n                                 np.random.normal(0, 0.1, velocities[i].shape))\n\n                swarms[i] = swarms[i] + velocities[i]\n                perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n                swarms[i] += perturbation\n                swarms[i] = np.clip(swarms[i], lb, ub)\n\n                scores = np.array([func(x) for x in swarms[i]])\n                self.func_evals += self.swarm_size\n\n                for j in range(self.swarm_size):\n                    if scores[j] < personal_best_scores[i][j]:\n                        personal_best[i][j] = swarms[i][j]\n                        personal_best_scores[i][j] = scores[j]\n\n                min_idx = personal_best_scores[i].argmin()\n                if personal_best_scores[i][min_idx] < global_best_scores[i]:\n                    global_bests[i] = personal_best[i][min_idx]\n                    global_best_scores[i] = personal_best_scores[i][min_idx]\n\n                updates.append((global_best_scores[i], global_bests[i]))\n\n            for score, best in updates:\n                if score < multi_global_best_score:\n                    multi_global_best_score = score\n                    multi_global_best = best\n\n            if np.random.rand() < mutation_rate:\n                for i in range(self.num_swarms):\n                    random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                    new_positions = self.cooperative_init(lb, ub)\n                    swarms[i][random_indexes] = new_positions[random_indexes]\n\n        return multi_global_best", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveMultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14994 with standard deviation 0.01552.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15249525528602192, 0.1525747245325274, 0.15199342103118918, 0.16785859508044587, 0.16799658868435718, 0.1670110851207397, 0.12990896287347664, 0.12994421635068976, 0.12968140780911175]}}
{"id": "218489d5-a466-442b-a804-0b29b0bfa8a1", "fitness": 0.14995643818259086, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Enhance swarm diversity and convergence by integrating LÃ©vy flight perturbation and adaptive parameter control mechanisms.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            swarm = swarm + velocities\n            perturbation = self.levy_flight((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "85b2698a-d8ca-4830-a08f-0b29c2c3269e", "fitness": 0.14995630952446803, "name": "EnhancedAdaptiveCooperativeSwarmPlus", "description": "Introduce LÃ©vy flight-based perturbation and dynamic mutation scaling to enhance the exploration capabilities of the swarm.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarmPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.5 * step  # New scaling factor\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.2 + 0.3 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.levy_flight((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarmPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.1525122559705565, 0.1525747245325274, 0.1520211997152392, 0.16788818750739964, 0.16799658868435718, 0.16705942209343205, 0.12991649036454223, 0.12994421635068976, 0.12969370050146822]}}
{"id": "1943ed99-cd24-4af2-9a10-2b9a28096569", "fitness": 0.14995643818259086, "name": "EnhancedExplorativeAdaptiveSwarm", "description": "Enhanced explorative adaptive swarm with dynamic inertia and chaotic perturbations for optimized convergence in black-box environments.", "code": "import numpy as np\n\nclass EnhancedExplorativeAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(60, budget // 3)  # Increased swarm size for enhanced exploration\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 2.5  # Cognitive coefficient tuned for better individual exploration\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.7  # Adjusted to refine search exploration\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = self.w_max - (self.w_max - self.w_min) * (self.func_evals / self.budget)  # Dynamic inertia weight\n            self.c1 = 2.5 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.15 + 0.35 * (1 - entropy / np.log(self.swarm_size))  # Adjusted mutation rate\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedExplorativeAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14996 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525747245325274, 0.1520211997152392, 0.16788882073289257, 0.16799658868435718, 0.16705942209343205, 0.1299166515676472, 0.12994421635068976, 0.12969370050146822]}}
{"id": "ab1596af-ecfa-47f1-9843-35398c6cd962", "fitness": 0.14995349630160376, "name": "EnhancedAdaptiveCooperativeSwarm", "description": "Introducing dynamic sub-swarm formation and enhanced local search to exploit diverse search regions effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCooperativeSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def form_sub_swarms(self, swarm, num_sub_swarms=3):\n        indices = np.random.choice(np.arange(self.swarm_size), size=(num_sub_swarms, self.swarm_size // num_sub_swarms), replace=False)\n        return [swarm[idx] for idx in indices]\n\n    def enhanced_local_search(self, swarm, global_best):\n        perturbation = np.random.uniform(-0.1, 0.1, swarm.shape)\n        return np.clip(swarm + perturbation, global_best - 0.1, global_best + 0.1)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            swarm = swarm + velocities\n            sub_swarms = self.form_sub_swarms(swarm)\n            for sub_swarm in sub_swarms:\n                sub_swarm = self.enhanced_local_search(sub_swarm, global_best)\n\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptiveCooperativeSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14995 with standard deviation 0.01553.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15251261946506411, 0.1525780408477807, 0.1520098765636526, 0.16788882073289257, 0.16800236362751853, 0.1670384821415707, 0.1299166515676472, 0.1299456875038999, 0.12968892426440737]}}
{"id": "179ca5df-ca80-4088-9e10-66bd7c5c4f32", "fitness": 0.15011251712296536, "name": "AdaptiveMemorySwarm", "description": "Utilize adaptive memory-based learning in conjunction with chaotic perturbation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        \"\"\"Update memory based on performance.\"\"\"\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            # Incorporate memory into position update\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Update memory based on performance\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15011 with standard deviation 0.01560.", "error": "", "parent_ids": ["0b9a6521-8870-4ba8-9fba-eecb4c2f607f"], "operator": null, "metadata": {"aucs": [0.15262694411790412, 0.15241432850533998, 0.15251343525511651, 0.16808660954933452, 0.16772140867588392, 0.16789364981590604, 0.1299675481560223, 0.12987237351564362, 0.12991635651553712]}}
{"id": "f851e826-6b9f-4a8d-abbc-7c63f61b3346", "fitness": 0.15011251712296536, "name": "DynamicSwarmRestructure", "description": "Introduce dynamic swarm restructuring and diversity-enhanced chaotic perturbation for improved exploration-exploitation synergy.", "code": "import numpy as np\n\nclass DynamicSwarmRestructure:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size, diversity_factor):\n        \"\"\"Enhanced chaotic perturbation based on current diversity.\"\"\"\n        beta = 1.5 + 0.5 * diversity_factor  # Adjusted for diversity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def restructure_swarm(self, swarm, scores):\n        \"\"\"Dynamic restructuring of the swarm based on current performance.\"\"\"\n        top_performers = np.argsort(scores)[:self.swarm_size // 2]\n        new_positions = np.random.rand(self.swarm_size // 2, self.dim)\n        swarm[top_performers] = new_positions\n        return swarm\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim), entropy) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                swarm = self.restructure_swarm(swarm, scores)\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm DynamicSwarmRestructure got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15011 with standard deviation 0.01560.", "error": "", "parent_ids": ["179ca5df-ca80-4088-9e10-66bd7c5c4f32"], "operator": null, "metadata": {"aucs": [0.15262694411790412, 0.15241432850533998, 0.15251343525511651, 0.16808660954933452, 0.16772140867588392, 0.16789364981590604, 0.1299675481560223, 0.12987237351564362, 0.12991635651553712]}}
{"id": "339701b5-bc4a-495b-8523-c05e7d47128e", "fitness": 0.15011251712296536, "name": "EnhancedSwarmOptimizer", "description": "Integrate LÃ©vy flight-based exploration and dynamic memory adaptation to enhance convergence and robustness in varied search spaces.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        \"\"\"Update memory based on performance.\"\"\"\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            # Incorporate memory into position update\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            perturbation = self.levy_flight((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Update memory based on performance\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15011 with standard deviation 0.01560.", "error": "", "parent_ids": ["179ca5df-ca80-4088-9e10-66bd7c5c4f32"], "operator": null, "metadata": {"aucs": [0.15262694411790412, 0.15241432850533998, 0.15251343525511651, 0.16808660954933452, 0.16772140867588392, 0.16789364981590604, 0.1299675481560223, 0.12987237351564362, 0.12991635651553712]}}
{"id": "78bb5e6b-fb5a-446f-be02-e87e1deb776b", "fitness": 0.10538899721422747, "name": "HybridMemorySwarm", "description": "Introduce hybrid velocity update synergizing differential evolution and particle swarm optimization for enhanced convergence.", "code": "import numpy as np\n\nclass HybridMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        \"\"\"Update memory based on performance.\"\"\"\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            for i in range(self.swarm_size):\n                rand_idx = np.random.choice(np.delete(np.arange(self.swarm_size), i), 3, replace=False)\n                mutant_vector = swarm[rand_idx[0]] + 0.8 * (swarm[rand_idx[1]] - swarm[rand_idx[2]])  # DE Mutation\n                trial_vector = np.where(np.random.rand(self.dim) < 0.9, mutant_vector, swarm[i])  # DE Crossover\n\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1[i] * (personal_best[i] - swarm[i]) +\n                                 self.c2 * r2[i] * (global_best - swarm[i]) + np.random.normal(0, 0.1, self.dim))\n\n                swarm[i] = trial_vector + velocities[i]  # Hybrid update\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Update memory based on performance\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm HybridMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10539 with standard deviation 0.01642.", "error": "", "parent_ids": ["179ca5df-ca80-4088-9e10-66bd7c5c4f32"], "operator": null, "metadata": {"aucs": [0.1080333558660701, 0.10781488604363232, 0.10791461413335246, 0.12431038568246167, 0.12393496130148518, 0.12410831670729328, 0.08417857689710895, 0.08408081086970631, 0.08412506742693693]}}
{"id": "ee8bc08c-a463-4650-b084-334411a3d4f4", "fitness": 0.15011251712296536, "name": "AdaptiveMemorySwarm", "description": "Refine adaptive memory swarm using a dynamic mutation rate scaling factor for improved search space coverage.", "code": "import numpy as np\n\nclass AdaptiveMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        \"\"\"Calculate diversity using entropy.\"\"\"\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        \"\"\"Update memory based on performance.\"\"\"\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.7 - 0.5 * (self.func_evals / self.budget)  # Adapt inertia weight\n            self.c1 = 2.0 - (1.5 * np.cos(np.pi * self.func_evals / self.budget))  # Dynamic cognitive coefficient\n            self.c2 = 2.0 - (1.5 * np.sin(np.pi * self.func_evals / self.budget))  # Dynamic social coefficient\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - swarm) +\n                          self.c2 * r2 * (global_best - swarm) + np.random.normal(0, 0.1, velocities.shape))  # Added noise\n\n            # Incorporate memory into position update\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            perturbation = self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            swarm += perturbation\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            # Update memory based on performance\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate * (1 - self.func_evals / self.budget):  # Added dynamic scaling factor\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15011 with standard deviation 0.01560.", "error": "", "parent_ids": ["179ca5df-ca80-4088-9e10-66bd7c5c4f32"], "operator": null, "metadata": {"aucs": [0.15262694411790412, 0.15241432850533998, 0.15251343525511651, 0.16808660954933452, 0.16772140867588392, 0.16789364981590604, 0.1299675481560223, 0.12987237351564362, 0.12991635651553712]}}
{"id": "2a5c9fed-1b09-4712-b274-77621cccdd90", "fitness": 0.15011647268834102, "name": "EnhancedMemorySwarm", "description": "Introduce a dual-strategy velocity update combining adaptive inertia weight and local exploitation with a perturbation-based exploration to balance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.5  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.7 * (self.func_evals / self.budget)  # Adapt inertia weight more aggressively\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            # Dual-strategy velocity update\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            # Incorporate memory into position update\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["179ca5df-ca80-4088-9e10-66bd7c5c4f32"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15249404424106883, 0.16809296097164528, 0.1677682158937417, 0.1678599236753353, 0.12996916346081555, 0.1298843237328281, 0.1299077713682839]}}
{"id": "9354b24a-2fde-480d-8eef-c92cce1b0f34", "fitness": 0.1501165439325386, "name": "EnhancedMemorySwarm", "description": "Enhance the chaotic perturbation by adjusting the beta parameter for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    # Adjustment in this function only as a single line change\n    def chaotic_perturbation(self, size):\n        beta = 1.8  # Adjusted for a broader search\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)  # Dynamic parameter for better initial diversity\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x  # Uniform scaling\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.7 * (self.func_evals / self.budget)  # Adapt inertia weight more aggressively\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            # Dual-strategy velocity update\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            # Incorporate memory into position update\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["2a5c9fed-1b09-4712-b274-77621cccdd90"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15249424840369163, 0.16809296097164528, 0.1677682158937417, 0.16786027820060012, 0.12996916346081555, 0.1298843237328281, 0.12990785387817427]}}
{"id": "cfc43fd3-6682-4e6b-9f7c-2599207c336f", "fitness": 0.15011805427749667, "name": "EnhancedMemorySwarm", "description": "Introduce an adaptive chaos intensity and hypermutation strategy for improved convergence in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - 0.7 * (self.func_evals / self.budget)\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["9354b24a-2fde-480d-8eef-c92cce1b0f34"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15249852051443735, 0.16809296097164528, 0.1677682158937417, 0.1678677008265701, 0.12996916346081555, 0.1298843237328281, 0.12990975224608126]}}
{"id": "f5f42bcc-c81a-4b56-b370-5a41c29fdd80", "fitness": 0.15011806085057847, "name": "EnhancedMemorySwarm", "description": "Introduce a dynamic inertia weight decay based on sigmoid function for improved performance in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))  # Changed line\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["cfc43fd3-6682-4e6b-9f7c-2599207c336f"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.1524985391024144, 0.16809296097164528, 0.1677682158937417, 0.16786773313987458, 0.12996916346081555, 0.1298843237328281, 0.1299097605025361]}}
{"id": "1edbd83d-b1e0-4850-9f65-70fe00a654c7", "fitness": 0.15011806085057847, "name": "EnhancedMemorySwarm", "description": "Introduce adaptive learning rate decay to further enhance exploration-exploitation balance in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["f5f42bcc-c81a-4b56-b370-5a41c29fdd80"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.1524985391024144, 0.16809296097164528, 0.1677682158937417, 0.16786773313987458, 0.12996916346081555, 0.1298843237328281, 0.1299097605025361]}}
{"id": "d2aba60a-4f34-4c52-820a-15275afc2674", "fitness": -Infinity, "name": "EnhancedMemorySwarm", "description": "EnhancedMemorySwarm with adaptive swarm size reduction based on convergence to improve efficiency and exploration balance.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5))) \n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n            if self.func_evals > self.budget * 0.75:  # New adaptive swarm size reduction\n                self.swarm_size = max(10, int(self.swarm_size * 0.9))\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,2) (6,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,2) (6,2) ')", "parent_ids": ["f5f42bcc-c81a-4b56-b370-5a41c29fdd80"], "operator": null, "metadata": {}}
{"id": "19191e61-b9f7-4b1d-b1cb-537dcf95a121", "fitness": 0.15011806085057847, "name": "EnhancedMemorySwarm", "description": "EnhancedMemorySwarm with hybrid chaotic perturbation and reinforced memory adaptation for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = 0.5 * self.memory[i] + 0.5 * swarm[i]  # Changed line\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["f5f42bcc-c81a-4b56-b370-5a41c29fdd80"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.1524985391024144, 0.16809296097164528, 0.1677682158937417, 0.16786773313987458, 0.12996916346081555, 0.1298843237328281, 0.1299097605025361]}}
{"id": "b2684668-2269-44f4-8a9d-c6c9f4c88aa8", "fitness": 0.1501167581373024, "name": "EnhancedMemorySwarm", "description": "Introduce adaptive learning rates based on swarm diversity in EnhancedMemorySwarm for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def calculate_diversity(self, swarm):\n        mean_position = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - mean_position, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            entropy = self.calculate_entropy(swarm)\n            diversity = self.calculate_diversity(swarm)\n            adaptive_c1 = self.c1 * (1 + diversity)\n            adaptive_c2 = self.c2 * (1 + diversity)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            \n            local_exploitation = r1 * adaptive_c1 * (personal_best - swarm)\n            global_exploration = r2 * adaptive_c2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["f5f42bcc-c81a-4b56-b370-5a41c29fdd80"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15243757676177927, 0.1524985391024144, 0.16809296097164528, 0.16776180479626424, 0.16786773313987458, 0.12996916346081555, 0.12988269118644014, 0.1299097605025361]}}
{"id": "ca6ba3e9-8ad0-426d-b16d-6b79150a2d8e", "fitness": 0.15011806085057847, "name": "EnhancedMemorySwarm", "description": "Introduce a self-adaptive chaotic perturbation coefficient for dynamic local exploration in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))  # Changed line\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size))\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["f5f42bcc-c81a-4b56-b370-5a41c29fdd80"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.1524985391024144, 0.16809296097164528, 0.1677682158937417, 0.16786773313987458, 0.12996916346081555, 0.1298843237328281, 0.1299097605025361]}}
{"id": "6e7e7e6d-e863-47e9-97e0-5f06414bae01", "fitness": 0.1501183040934096, "name": "EnhancedMemorySwarm", "description": "Introduce adaptive memory reinforcement and chaotic mutation rate for enhanced exploration-exploitation balance in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["f5f42bcc-c81a-4b56-b370-5a41c29fdd80"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.1524992269403329, 0.16809296097164528, 0.1677682158937417, 0.16786892898228134, 0.12996916346081555, 0.1298843237328281, 0.12991006600769062]}}
{"id": "17c02cb7-aec8-47e5-a8c7-4a5808a4ca03", "fitness": 0.15011830317593022, "name": "EnhancedMemorySwarm", "description": "Introduce dynamic inertia weight scheduling by using a cosine function for smoother exploration-exploitation transition in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.4 + 0.5 * (np.cos(np.pi * self.func_evals / self.budget) + 1) / 2  # Dynamic inertia weight\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration)\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["6e7e7e6d-e863-47e9-97e0-5f06414bae01"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.1524992269403329, 0.16809296097164528, 0.1677682158937417, 0.16786892898228134, 0.12996916346081555, 0.1298843237328281, 0.12991005775037645]}}
{"id": "a810b668-8865-46f5-8041-70f4beabf653", "fitness": 0.15011831632633946, "name": "EnhancedMemorySwarm", "description": "Modify velocity update to introduce inertia weight decay to improve convergence precision and speed in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + local_exploitation + global_exploration) * 0.99  # Introduced inertia weight decay\n\n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["6e7e7e6d-e863-47e9-97e0-5f06414bae01"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15249926412535308, 0.16809296097164528, 0.1677682158937417, 0.16786899363629293, 0.12996916346081555, 0.1298843237328281, 0.12991007426502799]}}
{"id": "febbdf85-239d-494f-b69e-800e283d6aff", "fitness": 0.15011871843762195, "name": "EnhancedMemorySwarm", "description": "Introduce adaptive learning rates and enhance memory utilization to improve exploration and exploitation balance in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Initial cognitive coefficient\n        self.c2 = 2.0  # Initial social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def adaptive_learning_rates(self):\n        self.c1 = 2.0 * (1 - self.func_evals / self.budget)  # Decreasing cognitive coefficient\n        self.c2 = 2.0 * (self.func_evals / self.budget)  # Increasing social coefficient\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            self.adaptive_learning_rates()\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + self.c1 * local_exploitation + self.c2 * global_exploration) * 0.99\n            \n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["a810b668-8865-46f5-8041-70f4beabf653"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15250039849482688, 0.16809296097164528, 0.1677682158937417, 0.1678709662680704, 0.12996916346081555, 0.1298843237328281, 0.12991058626531904]}}
{"id": "f97b375a-0bb9-4440-bbb7-fddef7fb193d", "fitness": 0.15011871843762195, "name": "EnhancedMemorySwarm", "description": "Introduce a dynamic swarm size adjustment to improve convergence speed and performance in EnhancedMemorySwarm.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Initial cognitive coefficient\n        self.c2 = 2.0  # Initial social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def adaptive_learning_rates(self):\n        self.c1 = 2.0 * (1 - self.func_evals / self.budget)  # Decreasing cognitive coefficient\n        self.c2 = 2.0 * (self.func_evals / self.budget)  # Increasing social coefficient\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.swarm_size = min(50, int(self.budget / (3 * (1 + 0.1 * self.func_evals / self.budget))))  # Dynamic swarm size adjustment\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            self.adaptive_learning_rates()\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + self.c1 * local_exploitation + self.c2 * global_exploration) * 0.99\n            \n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["febbdf85-239d-494f-b69e-800e283d6aff"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15250039849482688, 0.16809296097164528, 0.1677682158937417, 0.1678709662680704, 0.12996916346081555, 0.1298843237328281, 0.12991058626531904]}}
{"id": "c236833b-87b5-4e23-b173-d36edfc641c6", "fitness": 0.1500900802495046, "name": "EnhancedMemorySwarm", "description": "Introduce dynamic clustering and enhance particle diversity with hybrid initialization and adaptive mutation in EnhancedMemorySwarm.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.memory = np.random.rand(self.swarm_size, self.dim)\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def hybrid_init(self, lb, ub):\n        half_size = self.swarm_size // 2\n        x1 = np.random.rand(half_size, self.dim)\n        x2 = np.random.rand(half_size, self.dim)\n        chaotic_part = lb + 0.5 * (ub - lb) * x1\n        random_part = lb + (ub - lb) * x2\n        return np.vstack((chaotic_part, random_part))\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def adaptive_learning_rates(self):\n        self.c1 = 2.0 * (1 - self.func_evals / self.budget)\n        self.c2 = 2.0 * (self.func_evals / self.budget)\n\n    def cluster_particles(self, swarm):\n        kmeans = KMeans(n_clusters=3, random_state=0)\n        cluster_labels = kmeans.fit_predict(swarm)\n        return cluster_labels, kmeans.cluster_centers_\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.hybrid_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            self.adaptive_learning_rates()\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + self.c1 * local_exploitation + self.c2 * global_exploration) * 0.99\n            \n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            cluster_labels, cluster_centers = self.cluster_particles(swarm)\n            if np.random.rand() < mutation_rate:\n                for idx in range(self.swarm_size):\n                    swarm[idx] = 0.5 * (swarm[idx] + cluster_centers[cluster_labels[idx]])\n                swarm = np.clip(swarm, lb, ub)\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15009 with standard deviation 0.01559.", "error": "", "parent_ids": ["febbdf85-239d-494f-b69e-800e283d6aff"], "operator": null, "metadata": {"aucs": [0.152491848328973, 0.15254393623928453, 0.15245578285311567, 0.1678569634473256, 0.16794323198867556, 0.16779047809287417, 0.12990657142319484, 0.1299305410964371, 0.1298913687756611]}}
{"id": "ca4cf516-e88d-4c22-b308-61d391fdaa96", "fitness": -Infinity, "name": "EnhancedMemorySwarm", "description": "Implement a dynamic swarm size reduction strategy to progressively focus search efforts on promising regions.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Initial cognitive coefficient\n        self.c2 = 2.0  # Initial social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def adaptive_learning_rates(self):\n        self.c1 = 2.0 * (1 - self.func_evals / self.budget)  # Decreasing cognitive coefficient\n        self.c2 = 2.0 * (self.func_evals / self.budget)  # Increasing social coefficient\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            self.adaptive_learning_rates()\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + self.c1 * local_exploitation + self.c2 * global_exploration) * 0.99\n            \n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n            \n            self.swarm_size = max(5, int(self.swarm_size * 0.995))  # Gradually reduce swarm size\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (5,2) (6,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (5,2) (6,2) ')", "parent_ids": ["febbdf85-239d-494f-b69e-800e283d6aff"], "operator": null, "metadata": {}}
{"id": "b9efe929-09d9-43e6-a045-4ab3c5ab89f3", "fitness": 0.15011871843762195, "name": "EnhancedMemorySwarm", "description": "Augment swarm diversity using adaptive mutation-based differential evolution to enhance solution exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Initial cognitive coefficient\n        self.c2 = 2.0  # Initial social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def adaptive_learning_rates(self):\n        self.c1 = 2.0 * (1 - self.func_evals / self.budget)  # Decreasing cognitive coefficient\n        self.c2 = 2.0 * (self.func_evals / self.budget)  # Increasing social coefficient\n\n    def adaptive_mutation(self, swarm, lb, ub, rate):\n        for i in range(self.swarm_size):\n            if np.random.rand() < rate:\n                indices = np.random.choice(self.swarm_size, 3, replace=False)\n                a, b, c = swarm[indices[0]], swarm[indices[1]], swarm[indices[2]]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                swarm[i] = mutant\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            self.adaptive_learning_rates()\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + self.c1 * local_exploitation + self.c2 * global_exploration) * 0.99\n            \n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n            self.adaptive_mutation(swarm, lb, ub, mutation_rate)\n\n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["febbdf85-239d-494f-b69e-800e283d6aff"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15250039849482688, 0.16809296097164528, 0.1677682158937417, 0.1678709662680704, 0.12996916346081555, 0.1298843237328281, 0.12991058626531904]}}
{"id": "59fda245-d099-482a-80f1-dc40a27ade92", "fitness": 0.1501210432292204, "name": "EnhancedMemorySwarm", "description": "Enhance swarm diversity by introducing a small random perturbation upon velocity calculation.", "code": "import numpy as np\n\nclass EnhancedMemorySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = min(50, budget // 3)\n        self.w = 0.7  # Initial inertia weight\n        self.c1 = 2.0  # Initial cognitive coefficient\n        self.c2 = 2.0  # Initial social coefficient\n        self.memory = np.random.rand(self.swarm_size, self.dim)  # Memory for adaptive learning\n        self.func_evals = 0\n\n    def chaotic_perturbation(self, size):\n        beta = 1.8 + 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Adaptive beta for dynamic intensity\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, 1, size) * sigma\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def cooperative_init(self, lb, ub):\n        x = np.random.rand(self.swarm_size, self.dim)\n        r = 4 - 3 * (self.func_evals / self.budget)\n        for _ in range(100):\n            x = r * x * (1 - x)\n        return lb + 0.5 * (ub - lb) * x\n\n    def calculate_entropy(self, swarm):\n        prob = np.mean(swarm, axis=0)\n        entropy = -np.sum(prob * np.log(prob + 1e-10))\n        return entropy\n\n    def update_memory(self, swarm, scores, personal_best_scores):\n        for i in range(self.swarm_size):\n            if scores[i] < personal_best_scores[i]:\n                self.memory[i] = swarm[i]\n\n    def adaptive_learning_rates(self):\n        self.c1 = 2.0 * (1 - self.func_evals / self.budget)  # Decreasing cognitive coefficient\n        self.c2 = 2.0 * (self.func_evals / self.budget)  # Increasing social coefficient\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        swarm = self.cooperative_init(lb, ub)\n        velocities = np.random.uniform(-0.5, 0.5, (self.swarm_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_scores = np.array([func(x) for x in personal_best])\n        self.func_evals += self.swarm_size\n\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n\n        while self.func_evals < self.budget:\n            self.w = 0.9 - (0.9 - 0.4) / (1 + np.exp(-10 * (self.func_evals / self.budget - 0.5)))\n            self.adaptive_learning_rates()\n            entropy = self.calculate_entropy(swarm)\n            mutation_rate = 0.1 + 0.4 * (1 - entropy / np.log(self.swarm_size)) * np.sin((self.func_evals / self.budget) * np.pi)\n\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n\n            local_exploitation = r1 * (personal_best - swarm)\n            global_exploration = r2 * (global_best - swarm) + self.chaotic_perturbation((self.swarm_size, self.dim)) * mutation_rate\n            \n            velocities = (self.w * velocities + self.c1 * local_exploitation + self.c2 * global_exploration) * 0.99 + np.random.normal(0, 0.01, velocities.shape)\n            \n            memory_influence = np.random.rand(self.swarm_size, self.dim)\n            swarm = swarm + velocities + memory_influence * (self.memory - swarm)\n            swarm = np.clip(swarm, lb, ub)\n\n            scores = np.array([func(x) for x in swarm])\n            self.func_evals += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_scores[i] = scores[i]\n\n            min_idx = personal_best_scores.argmin()\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best = personal_best[min_idx]\n                global_best_score = personal_best_scores[min_idx]\n\n            self.update_memory(swarm, scores, personal_best_scores)\n\n            if np.random.rand() < mutation_rate:\n                random_indexes = np.random.choice(self.swarm_size, size=self.swarm_size // 4, replace=False)\n                new_positions = self.cooperative_init(lb, ub)\n                swarm[random_indexes] = new_positions[random_indexes]\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedMemorySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15012 with standard deviation 0.01560.", "error": "", "parent_ids": ["febbdf85-239d-494f-b69e-800e283d6aff"], "operator": null, "metadata": {"aucs": [0.15263059331395223, 0.15244125753739846, 0.15250697158376725, 0.16809296097164528, 0.1677682158937417, 0.16788240776904906, 0.12996916346081555, 0.1298843237328281, 0.12991349479978598]}}
