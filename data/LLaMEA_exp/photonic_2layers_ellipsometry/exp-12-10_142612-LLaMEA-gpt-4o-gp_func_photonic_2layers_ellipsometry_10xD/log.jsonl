{"id": "bb313a28-5ba3-4081-ae6e-ea06337dd4f3", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) with Differential Evolution (DE) for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "0e6fcb05-e18f-4023-8a66-b6c80c35ef16", "fitness": 0.07987691475719945, "name": "EnhancedHybridAPSO_DDE", "description": "An enhanced hybrid metaheuristic integrating Adaptive Particle Swarm Optimization (APSO) with Dynamic Differential Evolution (DDE) for adaptive exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridAPSO_DDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Initial inertia weight for APSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.98  # Damping factor for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive Particle Swarm Optimization (APSO)\n            self.inertia_weight *= self.alpha  # Dynamically update the inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic Differential Evolution (DDE) step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dyn = self.F + np.random.rand() * 0.1  # Dynamic F with small random perturbation\n                mutant = np.clip(pop[a] + F_dyn * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridAPSO_DDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "04f39ca0-b35d-4835-a0dc-e167ad191070", "fitness": 0.07987691475719945, "name": "ImprovedHybridPSODE", "description": "Introducing adaptive parameter tuning and a restart mechanism to the HybridPSODE for enhanced convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.inertia_damp = 0.99  # Damping factor for inertia weight\n        self.restart_threshold = 0.001  # Threshold for triggering a restart\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        stagnation_counter = 0\n        previous_best = func(global_best)\n\n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n\n            # Apply inertia weight damping\n            self.inertia_weight *= self.inertia_damp\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n\n            # Check for stagnation\n            current_best = func(global_best)\n            if abs(previous_best - current_best) < self.restart_threshold:\n                stagnation_counter += 1\n            else:\n                stagnation_counter = 0\n\n            previous_best = current_best\n\n            # Restart mechanism if stagnation persists\n            if stagnation_counter > 5:\n                pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocity = np.zeros((self.population_size, self.dim))\n                personal_best = pop.copy()\n                personal_best_fitness = np.array([func(ind) for ind in personal_best])\n                global_best = personal_best[np.argmin(personal_best_fitness)]\n                stagnation_counter = 0\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "2006917a-ac04-44b4-92c5-f40bde56b280", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Improved HybridPSODE by dynamically adjusting PSO parameters for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1_initial = 2.0  # Initial Cognitive coefficient for PSO\n        self.c2_initial = 2.0  # Initial Social coefficient for PSO\n        self.c1_final = 1.5  # Final Cognitive coefficient for PSO\n        self.c2_final = 1.5  # Final Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update c1 and c2 dynamically\n            c1 = self.c1_initial - (self.c1_initial - self.c1_final) * (evaluations / self.budget)\n            c2 = self.c2_initial - (self.c2_initial - self.c2_final) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               c1 * r1 * (personal_best[i] - pop[i]) +\n                               c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "4b7b307a-f2f3-40a7-aa32-e074255737f1", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Improved HybridPSODE with dynamic parameter adjustment for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased inertia weight for PSO\n        self.c1 = 1.2  # Adjusted cognitive coefficient for PSO\n        self.c2 = 1.7  # Adjusted social coefficient for PSO\n        self.F = 0.6  # Increased DE scaling factor\n        self.CR = 0.85  # Adjusted DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "c4a8595f-8760-4111-ad3c-2ccc3968977e", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "An enhanced HybridPSODE with adaptive parameters for improved convergence speed and diversity preservation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.min_inertia = 0.4  # New minimum inertia weight\n        self.max_inertia = 0.9  # New maximum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Adaptive inertia weight update\n                self.inertia_weight = self.min_inertia + (self.max_inertia - self.min_inertia) * (1 - evaluations / self.budget)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "4077b04e-625c-454b-9e7e-77fc90892e7d", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "Adaptive Hybrid PSODE with dynamic parameter adjustment for improved convergence by balancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.c1 = 2.0  # Higher cognitive coefficient for early exploration\n        self.c2 = 2.0  # Higher social coefficient for early exploration\n        self.F = 0.8  # Higher DE scaling factor for more aggressive mutation\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adapt parameters dynamically\n            progress = evaluations / self.budget\n            self.inertia_weight = 0.9 - 0.5 * progress\n            self.c1 = 2.5 - 1.5 * progress\n            self.c2 = 0.5 + 1.5 * progress\n            self.F = 0.8 - 0.5 * progress\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "63c783fb-fd99-49d1-b11c-97e2adf1bc70", "fitness": 0.07987691475719945, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic that combines Particle Swarm Optimization (PSO) with Differential Evolution (DE) and adaptive parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.inertia_weight_min = 0.4  # Minimum inertia weight for PSO\n        self.c1 = 2.0  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                inertia = (self.inertia_weight_min + \n                           (self.inertia_weight - self.inertia_weight_min) * \n                           ((self.budget - evaluations) / self.budget))\n                velocity[i] = (inertia * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "c7e9ade6-bb53-464d-b4e2-150cd79599a8", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight and crossover probability for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        evaluations = self.population_size\n        inertia_weight_decay = (self.inertia_weight - 0.4) / (self.budget / self.population_size)\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                adaptive_cr = self.CR * (1 - evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n            \n            self.inertia_weight = max(0.4, self.inertia_weight - inertia_weight_decay)\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "9c0e6c89-9f64-4554-9c89-067e53b60724", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "An adaptive hybrid metaheuristic combining PSO and DE with dynamic parameter tuning for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.c1 = 2.0  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.inertia_decay = 0.99  # Decay rate for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Adjust inertia weight adaptively\n            self.inertia_weight *= self.inertia_decay\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "6c70df7d-644f-4596-839e-c66ba1a95c6d", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE integrating adaptive parameters for improved convergence and efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update inertia weight for PSO\n            self.inertia_weight = 0.4 + 0.3 * (1 - evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "54347845-2b1e-4ee3-baec-9a8f54e243a1", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhance the HybridPSODE algorithm by introducing a dynamic adjustment of PSO parameters and an improved selection mechanism in DE to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.c1_initial = 2.0  # Increased cognitive coefficient for PSO\n        self.c2_initial = 2.0  # Increased social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.inertia_weight - 0.5 * evaluations / self.budget  # Dynamic inertia weight\n            c1 = self.c1_initial - 1.0 * evaluations / self.budget  # Dynamic cognitive coefficient\n            c2 = self.c2_initial - 1.0 * evaluations / self.budget  # Dynamic social coefficient\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (w * velocity[i] +\n                               c1 * r1 * (personal_best[i] - pop[i]) +\n                               c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n            \n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "488e1f7b-dc08-4c55-964a-386ddfae0948", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid algorithm that introduces adaptive parameters and a local search phase to improve exploitation and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.c1 = 2.0  # Increase cognitive coefficient for faster convergence\n        self.c2 = 2.0  # Increase social coefficient for faster convergence\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - evaluations) / self.budget\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Local search phase to exploit the best solution\n            if evaluations < self.budget:\n                local_search_solution = global_best + 0.1 * np.random.randn(self.dim)\n                local_search_solution = np.clip(local_search_solution, lb, ub)\n                local_search_fitness = func(local_search_solution)\n                evaluations += 1\n                if local_search_fitness < func(global_best):\n                    global_best = local_search_solution\n\n        return global_best", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "0d900803-1f4f-4038-8867-0e0f39797c13", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        adapt_step = self.budget // 5  # Adaptive step\n\n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Adaptive parameters\n            if evaluations % adapt_step == 0:\n                self.inertia_weight *= 0.95\n                self.CR = 0.8 + 0.1 * np.random.rand()\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "24bbac5e-ebc9-4870-b7e6-430ddc6a5cf3", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced hybrid algorithm integrating adaptive parameters for improved balance of exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased Inertia weight for PSO\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.7  # Increased DE scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "8fbf9069-7dd3-42f9-b4cf-2848aae3d02f", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced PSODE with adaptive parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Adaptive inertia weight for PSO\n        self.c1 = 2.0  # Adaptive cognitive coefficient for PSO\n        self.c2 = 2.0  # Adaptive social coefficient for PSO\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "3783a8fa-0dac-4844-a884-f672e596c1fb", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "An enhanced metaheuristic that adaptively tunes parameters of Particle Swarm Optimization (PSO) and Differential Evolution (DE) during optimization to improve search efficiency and convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.adaptive_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * self.adaptive_factor)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "60e24095-5aca-4bb5-8c60-bb64660054b7", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters for improved convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight = 0.9 - (0.5 * evaluations / self.budget)  # Adaptive inertia weight\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.8 * (1 - evaluations / self.budget)  # Adaptive DE scaling factor\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "3c2d01e2-543a-41c0-9040-17306f4b0112", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "An enhanced hybrid metaheuristic called AdaptiveHybridPSODE that dynamically adjusts parameters of PSO and DE for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.min_inertia_weight = 0.4  # Minimum inertia weight for dynamic adjustment\n        self.max_inertia_weight = 0.9  # Maximum inertia weight for dynamic adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_index]\n        global_best_fitness = personal_best_fitness[global_best_index]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust inertia weight\n            self.inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < global_best_fitness:\n                        global_best = pop[i]\n                        global_best_fitness = new_fitness\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < global_best_fitness:\n                        global_best = trial\n                        global_best_fitness = trial_fitness\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "95966475-5a7f-4fea-9d46-309ac5dccd7c", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight = 0.4 + 0.3 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.1 + 0.4 * (evaluations / self.budget)  # Adaptive DE scaling factor\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "3a37cccc-bf22-47fe-929d-0dd40fa342c0", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight and dynamic mutation strategy for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with dynamic mutation\n            self.F = 0.5 + 0.3 * np.random.rand()  # Dynamic mutation strategy\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "a222640c-e35b-4565-b901-92f3f546f7d0", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic integrating adaptive parameters into Particle Swarm Optimization (PSO) and Differential Evolution (DE) for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight *= 0.99  # Adaptive inertia weight\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive F\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "6ee37dce-20a0-426f-9ffe-82287b324368", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "An enhanced hybrid metaheuristic integrating adaptive parameters in PSO-DE, improving convergence by dynamically adjusting exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n        self.inertia_damping = 0.99\n        self.min_inertia = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.inertia_damping)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "b1dce987-49d7-4181-80e7-af79314f775b", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic combining Particle Swarm Optimization (PSO) with Differential Evolution (DE) using adaptive parameters for dynamic exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.9 - 0.7 * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 23, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "5486fd0f-59ad-4d33-a962-423c39722a6e", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced PSO-DE with adaptive parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 2.0  # Changed: Cognitive coefficient for PSO\n        self.c2 = 2.0  # Changed: Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Adjust inertia weight for better exploration-exploitation balance\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Changed: Adaptive inertia weight\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "3e02fe0d-6ef2-4d7b-9d27-8f586618ad5a", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid algorithm integrating adaptive inertia weight in PSO and dynamic DE parameters for improved convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.initial_inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.final_inertia_weight = 0.4  # Final inertia weight for PSO\n        self.c1 = 2.0  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Social coefficient for PSO\n        self.F_min = 0.4  # Minimum DE scaling factor\n        self.F_max = 0.9  # Maximum DE scaling factor\n        self.CR_min = 0.5  # Minimum DE crossover probability\n        self.CR_max = 1.0  # Maximum DE crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adapt inertia weight\n            w = self.initial_inertia_weight - (self.initial_inertia_weight - self.final_inertia_weight) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Calculate adaptive F and CR for DE\n            F = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.budget)\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "9fb4a8d2-166f-4bb6-aadd-4d18c483c553", "fitness": 0.07987691475719945, "name": "ImprovedHybridPSODE", "description": "Improved HybridPSODE incorporating adaptive parameters for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Initial cognitive coefficient for PSO\n        self.c2 = 1.5  # Initial social coefficient for PSO\n        self.F = 0.5  # Initial DE scaling factor\n        self.CR = 0.9  # Initial DE crossover probability\n        self.min_inertia_weight = 0.4  # Adaptive minimum inertia weight\n        self.max_inertia_weight = 0.9  # Adaptive maximum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        generation = 0\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.max_inertia_weight - (\n                (self.max_inertia_weight - self.min_inertia_weight) * \n                (evaluations / self.budget))\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            generation += 1  # Increment generation count\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "d0839c0b-a823-4bf7-b9d6-bb93b5c3ab6c", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic that introduces adaptive parameters and diversity restoration to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * (1 - evaluations / self.budget)\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Diversity restoration\n            if evaluations % (self.budget // 10) == 0:\n                pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "81521755-4b10-4138-9dd1-9e1f207daef7", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight and dynamic population size for better exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_initial = 0.9  # Initial inertia weight for PSO\n        self.inertia_weight_final = 0.4  # Final inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.dynamic_population_decrease_rate = 0.1  # Rate at which population size decreases\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            inertia_weight = self.inertia_weight_initial - (\n                (self.inertia_weight_initial - self.inertia_weight_final) * (evaluations / self.budget))\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 5) == 0:\n                self.population_size = max(5, int(self.population_size * (1 - self.dynamic_population_decrease_rate)))\n                pop = pop[:self.population_size]\n                velocity = velocity[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_fitness = personal_best_fitness[:self.population_size]\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "54f9c869-b5cc-487a-afaa-bb66028ba26e", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "A hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) with Adaptive Differential Evolution (ADE) uses adaptive scaling factors and crossover rates to improve search space exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_min = 0.4  # Minimum DE scaling factor\n        self.F_max = 0.9  # Maximum DE scaling factor\n        self.CR_min = 0.5  # Minimum DE crossover rate\n        self.CR_max = 1.0  # Maximum DE crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Adaptive Differential Evolution step\n            for i in range(self.population_size):\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                \n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "8c340e7c-7015-4112-8aeb-6b4a43bfe438", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Improved HybridPSODE with adaptive inertia weight and random reinitialization for enhanced diversification and convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.5 + 0.4 * (1 - evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Random reinitialization of worst solution\n            if evaluations < self.budget:\n                worst_idx = np.argmax(personal_best_fitness)\n                pop[worst_idx] = np.random.uniform(lb, ub, self.dim)\n                personal_best_fitness[worst_idx] = func(pop[worst_idx])\n                evaluations += 1\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "b64ef619-302e-4c81-9197-897d285d7b60", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic using adaptive parameters for improved PSO and DE balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.2  # Cognitive coefficient for PSO\n        self.c2 = 1.8  # Social coefficient for PSO\n        self.F = 0.6  # DE scaling factor\n        self.CR = 0.8  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "891bc1dc-5970-44de-b225-f87cb9266abb", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE by adjusting inertia weight dynamically and introducing elitism to improve convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        global_best_fitness = func(global_best)  # Store global best fitness\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Dynamic inertia weight adjustment\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    # Update global best with elitism check\n                    if new_fitness < global_best_fitness:\n                        global_best = pop[i]\n                        global_best_fitness = new_fitness\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < global_best_fitness:\n                        global_best = trial\n                        global_best_fitness = trial_fitness\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "2f52de1e-da0c-4d56-b3d8-37db4fe8acd9", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence efficiency and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adapt inertia weight over iterations\n            self.inertia_weight = max(self.inertia_weight_min, \n                                      self.inertia_weight * (1 - evaluations/self.budget))\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n\n            # Local search enhancement\n            if evaluations < self.budget:\n                local_search_idx = np.argmin(personal_best_fitness)\n                local_candidate = personal_best[local_search_idx] + np.random.normal(0, 0.1, self.dim)\n                local_candidate = np.clip(local_candidate, lb, ub)\n                local_fitness = func(local_candidate)\n                evaluations += 1\n                \n                if local_fitness < personal_best_fitness[local_search_idx]:\n                    personal_best[local_search_idx] = local_candidate\n                    personal_best_fitness[local_search_idx] = local_fitness\n                    if local_fitness < func(global_best):\n                        global_best = local_candidate\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "562dc62d-b0b3-4f2f-b85b-40c393ceecf6", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic parameter adaptation for improved convergence rates.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased inertia weight for better exploration\n        self.c1 = 2.0  # Adjusted cognitive coefficient for PSO\n        self.c2 = 2.0  # Adjusted social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "02b454f9-3372-4d84-8a90-4d7d9a143caa", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameter tuning for improved convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.w_min = 0.4  # Minimum inertia weight\n        self.w_max = 0.9  # Maximum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            iteration += 1\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "ded7d1ca-95ed-4e39-a402-28a03464a3ab", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Enhance HybridPSODE with adaptive parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - (0.5 * (evaluations / self.budget))  # Adaptive inertia\n            self.F = 0.5 + (0.3 * np.random.rand())  # Adaptive scaling factor\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 36, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "275c281c-8b79-48e8-ae31-1c1744505f40", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "Hybrid Adaptive PSODE with dynamic parameter tuning for improved convergence rates and diversity management.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.initial_F = 0.8\n        self.final_F = 0.2\n        self.C1 = 1.5\n        self.C2 = 1.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * (1 - progress) + self.final_inertia_weight\n            F = (self.initial_F - self.final_F) * (1 - progress) + self.final_F\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.C1 * r1 * (personal_best[i] - pop[i]) +\n                               self.C2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "1562d29e-1f16-4e80-8836-f1f654246b49", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic using adaptive parameters and randomization in DE for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["bb313a28-5ba3-4081-ae6e-ea06337dd4f3"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "56ccc97d-4456-40bc-a26a-0efdda0329d8", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic inertia adjustment and improved mutation strategy for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                inertia_weight_dynamic = 0.5 + np.random.rand() * 0.5 # Dynamic inertia update\n                velocity[i] = (inertia_weight_dynamic * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (global_best - pop[a]), lb, ub) # Improved mutation strategy\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "919e3ed2-b6fc-410a-b687-10110f831679", "fitness": 0.07997504139296116, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic combining adaptive PSO and DE with dynamic parameter tuning for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adjust inertia weight dynamically\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "77992d7b-730c-49f1-8162-1cc13ff75c2a", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Enhanced HybridPSODE using dynamic inertia weight and adaptive crossover probability for improved exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Dynamic inertia weight for PSO starting value\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamically adjusting inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic crossover probability for DE\n            self.CR = 0.6 + 0.3 * (evaluations / self.budget)\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "18e16433-f756-4626-aed6-d2468caf98d1", "fitness": 0.07997504139296116, "name": "RefinedHybridPSODE", "description": "An enhanced hybrid metaheuristic combining dynamic inertia, adaptive DE, and hybrid crossover for superior convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        max_iter = self.budget // self.population_size\n        \n        iter_count = 0\n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight - (\n                (self.inertia_weight - self.inertia_weight_min) * iter_count / max_iter)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                hybrid_crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(hybrid_crossover, mutant, pop[i]) * 0.5 + pop[i] * 0.5\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n                            \n            iter_count += 1\n\n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "bb84358b-a2e4-43dd-a448-dbe91f2c3fbd", "fitness": 0.07997504139296116, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid metaheuristic using adaptive parameters, randomization in DE, and dynamic inertia adjustment for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.inertia_weight_min = 0.4  # Minimum inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adjust inertia weight dynamically\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight - 0.01)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[np.argmin(personal_best_fitness)]:\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[np.argmin(personal_best_fitness)]:\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "975e8d17-04e9-488a-bf0b-259ab4e5570d", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "A dynamically adaptive hybrid metaheuristic that integrates PSO and DE with self-tuning parameters for enhanced exploration and exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_start = 0.9\n        self.inertia_weight_end = 0.4\n        self.c1 = 2.0  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Social coefficient for PSO\n        self.F_start = 0.5  # Initial DE scaling factor\n        self.F_end = 0.9  # Final DE scaling factor\n        self.CR_start = 0.8  # Initial DE crossover probability\n        self.CR_end = 0.4  # Final DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Calculate dynamic parameters\n            progress = evaluations / self.budget\n            inertia_weight = self.inertia_weight_start * (1 - progress) + self.inertia_weight_end * progress\n            F = self.F_start * (1 - progress) + self.F_end * progress\n            CR = self.CR_start * (1 - progress) + self.CR_end * progress\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "b6b1f46e-63b0-4d4c-9d39-e528c5878ac0", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia and dynamic crossover for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Adjusted inertia weight for better exploration\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.6  # Reduced DE crossover probability for diversification\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                inertia_weight = 0.9 - (0.5 * evaluations / self.budget)  # Adaptive inertia weight\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "994c2b96-31c6-4f7f-8ca0-d45ec9c20b19", "fitness": 0.07997504139296116, "name": "HybridPSODEPlusPlus", "description": "HybridPSODE++: An improved hybrid metaheuristic combining adaptive inertia weight and mutation strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODEPlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_max = 0.9  # Maximum inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            inertia_weight = (\n                self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n            )\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with adaptive mutation strategy\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSODEPlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "27ffe60c-48f0-4d1a-ae32-7716ab7b48b4", "fitness": 0.07987691475719945, "name": "AdaptiveHybridPSODE", "description": "Adaptive HybridPSODE utilizing dynamic parameter tuning and elitist selection for enhanced convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_initial, self.CR_final = 0.9, 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter tuning\n            self.F = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n            self.CR = self.CR_initial - (self.CR_initial - self.CR_final) * (evaluations / self.budget)\n            \n            # PSO step\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n\n            # DE step with elitist selection\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "2f49794c-454b-433f-8fa8-efee76dfc7ed", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic with adaptive DE parameters and dynamic population resizing for improved efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = np.random.uniform(0.3, 0.8)  # Adjusted adaptive DE scaling factor\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n            \n            if evaluations % (self.budget // 10) == 0:  # Dynamic population resizing\n                self.population_size = max(10, self.population_size - 1)\n                pop = pop[:self.population_size]\n                velocity = velocity[:self.population_size]\n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "fe583e24-ff08-4f2a-99eb-b37572d1620c", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic with improved adaptive DE parameters and dynamic inertia for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F_min, self.F_max = 0.4, 0.9  # DE scaling factor range\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        initial_budget = self.budget\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            self.inertia_weight -= 0.5 * (evaluations / initial_budget)  # Line 1 changed: Dynamic inertia\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            self.F = np.random.uniform(self.F_min, self.F_max)  # Line 2 changed: Adaptive DE scaling factor\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "b087f0bc-0d82-4362-839f-db4b4713ff7f", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic using adaptive parameters and dynamic neighborhood selection in DE for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F_dynamic = np.random.uniform(0.5, 1.0)  # Dynamic scaling factor\n                mutant = np.clip(pop[a] + F_dynamic * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "d00df875-aec6-4011-bbca-221b46b7d3d5", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "An adaptive hybrid metaheuristic that combines dynamically adjusted PSO parameters with self-adaptive DE strategies for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start high, decrease over time\n        self.c1 = 2.0  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Social coefficient for PSO\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.5\n        self.CR_max = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        adjust_rate = 0.99  # Factor to adjust inertia weight\n\n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            self.inertia_weight *= adjust_rate\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with self-adaptive parameters\n            F = np.random.uniform(self.F_min, self.F_max)\n            CR = np.random.uniform(self.CR_min, self.CR_max)\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "6a71853a-0ffb-4e42-abf7-9c5d88970ed0", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Enhanced hybrid metaheuristic utilizing adaptive inertia and dynamic population size for improved convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight update\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with dynamic population size\n            for i in range(max(10, self.population_size // 2)):  # Dynamic reduction\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "01b9eb21-50db-4bd4-a63b-25cd92db4abb", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "A hybrid metaheuristic combining adaptive PSO with DE, using dynamic adjustment of the DE scaling factor to enhance convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = 0.5  # Fixed DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.4 + (0.5 * evaluations / self.budget)  # Dynamic F adjustment\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "a3b2c9c1-0c2c-4ef1-ad07-632a9dfaeb7d", "fitness": 0.07987691475719945, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic using dynamic inertia and crossover adaptation for enhanced exploration and exploitation balance in optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.initial_inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.final_inertia_weight = 0.4  # Final inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.initial_F = 0.9  # Initial DE scaling factor\n        self.final_F = 0.4  # Final DE scaling factor\n        self.initial_CR = 0.9  # Initial DE crossover probability\n        self.final_CR = 0.1  # Final DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Calculate dynamic inertia weight\n            inertia_weight = self.initial_inertia_weight - (self.initial_inertia_weight - self.final_inertia_weight) * (evaluations / self.budget)\n            \n            # Calculate dynamic DE parameters\n            F = self.initial_F - (self.initial_F - self.final_F) * (evaluations / self.budget)\n            CR = self.initial_CR - (self.initial_CR - self.final_CR) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "1dae374b-b9a9-4898-8bd5-ca1aca782c04", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "An adaptive PSO-DE hybrid metaheuristic with dynamic inertia weight and adaptive mutation factor for improved solution quality.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Increased social coefficient for PSO\n        self.F = 0.5  # Fixed DE scaling factor for better stability\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight *= 0.99  # Adaptive inertia weight\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive DE scaling factor\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "1a69b8fd-d246-4cd2-a141-1683e791afac", "fitness": 0.07994895784152835, "name": "HybridPSODE", "description": "Enhanced HybridPSODE using dynamic inertia and adaptive crossover rate for improved flexibility and convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Increased inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = np.random.uniform(0.7, 1.0)  # Dynamic DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07995 with standard deviation 0.01886.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10323047801751206, 0.10472118327795044, 0.10336602785121618, 0.07817693378956603, 0.07881974146603243, 0.07824591053408503, 0.0575412111928012, 0.05786104502327549, 0.05757808942131626]}}
{"id": "b0841967-e869-4c64-9f1c-15a30264ad74", "fitness": 0.07997504139296116, "name": "ImprovedHybridPSODE", "description": "Introduce an adaptive inertia weight and crossover probability in HybridPSODE to enhance exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # Initial DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic adjustment of inertia weight and crossover probability\n            self.inertia_weight *= 0.99  # Gradually decrease inertia weight\n            self.CR = 0.9 - (0.5 * evaluations / self.budget)  # Decrease crossover probability\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "c0aab527-5b93-4a12-8fdc-3f6f4e79452c", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "A hybrid metaheuristic combining improved adaptive parameters and dynamic leader adjustment in DE for enhanced convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F_min, self.F_max = 0.4, 0.9  # Adaptive DE scaling factor range\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        global_best_fitness = func(global_best)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < global_best_fitness:\n                        global_best = pop[i]\n                        global_best_fitness = new_fitness\n                        if evaluations >= self.budget:\n                            break\n\n            # Adaptive Differential Evolution step\n            for i in range(self.population_size):\n                F = np.random.uniform(self.F_min, self.F_max)\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < global_best_fitness:\n                        global_best = trial\n                        global_best_fitness = trial_fitness\n                        if evaluations >= self.budget:\n                            break\n        \n        return global_best", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "18ef2412-9527-4d6c-8017-1f5816169f2c", "fitness": 0.07997504139296116, "name": "ImprovedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia and crossover rates to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n        self.CR_min = 0.2  # Minimum crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + (0.9 - self.inertia_weight_min) * (\n                1 - evaluations / self.budget\n            )\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Adaptive DE crossover rate\n            self.CR = self.CR_min + (0.9 - self.CR_min) * (\n                1 - evaluations / self.budget\n            )\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "afb41142-f4be-49fa-aad4-8e809c7a8e50", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Incrementing DE scaling factor and introducing diversity in PSO to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = np.random.permutation(self.population_size)  # Ensure diversity\n                a, b, c = indices[:3]\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            self.F = min(0.9, self.F + 0.01)  # Incrementally increase F\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "dd6e631a-7b0a-4b55-80ed-42a4d5b5b7bc", "fitness": 0.07997504139296116, "name": "EnhancedHybridPSODE", "description": "Introducing an adaptive mechanism for dynamically adjusting PSO parameters and incorporating a chaotic map to enhance diversity and convergence speed in the HybridPSODE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start with a larger inertia\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n        self.inertia_damping = 0.99  # Damping factor to gradually reduce inertia\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        chaotic_sequence = self.generate_chaotic_sequence(self.population_size)\n\n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Adaptive Inertia update\n            self.inertia_weight *= self.inertia_damping\n            # Enhance diversity with chaotic sequence\n            if evaluations < self.budget:\n                idx = np.random.randint(0, self.population_size)\n                pop[idx] = lb + chaotic_sequence[idx] * (ub - lb)\n\n        return global_best\n\n    def generate_chaotic_sequence(self, length):\n        # Using logistic map for chaos generation\n        sequence = np.zeros(length)\n        sequence[0] = np.random.rand()\n        for i in range(1, length):\n            sequence[i] = 3.99 * sequence[i-1] * (1 - sequence[i-1])\n        return sequence", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "8cd24150-6744-4071-a8bb-4338f61cf552", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "A refined hybrid algorithm with adaptive DE parameters and velocity update enhancement for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F_min, self.F_max = 0.4, 0.9  # Adaptive DE scaling factor range\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with adaptive F\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F = np.random.uniform(self.F_min, self.F_max)  # Adaptive F\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "36efbae2-dc18-407a-b6b9-c658e9a305ff", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Improved HybridPSODE by incorporating adaptive velocity clamping and dynamic CR adjustment for balanced exploration-exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.velocity_clamp = 0.1  # Initial velocity clamp\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = np.clip(self.inertia_weight * velocity[i] +\n                                      self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                      self.c2 * r2 * (global_best - pop[i]),\n                                      -self.velocity_clamp, self.velocity_clamp)\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            self.CR = 0.8 + 0.2 * np.sin(np.pi * evaluations / self.budget)  # Dynamic CR adjustment\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "718ae8b0-a477-42c2-bd08-1c58d074a980", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic with adaptive PSO and DE parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.5, 0.8)  # Slightly adjusted DE scaling factor\n        self.CR = 0.85  # Adjusted DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "2b5ffabe-4ef3-402b-80c6-86b57d094731", "fitness": 0.07987691475719945, "name": "HybridPSODE", "description": "Adaptive Hybrid PSODE with Dynamic Inertia and Randomized Mutation for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        iter_count = 0\n        \n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n            F = np.random.uniform(self.F_min, self.F_max)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with randomized mutation strategy\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "7ba13cd6-5f49-4918-a326-18cd2007a3e8", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.initial_inertia = 0.9  # Initial inertia weight for PSO\n        self.final_inertia = 0.4  # Final inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Linearly decreasing inertia weight\n            inertia_weight = self.initial_inertia - (self.initial_inertia - self.final_inertia) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "6e4c41ec-9b7a-427e-81ef-fdb63bba5efe", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic using adaptive parameters, randomization in DE, and dynamic velocity scaling for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                dynamic_inertia = self.inertia_weight * (0.5 + 0.5 * (self.budget - evaluations) / self.budget)  # Dynamic inertia\n                velocity[i] = (dynamic_inertia * velocity[i] +  # Changed line\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 67, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "47eaa1b7-d0f1-4049-a46a-b0b7b209b4f8", "fitness": 0.07997504139296116, "name": "ImprovedHybridPSODE", "description": "A novel hybrid metaheuristic combining adaptive PSO with a dynamic mutation strategy in DE for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.5, 0.9\n        self.F = np.random.uniform(self.F_min, self.F_max)\n        self.CR = self.CR_max\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Update inertia weight and DE parameters dynamically\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            self.F = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n            self.CR = self.CR_min + (self.CR_max - self.CR_min) * (evaluations / self.budget)\n\n            # PSO Step\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Adaptive Differential Evolution Step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n            \n            iteration += 1\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "a91c0647-c426-4eaa-a6b5-04803aca26ab", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic improving convergence speed by introducing adaptive inertia weight for PSO.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_start = 0.9  # Initial inertia weight for PSO\n        self.inertia_weight_end = 0.4    # Final inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update inertia weight linearly\n            t = evaluations / self.budget\n            inertia_weight = (self.inertia_weight_start * (1 - t) +\n                              self.inertia_weight_end * t)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "11c33c56-e983-4125-ba2c-dc7cd59546e8", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Improved hybrid metaheuristic with dynamic velocity and crossover adjustments for better adaptability.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight = 0.5 + np.random.rand() * 0.5  # Dynamic inertia weight\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                self.CR = 0.8 + np.random.rand() * 0.2  # Dynamic crossover probability\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "456e302e-e239-40a6-adaf-e9593365a6fe", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A hybrid PSO-DE algorithm with enhanced adaptive DE parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.5, 0.9)  # Enhanced adaptive DE scaling factor\n        self.CR = 0.8  # Slightly lowered DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "daef75b4-e191-4f7d-9e38-8b7f1040a545", "fitness": 0.07994895784152835, "name": "HybridPSODE", "description": "Refined hybrid metaheuristic with dynamic parameter adaptation for enhanced convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = np.random.uniform(0.7, 0.9)  # Dynamic DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 72, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07995 with standard deviation 0.01886.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10323047801751206, 0.10472118327795044, 0.10336602785121618, 0.07817693378956603, 0.07881974146603243, 0.07824591053408503, 0.0575412111928012, 0.05786104502327549, 0.05757808942131626]}}
{"id": "f92b8c1f-96cd-4315-891f-8352dde455e1", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A refined HybridPSODE optimizing parameter adaptation for enhanced convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.5  # Inertia weight for PSO (changed from 0.7)\n        self.c1 = 1.8  # Cognitive coefficient for PSO (changed from 1.5)\n        self.c2 = 1.8  # Social coefficient for PSO (changed from 1.5)\n        self.F = np.random.uniform(0.5, 1.0)  # Adaptive DE scaling factor (changed range)\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 73, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "370c4171-25e4-4516-8126-c079d96ab221", "fitness": 0.07987691475719945, "name": "DynamicHybridPSODE", "description": "A dynamic hybrid PSODE algorithm leveraging adaptive inertia weights and F values for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_F = 0.9\n        self.final_F = 0.4\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            inertia_weight = self.initial_inertia_weight - \\\n                             (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (evaluations / self.budget)\n            F = self.initial_F - (self.initial_F - self.final_F) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm DynamicHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "3a1d6e0a-d21f-430c-98e4-be1ec1807030", "fitness": 0.07997504139296116, "name": "HybridPSODE_Levy", "description": "Integrating adaptive parameters with Levy flight in HybridPSODE for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSODE_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n\n    def levy_flight(self, L=1.5):\n        sigma = (np.math.gamma(1 + L) * np.sin(np.pi * L / 2) /\n                 (np.math.gamma((1 + L) / 2) * L * 2 ** ((L - 1) / 2))) ** (1 / L)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / (np.abs(v) ** (1 / L))\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n\n            if evaluations < self.budget:\n                # Implementing Levy Flight for stochastic exploration\n                for i in range(self.population_size):\n                    levy_step = self.levy_flight()\n                    pop[i] = np.clip(pop[i] + levy_step, lb, ub)\n                    levy_fitness = func(pop[i])\n                    evaluations += 1\n                    if levy_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = levy_fitness\n                        if levy_fitness < func(global_best):\n                            global_best = pop[i]\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm HybridPSODE_Levy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "a08de061-eae9-4172-bbfd-268eeb9aea0f", "fitness": 0.07940088567661038, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic using adaptive parameters, randomization, and dynamic population size for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = np.random.randint(25, 35)  # Dynamic population size\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07940 with standard deviation 0.01854.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10292039661299679, 0.10233724201632644, 0.10307183553844168, 0.0780436378014876, 0.07779769980263551, 0.07810453595506439, 0.05747484267683389, 0.05735380244702881, 0.057503978238678366]}}
{"id": "608216f2-8c02-41d9-9561-5d08f9113883", "fitness": 0.07997504139296116, "name": "ImprovedHybridPSODE", "description": "A refined hybrid metaheuristic integrating adaptive inertia and diversity boost via random perturbations in PSODE for enhanced global exploration and convergence.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        self.evaluations = self.population_size\n\n        while self.evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.5 * (1 - self.evaluations / self.budget)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                self.evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if self.evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with diversity boost\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant + perturbation, pop[i])\n                \n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if self.evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "f4b06a17-9a2f-4d7d-a453-ba6fc521a849", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Introducing a time-varying inertia weight for PSO to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_initial = 0.9  # Initial inertia weight for PSO\n        self.inertia_weight_final = 0.4  # Final inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update inertia weight\n            inertia_weight = self.inertia_weight_initial - ((self.inertia_weight_initial - self.inertia_weight_final) * evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "4fa6b89b-e194-4af4-a139-be3ada1e26ea", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic using dynamic inertia weight adjustment for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - (0.6 * evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "e64712aa-177b-44ef-a695-c21d79a0282f", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Improved hybrid metaheuristic with optimized DE parameters for enhanced performance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.5, 0.8)  # Adaptive DE scaling factor (modified)\n        self.CR = 0.8  # DE crossover probability (modified)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n        \n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "d3ad627d-24e1-4baa-b9c1-e1959e929259", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Refining the DE scaling factor range and introducing inertia decay for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.5, 0.8)  # Adjusted DE scaling factor range\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Inertia weight decay\n            self.inertia_weight *= 0.99\n\n        return global_best", "configspace": "", "generation": 81, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "7bfeeb01-a16e-48a5-90d7-e2c8bc64500e", "fitness": 0.07987691475719945, "name": "RefinedHybridPSODE", "description": "A refined hybrid PSO-DE that dynamically adjusts PSO inertia weight and DE scaling factor based on the population's fitness diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update PSO parameters dynamically based on fitness diversity\n            fitness_diversity = np.std(personal_best_fitness) / np.mean(personal_best_fitness)\n            inertia_weight = (self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * \n                              evaluations / self.budget)\n            F = np.clip(0.4 + 0.5 * fitness_diversity, 0.4, 0.9)  # Adapt DE based on diversity\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 82, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "5594d359-1b0b-4ad7-8f93-19c76591a6ed", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic using adaptive parameters, dynamic population size, and randomization in DE for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive population size\n            if evaluations > self.budget * 0.7:\n                self.population_size = max(15, self.population_size // 2)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "8bb0ca6e-cf66-488b-9fb8-c01e23cb593a", "fitness": 0.07987691475719945, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic that integrates adaptive inertia weight and dynamic parameter tuning for Particle Swarm Optimization (PSO) and Differential Evolution (DE) to enhance exploration and exploitation balance.  ", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_max = 0.9  # Max inertia weight for PSO\n        self.inertia_weight_min = 0.4  # Min inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F_max = 0.9  # Max DE scaling factor\n        self.F_min = 0.4  # Min DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic inertia weight adjustment\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with adaptive F\n            F = self.F_max - (self.F_max - self.F_min) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "1a226aba-f3f9-4db3-a326-95a4611d60b4", "fitness": 0.07987691475719945, "name": "ImprovedHybridPSODE", "description": "A novel hybrid PSO-DE optimizer utilizes dynamic parameter adaptation and elite selection to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Increased inertia weight for faster exploration\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 2.0  # Increased social coefficient for better convergence\n        self.F = 0.5  # Fixed DE scaling factor to stabilize search\n        self.CR = 0.9  # DE crossover probability\n        self.elitism_rate = 0.1  # Portion of elite individuals retained\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Elite selection\n            elite_size = int(self.population_size * self.elitism_rate)\n            elite_indices = np.argsort(personal_best_fitness)[:elite_size]\n            elite_pop = personal_best[elite_indices]\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                if i in elite_indices:\n                    continue  # Skip updating elite individuals\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                if i in elite_indices:\n                    continue  # Skip evaluating elite individuals\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if i in elite_indices:\n                    continue  # Skip DE operation on elite individuals\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "3512719f-7cdc-4e05-8ffc-05475803b5f7", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Improved HybridPSODE with adaptive inertia weight and dynamic population size for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, max(20, dim))  # Dynamic population size\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            inertia_weight = 0.9 - (0.5 * evaluations / self.budget)  # Adaptive inertia weight update\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "ff9bed1a-888e-4046-8e09-d02d731014da", "fitness": 0.07997504139296116, "name": "RefinedHybridPSODE", "description": "An enhanced hybrid metaheuristic integrating adaptive inertia weight and dynamic crossover rate in PSO-DE for improved exploration-exploitation balance.  ", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_max = 0.9  # Maximum inertia weight for PSO\n        self.inertia_weight_min = 0.4  # Minimum inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR_max = 0.9  # Maximum DE crossover probability\n        self.CR_min = 0.1  # Minimum DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        evaluations = self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Calculate adaptive inertia weight\n            inertia_weight = self.inertia_weight_max - (\n                (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            )\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Calculate dynamic crossover rate\n            CR = self.CR_max - (\n                (self.CR_max - self.CR_min) * (evaluations / self.budget)\n            )\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            iteration += 1\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "1497e35f-e825-4976-a35b-dce3ec251800", "fitness": 0.07997504139296116, "name": "EnhancedHybridPSODE", "description": "Introducing adaptive inertia weight and bounding strategy in HybridPSODE to balance exploration and exploitation for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_max = 0.9  # Max inertia weight for PSO\n        self.inertia_weight_min = 0.4  # Min inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "3220cb8b-f2b3-4cbe-b325-9f4810b16335", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic with improved DE parameter control for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.5, 1.0)  # Adjusted DE scaling factor range\n        self.CR = 0.8  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "aed1a790-a441-49fe-8641-5a9ace785ba0", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "Enhanced hybrid PSO-DE with improved DE scaling and inertia weight adaptation for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Changed: Increased inertia weight for better exploration\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.5, 0.9)  # Changed: Increased lower bound of DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 90, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "bac3e324-b9d9-4c43-a5a6-a7e51bb8c5ea", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A synergistic metaheuristic combining adaptive PSO velocity dynamics and DE diversity injection for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = np.random.uniform(0.4, 0.9)\n        self.CR = 0.9\n        self.adaptive_rate = 0.9  # Adaptive inertia decay rate\n        self.velocity_limit = 0.2  # Maximum velocity limit\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO with adaptive inertia\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight *= self.adaptive_rate\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                velocity[i] = np.clip(velocity[i], -self.velocity_limit, self.velocity_limit)\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step with stochastic F adaptation\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "a6f05d84-d9dd-4f6d-a3fb-3c23cbd86748", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "Adaptive Hybrid PSODE with dynamic parameter tuning and multi-faceted exploration and exploitation balance for improved optimization performance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = 0.9\n        self.min_inertia, self.max_inertia = 0.4, 0.9\n\n    def adaptive_parameters(self, current_eval):\n        # Dynamic adjustment of inertia weight and DE scaling factor\n        self.inertia_weight = self.min_inertia + (\n            self.max_inertia - self.min_inertia) * (1 - (current_eval / self.budget))\n        self.F = self.F_min + (self.F_max - self.F_min) * (current_eval / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            self.adaptive_parameters(evaluations)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "a00fd547-dc7f-454b-9cb2-3b91659bb2c5", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia and dynamic crossover to balance exploration and exploitation for better convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight_min = 0.4\n        self.inertia_weight_max = 0.9\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.5\n        self.CR_max = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight_min + (self.inertia_weight_max - self.inertia_weight_min) * (self.budget - evaluations) / self.budget\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.budget)\n            CR = self.CR_max - (self.CR_max - self.CR_min) * (evaluations / self.budget)\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "235e9fd6-1031-40fc-b84b-671291c828e2", "fitness": 0.07987691475719945, "name": "MetaPSODE", "description": "A novel Meta-PSODE algorithm combining dynamic parameter tuning and elitism to enhance exploration-exploitation balance for black-box optimization.", "code": "import numpy as np\n\nclass MetaPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_F = 0.5\n        self.initial_CR = 0.9\n        self.elite_ratio = 0.1  # Percentage of elite individuals\n        self.elite_size = int(self.population_size * self.elite_ratio)\n        self.dynamic_factor = 0.99  # Dynamic factor for parameter adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions and apply elitism\n            fitness = np.array([func(ind) for ind in pop])\n            evaluations += self.population_size\n            ranked_indices = np.argsort(fitness)\n            elite_indices = ranked_indices[:self.elite_size]\n            if func(pop[elite_indices[0]]) < func(global_best):\n                global_best = pop[elite_indices[0]]\n            \n            # Update personal bests\n            better_indices = fitness < personal_best_fitness\n            personal_best[better_indices] = pop[better_indices]\n            personal_best_fitness[better_indices] = fitness[better_indices]\n\n            # Differential Evolution step with dynamic parameters\n            F = self.initial_F * self.dynamic_factor**(evaluations / self.budget)\n            CR = self.initial_CR * self.dynamic_factor**(evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm MetaPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "1ee2a62d-41a2-4a73-bb9d-5147979c17be", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic with adaptive learning rates and enhanced memory update for improved convergence in DE and PSO.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n            # Implement adaptive learning rates\n            self.inertia_weight = np.random.uniform(0.6, 0.8)\n            self.F = np.random.uniform(0.5, 0.9)\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "3f3d4109-965b-4221-b65c-bebbb16378f6", "fitness": 0.07987691475719945, "name": "EnhancedHybridPSODE", "description": "An adaptive hybrid metaheuristic integrating dynamic parameter adjustment in PSO and DE for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9  # Start with a higher inertia weight for exploration\n        self.inertia_weight_decay = 0.99  # Gradually decay inertia weight\n        self.c1 = 2.0  # Increase cognitive coefficient for stronger personal influence\n        self.c2 = 2.0  # Increase social coefficient for stronger group influence\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adapt inertia weight\n            self.inertia_weight *= self.inertia_weight_decay\n            self.inertia_weight = max(0.4, self.inertia_weight)\n\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # DE step with adaptive F\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                F = np.random.uniform(self.F_min, self.F_max)\n                mutant = np.clip(pop[a] + F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07988 with standard deviation 0.01882.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10297494783103878, 0.10450159263304093, 0.10344765994678196, 0.07806508192107486, 0.07872469532592363, 0.07828268752493162, 0.057485227405237205, 0.05781367984400343, 0.05759666038276268]}}
{"id": "266a4dae-5208-476c-b7c3-b80568330138", "fitness": 0.07994895784152835, "name": "HybridPSODE", "description": "A refined hybrid metaheuristic with dynamic adjustment of DE parameters for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n        self.CR = np.random.uniform(0.7, 0.9)  # Dynamic DE crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.8 if evaluations < self.budget / 2 else 0.5  # Dynamic F adjustment\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07995 with standard deviation 0.01886.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10323047801751206, 0.10472118327795044, 0.10336602785121618, 0.07817693378956603, 0.07881974146603243, 0.07824591053408503, 0.0575412111928012, 0.05786104502327549, 0.05757808942131626]}}
{"id": "915f1ad6-015a-4595-af40-106f02ddac84", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "An innovative hybrid metaheuristic using adaptive inertia and adaptive crossover for enhanced exploration and exploitation balance in PSO-DE.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.initial_inertia_weight = 0.9  # Initial inertia weight for PSO\n        self.final_inertia_weight = 0.4  # Final inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.initial_CR = 0.9  # Initial DE crossover probability\n        self.final_CR = 0.4  # Final DE crossover probability\n        self.F = np.random.uniform(0.4, 0.9)  # Adaptive DE scaling factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Linearly decrease inertia weight and crossover probability\n            t = evaluations / self.budget\n            inertia_weight = self.initial_inertia_weight * (1 - t) + self.final_inertia_weight * t\n            CR = self.initial_CR * (1 - t) + self.final_CR * t\n            \n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
{"id": "6718b034-64cc-4139-9039-1c8267299d32", "fitness": 0.07997504139296116, "name": "HybridPSODE", "description": "A hybrid adaptive strategy integrating PSO and DE with dynamic parameter tuning for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Size of the population\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.c1 = 2.0  # Increased cognitive coefficient for PSO\n        self.c2 = 2.0  # Increased social coefficient for PSO\n        self.F = np.random.uniform(0.5, 0.9)  # Adaptive DE scaling factor\n        self.CR = 0.8  # DE crossover probability\n        self.inertia_damp = 0.99  # Damping factor for inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_fitness = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Update velocities and positions for PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n            # Evaluate new positions\n            for i in range(self.population_size):\n                new_fitness = func(pop[i])\n                evaluations += 1\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < func(global_best):\n                        global_best = pop[i]\n                        if evaluations >= self.budget:\n                            break\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = trial\n                    personal_best_fitness[i] = trial_fitness\n                    if trial_fitness < func(global_best):\n                        global_best = trial\n                        if evaluations >= self.budget:\n                            break\n            \n            # Dynamically adjust parameters\n            self.inertia_weight *= self.inertia_damp\n            self.F = np.random.uniform(0.4, 0.9)  # Update F within a broader range\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07998 with standard deviation 0.01888.", "error": "", "parent_ids": ["1562d29e-1f16-4e80-8836-f1f654246b49"], "operator": null, "metadata": {"aucs": [0.10295352577542916, 0.10412179289173662, 0.10438856107462047, 0.07805490546561344, 0.07856648444035697, 0.07868107052899076, 0.05748004003360274, 0.05773608505443517, 0.057792907271865146]}}
