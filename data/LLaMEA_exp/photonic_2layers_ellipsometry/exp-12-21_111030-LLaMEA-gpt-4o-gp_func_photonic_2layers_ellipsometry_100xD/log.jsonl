{"id": "bbc8a48d-cfd4-4a38-bc44-0c97ffd9fe76", "fitness": 0.053035728571636104, "name": "AdaptiveDifferentialEvolution", "description": "A novel metaheuristic algorithm combining Differential Evolution and Adaptive Local Search for efficient black-box optimization within given constraints.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        return self.population[a] + self.F * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.009274885975867453, 0.009270329602811378, 0.009267803950283038, 0.07873605952625307, 0.07869411334609955, 0.07867108113271182, 0.07116408462845014, 0.07113075466471785, 0.07111244431753061]}}
{"id": "8690c6d4-7117-4656-9fb1-98fe7dda4e5b", "fitness": 0.05299758150162001, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced AdaptiveDifferentialEvolution with dynamic parameter tuning and elite preservation for superior convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.elite = None\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def dynamic_parameters(self, evaluations):\n        self.F = 0.5 + (0.3 * np.sin(np.pi * evaluations / self.budget))\n        self.CR = 0.8 + (0.2 * np.cos(np.pi * evaluations / self.budget))\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        return self.population[a] + self.F * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.dynamic_parameters(evaluations)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n            # Update the elite\n            best_idx = np.argmin(self.fitness)\n            if self.elite is None or self.fitness[best_idx] < func(self.elite):\n                self.elite = self.population[best_idx].copy()\n\n        return self.elite", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05300 with standard deviation 0.03108.", "error": "", "parent_ids": ["bbc8a48d-cfd4-4a38-bc44-0c97ffd9fe76"], "operator": null, "metadata": {"aucs": [0.009275573085560151, 0.009257132545531843, 0.00926204853800594, 0.07874305762452782, 0.07856427440404301, 0.07861116155073367, 0.07116951933110405, 0.07102929636597055, 0.0710661700691031]}}
{"id": "3db2f49c-7521-4b2f-b10f-21e428db4deb", "fitness": 0.05299653536126213, "name": "AdaptiveDifferentialEvolution", "description": "Improved the mutation strategy by introducing a dynamic differential weight and enhanced the local search application probability for better exploration.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        dynamic_F = 0.5 + np.random.rand() * 0.3  # Dynamic differential weight\n        return self.population[a] + dynamic_F * (self.population[b] - self.population[c])\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.4:  # 40% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05300 with standard deviation 0.03108.", "error": "", "parent_ids": ["bbc8a48d-cfd4-4a38-bc44-0c97ffd9fe76"], "operator": null, "metadata": {"aucs": [0.009278093430763024, 0.009271531819161294, 0.009244967205481291, 0.07876873261271855, 0.0787044096348225, 0.07843976363498806, 0.07118943727939497, 0.07113910846325378, 0.0709327741707757]}}
{"id": "a1bce757-eb04-4b78-aa1f-f75d33b8487d", "fitness": 0.05571067489450923, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Dynamic Parameter Adjustment and Memory Archive for improved exploration-exploitation balance and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05571 with standard deviation 0.03314.", "error": "", "parent_ids": ["bbc8a48d-cfd4-4a38-bc44-0c97ffd9fe76"], "operator": null, "metadata": {"aucs": [0.009271198938955783, 0.009258357001085238, 0.0102207847087602, 0.07869845916406926, 0.07857202453736045, 0.09248967643478678, 0.07113495686823013, 0.07103605690776316, 0.08071455948957207]}}
{"id": "6a736caa-2d83-4f5f-83ab-1552f4aecba3", "fitness": 0.053137422469684475, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Randomized Subpopulation Strategy and Memory Archive for improved exploration-exploitation balance and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        subpop_size = max(3, int(0.1 * self.population_size))\n        subpop_indices = np.random.choice(range(self.population_size), subpop_size, replace=False)\n        a, b = np.random.choice(subpop_indices, 2, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.select_from_memory_archive())\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return np.mean(self.population, axis=0)  # Use mean if archive is empty\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05314 with standard deviation 0.03116.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009270837104128571, 0.009342609494978227, 0.009245700550710834, 0.07869494173360947, 0.07945516106907557, 0.07844083337578933, 0.0711321196320438, 0.07171970064634858, 0.07093489862047586]}}
{"id": "0343c7c9-def4-420a-91b7-97344a298e02", "fitness": 0.05301580692567112, "name": "AdvancedDifferentialEvolution", "description": "Advanced Differential Evolution with Stochastic Adaptive Parameters and Memory Archive for Enhanced Convergence and Solution Diversity", "code": "import numpy as np\n\nclass AdvancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.init_parameters()\n\n    def init_parameters(self):\n        self.F = 0.5  # Differential weight initialized\n        self.CR = 0.9  # Crossover probability initialized\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.1, 1.0\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def stochastic_local_search(self, candidate):\n        perturbation_strength = np.random.laplace(0, 0.1, self.dim)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = self.F_min + (self.F_max - self.F_min) * np.random.beta(2, 5)\n        self.CR = self.CR_min + (self.CR_max - self.CR_min) * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                if np.random.rand() < 0.3:\n                    candidate = self.stochastic_local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 5, "feedback": "The algorithm AdvancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009258333544270303, 0.009275366610146607, 0.009270306484583601, 0.07857291319757631, 0.07874151870641755, 0.07869047432027532, 0.07103654133660375, 0.07116822603611739, 0.07112858209504924]}}
{"id": "ce17c3a4-9632-4cdc-ab84-4e4e6944dc09", "fitness": 0.05296964971041234, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Dynamic Population Reduction and Synergistic Memory Utilization for Optimal Convergence and Solution Quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        self.fitness = np.full(self.initial_population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n        # Reduce population size dynamically\n        self.population_size = max(4, int(self.initial_population_size * (1 - evaluation_ratio)))\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.initial_population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                # Use best candidate from memory archive if beneficial\n                archive_candidate = self.select_from_memory_archive()\n                if archive_candidate is not None:\n                    archive_fitness = func(archive_candidate)\n                    evaluations += 1\n                    if archive_fitness < self.fitness[i]:\n                        self.population[i] = archive_candidate\n                        self.fitness[i] = archive_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05297 with standard deviation 0.03106.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009259084937530249, 0.009258487857045195, 0.009264373241651302, 0.07857513120112503, 0.07857334484829626, 0.07863524164318147, 0.07103918006945176, 0.07103720673798852, 0.07108479685744129]}}
{"id": "af4c4a80-6878-4bb5-b5e8-f3926ee80375", "fitness": 0.053036649465776416, "name": "AdaptiveDynamicNeighborhoodDifferentialEvolution", "description": "Adaptive Dynamic Neighborhood Differential Evolution (ADN-DE) combines dynamic parameter adjustment with adaptive local search and neighborhood-based mutation for enhanced convergence and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass AdaptiveDynamicNeighborhoodDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        neighbors = np.random.choice(idxs, 5, replace=False)  # Neighborhood of 5\n        a, b, c = neighbors[:3]\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.4 * (1 - evaluation_ratio)  # Dynamic adjustment favoring exploration initially\n        self.CR = 0.9 - 0.4 * np.cos(np.pi * evaluation_ratio)  # Smoother transition for CR\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            worst_idx = np.argmax([cf for _, cf in self.memory_archive])\n            del self.memory_archive[worst_idx]\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.5:  # Increased likelihood of local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDynamicNeighborhoodDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.00928180045667848, 0.009271894302250283, 0.009260132033974022, 0.07880668119936185, 0.0787072620023005, 0.07858933261659318, 0.07122160909831077, 0.0711414471379972, 0.07104968634452147]}}
{"id": "86b6929d-b307-442b-b56b-b858ffa4d866", "fitness": 0.05302053728926618, "name": "HybridAdaptiveDifferentialEvolution", "description": "Hybrid Adaptive Differential Evolution with Dynamic Parameter Adjustment, Memory Archive, and Stochastic Tournament Selection for enhanced diversity and convergence speed.", "code": "import numpy as np\n\nclass HybridAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def stochastic_tournament_selection(self):\n        candidates = np.random.choice(self.population_size, 3, replace=False)\n        selected = sorted(candidates, key=lambda idx: self.fitness[idx])\n        return self.population[selected[0]]\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                # Stochastic tournament selection\n                if np.random.rand() < 0.2:  # 20% chance to replace with a tournament-selected individual\n                    selected = self.stochastic_tournament_selection()\n                    selected_fitness = func(selected)\n                    evaluations += 1\n\n                    if selected_fitness < self.fitness[i]:\n                        self.population[i] = selected\n                        self.fitness[i] = selected_fitness\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 8, "feedback": "The algorithm HybridAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009275697123766524, 0.009265688071418365, 0.009264591503152397, 0.07874426307941718, 0.07864677964481215, 0.0786370183027496, 0.07117047900286821, 0.07109404592968571, 0.0710862729455255]}}
{"id": "1592c9fa-f9d5-4c8a-a941-536302afb046", "fitness": 0.05367612744355102, "name": "DynamicAdaptiveDifferentialEvolution", "description": "\"Dynamic Adaptive Differential Evolution with Memory Archive and Stochastic Local Search for Enhanced Exploration and Exploitation in Black Box Optimization.\"", "code": "import numpy as np\n\nclass DynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_base = 0.8  # Base differential weight\n        self.CR_base = 0.9  # Base crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.successful_deltas = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F_current * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR_current\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self):\n        if self.successful_deltas:\n            mean_delta = np.mean(self.successful_deltas)\n            self.F_current = self.F_base + 0.1 * np.exp(-mean_delta)\n            self.CR_current = self.CR_base - 0.1 * np.exp(-mean_delta)\n        else:\n            self.F_current = self.F_base\n            self.CR_current = self.CR_base\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.adjust_parameters()\n            self.successful_deltas.clear()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.successful_deltas.append(abs(self.fitness[i] - trial_fitness))\n\n                # Perform stochastic local search\n                if np.random.rand() < 0.4:  # 40% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.successful_deltas.append(abs(self.fitness[i] - candidate_fitness))\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 9, "feedback": "The algorithm DynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05368 with standard deviation 0.03150.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009515850128748893, 0.009270179088459507, 0.009317285717577617, 0.0813175935533117, 0.0786925775394215, 0.07918414215764757, 0.07314665763050643, 0.07112956337543419, 0.07151129780085175]}}
{"id": "ab2ef7d0-bdfa-4eee-9808-058006db4cc2", "fitness": -Infinity, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Dynamic Parameter Adjustment, Memory Archive, and Adaptive Population Reduction for improved convergence and resource management.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.min_population_size = 4  # Minimum size for the population\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def reduce_population(self):\n        if self.population_size > self.min_population_size:\n            sorted_idx = np.argsort(self.fitness)\n            self.population = self.population[sorted_idx[:self.population_size // 2]]\n            self.fitness = self.fitness[sorted_idx[:self.population_size // 2]]\n            self.population_size = len(self.population)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n            # Reduce population size adaptively\n            if evaluations / self.budget > 0.5:  # Start reducing after 50% of budget\n                self.reduce_population()\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 10, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {}}
{"id": "8bec707e-8dda-4616-89bf-eb191e0ebe4f", "fitness": 0.05571067489450923, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with improved memory archive replacement strategy for better solution retention.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        # Change starts here\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive = sorted(self.memory_archive, key=lambda x: x[1])[:self.population_size]\n        # Change ends here\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05571 with standard deviation 0.03314.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009271198938955783, 0.009258357001085238, 0.0102207847087602, 0.07869845916406926, 0.07857202453736045, 0.09248967643478678, 0.07113495686823013, 0.07103605690776316, 0.08071455948957207]}}
{"id": "ce4182b4-71a1-4c75-9348-0f7576815c5a", "fitness": 0.05302645679345197, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with Dynamic Parameter Adjustment, Memory Archive, and Rotation-invariant Crossover for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def rotation_invariant_crossover(self, target, mutant):  # Changed\n        j_rand = np.random.randint(self.dim)\n        trial = np.copy(target)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.rotation_invariant_crossover(self.population[i], mutant)  # Changed\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 12, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03109.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.00927393676541688, 0.009266421788565515, 0.009268566152822011, 0.07872636906751884, 0.07865429446871997, 0.07867561024910075, 0.07115656913864299, 0.07109984997900642, 0.07111649353127436]}}
{"id": "f42b58d1-871f-4426-9bfc-ac116ccad7cd", "fitness": -Infinity, "name": "HybridAdaptiveDifferentialEvolution", "description": "Hybrid Adaptive Differential Evolution with Novel Memetic Strategy and Diversity Control for Enhanced Optimization Efficiency and Solution Quality.", "code": "import numpy as np\n\nclass HybridAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_base = 0.8  # Base differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        F = self.F_base * (1.0 - np.min(self.fitness) / np.max(self.fitness))\n        mutant = self.population[a] + F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = np.random.normal(0, 0.1, self.dim)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F_base = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            worst_idx = np.argmax([x[1] for x in self.memory_archive])\n            del self.memory_archive[worst_idx]\n\n    def diversify_population(self):\n        if len(self.memory_archive) >= self.population_size:\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # 10% chance to diversify\n                    best_archive_candidate = self.select_from_memory_archive()\n                    if best_archive_candidate is not None:\n                        blend_factor = np.random.rand()\n                        self.population[i] = (blend_factor * self.population[i] +\n                                              (1 - blend_factor) * best_archive_candidate)\n                        self.population[i] = np.clip(self.population[i], \n                                                     func.bounds.lb, func.bounds.ub)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n            self.diversify_population()\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 13, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {}}
{"id": "7553d51d-b0c8-4edc-aa88-fb84550d6913", "fitness": -Infinity, "name": "EnhancedAdaptiveDEWithSelfOrganizingDynamics", "description": "Enhanced Adaptive DE with Self-Organizing Population Dynamics and Adaptive Selection Pressure for efficient convergence and improved robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEWithSelfOrganizingDynamics:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.diversity_threshold = 0.1\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def compute_diversity(self):\n        if self.population is not None:\n            mean = np.mean(self.population, axis=0)\n            diversity = np.mean(np.linalg.norm(self.population - mean, axis=1))\n            return diversity\n        return 0\n\n    def adjust_population_size(self, diversity):\n        if diversity < self.diversity_threshold and self.population_size > 5:\n            self.population_size = max(5, int(self.population_size * 0.9))\n        elif diversity > 2 * self.diversity_threshold:\n            self.population_size = min(100, int(self.population_size * 1.1))\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            diversity = self.compute_diversity()\n            self.adjust_population_size(diversity)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 14, "feedback": "An exception occurred: IndexError('index 21 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 21 is out of bounds for axis 0 with size 20')", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {}}
{"id": "b61a41c0-dcdb-41bf-a43f-51b7a225468d", "fitness": 0.053021592951233654, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with History-Based Parameter Adaptation and Increased Local Search Frequency for improved convergence speed and reliability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  \n        self.CR = 0.9  \n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.history_f = []\n        self.history_cr = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        f_history_mean = np.mean(self.history_f) if self.history_f else self.F\n        cr_history_mean = np.mean(self.history_cr) if self.history_cr else self.CR\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio + f_history_mean)\n        self.CR = 0.9 - 0.5 * evaluation_ratio + cr_history_mean\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.history_f.append(self.F)\n                    self.history_cr.append(self.CR)\n\n                if np.random.rand() < 0.5:  # Increased to 50% chance for local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009276628764385286, 0.009264754760373362, 0.00926464718313813, 0.07875379944134053, 0.07864158599088156, 0.07863853395860199, 0.07117786412354066, 0.07108925291624868, 0.07108726942259269]}}
{"id": "30428fb3-8874-4afe-8c6c-f25d1092ac4d", "fitness": -Infinity, "name": "MultiStrategyAdaptiveDifferentialEvolution", "description": "Multi-Strategy Adaptive Differential Evolution with Competitive Population and Memory-based Parameter Adaptation for enhanced convergence speed and solution quality.", "code": "import numpy as np\n\nclass MultiStrategyAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.strategy_probabilities = [0.5, 0.5]  # Initial probability for each strategy\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate_current_to_best(self, idx, best_idx):\n        idxs = [i for i in range(self.population_size) if i != idx and i != best_idx]\n        a, b = np.random.choice(idxs, 2, replace=False)\n        F_best = 0.5  # Dynamic differential weight\n        mutant = self.population[idx] + F_best * (self.population[best_idx] - self.population[idx]) + F_best * (self.population[a] - self.population[b])\n        return mutant\n\n    def mutate_rand_1(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        F_rand = 0.8  # Static differential weight\n        mutant = self.population[a] + F_rand * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = 0.9  # Static crossover probability\n        crossover_mask = np.random.rand(self.dim) < CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def adaptive_local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def update_strategy_probabilities(self, improvement, strategy_index):\n        learning_rate = 0.1\n        decay = 0.99\n        for i in range(len(self.strategy_probabilities)):\n            if i == strategy_index:\n                self.strategy_probabilities[i] += learning_rate * improvement\n            self.strategy_probabilities[i] *= decay\n        total = sum(self.strategy_probabilities)\n        self.strategy_probabilities = [p / total for p in self.strategy_probabilities]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            best_idx = np.argmin(self.fitness)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                strategy_index = np.random.choice(len(self.strategy_probabilities), p=self.strategy_probabilities)\n                \n                if strategy_index == 0:\n                    mutant = self.mutate_current_to_best(i, best_idx)\n                else:\n                    mutant = self.mutate_rand_1(i)\n                \n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    improvement = self.fitness[i] - trial_fitness\n                    self.fitness[i] = trial_fitness\n                    self.update_memory_archive(trial, trial_fitness)\n                else:\n                    improvement = 0\n                \n                # Apply local search with a memory-based adaptive probability\n                if np.random.rand() < min(0.3, 0.5 * (1 - evaluations / self.budget)):\n                    candidate = self.adaptive_local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.update_memory_archive(candidate, candidate_fitness)\n\n                self.update_strategy_probabilities(improvement, strategy_index)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 16, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {}}
{"id": "640dd53e-72d1-40fa-a9b6-cffe3c7fdd3e", "fitness": 0.05301372033841088, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Modified the local search strategy by increasing perturbation strength and probability of local search application for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    # Increase perturbation strength for local search\n    def local_search(self, candidate):\n        perturbation_strength = 0.2 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n\n                # Increased probability to apply local search\n                if np.random.rand() < 0.5:  # 50% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    \n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    \n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                \n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05301 with standard deviation 0.03109.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009273287857791357, 0.00926131755298587, 0.009268168100036056, 0.07871978995963191, 0.07860217294401184, 0.07867336288825821, 0.07115148277176131, 0.07105943836557738, 0.07111446260564402]}}
{"id": "04a5b7b5-ae18-4824-8296-ea869c61fa1a", "fitness": 0.05571078455277165, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Random Reinitialization on Stagnation to escape local optima and improve diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10  # New attribute to track stagnation\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0  # Reset counter on improvement\n                else:\n                    self.stagnation_counter += 1\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0  # Reset counter on improvement\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                # Random reinitialization on stagnation\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05571 with standard deviation 0.03314.", "error": "", "parent_ids": ["a1bce757-eb04-4b78-aa1f-f75d33b8487d"], "operator": null, "metadata": {"aucs": [0.009271198938955783, 0.00925844519370489, 0.0102207847087602, 0.07869845916406926, 0.07857292326910259, 0.09248967643478678, 0.07113495686823013, 0.07103605690776316, 0.08071455948957207]}}
{"id": "df5e4f2e-5ad3-45eb-8eef-8c217bbfb52c", "fitness": 0.053053857884091254, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Self-Adaptive Parameter Control and Improved Diversity Mechanism to boost convergence speed and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.population_size)\n        self.max_stagnation = 10\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self):\n        self.F = np.clip(0.5 + 0.3 * np.random.rand(), 0.4, 0.9)\n        self.CR = np.clip(0.9 - 0.5 * np.random.rand(), 0.1, 0.9)\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                self.adjust_parameters()\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0  # Reset counter on improvement\n                else:\n                    self.stagnation_counter[i] += 1\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.3:  # 30% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0  # Reset counter on improvement\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                # Random reinitialization on stagnation\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05305 with standard deviation 0.03111.", "error": "", "parent_ids": ["04a5b7b5-ae18-4824-8296-ea869c61fa1a"], "operator": null, "metadata": {"aucs": [0.009275456945533778, 0.009277088690111124, 0.00926973715781243, 0.07874188314158015, 0.07875861146723684, 0.07868658974073117, 0.07116860600517627, 0.07118157014381954, 0.07112517766481996]}}
{"id": "d1c5e4f7-7d9b-4f59-a5d9-d705e3dbde0a", "fitness": 0.052990761946150364, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introducing Dynamic Memory Archive Management and Adaptive Mutation for Enhanced Adaptive Differential Evolution to boost exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.dynamic_archive_size = max(2, int(0.1 * self.population_size))\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        trial_F = self.F * (1.0 + 0.2 * np.sin(2 * np.pi * np.random.rand()))\n        mutant = self.population[a] + trial_F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.dynamic_archive_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            best_candidate = min(self.memory_archive, key=lambda x: x[1])[0]\n            return best_candidate\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05299 with standard deviation 0.03107.", "error": "", "parent_ids": ["04a5b7b5-ae18-4824-8296-ea869c61fa1a"], "operator": null, "metadata": {"aucs": [0.009277840740228527, 0.009260116250770056, 0.009254100235079221, 0.07876615343381166, 0.07858824873672932, 0.07853047211751929, 0.0711874327603117, 0.07104894933886674, 0.07100354390203678]}}
{"id": "42a1c5ef-c859-42bf-8a03-bdccc312e3bb", "fitness": 0.053003605734551124, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Improved exploration by increasing the chance of local search to 40%.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8  # Initial differential weight\n        self.CR = 0.9  # Initial crossover probability\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10  # New attribute to track stagnation\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0  # Reset counter on improvement\n                else:\n                    self.stagnation_counter += 1\n\n                # Perform adaptive local search\n                if np.random.rand() < 0.4:  # 40% chance to apply local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0  # Reset counter on improvement\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                # Random reinitialization on stagnation\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05300 with standard deviation 0.03108.", "error": "", "parent_ids": ["04a5b7b5-ae18-4824-8296-ea869c61fa1a"], "operator": null, "metadata": {"aucs": [0.009271510676876593, 0.009258551805385595, 0.009267944042711918, 0.07870162349719179, 0.07857401253292007, 0.07867115823556914, 0.07113738042739759, 0.07103753163460991, 0.07111273875829749]}}
{"id": "0a5e9609-0ec0-4fdb-8bad-19e2e3d01ad4", "fitness": 0.05470888377165455, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Stochastic Adaptive Control and Elite Learning to dynamically balance exploration and exploitation and leverage elite solutions.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * self.dim\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.elite_ratio = 0.1  # Proportion of elites\n        self.elite_pool = []  # Store elite solutions\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        base = self.select_base_vector(a)\n        mutant = base + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def select_base_vector(self, idx):\n        if np.random.rand() < 0.5 and self.elite_pool:\n            return self.elite_pool[np.random.randint(0, len(self.elite_pool))]\n        return self.population[idx]\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.5 + 0.4 * np.cos(np.pi * evaluation_ratio)\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def update_elite_pool(self):\n        sorted_population = sorted(zip(self.population, self.fitness), key=lambda x: x[1])\n        elite_count = int(self.elite_ratio * self.population_size)\n        self.elite_pool = [x[0] for x in sorted_population[:elite_count]]\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n            self.update_elite_pool()\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05471 with standard deviation 0.03227.", "error": "", "parent_ids": ["04a5b7b5-ae18-4824-8296-ea869c61fa1a"], "operator": null, "metadata": {"aucs": [0.009277786004439958, 0.009268330320399976, 0.00995091388417313, 0.07876559566485786, 0.07867171666450179, 0.0869170295351347, 0.07118699864627143, 0.0711137560405487, 0.07722782718456345]}}
{"id": "5d873d57-3a08-42fc-8010-7ea0e408a2a2", "fitness": 0.05811474072700061, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Dynamic Population Resizing and Adaptive Parameter Tuning in Enhanced Adaptive Differential Evolution to bolster exploration and exploitation balance, improving convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5  # Population resize threshold\n        \n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n    \n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05811 with standard deviation 0.03574.", "error": "", "parent_ids": ["04a5b7b5-ae18-4824-8296-ea869c61fa1a"], "operator": null, "metadata": {"aucs": [0.009271263097944793, 0.009259284925838496, 0.010542736099370509, 0.07869911422927489, 0.07858147445636776, 0.10765242274456066, 0.07114081015482843, 0.07104339891553679, 0.08684216191928318]}}
{"id": "4d243446-0fbc-4dcb-88f4-02cbb4e6260d", "fitness": 0.05300478057067518, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce stochastic adaptive scaling of mutation factor for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5  # Population resize threshold\n        \n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        stochastic_factor = 0.5 + np.random.rand() * 0.3  # Stochastic scaling\n        mutant = self.population[a] + stochastic_factor * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n    \n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05300 with standard deviation 0.03108.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009278191901855304, 0.009266947282881577, 0.009253402991579618, 0.0787697368185154, 0.07865773701389644, 0.07852490118165212, 0.07119021598998743, 0.07110289137769532, 0.07099900057801345]}}
{"id": "f0ed29e5-b461-4271-821d-dfc340292f0e", "fitness": 0.053040068415126713, "name": "QuantumInspiredAdaptiveDifferentialEvolution", "description": "Introducing Quantum-inspired Adaptive Exploration in Differential Evolution to leverage probabilistic transitions and dynamic population diversity for enhanced convergence and solution accuracy.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def quantum_exploration(self, candidate):\n        perturbation_strength = (np.random.rand(self.dim) - 0.5) * np.random.choice([-1, 1], self.dim)\n        return candidate + perturbation_strength * self.F\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.quantum_exploration(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 25, "feedback": "The algorithm QuantumInspiredAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009278351696633824, 0.009270699170090602, 0.009266131663646648, 0.07877137236022624, 0.07869775544593782, 0.07865278483251015, 0.0711914798467721, 0.07113358396821523, 0.0710984567521078]}}
{"id": "3f006fde-d4cb-4610-823b-dbe315feb68a", "fitness": 0.05293666868863451, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with integrated memory archive exploitation for improved solution refinement and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5  # Population resize threshold\n        \n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n    \n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                # Explore memory archive for better candidates\n                mem_candidate = self.select_from_memory_archive()\n                if mem_candidate is not None:\n                    mem_candidate = np.clip(mem_candidate, func.bounds.lb, func.bounds.ub)\n                    mem_candidate_fitness = func(mem_candidate)\n                    evaluations += 1\n                    if mem_candidate_fitness < self.fitness[i]:\n                        self.population[i] = mem_candidate\n                        self.fitness[i] = mem_candidate_fitness\n                        self.stagnation_counter = 0\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05294 with standard deviation 0.03104.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009259115737848878, 0.00925851300617997, 0.009248743452845654, 0.0785754439774421, 0.07857360068106956, 0.07847607273716695, 0.07103940521609742, 0.0710372694214576, 0.07096185396760246]}}
{"id": "a6beab0d-3ead-41e6-b64b-3d3fad6cce09", "fitness": -Infinity, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introducing Adaptive Memory-Driven Exploration and Local Search Enhancement in Enhanced Adaptive Differential Evolution, optimally balancing exploration-exploitation for improved convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            sampled_candidates = np.random.choice(self.memory_archive, min(5, len(self.memory_archive)), replace=False)\n            return min(sampled_candidates, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                if np.random.rand() < 0.2:\n                    memory_candidate = self.select_from_memory_archive()\n                    if memory_candidate is not None:\n                        memory_candidate_fitness = func(memory_candidate)\n                        evaluations += 1\n                        if memory_candidate_fitness < self.fitness[i]:\n                            self.population[i] = memory_candidate\n                            self.fitness[i] = memory_candidate_fitness\n                            self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 27, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 2) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1, 2) + inhomogeneous part.')", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {}}
{"id": "c410f9b7-9198-4279-8880-2129730c3be1", "fitness": 0.05811474072700061, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhance exploitative capabilities by adjusting population resizing threshold dynamically based on performance trends.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5  # Population resize threshold\n        \n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n    \n    def resize_population(self, evaluations):\n        # Dynamically adjust population resizing threshold based on performance\n        self.dynamic_resizing_threshold = 0.5 if np.mean(self.fitness) > np.median(self.fitness) else 0.3\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05811 with standard deviation 0.03574.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009271263097944793, 0.009259284925838496, 0.010542736099370509, 0.07869911422927489, 0.07858147445636776, 0.10765242274456066, 0.07114081015482843, 0.07104339891553679, 0.08684216191928318]}}
{"id": "cd6d63ab-46f4-481e-a6a5-d484b2fc4859", "fitness": 0.053035728571636104, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrating Self-Adaptive Parameter Control and Adaptive Stagnation Handling in Enhanced Differential Evolution for improved exploration and exploitation balance, enhancing convergence and solution robustness. ", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.cos(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.3 * evaluation_ratio\n    \n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = max(self.initial_population_size // 2, 4)\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def adaptive_stagnation_handling(self):\n        self.max_stagnation = max(5, self.max_stagnation - 1)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n                    self.adaptive_stagnation_handling()\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009274885975867453, 0.009270329602811378, 0.009267803950283038, 0.07873605952625307, 0.07869411334609955, 0.07867108113271182, 0.07116408462845014, 0.07113075466471785, 0.07111244431753061]}}
{"id": "cde6af02-b493-4d93-b8e4-c292139b4a1c", "fitness": 0.05299453044407332, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Incorporating Fitness-Based Population Scaling and Adaptive Mutation Strategies in Enhanced Differential Evolution to optimize exploration-exploitation trade-off and improve convergence efficiency and accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = 0\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5  # Population resize threshold\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx, evaluation_ratio):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        F_dynamic = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        mutant = self.population[a] + F_dynamic * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR_dynamic = 0.7 + 0.2 * np.random.rand()\n        crossover_mask = np.random.rand(self.dim) < CR_dynamic\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = max(5, int(self.initial_population_size * (0.5 + 0.5 * (1 - evaluations / self.budget))))\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.initial_population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i, evaluation_ratio)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter = 0\n                else:\n                    self.stagnation_counter += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05299 with standard deviation 0.03108.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009276342767928103, 0.009264311256019231, 0.00925313018370344, 0.07875087769516198, 0.07863080347961215, 0.07852136046837732, 0.07117559615358648, 0.07108199364990364, 0.0709963583423675]}}
{"id": "33368d53-6b47-49bf-986a-a4b2e3b79961", "fitness": 0.05811558455295997, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Enhanced Dynamic Adaptive Differential Evolution with Adaptive Mutation and Crossover for Improved Convergence and Diversity Maintenance in Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedDynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05812 with standard deviation 0.03574.", "error": "", "parent_ids": ["5d873d57-3a08-42fc-8010-7ea0e408a2a2"], "operator": null, "metadata": {"aucs": [0.009271940442122761, 0.009259284925838496, 0.010542736099370509, 0.0787060313187311, 0.07858147445636776, 0.10765242274456066, 0.07114081015482843, 0.07104339891553679, 0.08684216191928318]}}
{"id": "d1502bd6-b5c1-4ce1-a3a1-f0276835ed2b", "fitness": 0.05301611229471191, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Enhanced Dynamic Adaptive Differential Evolution with Optimized Mutation Strategy for Improved Convergence in Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c]) + np.random.normal(0, 0.1, self.dim)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedDynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009269708497895435, 0.009272966877564626, 0.009261216422244312, 0.07868325146614163, 0.07872019708065336, 0.07860338520596533, 0.07112315465945829, 0.07115112938371737, 0.07106000105876686]}}
{"id": "7c186ea2-8292-4bd9-9cc6-11f755ff2538", "fitness": 0.0530186159467152, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Enhanced Dynamic Adaptive Differential Evolution with Improved Mutation Strategy for Better Exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        mutant += 0.1 * np.random.uniform(-1, 1, self.dim)  # Added random perturbation\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedDynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009272548522860968, 0.009271188414893605, 0.00926114534604805, 0.07871221263736417, 0.07870304998895195, 0.07860390648756455, 0.07114562538281188, 0.07113766133326205, 0.07106020540667957]}}
{"id": "e1a819de-9fdb-48e8-b4b3-8583102da200", "fitness": 0.053005269625774204, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Introduced adaptive local search and feedback mechanism to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        adaptive_step = 1 / (1 + np.exp(-5 * (self.CR - 0.5)))  # Adaptive step size\n        return candidate + perturbation_strength * adaptive_step\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedDynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05301 with standard deviation 0.03108.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009271940442122761, 0.009259243364563519, 0.009267600374803342, 0.0787060313187311, 0.07858105208204191, 0.07866768264861834, 0.07114081015482843, 0.07104302887399017, 0.07111003737226829]}}
{"id": "fb4b94fd-b05c-43b4-89ad-185bccfacab2", "fitness": -Infinity, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Enhanced Dynamic Adaptive Differential Evolution with Adaptive Mutation, Crossover, and Population Clustering for Improved Exploration-Exploitation Balance in Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.cluster_interval = 20  # Interval for clustering the population\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def cluster_population(self):\n        if self.population_size > 5:\n            kmeans = KMeans(n_clusters=max(2, self.population_size // 10), random_state=0)\n            kmeans.fit(self.population)\n            return kmeans.labels_\n        return np.zeros(self.population_size, dtype=int)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n        cluster_labels = np.zeros(self.population_size)\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.cluster_interval == 0:\n                cluster_labels = self.cluster_population()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                cluster_idx = cluster_labels[i]\n                cluster_indices = np.where(cluster_labels == cluster_idx)[0]\n                other_indices = [idx for idx in cluster_indices if idx != i]\n\n                if len(other_indices) >= 3:\n                    a, b, c = np.random.choice(other_indices, 3, replace=False)\n                else:\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = np.random.choice(idxs, 3, replace=False)\n\n                mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 35, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 10')", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {}}
{"id": "1857e053-d641-492c-8bac-0845cce01e55", "fitness": 0.05300956364587587, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Enhanced Dynamic Adaptive Differential Evolution with Strategic Parameter Tuning for Better Convergence in Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        # Adjusted parameter update for CR for improved convergence\n        self.CR = 0.7 + 0.2 * np.cos(np.pi * evaluation_ratio)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedDynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05301 with standard deviation 0.03108.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009271910176687381, 0.009261287373146132, 0.00926760688096362, 0.07870572225119388, 0.07860188930193701, 0.07866773845191288, 0.07114057124517137, 0.07105926422790387, 0.0711100829039667]}}
{"id": "00d4464c-7a87-47d3-84df-a3d8ebd0cb06", "fitness": 0.05553715506883518, "name": "EnhancedDynamicAdaptiveDifferentialEvolution", "description": "Introduced a probabilistic factor into the mutation step to enhance exploration of the search space.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutation_factor = np.random.uniform(0.5, 1.0)  # Added line\n        mutant = self.population[a] + mutation_factor * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedDynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05554 with standard deviation 0.03300.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009278267428699083, 0.010108676294056207, 0.009263622624548606, 0.07877050680515307, 0.09161688378723554, 0.07862845045639621, 0.07119081241027814, 0.07989780509455247, 0.07107937071859727]}}
{"id": "9829d356-ba78-4d4b-a048-3f635f4bebd2", "fitness": 0.05303437807928568, "name": "AdaptiveEnhancedDifferentialEvolution", "description": "Adaptive Enhanced Differential Evolution with Dual Population Dynamics for Diversified Exploration and Intensified Exploitation in Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveEnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.main_population_size = self.initial_population_size // 2\n        self.aux_population_size = self.initial_population_size // 2\n        self.main_population = None\n        self.aux_population = None\n        self.main_fitness = None\n        self.aux_fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.main_population_size)\n        self.max_stagnation = 10\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.main_population = np.random.uniform(lb, ub, (self.main_population_size, self.dim))\n        self.main_fitness = np.full(self.main_population_size, np.inf)\n        self.aux_population = np.random.uniform(lb, ub, (self.aux_population_size, self.dim))\n        self.aux_fitness = np.full(self.aux_population_size, np.inf)\n\n    def mutate(self, main_idx, aux=False):\n        population = self.aux_population if aux else self.main_population\n        idxs = [i for i in range(population.shape[0]) if i != main_idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = population[a] + self.F * (population[b] - population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.main_population_size:\n            self.memory_archive.pop(0)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for i in range(self.main_population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.main_population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.main_fitness[i]:\n                    self.main_population[i] = trial\n                    self.main_fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.main_population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.main_fitness[i]:\n                        self.main_population[i] = candidate\n                        self.main_fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.main_population[i], self.main_fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.main_population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.main_fitness[i] = func(self.main_population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n            \n            if evaluations >= self.budget:\n                break\n\n            # Auxiliary population evolution for additional exploration\n            for j in range(self.aux_population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(j, aux=True)\n                trial = self.crossover(self.aux_population[j], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.aux_fitness[j]:\n                    self.aux_population[j] = trial\n                    self.aux_fitness[j] = trial_fitness\n\n        best_idx_main = np.argmin(self.main_fitness)\n        best_idx_aux = np.argmin(self.aux_fitness)\n        return self.main_population[best_idx_main] if self.main_fitness[best_idx_main] < self.aux_fitness[best_idx_aux] else self.aux_population[best_idx_aux]", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveEnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009272167164340761, 0.009272977997286658, 0.009267772683723807, 0.07870952243592877, 0.07871797504081146, 0.07866631992406792, 0.07114333229565506, 0.07114981607503301, 0.0711095190967237]}}
{"id": "0c46078b-6e8a-4f72-af79-9a56839cb1a5", "fitness": 0.11962849738604679, "name": "AdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Adaptive Dynamic Differential Evolution with Hierarchical Clustering for Enhanced Exploration and Exploitation Balance in Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.2 * self.budget\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:  # Randomly perturb some within clusters\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11963 with standard deviation 0.18382.", "error": "", "parent_ids": ["33368d53-6b47-49bf-986a-a4b2e3b79961"], "operator": null, "metadata": {"aucs": [0.009277218381335328, 0.011903596311796716, 0.00927686707933617, 0.07875979121725551, 0.6296311836186814, 0.07875642777974501, 0.07118249064517868, 0.1166890356177619, 0.07117986582333014]}}
{"id": "aa107c3f-c7f8-497d-86a4-4085c3c69641", "fitness": 0.05304320847173519, "name": "EnhancedAdaptiveDynamicDifferentialEvolution", "description": "Enhanced Adaptive Dynamic Differential Evolution with Hierarchical Clustering and Dynamic Memory Archive for Improved Exploration and Exploitation in Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 8  # Reduced for quicker adaptability\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.2 * self.budget\n        self.local_search_prob = 0.4  # Increased probability of local search\n        self.memory_archive_size = 5  # Dynamic memory archive\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.memory_archive.sort(key=lambda x: x[1])  # Sort to keep the best\n        if len(self.memory_archive) > self.memory_archive_size:\n            self.memory_archive.pop()  # Keep only the best solutions\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return self.memory_archive[np.random.randint(len(self.memory_archive))][0]\n        return None\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:  # Randomly perturb some within clusters\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < self.local_search_prob:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    new_candidate = self.select_from_memory_archive()\n                    if new_candidate is not None:\n                        self.population[i] = new_candidate\n                    else:\n                        self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["0c46078b-6e8a-4f72-af79-9a56839cb1a5"], "operator": null, "metadata": {"aucs": [0.009276945423151606, 0.009265110736404791, 0.009275247578926171, 0.07875700810917363, 0.07863895049546799, 0.07873989613715626, 0.07118032969086496, 0.07108833612397136, 0.07116705195049988]}}
{"id": "61f60da2-62d7-4695-82d9-352f7389f75e", "fitness": 0.05446693875378609, "name": "AdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Improved Adaptive Dynamic Differential Evolution by enhancing clustering and local search for better exploration-exploitation trade-off.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.2 * self.budget\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.2 * (np.random.rand(self.dim) - 0.5)  # Increase local search strength\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def select_from_memory_archive(self):\n        if self.memory_archive:\n            return min(self.memory_archive, key=lambda x: x[1])[0]\n        return None\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(3, self.population_size // 10))  # Increase minimum clusters\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:  # Randomly perturb some within clusters\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05447 with standard deviation 0.03209.", "error": "", "parent_ids": ["0c46078b-6e8a-4f72-af79-9a56839cb1a5"], "operator": null, "metadata": {"aucs": [0.00984778195192848, 0.009278436479591812, 0.009261988809603272, 0.08580633648955394, 0.07877222229908187, 0.07860762813110422, 0.07637189186948745, 0.07119214891773251, 0.07106401383599126]}}
{"id": "2907da50-defb-4683-9874-e8c09455c78e", "fitness": 0.05304244823978139, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Enhanced Adaptive Dynamic Differential Evolution with Hierarchical Clustering and Opposition-Based Learning for Improved Exploration in Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.2 * self.budget\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n        self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        self.memory_archive.append((candidate, candidate_fitness))\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n\n    def opposition_based_learning(self, candidate, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        opposite = lb + ub - candidate\n        return np.clip(opposite, lb, ub)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                if np.random.rand() < 0.2:  # Apply opposition-based learning randomly\n                    opposite = self.opposition_based_learning(self.population[i], func.bounds)\n                    opposite_fitness = func(opposite)\n                    evaluations += 1\n\n                    if opposite_fitness < self.fitness[i]:\n                        self.population[i] = opposite\n                        self.fitness[i] = opposite_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["0c46078b-6e8a-4f72-af79-9a56839cb1a5"], "operator": null, "metadata": {"aucs": [0.009266607826056816, 0.00927712887749732, 0.009273273769380475, 0.07865169688877427, 0.07875986954717529, 0.07872052252923367, 0.07109864722246395, 0.0711823908842859, 0.07115189661316479]}}
{"id": "1c4e66f5-b403-4f3e-af30-44b581183a79", "fitness": 0.14677134387282567, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Enhanced Adaptive Dynamic Differential Evolution integrating Dynamic Clustering and Memory-based Parameter Tuning for robust Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14677 with standard deviation 0.25068.", "error": "", "parent_ids": ["0c46078b-6e8a-4f72-af79-9a56839cb1a5"], "operator": null, "metadata": {"aucs": [0.009417152789579553, 0.012295867791292103, 0.00979040515794638, 0.08024281219437246, 0.8472149845303032, 0.0845132141817726, 0.07232579023087682, 0.12959864146339517, 0.07554322651589274]}}
{"id": "51a14981-75ff-4ec6-8d48-c88a9406e6df", "fitness": 0.053602978001296396, "name": "AdvancedDynamicDifferentialEvolution", "description": "Incorporate dynamic learning rate tuning and adaptive mutation strategies to enhance convergence in black box optimization tasks.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdvancedDynamicDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_bounds = (0.5, 0.9)\n        self.CR_bounds = (0.3, 0.9)\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n        self.learning_rate = 0.05\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        F = np.random.uniform(*self.F_bounds)\n        mutant = self.population[a] + F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(*self.CR_bounds)\n        crossover_mask = np.random.rand(self.dim) < CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = self.learning_rate * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.learning_rate = 0.1 * np.cos(np.pi * evaluation_ratio)\n        if self.parameter_memory:\n            recent_params = self.parameter_memory[-5:]\n            self.F_bounds = (max(0.5, np.mean([p['F'] for p in recent_params]) - 0.1), \n                             min(0.9, np.mean([p['F'] for p in recent_params]) + 0.1))\n            self.CR_bounds = (max(0.3, np.mean([p['CR'] for p in recent_params]) - 0.1), \n                              min(0.9, np.mean([p['CR'] for p in recent_params]) + 0.1))\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], self.F_bounds[0], self.CR_bounds[0])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 44, "feedback": "The algorithm AdvancedDynamicDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05360 with standard deviation 0.03146.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009275036685420068, 0.009275670279219717, 0.009520622490354125, 0.07873752921937238, 0.07874561421302917, 0.08135667424229098, 0.07116525480367175, 0.07117121907386847, 0.07317918100444087]}}
{"id": "bf705c92-e2fb-4f87-9651-7006f29ee5ec", "fitness": -Infinity, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Enhanced Adaptive Dynamic Differential Evolution with Clustered Local Search Integration for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)  # line 1 modified\n            self.CR = 0.9 - 0.4 * evaluation_ratio  # line 2 modified\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // (1 + evaluations // self.clustering_interval)  # line 3 modified\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.2:  # line 4 modified\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n                self.population[i] = np.clip(self.population[i], func.bounds.lb, func.bounds.ub)  # line 5 modified\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 45, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {}}
{"id": "181d2b83-7f3e-4750-bf34-f87c01cb77d3", "fitness": 0.05305835620850768, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Fine-tuned crossover probability dynamically adjusted with evaluation ratio for improved diversity.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + evaluation_ratio * 0.1  # Adjusted line\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05306 with standard deviation 0.03111.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009246451849064918, 0.009277979162967687, 0.00929957244665347, 0.07844906919251982, 0.07876785530955288, 0.07899006710632817, 0.07094099320203096, 0.07118870330109728, 0.07136451430635393]}}
{"id": "fa34a3dc-bf72-4cf1-9730-0d46ae9adc16", "fitness": -Infinity, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Optimized Enhanced Adaptive Dynamic Differential Evolution leveraging Adaptive Mutation Scaling for improved convergence in Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, func.bounds.lb, func.bounds.ub)  # Ensure mutant is within bounds\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 47, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {}}
{"id": "3d6b1053-4250-4cfe-9ada-6b91f35c3732", "fitness": 0.14673962499100723, "name": "EnhancedHybridDifferentialEvolution", "description": "Enhanced Hybrid Differential Evolution with Adaptive Memory and Local Search for Improved Black Box Optimization Performance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def balance_exploration_exploitation(self, evaluations):\n        if evaluations < self.budget * 0.3:\n            self.CR = 0.9\n        elif evaluations < self.budget * 0.6:\n            self.CR = 0.6\n        else:\n            self.CR = 0.3\n        \n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n            self.balance_exploration_exploitation(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14674 with standard deviation 0.25068.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009438524925904912, 0.012295867791292103, 0.009758612124242894, 0.08047810194343075, 0.8472149845303032, 0.08411593209502399, 0.07250496345494706, 0.12959864146339517, 0.0752509965905247]}}
{"id": "f5020820-6b13-4d3d-9633-10e97e907566", "fitness": 0.14631422091465854, "name": "HybridAdaptiveDifferentialEvolution", "description": "Hybrid Adaptive Differential Evolution with Dynamic Parameter Control and Cluster-Based Diversity Enhancement for Efficient Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass HybridAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n        self.adaptive_F_CR = True\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.adaptive_F_CR:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 49, "feedback": "The algorithm HybridAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14631 with standard deviation 0.25081.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009266288405022749, 0.012295867791292103, 0.009739618511160453, 0.07865051847567772, 0.8472149845303032, 0.08388496482999785, 0.07109738328529813, 0.12959864146339517, 0.07507972093977966]}}
{"id": "4503e39b-a281-4820-be34-2e661d7897e5", "fitness": 0.05302451345442041, "name": "AdvancedMultiPopulationAdaptiveDifferentialEvolution", "description": "An advanced multi-population approach combining Adaptive Differential Evolution with Dynamic Clustering and Memory-based Parameter Adaptation for scalable black box optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdvancedMultiPopulationAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_base = 0.8\n        self.CR_base = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.num_subpopulations = 3\n        self.subpopulations = [None] * self.num_subpopulations\n        self.sub_fitness = [None] * self.num_subpopulations\n        self.memory_archive = []\n        self.stagnation_counters = [np.zeros(self.initial_population_size) for _ in range(self.num_subpopulations)]\n        self.max_stagnation = 10\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        for i in range(self.num_subpopulations):\n            pop_size = self.initial_population_size // self.num_subpopulations\n            self.subpopulations[i] = np.random.uniform(lb, ub, (pop_size, self.dim))\n            self.sub_fitness[i] = np.full(pop_size, np.inf)\n\n    def mutate(self, sub_idx, idx):\n        pop_size = len(self.subpopulations[sub_idx])\n        idxs = [i for i in range(pop_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.subpopulations[sub_idx][a] + self.F_base * (self.subpopulations[sub_idx][b] - self.subpopulations[sub_idx][c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR_base\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F_base = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR_base = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F_base = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR_base = 0.9 - 0.5 * evaluation_ratio\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.initial_population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, sub_idx):\n        kmeans = KMeans(n_clusters=max(2, len(self.subpopulations[sub_idx]) // 10))\n        kmeans.fit(self.subpopulations[sub_idx])\n        for i in range(len(self.subpopulations[sub_idx])):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.subpopulations[sub_idx][i] += 0.05 * (cluster_center - self.subpopulations[sub_idx][i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n\n            for sub_idx in range(self.num_subpopulations):\n                if evaluations % self.clustering_interval == 0:\n                    self.apply_clustering(sub_idx)\n\n                for i in range(len(self.subpopulations[sub_idx])):\n                    if evaluations >= self.budget:\n                        break\n\n                    f = self.F_base + 0.1 * (np.random.rand() - 0.5)\n                    cr = self.CR_base + 0.1 * (np.random.rand() - 0.5)\n\n                    mutant = self.mutate(sub_idx, i)\n                    trial = self.crossover(self.subpopulations[sub_idx][i], mutant)\n                    trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                    trial_fitness = func(trial)\n                    evaluations += 1\n\n                    if trial_fitness < self.sub_fitness[sub_idx][i]:\n                        self.subpopulations[sub_idx][i] = trial\n                        self.sub_fitness[sub_idx][i] = trial_fitness\n                        self.stagnation_counters[sub_idx][i] = 0\n                    else:\n                        self.stagnation_counters[sub_idx][i] += 1\n\n                    self.update_memory_archive(self.subpopulations[sub_idx][i], self.sub_fitness[sub_idx][i], f, cr)\n\n                    if self.stagnation_counters[sub_idx][i] >= self.max_stagnation:\n                        lb, ub = func.bounds.lb, func.bounds.ub\n                        self.subpopulations[sub_idx][i] = np.random.uniform(lb, ub, self.dim)\n                        self.sub_fitness[sub_idx][i] = func(self.subpopulations[sub_idx][i])\n                        evaluations += 1\n                        self.stagnation_counters[sub_idx][i] = 0\n\n        best_overall_idx = np.argmin([np.min(fitness) for fitness in self.sub_fitness])\n        best_idx_in_subpop = np.argmin(self.sub_fitness[best_overall_idx])\n        return self.subpopulations[best_overall_idx][best_idx_in_subpop]", "configspace": "", "generation": 50, "feedback": "The algorithm AdvancedMultiPopulationAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009243999279181403, 0.009276933103914864, 0.009287038087110955, 0.07842581919498726, 0.07875696671083787, 0.07886394890472237, 0.07092256660679408, 0.07118030316241897, 0.07126304603981592]}}
{"id": "fd2fe0ac-8f2c-4c95-950d-a9dc644c3542", "fitness": 0.14661567507561873, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Enhanced Adaptive Dynamic Differential Evolution with improved clustering influence for Black Box Optimization.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.2:  # Changed from 0.1 to 0.2 (enhanced clustering influence)\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14662 with standard deviation 0.25072.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009344082738408033, 0.012295928554512559, 0.009792895688303993, 0.07945843374990591, 0.8472156037590907, 0.08454436087829609, 0.07172448657549413, 0.12959915840252922, 0.07556612533402773]}}
{"id": "1aba9a10-3d91-44f1-8bc3-944671008132", "fitness": 0.1465891068155628, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Introduced a minor adaptive tweak to the mutation factor to slightly improve exploration capabilities.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (1 - evaluation_ratio) * (np.random.rand() - 0.5)  # Modified line\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14659 with standard deviation 0.25073.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009334855455796043, 0.012295867791292103, 0.00979040515794638, 0.07936117758816152, 0.8472149845303032, 0.0845132141817726, 0.0716495886555053, 0.12959864146339517, 0.07554322651589274]}}
{"id": "0aedb6ed-d724-4ae3-ba1d-0eb245fba1a8", "fitness": 0.14677134387282567, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Improved Dynamic Parameter Adjustment by Modifying Sinusoidal Function Coefficients for Enhanced Adaptability.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.4 * np.sin(1.5 * np.pi * evaluation_ratio)  # Modified line\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % self.clustering_interval == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14677 with standard deviation 0.25068.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009417152789579553, 0.012295867791292103, 0.00979040515794638, 0.08024281219437246, 0.8472149845303032, 0.0845132141817726, 0.07232579023087682, 0.12959864146339517, 0.07554322651589274]}}
{"id": "4db67aee-adca-41ea-892f-341ec4ef76b5", "fitness": 0.14698406879933174, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Introduced adaptive clustering frequency based on evaluation ratio to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % int(self.clustering_interval * (1 - 0.5 * evaluation_ratio)) == 0:  # Updated line\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14698 with standard deviation 0.25062.", "error": "", "parent_ids": ["1c4e66f5-b403-4f3e-af30-44b581183a79"], "operator": null, "metadata": {"aucs": [0.009417152789579553, 0.012295867791292103, 0.009867974698908988, 0.08024281219437246, 0.8472149845303032, 0.0855854001207681, 0.07232579023087682, 0.12959864146339517, 0.07630799537448951]}}
{"id": "ae213430-2485-4732-ae86-bd43f01ca61f", "fitness": 0.1461198882528409, "name": "EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering", "description": "Enhanced differential candidate evaluation with smarter local search probability adjustment.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_interval = 0.1 * self.budget\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self):\n        kmeans = KMeans(n_clusters=max(2, self.population_size // 10))\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluations % int(self.clustering_interval * (1 - 0.5 * evaluation_ratio)) == 0:\n                self.apply_clustering()\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3 * (1-evaluation_ratio):  # Updated line\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveDynamicDifferentialEvolutionWithClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14612 with standard deviation 0.25086.", "error": "", "parent_ids": ["4db67aee-adca-41ea-892f-341ec4ef76b5"], "operator": null, "metadata": {"aucs": [0.009266843441743444, 0.012295867791292103, 0.009658748040295873, 0.07865618512435935, 0.8472149845303032, 0.08292357236377801, 0.07110177053621924, 0.12959864146339517, 0.07436238098418158]}}
{"id": "bab8f4d9-8e82-4051-ab46-e565fb7fc03e", "fitness": 0.14698627604340656, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Introduced adaptive differential evolution with multi-phase clustering to balance exploration and exploitation dynamically.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14699 with standard deviation 0.25062.", "error": "", "parent_ids": ["4db67aee-adca-41ea-892f-341ec4ef76b5"], "operator": null, "metadata": {"aucs": [0.009418133172778176, 0.012295867791292103, 0.009867974698908988, 0.08025352384093953, 0.8472149845303032, 0.0855854001207681, 0.07233396339778453, 0.12959864146339517, 0.07630799537448951]}}
{"id": "75ee492d-28f5-4fc7-8b0c-c9dd3ad8b926", "fitness": 0.14608526239675504, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced differential evolution with dynamic crossover rate adaptation based on fitness improvements.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5) * (1 - self.fitness[i] / (np.min(self.fitness) + 1e-8))  # Modified line\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14609 with standard deviation 0.25087.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009250639348523992, 0.012295867791292103, 0.00965863643042797, 0.07849119181441555, 0.8472149845303032, 0.08292226933782476, 0.07097371951788045, 0.12959864146339517, 0.07436141133673213]}}
{"id": "79caccfe-e370-45eb-92fd-f2c9a2b68658", "fitness": 0.05306128950273978, "name": "EnhancedHierarchicalClusteringDifferentialEvolution", "description": "Introduced a hierarchical clustering strategy with dynamic feedback mechanisms to further enhance exploration-exploitation trade-off and maintain diversity.", "code": "import numpy as np\nfrom sklearn.cluster import AgglomerativeClustering\n\nclass EnhancedHierarchicalClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_hierarchical_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        clustering = AgglomerativeClustering(n_clusters=n_clusters)\n        labels = clustering.fit_predict(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_points = self.population[labels == labels[i]]\n                cluster_center = np.mean(cluster_points, axis=0)\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_hierarchical_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedHierarchicalClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05306 with standard deviation 0.03112.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009278537876471371, 0.00927506787352872, 0.009272386883570238, 0.07877325384880318, 0.07873821722359498, 0.07871090280465409, 0.0711929410590415, 0.0711657208059383, 0.07114457714905564]}}
{"id": "920fdcc1-87e4-4efa-a9b0-223c9e359240", "fitness": 0.05302869929172354, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced adaptive differential evolution by optimizing the mutation scaling factor for better convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        # Change: optimized the mutation scaling factor for better search adaptability.\n        mutant = self.population[a] + (0.9 * self.F) * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 59, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009265035624708373, 0.009275101873344571, 0.009270323193102614, 0.07863801144777693, 0.07873823896818077, 0.07868992386748008, 0.07108761527148577, 0.07116579567638237, 0.07112824770305037]}}
{"id": "b43bb406-724a-468e-8db0-ea85cf8e2897", "fitness": 0.05354863150979753, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Improved exploration by increasing perturbation strength in the local search strategy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.2 * (np.random.rand(self.dim) - 0.5) # Increased perturbation strength from 0.1 to 0.2\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05355 with standard deviation 0.03142.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009444843975615402, 0.009275250684865899, 0.00932508489287276, 0.08058575288449643, 0.07873975925673349, 0.07925348922238695, 0.07257870641035113, 0.07116697893830914, 0.07156781732254658]}}
{"id": "57a182b3-32cd-444f-8324-8d9d0e554b1b", "fitness": 0.0530175104404019, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced exploration by adjusting mutation factors based on clustering density, improving solution diversity.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n        self.F = 0.8 / max(1, n_clusters)  # Adjust mutation factor based on clustering density\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009262967166415836, 0.009275267297398582, 0.009266921662624994, 0.07861719713174475, 0.07873992915892658, 0.07865535465935902, 0.0710713912376808, 0.0711671161320494, 0.07110144951741715]}}
{"id": "b0f6a61e-6082-4405-8809-1a892ae0f7fe", "fitness": 0.053032753974292794, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced local search by adapting perturbation strength based on population diversity to improve exploration.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        population_std = np.std(self.population, axis=0)\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5) * population_std  # Change 1\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009266169117924106, 0.009274355978576065, 0.00927187601383539, 0.07864929945790966, 0.07873062552477417, 0.07870564838256688, 0.07109644071795573, 0.07115990525534488, 0.07114046531974827]}}
{"id": "32306f62-e6af-4985-a88a-248f1d4a4856", "fitness": 0.05299733725469798, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced exploitation via targeted local search adaptation to boost convergence in differential evolution.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5) * np.sign(np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 63, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05300 with standard deviation 0.03108.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009261004078860546, 0.009268940393649672, 0.009265636910279484, 0.07859668514124962, 0.07867586232546697, 0.07864307119631075, 0.07105561505508307, 0.07111739221794966, 0.07109182797343205]}}
{"id": "c3ac2b1f-8b40-4bf7-b244-b8748f46d00b", "fitness": 0.05290378688800845, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced adaptive differential evolution with dynamic parameter tuning and neighborhood-based search to improve convergence and robustness.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.6\n        self.clustering_phase_threshold = 0.4\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def adaptive_local_search(self, candidate, func):\n        neighborhood_size = 5\n        best_local = candidate.copy()\n        best_fitness = func(best_local)\n        for _ in range(neighborhood_size):\n            neighbor = self.local_search(candidate)\n            neighbor = np.clip(neighbor, func.bounds.lb, func.bounds.ub)\n            neighbor_fitness = func(neighbor)\n            if neighbor_fitness < best_fitness:\n                best_local, best_fitness = neighbor, neighbor_fitness\n        return best_local, best_fitness\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate, candidate_fitness = self.adaptive_local_search(self.population[i], func)\n                    evaluations += 5  # Each local search checks 5 neighbors\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05290 with standard deviation 0.03102.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009268640310787668, 0.009250947714776303, 0.009231639129779534, 0.07867469514834524, 0.07849297760847562, 0.07829901890720048, 0.0711161050075444, 0.07097548286393729, 0.07082457530122954]}}
{"id": "a6d5ef89-ae2d-4941-8a44-6fcfd194e802", "fitness": 0.1452491323501221, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced the parameter adaptation and clustering strategy to increase convergence speed and solution quality.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (8 * phase))  # Adjusted clustering frequency\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.06 * (cluster_center - self.population[i])  # Increased cluster influence\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14525 with standard deviation 0.25111.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.00926608387858252, 0.012295867791292103, 0.00927211031040498, 0.07864843754419437, 0.8472149845303032, 0.07870802247096609, 0.07109573162412586, 0.12959864146339517, 0.07114231153783479]}}
{"id": "b75339af-5bfd-4f2f-bdc0-0b21b1ea6147", "fitness": 0.05302497295818476, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced parameter adjustment and randomization to improve dynamic exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio) + 0.05 * np.random.rand()  # Slightly randomized\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 66, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05302 with standard deviation 0.03109.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009265911410680339, 0.009271061879273956, 0.00927160353156442, 0.07864741866531089, 0.07869801184773972, 0.07870306263267135, 0.07109483649437054, 0.07113440240089997, 0.07113844776115164]}}
{"id": "9bdf6a1b-51f6-4684-a559-214557c66ad9", "fitness": 0.05304578509647787, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced the mutation strategy by introducing diversity-aware scaling to improve exploration and convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        diversity_factor = np.std(self.population, axis=0) / (np.ptp(self.population, axis=0) + 1e-8)\n        adaptive_F = self.F * (1 + np.mean(diversity_factor))  # Add diversity-aware scaling\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 67, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05305 with standard deviation 0.03111.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009269588329578138, 0.009274691746691377, 0.009274321873449787, 0.07868348679374482, 0.07873405040611825, 0.07873053810943842, 0.07112306505114874, 0.07116254721408444, 0.07115977634404691]}}
{"id": "7dff6052-340a-46df-a279-2289d3e99162", "fitness": 0.053014878071756893, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Enhanced adaptive differential evolution with dynamic scaling of mutation factor and self-adaptive crossover rates to improve search efficiency and convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.8  # Base crossover rate\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.3\n        self.clustering_phase_threshold = 0.5\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = self.F_base + 0.2 * np.sin(np.pi * evaluation_ratio)\n            self.CR = self.CR_base - 0.4 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = max(4, self.initial_population_size // 2)\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (5 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (5 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05301 with standard deviation 0.03109.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.00927068878608961, 0.009262868484252507, 0.009269934906758537, 0.07869564776659987, 0.07861872026495187, 0.07868618765123503, 0.07113234473605257, 0.07107216891012569, 0.07112534113974633]}}
{"id": "4a322ced-1c47-4e63-8cef-d23c3c968006", "fitness": 0.14669631405148095, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Dynamic Subpopulation Management to improve convergence and diversity.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def dynamic_subpopulation_exchange(self):\n        subpop_size = self.population_size // 3\n        if len(self.memory_archive) >= subpop_size:\n            indices = np.random.choice(len(self.memory_archive), subpop_size, replace=False)\n            selected_archive = [self.memory_archive[i][0] for i in indices]\n            self.population[:subpop_size] = selected_archive\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n            if evaluation_ratio > 0.5:\n                self.dynamic_subpopulation_exchange()\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14670 with standard deviation 0.25070.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009417152789579553, 0.012295867791292103, 0.00976067853612006, 0.08024281219437246, 0.8472149845303032, 0.08414120256999069, 0.07232579023087682, 0.12959864146339517, 0.07526969635739833]}}
{"id": "614f4d83-ff8b-4f2e-98c7-1d910796b3c0", "fitness": 0.05303222054202164, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced exploitation by adjusting perturbation strength in local search for better convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)  # Adjusted from 0.1\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 70, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009266080188433556, 0.009274196501811383, 0.009271873234556693, 0.07864839332314533, 0.07872899996123739, 0.07870561896872441, 0.0710957370274603, 0.07115864298508401, 0.07114044268774167]}}
{"id": "ca0fdb4d-e740-469a-9f3b-4dfe074122e0", "fitness": 0.14698627604340656, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Leverages adaptive differential evolution with multi-phase clustering and a dynamic population strategy for enhanced adaptability and convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14699 with standard deviation 0.25062.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009418133172778176, 0.012295867791292103, 0.009867974698908988, 0.08025352384093953, 0.8472149845303032, 0.0855854001207681, 0.07233396339778453, 0.12959864146339517, 0.07630799537448951]}}
{"id": "954e0d4f-40be-46bd-b703-00bcdc8d430e", "fitness": 0.146699292089058, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Dynamic Clustering and Stagnation-driven Mutation to better explore solution space.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 5\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n        self.dynamic_mutation_factor = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def stagnation_mutation(self, idx):\n        if self.stagnation_counter[idx] >= self.max_stagnation:\n            self.population[idx] += self.dynamic_mutation_factor * np.random.standard_normal(self.dim)\n            self.stagnation_counter[idx] = 0\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n                    self.stagnation_mutation(i)\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14670 with standard deviation 0.25070.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009417152789579553, 0.012295867791292103, 0.009758612124242894, 0.08024281219437246, 0.8472149845303032, 0.08411593209502399, 0.07239862922278761, 0.12959864146339517, 0.0752509965905247]}}
{"id": "7abeb7de-1f51-4018-96d3-ccec440ae7d1", "fitness": 0.053036322334280336, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Enhanced adaptive differential evolution with multi-phase clustering by incorporating adaptive control parameters and elite preservation for improved exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_base = 0.5\n        self.CR_base = 0.7\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.elite_size = max(1, self.population_size // 10)\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = self.F_base + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = self.CR_base - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness):\n        if len(self.memory_archive) < self.population_size:\n            self.memory_archive.append((candidate, candidate_fitness))\n        else:\n            worst_idx = np.argmax([fit for _, fit in self.memory_archive])\n            if candidate_fitness < self.memory_archive[worst_idx][1]:\n                self.memory_archive[worst_idx] = (candidate, candidate_fitness)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def preserve_elites(self):\n        elite_indices = np.argsort(self.fitness)[:self.elite_size]\n        for idx in elite_indices:\n            self.population[idx] = self.memory_archive[idx % len(self.memory_archive)][0]\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i])\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n            self.preserve_elites()\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.00926557019155727, 0.009275633618846757, 0.009272880966325059, 0.07864302292284508, 0.0787438389831534, 0.07871584575392077, 0.07109160907683876, 0.07117010103206312, 0.07114839846297283]}}
{"id": "bccdf753-421e-4312-b7bc-bd6adfc31f84", "fitness": 0.053041312191055824, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced local search and mutation strategy to improve convergence speed and solution accuracy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c] + 0.1 * (self.population[a] - self.population[idx]))\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 74, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009266244796629297, 0.009276237360786754, 0.00927396214634002, 0.07865002681404432, 0.07874981544798942, 0.07872683461752505, 0.07109699477520837, 0.07117477475029976, 0.07115691901067944]}}
{"id": "9bc08ea7-b1b8-4a80-9eb3-9fb64f7271a3", "fitness": 0.14529921036100507, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced clustering strategy by increasing cluster center attraction and optimizing mutation factor adjustment.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(1.2 * np.pi * evaluation_ratio)  # Adjusted mutation factor\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.1 * (cluster_center - self.population[i])  # Increased attraction to center\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 75, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14530 with standard deviation 0.25110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.00928945149565974, 0.012295867791292103, 0.009272007348525624, 0.07888923213623533, 0.8472149845303032, 0.07870697260341775, 0.07128424047364301, 0.12959864146339517, 0.07114149540657388]}}
{"id": "75d73179-2e8a-4fdf-8d34-744b9023f763", "fitness": 0.053028819865314304, "name": "HistoricalAdaptiveClusteringDifferentialEvolution", "description": "Incorporate historical-based parameter adaptation and hybrid clustering to enhance convergence speed and solution accuracy.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass HistoricalAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n        self.history_F = []\n        self.history_CR = []\n    \n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.history_F:\n            self.F = np.mean(self.history_F[-5:]) + 0.1 * np.sin(evaluation_ratio * np.pi)\n            self.CR = np.mean(self.history_CR[-5:]) + 0.05 * np.cos(evaluation_ratio * np.pi)\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        self.history_F.append(f)\n        self.history_CR.append(cr)\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters, n_init='auto')\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.2:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.1 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 76, "feedback": "The algorithm HistoricalAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009274792411902322, 0.009271870410456962, 0.009263681288739334, 0.07873555009844968, 0.07870775248115891, 0.07862373107985021, 0.07116363945707316, 0.0711417204342919, 0.07107664112590628]}}
{"id": "8fa31263-817a-4b59-9766-f2b79665124c", "fitness": 0.0530466694951849, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced mutation strategy and local search intensity to improve exploration and convergence balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 8  # Changed from 10 to 8\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        perturbation = 0.05 * np.random.normal(size=self.dim)  # Added perturbation\n        return mutant + perturbation\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.15 * (np.random.rand(self.dim) - 0.5)  # Changed from 0.1 to 0.15\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05305 with standard deviation 0.03111.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009264637542517273, 0.009277017291285827, 0.009277074011282416, 0.07863662344636069, 0.0787577892847271, 0.07875841891665591, 0.07108608492579682, 0.0711809555969023, 0.07118142444113573]}}
{"id": "0e3961c1-ca93-41b0-80e0-401f96bdc3b4", "fitness": 0.05302821880121061, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Introduced hybrid local search with self-adaptive parameters and archive-based perturbation for enhanced exploration and exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 7  # Changed from 10 to 7\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n        self.archive_perturbation_strength = 0.05  # New parameter\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.09 * (np.random.rand(self.dim) - 0.5)  # Adjusted strength\n        return candidate + perturbation_strength\n\n    def apply_archive_perturbation(self, candidate):\n        if self.memory_archive:\n            archive_sample = self.memory_archive[np.random.randint(len(self.memory_archive))][0]\n            perturbation = self.archive_perturbation_strength * (archive_sample - candidate)\n            return candidate + perturbation\n        return candidate\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = self.apply_archive_perturbation(candidate)\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 78, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009259316643107085, 0.009276987484651888, 0.009273931737686758, 0.07857979225341993, 0.07875748203964417, 0.07872659626743717, 0.07104243473199512, 0.07118071570060391, 0.07115671235234944]}}
{"id": "0033e87a-8309-4c13-a0b6-8564589900e4", "fitness": 0.14698627604340656, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Minor enhancement by adjusting the mutation scaling factor to improve exploration, maintaining code change within the limit.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.85  # Slight change in mutation scaling factor from 0.8 for better exploration\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 79, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14699 with standard deviation 0.25062.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009418133172778176, 0.012295867791292103, 0.009867974698908988, 0.08025352384093953, 0.8472149845303032, 0.0855854001207681, 0.07233396339778453, 0.12959864146339517, 0.07630799537448951]}}
{"id": "59404a13-4066-48fc-bbac-9da842072cce", "fitness": 0.05304674579308428, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Enhanced the adaptive parameter adjustment using cosine function to refine exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.cos(np.pi * evaluation_ratio)  # Changed sine to cosine\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05305 with standard deviation 0.03111.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.00927176718154632, 0.009274678216096843, 0.009272630398503456, 0.07870535402760093, 0.07873391256058071, 0.07871336433698839, 0.07114008552803242, 0.07116244210247213, 0.0711464777859373]}}
{"id": "c4c68e5d-9624-44dc-b81f-a28bef2d9b6d", "fitness": 0.053032437309441786, "name": "EnhancedClusteringAdaptiveDifferentialEvolution", "description": "Enhanced clustering with a dynamic memory archive and adaptive step size for improved convergence in multi-phase differential evolution.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteringAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.memory_archive_size = 50\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.memory_archive_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters, n_init=5)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedClusteringAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009271306180617334, 0.009273264637269518, 0.00926783094180128, 0.07869959656047198, 0.0787194637012738, 0.0786647457317371, 0.07113578663425191, 0.07115125843229819, 0.07110868296525497]}}
{"id": "c316e3b5-a5a6-4457-a57a-24bc406344bf", "fitness": 0.053037871357625846, "name": "EnhancedClusteringHybridDifferentialEvolution", "description": "Enhanced adaptive differential evolution with hybrid clustering and differential mutation strategies to improve convergence speed and robustness.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedClusteringHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n        self.hybrid_factor = 0.5\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c, d = np.random.choice(idxs, 4, replace=False)\n        mutant = (self.population[a] + self.F * (self.population[b] - self.population[c]) +\n                  self.hybrid_factor * (self.population[d] - self.population[idx]))\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedClusteringHybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05304 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009273263931956266, 0.0092674532747542, 0.009274126665958282, 0.07872015994388581, 0.07866108500469149, 0.07872883310063883, 0.07115165536678647, 0.0711058629850918, 0.07115840194486944]}}
{"id": "b4a11c6d-279e-47ec-a969-9db39045acc2", "fitness": 0.05303110449593099, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Enhanced adaptive differential evolution with dynamic clustering and historical parameter tuning for improved convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.4  # Adjusted threshold for quicker resizing\n        self.clustering_phase_threshold = 0.25 # Earlier start for clustering\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.05 * (np.random.rand(self.dim) - 0.5)  # Reduced perturbation for finer tuning\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            recent_memory = self.parameter_memory[-10:]  # Increased memory window\n            self.F = np.clip(np.mean([p['F'] for p in recent_memory]), 0.5, 0.9)\n            self.CR = np.clip(np.mean([p['CR'] for p in recent_memory]), 0.1, 0.9)\n        else:\n            self.F = 0.5 + 0.4 * np.sin(np.pi * evaluation_ratio)  # Adjusted parameter variation\n            self.CR = 0.9 - 0.4 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.2:  # Increased chance for clustering adjustments\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.1 * (cluster_center - self.population[i])  # Strengthened clustering effect\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05303 with standard deviation 0.03110.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.0092658600773603, 0.009273976143797658, 0.009271785444559977, 0.07864618314658112, 0.07872674868120655, 0.07870472199717105, 0.07109400075966488, 0.07115690072790448, 0.07113976348513296]}}
{"id": "727b76d5-09ec-43bc-b56f-cd5bb2fbadff", "fitness": 0.14697186073422255, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced version with adaptive multi-parameter tuning and dynamic subgroup integration for diversified exploration and intensified exploitation.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F_mean = 0.5\n        self.CR_mean = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F_mean * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR_mean\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if len(self.parameter_memory) >= 5:\n            self.F_mean = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR_mean = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F_mean = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR_mean = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def diversify_and_intensify(self, func, candidate, candidate_fitness):\n        if np.random.rand() < 0.3:\n            candidate = self.local_search(candidate)\n            candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n            new_fitness = func(candidate)\n            return candidate, new_fitness if new_fitness < candidate_fitness else candidate_fitness\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F_mean + 0.1 * (np.random.rand() - 0.5)\n                cr = self.CR_mean + 0.1 * (np.random.rand() - 0.5)\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i], self.fitness[i] = trial, trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                candidate, candidate_fitness = self.diversify_and_intensify(func, self.population[i], self.fitness[i])\n                if candidate_fitness < self.fitness[i]:\n                    self.population[i], self.fitness[i] = candidate, candidate_fitness\n                    self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14697 with standard deviation 0.25062.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009417152789579553, 0.012295867791292103, 0.009862694857185383, 0.08024281219437246, 0.8472149845303032, 0.08552626094826588, 0.07232579023087682, 0.12959864146339517, 0.07626254180273251]}}
{"id": "54d58dab-b65b-4517-afaa-285b5b426bf8", "fitness": 0.14698643529128116, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Minor adjustment to exploration by increasing mutation factor variability for enhanced search space traversal.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)  # Increased variability in mutation factor\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14699 with standard deviation 0.25062.", "error": "", "parent_ids": ["bab8f4d9-8e82-4051-ab46-e565fb7fc03e"], "operator": null, "metadata": {"aucs": [0.009423880217653391, 0.012295867791292103, 0.009861826241019056, 0.08034642494561084, 0.8472149845303032, 0.08549383182782289, 0.072398297749106, 0.12959864146339517, 0.07624416285532798]}}
{"id": "173998a6-3393-4086-a83b-037da33bf2e1", "fitness": 0.14698643529128116, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Introduce adaptive clustering with diversity preservation and adaptive parameter scaling for robust exploration-exploitation balance.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n        self.diversity_threshold = 0.1\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def check_diversity(self):\n        centroid = np.mean(self.population, axis=0)\n        diversity = np.mean(np.linalg.norm(self.population - centroid, axis=1))\n        return diversity\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n            if self.check_diversity() < self.diversity_threshold:\n                lb, ub = func.bounds.lb, func.bounds.ub\n                self.population[i] = np.random.uniform(lb, ub, self.dim)\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.1 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14699 with standard deviation 0.25062.", "error": "", "parent_ids": ["54d58dab-b65b-4517-afaa-285b5b426bf8"], "operator": null, "metadata": {"aucs": [0.009423880217653391, 0.012295867791292103, 0.009861826241019056, 0.08034642494561084, 0.8472149845303032, 0.08549383182782289, 0.072398297749106, 0.12959864146339517, 0.07624416285532798]}}
{"id": "fd85efc5-da81-41b2-a265-b0344e5783ed", "fitness": 0.14699667750788134, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Fine-tune the crossover rate variability for improved exploration without impacting existing diversity mechanisms.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)  # Increased variability in mutation factor\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)  # Reduced variability in crossover rate\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 87, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14700 with standard deviation 0.25061.", "error": "", "parent_ids": ["54d58dab-b65b-4517-afaa-285b5b426bf8"], "operator": null, "metadata": {"aucs": [0.009423880217653391, 0.012295867791292103, 0.009865274350300268, 0.08034642494561084, 0.8472149845303032, 0.08554626508823748, 0.072398297749106, 0.12959864146339517, 0.07628046143503353]}}
{"id": "0a51b4f9-00c6-4ed9-b4d5-123d288b14eb", "fitness": 0.1466673729388029, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Increase the mutation factor variability to enhance exploration in the optimization process.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.3 * (np.random.rand() - 0.5)  # Increased variability in mutation factor\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)  # Reduced variability in crossover rate\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14667 with standard deviation 0.25071.", "error": "", "parent_ids": ["fd85efc5-da81-41b2-a265-b0344e5783ed"], "operator": null, "metadata": {"aucs": [0.009266196563006535, 0.012295867791292103, 0.009872548917527313, 0.0786495805987758, 0.8472149845303032, 0.08565551074285949, 0.07109665534678355, 0.12959864146339517, 0.07635637049528243]}}
{"id": "92fe97ad-1dae-4ed9-b6bb-974be6978ce8", "fitness": -Infinity, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Introduce a dynamic crossover rate variability based on fitness improvements to enhance adaptability.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            # Change: Adjust CR variability based on recent improvement\n            recent_improvement = np.mean([max(0, self.fitness[i] - self.memory_archive[-1][1]) for i in range(len(self.memory_archive))])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]]) + 0.1 * recent_improvement\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)  # Increased variability in mutation factor\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)  # Reduced variability in crossover rate\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 89, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_ids": ["fd85efc5-da81-41b2-a265-b0344e5783ed"], "operator": null, "metadata": {}}
{"id": "5d7b80ee-510c-4a0d-acde-f9df18f208d4", "fitness": 0.04820976592153982, "name": "AdaptiveMultiPhaseClusteringDifferentialEvolution", "description": "Introduce adaptive mutation scaling based on the fitness variance to achieve improved convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdaptiveMultiPhaseClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Changed line: Adaptive mutation scaling based on fitness variance\n                f = self.F + 0.15 * (np.std(self.fitness) / np.mean(self.fitness))\n\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)  \n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptiveMultiPhaseClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04821 with standard deviation 0.03122.", "error": "", "parent_ids": ["fd85efc5-da81-41b2-a265-b0344e5783ed"], "operator": null, "metadata": {"aucs": [0.004226297226436304, 0.00429948165693983, 0.004319855783827098, 0.07339969331356144, 0.07413859870876038, 0.07434824477243807, 0.06594694681926261, 0.06652134940785093, 0.06668742560478169]}}
{"id": "cb530c08-c5b6-466c-9f53-ffe185cd60fd", "fitness": 0.052981453981973924, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Enhance stochastic diversity with adaptive clustering and parameter variability modulation based on dynamic phases.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (5 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.05:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.1 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05298 with standard deviation 0.03107.", "error": "", "parent_ids": ["fd85efc5-da81-41b2-a265-b0344e5783ed"], "operator": null, "metadata": {"aucs": [0.009271018758821636, 0.009248456056487941, 0.009268011906096052, 0.07869901217460384, 0.07847438095364523, 0.07866707030278841, 0.07113495218582755, 0.07095981421956654, 0.07111036927992809]}}
{"id": "52ac62a5-f1a6-4f55-ab02-acb83f204fca", "fitness": 0.05306993603915836, "name": "EnhancedAdaptiveClusteringDE", "description": "Enhance exploration by incorporating adaptive mutation scaling based on population diversity and dynamically shifting search focus through iterative clustering variations.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        diversity_factor = np.std(self.population, axis=0).mean()\n        adaptive_F = self.F * (1 + 0.1 * diversity_factor)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        if self.parameter_memory:\n            self.F = np.mean([p['F'] for p in self.parameter_memory[-5:]])\n            self.CR = np.mean([p['CR'] for p in self.parameter_memory[-5:]])\n        else:\n            self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio)\n            self.CR = 0.9 - 0.5 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.15:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            if evaluation_ratio < self.clustering_phase_threshold:\n                phase = 1\n            else:\n                phase = 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveClusteringDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05307 with standard deviation 0.03112.", "error": "", "parent_ids": ["fd85efc5-da81-41b2-a265-b0344e5783ed"], "operator": null, "metadata": {"aucs": [0.009276600742564756, 0.009277084415623915, 0.00927635154523887, 0.07875410258670812, 0.0787584532645138, 0.07875143176039301, 0.07117798526578056, 0.07118146727919106, 0.07117594749241118]}}
{"id": "43dbba15-084a-42fc-9762-c29dfd2ef193", "fitness": 0.15126099054377196, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Introduce nonlinear dynamic parameter adaptation and adaptive clustering phases to enhance diversity and convergence speed.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15126 with standard deviation 0.24953.", "error": "", "parent_ids": ["fd85efc5-da81-41b2-a265-b0344e5783ed"], "operator": null, "metadata": {"aucs": [0.010864046564779684, 0.012297601226982202, 0.009757029593476907, 0.10410709359590031, 0.8472331374533285, 0.08409661063572826, 0.08814411601606764, 0.12961267849174973, 0.07523660131593446]}}
{"id": "c65650d4-4598-4b67-90e1-17a1f3ff6177", "fitness": 0.05478101703636208, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Refine mutation strategy to balance exploration-exploitation by adjusting F with a cosine function.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + (0.5 + 0.3 * np.cos(np.pi * (self.budget / self.budget**2))) * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05478 with standard deviation 0.03232.", "error": "", "parent_ids": ["43dbba15-084a-42fc-9762-c29dfd2ef193"], "operator": null, "metadata": {"aucs": [0.009271765215619898, 0.009994437548741075, 0.009272674561695116, 0.07870533418232228, 0.0872618528056257, 0.0787138148884432, 0.07114008080626422, 0.07752238138386136, 0.07114681193468586]}}
{"id": "f7808cd4-3736-4196-846d-ad713778f64a", "fitness": 0.05301393004779192, "name": "AdvancedAdaptiveClusteringDifferentialEvolution", "description": "Introduce adaptive multi-phase clustering with feedback loops and selective local search enhancement to boost convergence efficiency and solution quality.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass AdvancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.2:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.1 * (cluster_center - self.population[i])\n\n    def selective_local_search(self, candidate, candidate_fitness, phase):\n        if phase == 1 and candidate_fitness < np.median(self.fitness):\n            return self.local_search(candidate)\n        return candidate\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.4:\n                    candidate = self.selective_local_search(self.population[i], self.fitness[i], phase)\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 95, "feedback": "The algorithm AdvancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05301 with standard deviation 0.03109.", "error": "", "parent_ids": ["43dbba15-084a-42fc-9762-c29dfd2ef193"], "operator": null, "metadata": {"aucs": [0.009257112350015029, 0.00927496756779378, 0.00927144515151812, 0.07855708552584229, 0.07873686580904415, 0.07870125350051171, 0.07102483821711647, 0.07116472047720535, 0.07113708183108036]}}
{"id": "3fbb00eb-3251-4fa1-b877-c4ac8933ba1c", "fitness": 0.05897487065185279, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Introduce a dynamic perturbation strength in the local search to adaptively enhance exploration.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, evaluation_ratio):  # Added evaluation_ratio as a parameter\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5) * (1 - evaluation_ratio)  # Changed line\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i], evaluation_ratio)  # Updated call with evaluation_ratio\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05897 with standard deviation 0.03509.", "error": "", "parent_ids": ["43dbba15-084a-42fc-9762-c29dfd2ef193"], "operator": null, "metadata": {"aucs": [0.009834523434508746, 0.01049818472365427, 0.009757039672961598, 0.0851892333495603, 0.09659261485305126, 0.08409673365352943, 0.07601646469210654, 0.08355225800621535, 0.07523678348108764]}}
{"id": "0b6f751a-94b3-44cb-ab14-e370ae219f0b", "fitness": 0.05431365827751725, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Introduce a memory-guided mutation strategy to utilize historical parameter settings for enhanced convergence.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        if self.parameter_memory:  # New line: Memory-guided mutation strategy\n            f, cr = self.parameter_memory[np.random.randint(len(self.parameter_memory))].values()\n        else:\n            f = self.F\n        mutant = self.population[a] + f * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.3:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05431 with standard deviation 0.03196.", "error": "", "parent_ids": ["43dbba15-084a-42fc-9762-c29dfd2ef193"], "operator": null, "metadata": {"aucs": [0.009262914172965653, 0.009277784087465601, 0.009821082716606977, 0.078616368529844, 0.07876560940732769, 0.08496127246314766, 0.07107083767451916, 0.07118701745145029, 0.07586003799432828]}}
{"id": "62383443-aeda-49ff-82f1-9946eb74d29b", "fitness": 0.15150410517908866, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Slightly increase the probability of local search to enhance exploitation capabilities.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.35:  # Increased probability for local search\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15150 with standard deviation 0.24953.", "error": "", "parent_ids": ["43dbba15-084a-42fc-9762-c29dfd2ef193"], "operator": null, "metadata": {"aucs": [0.010948536851553836, 0.012305924408067326, 0.009658622401349293, 0.10680201860018212, 0.8473377689703214, 0.0829221055623206, 0.08951130999400714, 0.12968936307039958, 0.0743612967535967]}}
{"id": "d205bedc-129d-4187-a958-5b4fd2d9537c", "fitness": 0.05305808412789349, "name": "EnhancedAdaptiveClusteringDifferentialEvolution", "description": "Introduce inertia weighting and adaptive mutation to balance exploration and exploitation in EnhancedAdaptiveClusteringDifferentialEvolution.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAdaptiveClusteringDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.inertia_weight = 0.5\n        self.initial_population_size = 10 * self.dim\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.fitness = None\n        self.memory_archive = []\n        self.stagnation_counter = np.zeros(self.initial_population_size)\n        self.max_stagnation = 10\n        self.dynamic_resizing_threshold = 0.5\n        self.clustering_phase_threshold = 0.3\n        self.parameter_memory = []\n\n    def initialize(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, np.inf)\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        adaptive_mutation = np.random.uniform(-0.1, 0.1, self.dim) * self.inertia_weight\n        return mutant + adaptive_mutation\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate):\n        perturbation_strength = 0.1 * (np.random.rand(self.dim) - 0.5)\n        return candidate + perturbation_strength\n\n    def adjust_parameters(self, evaluation_ratio):\n        self.F = 0.5 + 0.3 * np.sin(np.pi * evaluation_ratio**2)\n        self.CR = 0.9 - 0.5 * (evaluation_ratio**2)\n        self.inertia_weight = 0.9 - 0.4 * evaluation_ratio\n\n    def resize_population(self, evaluations):\n        if evaluations > self.budget * self.dynamic_resizing_threshold:\n            self.population_size = self.initial_population_size // 2\n            self.population = self.population[:self.population_size]\n            self.fitness = self.fitness[:self.population_size]\n            self.stagnation_counter = self.stagnation_counter[:self.population_size]\n\n    def update_memory_archive(self, candidate, candidate_fitness, f, cr):\n        self.memory_archive.append((candidate, candidate_fitness))\n        self.parameter_memory.append({'F': f, 'CR': cr})\n        if len(self.memory_archive) > self.population_size:\n            self.memory_archive.pop(0)\n            self.parameter_memory.pop(0)\n\n    def apply_clustering(self, phase):\n        n_clusters = max(2, self.population_size // (10 * phase))\n        kmeans = KMeans(n_clusters=n_clusters)\n        kmeans.fit(self.population)\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                cluster_center = kmeans.cluster_centers_[kmeans.labels_[i]]\n                self.population[i] += 0.05 * (cluster_center - self.population[i])\n\n    def __call__(self, func):\n        self.initialize(func.bounds)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            self.adjust_parameters(evaluation_ratio)\n            self.resize_population(evaluations)\n\n            phase = 1 if evaluation_ratio < self.clustering_phase_threshold else 2\n\n            if evaluations % int((1 - 0.5 * evaluation_ratio**2) * self.budget / (10 * phase)) == 0:\n                self.apply_clustering(phase)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                f = self.F + 0.15 * (np.random.rand() - 0.5)\n                cr = self.CR + 0.05 * (np.random.rand() - 0.5)\n\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, func.bounds.lb, func.bounds.ub)\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.stagnation_counter[i] = 0\n                else:\n                    self.stagnation_counter[i] += 1\n\n                if np.random.rand() < 0.35:\n                    candidate = self.local_search(self.population[i])\n                    candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n\n                    if candidate_fitness < self.fitness[i]:\n                        self.population[i] = candidate\n                        self.fitness[i] = candidate_fitness\n                        self.stagnation_counter[i] = 0\n\n                self.update_memory_archive(self.population[i], self.fitness[i], f, cr)\n\n                if self.stagnation_counter[i] >= self.max_stagnation:\n                    lb, ub = func.bounds.lb, func.bounds.ub\n                    self.population[i] = np.random.uniform(lb, ub, self.dim)\n                    self.fitness[i] = func(self.population[i])\n                    evaluations += 1\n                    self.stagnation_counter[i] = 0\n\n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx]", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveClusteringDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05306 with standard deviation 0.03111.", "error": "", "parent_ids": ["62383443-aeda-49ff-82f1-9946eb74d29b"], "operator": null, "metadata": {"aucs": [0.00926991330253335, 0.00927640687797715, 0.009277879019174429, 0.07868937641174645, 0.07875152188489087, 0.07876661335685453, 0.07112716486959725, 0.07117610155199339, 0.071187779876274]}}
