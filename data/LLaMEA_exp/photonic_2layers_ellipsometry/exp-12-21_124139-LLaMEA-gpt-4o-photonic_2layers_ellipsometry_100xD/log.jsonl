{"id": "bb79f8a0-649e-4d34-ba5b-05f59d21aa9b", "fitness": 0.017877285272681582, "name": "EvolutionarySwarmGradientSearch", "description": "Evolutionary Swarm Gradient Search (ESGS) combines evolutionary and particle swarm strategies with gradient estimation to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n        \n        return global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01788 with standard deviation 0.01210.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.01184235985286275, 0.007029527619041964, 0.034759968346140036]}}
{"id": "495aaada-d3d1-4299-aa51-1fb0ec977f70", "fitness": 0.04097533607559437, "name": "EvolutionarySwarmGradientSearch", "description": "Enhanced Evolutionary Swarm Gradient Search refines position updates with adaptive inertia weight and introduces elitism.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n        return global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04098 with standard deviation 0.02121.", "error": "", "parent_ids": ["bb79f8a0-649e-4d34-ba5b-05f59d21aa9b"], "operator": null, "metadata": {"aucs": [0.020329132567643127, 0.07013678488470487, 0.032460090774435124]}}
{"id": "8261a49b-23ee-49fd-aadf-637543f784a6", "fitness": 0.02453652253701777, "name": "HybridEvolutionarySwarmGradientSearch", "description": "Hybridized Evolutionary Swarm Gradient Search integrates crossover-based recombination, enhanced elitism, and dynamic parameter tuning to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridEvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.crossover_rate = 0.3  # New parameter for crossover\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Apply crossover\n                if np.random.rand() < self.crossover_rate:\n                    partner_idx = np.random.randint(self.population_size)\n                    crossover_mask = np.random.rand(self.dim) < 0.5\n                    positions[i][crossover_mask] = positions[partner_idx][crossover_mask]\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n        return global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridEvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02454 with standard deviation 0.01382.", "error": "", "parent_ids": ["495aaada-d3d1-4299-aa51-1fb0ec977f70"], "operator": null, "metadata": {"aucs": [0.03478970857147046, 0.0050000000000000044, 0.033819859039582845]}}
{"id": "f4ba0d11-966e-4e63-b533-1277e157c024", "fitness": 0.04097533607559437, "name": "EvolutionarySwarmGradientSearch", "description": "Introduced adaptive mutation rate and convergence acceleration to improve search dynamics.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n        self.mutation_decay = self.mutation_rate / self.budget  # New: Adaptive mutation decay\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply adaptive mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Apply adaptive mutation rate\n            self.mutation_rate = max(0.01, self.mutation_rate - self.mutation_decay)  # New: Adaptive mutation rate\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n        return global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04098 with standard deviation 0.02121.", "error": "", "parent_ids": ["495aaada-d3d1-4299-aa51-1fb0ec977f70"], "operator": null, "metadata": {"aucs": [0.020329132567643127, 0.07013678488470487, 0.032460090774435124]}}
{"id": "63061c1b-9a29-469c-9bcc-6dbb9d4aebde", "fitness": 0.04120312663650113, "name": "EvolutionarySwarmGradientSearch", "description": "Enhanced Evolutionary Swarm Gradient Search refines position updates with adaptive inertia weight, introduces elitism, and adjusts social coefficient dynamically based on convergence speed.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04120 with standard deviation 0.02099.", "error": "", "parent_ids": ["495aaada-d3d1-4299-aa51-1fb0ec977f70"], "operator": null, "metadata": {"aucs": [0.021012504250363384, 0.07013678488470487, 0.032460090774435124]}}
{"id": "4c42f9fb-bfc7-4b55-9e5f-d46d33167a35", "fitness": 0.04120312663650113, "name": "EvolutionarySwarmGradientSearch", "description": "Introduce dynamic mutation rate adjustment based on convergence speed to enhance exploration.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Dynamic mutation rate adjustment\n            self.mutation_rate = max(0.05, self.mutation_rate * (1 - 0.5 * (global_best_score / (np.mean(personal_best_scores) + 1e-8))))\n\n        return global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04120 with standard deviation 0.02099.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.021012504250363384, 0.07013678488470487, 0.032460090774435124]}}
{"id": "11db7481-96bb-4cd7-ab41-ae135cc0f6db", "fitness": -Infinity, "name": "EvolutionarySwarmGradientSearch", "description": "Introduce velocity clamping to prevent excessive velocities, improving the search's stability and convergence. ", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n        self.max_velocity = 0.2 * (np.array(func.bounds.ub) - np.array(func.bounds.lb))  # Added velocity clamping\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)  # Clamp velocities\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 6, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {}}
{"id": "7518e59a-0514-444d-8ae6-9ee18f9e91a2", "fitness": 0.03327167488440208, "name": "EvolutionarySwarmGradientSearch", "description": "Refine swarm intelligence by introducing adaptive mutation rate based on population diversity.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                diversity = np.std(positions)\n                self.mutation_rate = max(0.01, min(0.3, diversity * 0.1))  # Adaptive mutation rate\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03327 with standard deviation 0.00498.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.03974120009512305, 0.027613733783648065, 0.032460090774435124]}}
{"id": "c1174fea-47ba-48db-b2fc-e324df3d8540", "fitness": 0.041084274662840516, "name": "EvolutionarySwarmGradientSearch", "description": "Incorporate a converging cognitive coefficient for balancing exploration and exploitation over iterations.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5  # Dynamic adjustment for cognitive coefficient\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n            \n            # Adjust cognitive coefficient over iterations\n            self.cognitive_coeff *= 0.99  # Decrease cognitive coefficient over time\n\n        return global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04108 with standard deviation 0.02110.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.020655948329381557, 0.07013678488470487, 0.032460090774435124]}}
{"id": "2da5e0a2-b9bb-46b7-9413-15eb24dd02db", "fitness": 0.022006649889129037, "name": "AdaptiveEliteInformedPSO", "description": "Adaptive Elite-Informed Particle Swarm Optimization introduces elite-guided exploration with adaptive learning rates, integrates a differential mutation strategy, and dynamically tunes cognitive and social factors based on convergence metrics.", "code": "import numpy as np\n\nclass AdaptiveEliteInformedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_scale = 0.1\n        self.inertia_weight_decay = (0.7 - 0.3) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm positions and velocities\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        # Initialize elite solutions\n        elite_count = max(2, int(self.population_size * 0.1))\n        elites = positions[np.argsort(personal_best_scores)[:elite_count]]\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity with elite influence\n                elite_influence = np.mean(elites, axis=0)\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                    + self.mutation_scale * np.random.rand(self.dim) * (elite_influence - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Update elite solutions\n            elites = positions[np.argsort(personal_best_scores)[:elite_count]]\n            \n            # Adaptive adjustment of inertia weight and coefficients\n            self.inertia_weight = max(0.3, self.inertia_weight - self.inertia_weight_decay)\n            score_diff = (global_best_score / (np.mean(personal_best_scores) + 1e-8))\n            self.cognitive_coeff = min(2.0, self.cognitive_coeff + score_diff * 0.1)\n            self.social_coeff = min(2.0, self.social_coeff + score_diff * 0.1)\n\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n        return global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveEliteInformedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02201 with standard deviation 0.00773.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.01401987636991664, 0.01953998252303535, 0.032460090774435124]}}
{"id": "7b8ee9b8-a0fd-4457-9af8-02daff39cb05", "fitness": 0.03836390556324439, "name": "EvolutionarySwarmGradientSearch", "description": "The refined strategy incorporates chaotic dynamic inertia weight and adaptive mutation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.tanh(self.evaluations/self.budget), self.dim)  # Adaptive mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            self.inertia_weight *= 0.8 - 0.5 * np.cos(np.pi * self.evaluations / self.budget)  # Chaotic dynamic inertia\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03836 with standard deviation 0.01915.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.018826048825069108, 0.0318850226978451, 0.06438064516681896]}}
{"id": "acc41b42-b1cf-4cb0-b44e-c94293a7912a", "fitness": 0.030274063794654988, "name": "EvolutionarySwarmGradientSearch", "description": "Introduce velocity clamping mechanism to prevent excessive velocity, thus improving convergence stability.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n        self.max_velocity = 0.2 * (ub - lb)  # Added: Velocity clamping\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                velocities[i] = np.clip(velocities[i], -self.max_velocity, self.max_velocity)  # Updated: Apply velocity clamping\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03027 with standard deviation 0.01716.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.025306900164494106, 0.01217980248487327, 0.05333548873459759]}}
{"id": "7e7bd1e3-feaa-4d3d-b551-526369491cf6", "fitness": 0.03438365283203163, "name": "QuantumInspiredEvolutionarySwarmGradientSearch", "description": "Quantum-inspired Evolutionary Swarm Gradient Search utilizes quantum superposition principles for enhanced exploration, integrates non-linear inertia weight adaptation, and employs dynamic learning factors to improve convergence robustness.", "code": "import numpy as np\n\nclass QuantumInspiredEvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Non-linear inertia adaptation\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Dynamic social adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget ** 0.5)  # Non-linear decay\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm with quantum superposition\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity with quantum-inspired superposition\n                q_factor = np.random.choice([-1, 1], size=self.dim) * np.abs(np.random.rand(self.dim))\n                velocities[i] = (\n                    self.inertia_weight * velocities[i] * q_factor\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Non-linear adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight * (1 - self.inertia_weight_decay))\n            \n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm QuantumInspiredEvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03438 with standard deviation 0.01417.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.014894246278462364, 0.048179357291269875, 0.04007735492636266]}}
{"id": "76052242-ff13-4e7b-bd0c-1dedc6be7adc", "fitness": 0.037969086622666515, "name": "EvolutionarySwarmGradientSearch", "description": "Introduce a random perturbation to the global best position for enhanced exploration.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Introduce random perturbation to the global best position\n            global_best_position += np.random.normal(0, 0.01, self.dim)\n\n        return global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03797 with standard deviation 0.02678.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.00556852595816737, 0.0711596233467704, 0.03717911056306178]}}
{"id": "a7d6207b-f7e5-497c-be2b-81548c102eaa", "fitness": 0.02207214619957924, "name": "QuantumInspiredEvolutionarySwarmGradientSearch", "description": "Quantum-inspired Evolutionary Swarm Gradient Search enhances exploration and exploitation via quantum superposition principles, adaptive population size, and dynamic learning rates for optimized convergence.", "code": "import numpy as np\n\nclass QuantumInspiredEvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.initial_population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.population_growth_rate = 1.01  # Adaptive population growth\n        self.learning_rate_base = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        population_size = self.initial_population_size\n        positions = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Quantum-inspired position update\n                quantum_factor = np.random.rand(self.dim) < 0.5\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                ) * quantum_factor\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            learning_rate = self.learning_rate_base * (1 - (global_best_score / (np.mean(personal_best_scores) + 1e-8)))\n            self.social_coeff = min(2.0, self.social_coeff + learning_rate)\n\n            # Update population size adaptively\n            population_size = int(self.initial_population_size * (self.population_growth_rate ** (self.evaluations / self.budget)))\n            population_size = min(population_size, self.budget - self.evaluations)\n\n        return global_best_position", "configspace": "", "generation": 14, "feedback": "The algorithm QuantumInspiredEvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02207 with standard deviation 0.01517.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.01238604831099821, 0.010333121177233728, 0.043497269110505776]}}
{"id": "e6474084-676b-43a4-bab3-f5825e9f5187", "fitness": 0.04107256575418805, "name": "AdaptiveEliteEvolutionarySwarm", "description": "Adaptive Elite-driven Evolutionary Swarm optimizes with dynamic inertia, elite retention, adaptive social-cognitive interplay, and strategic exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveEliteEvolutionarySwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            convergence_factor = global_best_score / (np.mean(personal_best_scores) + 1e-8)\n            self.social_coeff = min(2.0, self.social_coeff + convergence_factor * 0.05)\n            self.cognitive_coeff = max(1.0, self.cognitive_coeff - convergence_factor * 0.05)\n            self.mutation_rate = max(0.05, self.mutation_rate - convergence_factor * 0.01)\n\n        return global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveEliteEvolutionarySwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04107 with standard deviation 0.02111.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.020620821603424155, 0.07013678488470487, 0.032460090774435124]}}
{"id": "94e3e476-73f8-4dba-84b9-8ed8b50b1477", "fitness": 0.022404015507322367, "name": "EvolutionarySwarmGradientSearch", "description": "Introduced local search exploitation by refining personal best positions using a small neighborhood search.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n                # New line: Local search around personal best\n                local_search_position = personal_best_positions[i] + np.random.uniform(-0.05, 0.05, self.dim)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_score = func(local_search_position)\n                self.evaluations += 1\n                if local_score < personal_best_scores[i]:\n                    personal_best_positions[i] = local_search_position\n                    personal_best_scores[i] = local_score\n                    if local_score < global_best_score:\n                        global_best_position = local_search_position\n                        global_best_score = local_score\n\n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02240 with standard deviation 0.01242.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.029018209976775844, 0.03319383654519126]}}
{"id": "296f9e42-b6ae-456c-b64d-bc165128c808", "fitness": -Infinity, "name": "EvolutionarySwarmGradientSearch", "description": "Introducing dynamic population size adjustment and enhanced diversity for improved exploration and convergence in Evolutionary Swarm Gradient Search.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.diversity_threshold = 0.1  # New: Threshold for diversity check\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Calculate diversity\n                diversity = np.std(positions, axis=0).mean()\n\n                # Adjust population size based on diversity\n                if diversity < self.diversity_threshold and self.population_size > 10:\n                    self.population_size -= 1  # Reduce population size to enhance exploitation\n                elif diversity > self.diversity_threshold and self.population_size < self.initial_population_size * 2:\n                    self.population_size += 1  # Increase population size to enhance exploration\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 17, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {}}
{"id": "c382d79a-f5fa-4ee7-9ee4-e8e47cd556fe", "fitness": 0.033783121511579285, "name": "QuantumInspiredEvolutionarySwarmGradientSearch", "description": "A Quantum-Inspired Evolutionary Swarm Gradient Search incorporates quantum superposition for diverse exploration, adaptive inertia refinement, and dynamic elitism to enhance convergence.", "code": "import numpy as np\n\nclass QuantumInspiredEvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_prob = 0.1  # Probability of quantum-inspired update\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Quantum-inspired position update\n                if np.random.rand() < self.quantum_prob:\n                    positions[i] = np.random.uniform(lb, ub, self.dim)\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm QuantumInspiredEvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03378 with standard deviation 0.01529.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.013599537927174943, 0.050604557433197805, 0.037145269174365114]}}
{"id": "9c508f78-798b-4fea-aaa7-715842fa8ec4", "fitness": 0.027185354076265062, "name": "EvolutionarySwarmGradientSearch", "description": "Enhanced Evolutionary Swarm Gradient Search introduces a dynamic mutation rate based on diversity and a local search phase to exploit promising regions effectively. ", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Dynamic mutation rate based on swarm diversity\n                swarm_diversity = np.std(positions, axis=0).mean()\n                mutation_rate_dynamic = max(0.05, min(0.3, swarm_diversity / (ub - lb).mean()))\n\n                # Apply mutation with dynamic rate\n                if np.random.rand() < mutation_rate_dynamic:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Local search phase\n            if self.evaluations < self.budget and np.random.rand() < 0.1:\n                local_search_position = global_best_position + np.random.normal(0, 0.05, self.dim)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_score = func(local_search_position)\n                self.evaluations += 1\n                if local_score < global_best_score:\n                    global_best_position = local_search_position\n                    global_best_score = local_score\n\n        return global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02719 with standard deviation 0.01360.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.03974120009512305, 0.008289886349273856, 0.03352497578439828]}}
{"id": "2259c838-81aa-4bad-82d8-093601c5fb04", "fitness": 0.04120312663650113, "name": "EvolutionarySwarmGradientSearch", "description": "Introducing a dynamic mutation rate that decreases over time to enhance convergence stability.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1  # Initial mutation rate\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n        self.mutation_decay = self.mutation_rate / self.budget  # New: Dynamic mutation rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Decrease mutation rate over time\n            self.mutation_rate = max(0.01, self.mutation_rate - self.mutation_decay)  # New: dynamic mutation rate decrease\n\n        return global_best_position", "configspace": "", "generation": 20, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04120 with standard deviation 0.02099.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.021012504250363384, 0.07013678488470487, 0.032460090774435124]}}
{"id": "b58d142d-8b6d-4b9c-b8db-2aa6cc57cafb", "fitness": 0.04120312663650113, "name": "EvolutionarySwarmGradientSearch", "description": "Incorporate a gradual reduction in mutation rate to balance exploration and exploitation over iterations.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n        self.mutation_rate_decay = self.mutation_rate / self.budget  # New: Adaptive mutation rate\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Decrement mutation rate\n            self.mutation_rate = max(0.01, self.mutation_rate - self.mutation_rate_decay)  # New: Adapt mutation rate\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 21, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04120 with standard deviation 0.02099.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.021012504250363384, 0.07013678488470487, 0.032460090774435124]}}
{"id": "5a838980-c81b-4cfa-b494-f3287bb65043", "fitness": 0.0386089317409796, "name": "EvolutionarySwarmGradientSearch", "description": "Introduction of time-varying cognitive coefficient to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n            \n            # Time-varying cognitive coefficient\n            self.cognitive_coeff = 1.5 + 0.5 * (self.evaluations / self.budget)\n\n        return global_best_position", "configspace": "", "generation": 22, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03861 with standard deviation 0.02364.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.01322991956379882, 0.07013678488470487, 0.032460090774435124]}}
{"id": "f89ea7cb-b344-49ea-affb-04754eab377c", "fitness": 0.040158043266177924, "name": "ImprovedEvolutionarySwarmGradientSearch", "description": "Improved Evolutionary Swarm Gradient Search incorporates dynamic leader strategy, variable mutation rate, and convergence-aware social coefficient adjustment.", "code": "import numpy as np\n\nclass ImprovedEvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.leader_decay = np.linspace(1.0, 0.5, self.budget)  # New: Leader decay parameter\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity considering leader decay\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * ((1 - self.leader_decay[self.evaluations]) * global_best_position + self.leader_decay[self.evaluations] * previous_global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Variable mutation rate\n                mutation_rate = self.mutation_rate * (1 - self.evaluations / self.budget)\n                if np.random.rand() < mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Convergence-aware social coefficient adjustment\n            diversity = np.std(personal_best_positions)\n            self.social_coeff = min(2.0, 1.5 + (diversity / (np.mean(personal_best_scores) + 1e-8)) * 0.5)\n\n        return global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm ImprovedEvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04016 with standard deviation 0.02277.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.015000475472506603, 0.07013678488470487, 0.035336869441322305]}}
{"id": "d3f2131e-df6c-40b0-938a-a0776790acf0", "fitness": 0.022707267967724116, "name": "EvolutionarySwarmGradientSearch", "description": "Introduced non-uniform mutation based on the evaluations ratio to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EvolutionarySwarmGradientSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Updated: Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5  # Social coefficient: Dynamic adjustment\n        self.mutation_rate = 0.1\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget  # Updated: Adaptive inertia\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize swarm\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Elitism: Save the best position from the previous generation\n            previous_global_best_position = np.copy(global_best_position)  # New line for elitism\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    tau = (1 - (self.evaluations / self.budget)) ** 2  # Non-uniform mutation\n                    mutation = np.random.normal(0, tau, self.dim)\n                    positions[i] += mutation\n\n                # Clip positions to the bounds\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate and update personal and global bests\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            # Apply adaptive inertia weight\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)  # Updated inertia weight\n            # Ensure elitism\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamically adjust social coefficient based on convergence\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n        return global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm EvolutionarySwarmGradientSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02271 with standard deviation 0.00695.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.016750919302794043, 0.018910793825943184, 0.032460090774435124]}}
{"id": "81b0c798-2c9c-427a-b722-442f57c45311", "fitness": 0.0419628735041098, "name": "AdaptiveMemorySwarmSearch", "description": "Adaptive Memory Swarm Search enhances swarm intelligence by integrating an adaptive memory mechanism to improve exploration-exploitation balance and incorporates noise-resilient updates for dynamic environments.", "code": "import numpy as np\n\nclass AdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  # Memory for storing past best solutions\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Memory mechanism\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            # Use memory to improve exploration-exploitation\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n        return global_best_position", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04196 with standard deviation 0.02027.", "error": "", "parent_ids": ["63061c1b-9a29-469c-9bcc-6dbb9d4aebde"], "operator": null, "metadata": {"aucs": [0.02329174485318941, 0.07013678488470487, 0.032460090774435124]}}
{"id": "055c9aec-0d10-4f09-859b-39584fdec8c3", "fitness": 0.04168494708695821, "name": "AdaptiveMemorySwarmSearch", "description": "Enhanced Adaptive Memory Swarm Search with improved adaptive cognitive coefficient for better individual exploration.", "code": "import numpy as np\n\nclass AdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  # Memory for storing past best solutions\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Memory mechanism\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            # Use memory to improve exploration-exploitation\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n            \n            # Adjust cognitive coefficient based on memory\n            self.cognitive_coeff = max(1.0, 1.5 - (global_best_score / (np.max(personal_best_scores) + 1e-8)) * 0.5)\n\n        return global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm AdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04168 with standard deviation 0.02053.", "error": "", "parent_ids": ["81b0c798-2c9c-427a-b722-442f57c45311"], "operator": null, "metadata": {"aucs": [0.02245796560173463, 0.07013678488470487, 0.032460090774435124]}}
{"id": "38e5610b-d576-4fcd-8e4b-28e8f0b80d65", "fitness": 0.019198866695937806, "name": "QuantumInspiredAdaptiveMemorySwarmSearch", "description": "Quantum-Inspired Adaptive Memory Swarm Search enhances swarm intelligence by integrating quantum superposition principles with an adaptive memory mechanism to improve exploration-exploitation balance and incorporates noise-resilient updates for dynamic environments.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        def quantum_superposition():\n            return np.random.uniform(lb, ub) + np.random.uniform(-1, 1) * (global_best_position - lb)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                if np.random.rand() < 0.1:  # Quantum-inspired position update\n                    positions[i] = quantum_superposition()\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n        return global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm QuantumInspiredAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01920 with standard deviation 0.02008.", "error": "", "parent_ids": ["81b0c798-2c9c-427a-b722-442f57c45311"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.04759660008781341]}}
{"id": "4d75befe-80ad-41bd-8b09-464e572e1d2e", "fitness": 0.03754546167799714, "name": "MultiLayeredAdaptiveMemorySwarmSearch", "description": "Multi-layered Adaptive Memory Swarm Search introduces layered memory storage for strategic diversity preservation and controlled exploration, improving convergence speed and solution quality.", "code": "import numpy as np\n\nclass MultiLayeredAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  # Memory for storing past best solutions\n        self.memory_layers = [[], []]  # Two layers of memory\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Multi-layer Memory mechanism\n            self.memory_layers[0].append((global_best_position, global_best_score))\n            if len(self.memory_layers[0]) > self.memory_size:\n                self.memory_layers[0].pop(0)\n            \n            if np.random.rand() < 0.5:  # 50% chance to promote to second layer\n                self.memory_layers[1].extend(self.memory_layers[0])\n                self.memory_layers[0] = []\n                self.memory_layers[1] = sorted(self.memory_layers[1], key=lambda x: x[1])[:self.memory_size]\n\n            # Use the best from all layers to improve exploration-exploitation\n            all_memory = self.memory_layers[0] + self.memory_layers[1]\n            if len(all_memory) > 1:\n                memory_best_position = min(all_memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n        return global_best_position", "configspace": "", "generation": 28, "feedback": "The algorithm MultiLayeredAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03755 with standard deviation 0.02480.", "error": "", "parent_ids": ["81b0c798-2c9c-427a-b722-442f57c45311"], "operator": null, "metadata": {"aucs": [0.01003950937485143, 0.07013678488470487, 0.032460090774435124]}}
{"id": "59dc564b-873a-46a8-8af6-9ea9dfc0227c", "fitness": 0.04162071465550702, "name": "AdaptiveMemorySwarmSearch", "description": "Adaptive Memory Swarm Search refines dynamic inertia weight updates and leverages historical memory for more effective exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  # Memory for storing past best solutions\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Memory mechanism\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            # Use memory to improve exploration-exploitation\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                exploration_factor = np.random.rand(self.dim)  # Change 1: Introduce dynamic exploration factor\n                for i in range(self.population_size):\n                    positions[i] += exploration_factor * (memory_best_position - positions[i])  # Change 2: Apply factor\n\n        return global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04162 with standard deviation 0.02059.", "error": "", "parent_ids": ["81b0c798-2c9c-427a-b722-442f57c45311"], "operator": null, "metadata": {"aucs": [0.02226526830738107, 0.07013678488470487, 0.032460090774435124]}}
{"id": "df660fd3-065b-47b9-8142-4cb64d87d16b", "fitness": 0.04243904213019878, "name": "AdaptiveMemorySwarmSearch", "description": "Enhanced Adaptive Memory Swarm Search with adaptive mutation rate for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  # Memory for storing past best solutions\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            # Memory mechanism\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            # Use memory to improve exploration-exploitation\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            # Adaptive mutation rate based on convergence progress\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04244 with standard deviation 0.01996.", "error": "", "parent_ids": ["81b0c798-2c9c-427a-b722-442f57c45311"], "operator": null, "metadata": {"aucs": [0.02389422207569125, 0.07013678488470487, 0.03328611943020021]}}
{"id": "96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8", "fitness": 0.04649112825325474, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Dynamic Quantum-Inspired Adaptive Memory Swarm Search with variable inertia and mutation for enhanced convergence and diversity.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05  # Step size for quantum-inspired dimension updates\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04649 with standard deviation 0.02550.", "error": "", "parent_ids": ["df660fd3-065b-47b9-8142-4cb64d87d16b"], "operator": null, "metadata": {"aucs": [0.011094233591703917, 0.07013678488470487, 0.05824236628335544]}}
{"id": "27e5c689-b436-474d-849c-2a86cd1724fa", "fitness": 0.03523770512798959, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced adaptive quantum-inspired swarm search with fine-tuned mutation rate for improved convergence and diversity.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05  # Step size for quantum-inspired dimension updates\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.05, self.dim)  # Fine-tuned mutation rate\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03524 with standard deviation 0.01943.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.010713991319396432, 0.036769204843288494, 0.05822991922128384]}}
{"id": "e4528b35-015d-44ef-b1b6-b21733cf23b3", "fitness": 0.03789703641694797, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Modified Dynamic Quantum Adaptive Memory Swarm Search by adjusting mutation rate decay for improved exploration and convergence.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05  # Step size for quantum-inspired dimension updates\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            # Modified mutation rate decay\n            self.mutation_rate = max(0.01, 0.1 - 0.05 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03790 with standard deviation 0.02441.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.011094233591703917, 0.07013678488470487, 0.032460090774435124]}}
{"id": "862c906e-d175-41ef-8232-e92985e3cb68", "fitness": 0.030349844406470445, "name": "EnhancedQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced Quantum-Inspired Adaptive Memory Swarm Optimization with Self-Adaptive Parameters and Diversity Preservation.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (self.initial_inertia_weight - self.final_inertia_weight) / self.budget\n        self.quantum_step = 0.05\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                inertia_weight = self.initial_inertia_weight - (self.evaluations / self.budget) * (self.initial_inertia_weight - self.final_inertia_weight)\n                cognitive_coeff_adaptive = self.cognitive_coeff * (1 - self.evaluations / self.budget)\n                social_coeff_adaptive = self.social_coeff * (self.evaluations / self.budget)\n                \n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + cognitive_coeff_adaptive * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + social_coeff_adaptive * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            # Quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    if np.std(positions) < self.diversity_threshold:\n                        positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03035 with standard deviation 0.01309.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.019255999774510868, 0.023060581945838377, 0.048732951499062094]}}
{"id": "df634766-70ec-42d4-9dca-ed564ca90334", "fitness": 0.035865625219713336, "name": "EnhancedQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced Quantum-Driven Adaptive Memory Swarm Search with dynamic exploration-exploitation balance and adaptive quantum steps for robust convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.base_quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n                \n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Adaptive quantum-inspired position update\n            quantum_step = self.base_quantum_step * (global_best_score / (np.mean(personal_best_scores) + 1e-8))\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.5:  # Adjusted probability for memory influence\n                        positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03587 with standard deviation 0.02670.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.07013678488470487, 0.032460090774435124]}}
{"id": "040f3bcc-c4d7-4fd2-ab0a-c5c6c7b1c718", "fitness": 0.014153363591478377, "name": "EnhancedQuantumMemorySwarmOptimization", "description": "Enhanced Quantum-Inspired Memory Swarm Optimization with adaptive learning rates and elite preservation for accelerated convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedQuantumMemorySwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.elite_ratio = 0.1\n        self.elite_size = max(1, int(self.elite_ratio * self.population_size))\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.1  # Increased step size for quantum-inspired updates\n        self.adaptive_learning = True\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            # Preserve elite solutions\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_size]\n            elite_positions = positions[elite_indices]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n\n                # Apply quantum-inspired position update\n                if np.random.rand() < 0.5:\n                    random_dim = np.random.randint(self.dim)\n                    velocities[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n\n                positions[i] += velocities[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n            self.social_coeff = min(2.5, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.2)\n\n            # Update memory with elite solutions\n            for elite_pos in elite_positions:\n                self.memory.append((elite_pos, func(elite_pos)))\n            self.memory.sort(key=lambda x: x[1])\n            self.memory = self.memory[:self.memory_size]\n\n            if len(self.memory) > 1:\n                memory_best_position = self.memory[0][0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            if self.adaptive_learning:\n                avg_score = np.mean(personal_best_scores)\n                self.mutation_rate = max(0.01, 0.1 * (avg_score / (global_best_score + 1e-8)))\n\n        return global_best_position", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedQuantumMemorySwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "16750462-087d-4293-98d0-81353b1e80cc", "fitness": 0.04649112825325474, "name": "EnhancedDynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced Dynamic Quantum-Inspired Adaptive Memory Swarm Search with adaptive mutation, memory-driven exploration, and tuned parameters for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                exploration_factor = np.random.rand() * 0.5  \n                for i in range(self.population_size):\n                    positions[i] += exploration_factor * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedDynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04649 with standard deviation 0.02550.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.011094233591703917, 0.07013678488470487, 0.05824236628335544]}}
{"id": "7966377d-5b34-4d71-9234-492ca858b59f", "fitness": 0.0363073752890846, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced Dynamic Quantum-Inspired Adaptive Memory Swarm Search with adaptive learning rates and an improved quantum-inspired update mechanism for better exploration and convergence.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05  # Step size for quantum-inspired dimension updates\n        self.learning_rate = 0.01  # New parameter for adaptive learning\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Improved quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                quantum_adjustment = self.quantum_step * np.tanh(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i][random_dim] += quantum_adjustment\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i]) * self.learning_rate\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03631 with standard deviation 0.02619.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.0063252502081138084, 0.07013678488470487, 0.032460090774435124]}}
{"id": "7bdf2ffb-4d1b-49f9-b348-01661c4b33bf", "fitness": 0.0363275317708317, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhance the swarm's convergence by introducing adaptive mutation scaling based on fitness improvement.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05  # Step size for quantum-inspired dimension updates\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * (self.evaluations / self.budget), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03633 with standard deviation 0.02273.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.04575001798698519, 0.058232577325509904]}}
{"id": "016472ed-5ce6-485a-9435-46194365e2cf", "fitness": 0.04649112825325474, "name": "EnhancedQuantumSwarmSearch", "description": "Enhanced Quantum Swarm Search with Adaptive Search Strategies and Memory-Driven Exploration for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05  \n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    exploration_factor = np.random.rand()\n                    positions[i] += exploration_factor * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedQuantumSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04649 with standard deviation 0.02550.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.011094233591703917, 0.07013678488470487, 0.05824236628335544]}}
{"id": "a016ea54-79d6-4f79-ae41-31fd46a9b2f0", "fitness": 0.03006089590322769, "name": "EnhancedQuantumMemorySwarmSearch", "description": "Enhanced Quantum-Inspired Memory Swarm Search with dynamic parameter tuning, quantum tunneling, and adaptive topology for efficient convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05\n        self.adaptive_topology = True  # New adaptive topology flag\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            # Adaptive topology: adjust influence based on performance\n            if self.adaptive_topology:\n                self.cognitive_coeff = 1.5 + 0.5 * (1 - (global_best_score / (np.mean(personal_best_scores) + 1e-8)))\n                self.social_coeff = 1.5 + 0.5 * (global_best_score / (np.mean(personal_best_scores) + 1e-8))\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum tunneling\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # 10% chance of quantum tunneling\n                    random_dim = np.random.randint(self.dim)\n                    positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedQuantumMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03006 with standard deviation 0.01217.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.013005087670256099, 0.040555835205779545, 0.03662176483364743]}}
{"id": "58ce104f-4775-496c-ab5b-58eb262b0e5b", "fitness": 0.056066643211507304, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced mutation strategy with dynamic scaling based on population diversity for improved exploration.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05607 with standard deviation 0.04084.", "error": "", "parent_ids": ["96fa4a6f-f92b-4a8d-a3f8-17d3ce4c2ee8"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.10497837722434289, 0.05822155241017901]}}
{"id": "a404142e-3c5e-4b2f-87df-b9cabb55120f", "fitness": 0.031185800905577838, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced adaptive mutation scaling based on the diversity of personal best scores to enhance exploration.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(personal_best_scores) / np.mean(personal_best_scores), self.dim)  # Adaptive mutation scaling\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03119 with standard deviation 0.01939.", "error": "", "parent_ids": ["58ce104f-4775-496c-ab5b-58eb262b0e5b"], "operator": null, "metadata": {"aucs": [0.013754057569964173, 0.02156434966008125, 0.058238995486688094]}}
{"id": "677974ce-9056-4bd2-ae04-51ceab3d5806", "fitness": 0.02721932517566598, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduction of adaptive quantum step size to enhance convergence speed in high-dimensional spaces.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / self.budget\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * (1 / (self.evaluations + 1)) * np.sign(global_best_position[random_dim] - positions[i][random_dim]) # Change made here\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 44, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02722 with standard deviation 0.01643.", "error": "", "parent_ids": ["58ce104f-4775-496c-ab5b-58eb262b0e5b"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.04419788475256281, 0.032460090774435124]}}
{"id": "37aca4f8-bc26-4f13-ba32-b58c7db4271a", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced inertia weight decay for better convergence control in dynamic environments.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["58ce104f-4775-496c-ab5b-58eb262b0e5b"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "db25c189-2b5e-4a28-81fd-880b70152fc6", "fitness": 0.021560039315718926, "name": "AdaptiveHybridSwarmSearch", "description": "Introduce adaptive swarm intelligence with hybrid learning and collaborative mutation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  \n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            hybrid_learners = np.random.choice(self.population_size, self.population_size // 2, replace=False)\n            for learner in hybrid_learners:\n                peer = np.random.choice(self.population_size)\n                positions[learner] += 0.5 * (positions[peer] - positions[learner])\n                positions[learner] = np.clip(positions[learner], lb, ub)\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveHybridSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02156 with standard deviation 0.01190.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.02722002717272165, 0.032460090774435124]}}
{"id": "fb37748c-4ae1-4ad4-aeed-05578ebc08da", "fitness": 0.0281277130777704, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhanced quantum step scaling and adaptive velocity clamping for improved convergence.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                # Adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement enhanced quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i][random_dim] *= 1.0 + 0.1 * np.random.randn()  # Apply scaling factor\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02813 with standard deviation 0.00857.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.019232762918917512, 0.025450276239854075, 0.03970010007453961]}}
{"id": "9fb0c891-4327-453f-8471-6a519068b15d", "fitness": -Infinity, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Hybrid Quantum-Social Swarm Optimization with Adaptive Learning for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_learning_rate = 0.05\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement hybrid quantum-social adjustment\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                quantum_adjustment = self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                social_memory_influence = np.random.rand() * (previous_global_best_position - positions[i])\n                positions[i][random_dim] += self.adaptive_learning_rate * quantum_adjustment + social_memory_influence\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            best_in_memory = min(self.memory, key=lambda x: x[1], default=(global_best_position, global_best_score))[0]\n            for i in range(self.population_size):\n                positions[i] += np.random.rand() * (best_in_memory - positions[i])\n\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            self.memory.append((global_best_position, global_best_score))\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 48, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {}}
{"id": "52f28297-4f42-490c-9cfb-dc2894330807", "fitness": 0.024571154498709762, "name": "AdaptiveQuantumSwarmMemorySearch", "description": "Adaptive Quantum Swarm Search with Dynamic Memory and Exploration-Exploitation Balance for Improved Global Convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumSwarmMemorySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.exploration_factor = 0.3\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                if np.random.rand() < (1 - self.exploration_factor):\n                    random_dim = np.random.randint(self.dim)\n                    positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                else:\n                    positions[i] += np.random.uniform(-1, 1, self.dim) * self.quantum_step\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptiveQuantumSwarmMemorySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02457 with standard deviation 0.00570.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.02206167967382311, 0.01919169304787105, 0.032460090774435124]}}
{"id": "1166f39e-0cbd-4f8a-8828-4a9b74685440", "fitness": 0.07520320899585664, "name": "MultiPerspectiveAdaptiveSwarmSearch", "description": "Multi-Perspective Adaptive Swarm Search with enhanced memory for dynamic convergence control.", "code": "import numpy as np\n\nclass MultiPerspectiveAdaptiveSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    distance_to_memory = np.linalg.norm(memory_best_position - positions[i])\n                    attraction_strength = np.exp(-distance_to_memory / self.dim)\n                    positions[i] += attraction_strength * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm MultiPerspectiveAdaptiveSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "53acbf98-5599-48ab-a2e7-8f368e7f0f1f", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced adaptive memory scoring to fine-tune the swarm's social component.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                # Change: use weighted average for memory best position\n                memory_scores = np.array([x[1] for x in self.memory])\n                memory_weights = memory_scores / np.sum(memory_scores)\n                memory_best_position = np.average([x[0] for x in self.memory], axis=0, weights=memory_weights)\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 51, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "a471d8bc-fae8-4212-89da-15f51259cf6c", "fitness": 0.024802641049895047, "name": "EnhancedDynamicQuantumAdaptiveMemorySwarmSearch", "description": "Utilizes adaptive swarm dynamics with diversity preservation through stochastic perturbations and dynamic pheromone trails to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.pheromone_decay = 0.9\n        self.pheromones = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                    + self.pheromones[i]\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n            self.pheromones *= self.pheromone_decay\n            for i in range(self.population_size):\n                self.pheromones[i] += np.random.normal(0, 0.01, self.dim)\n\n        return global_best_position", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedDynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02480 with standard deviation 0.00748.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.014662140788587963, 0.027285691586662053, 0.032460090774435124]}}
{"id": "9cb7a099-a5e9-41f2-947a-cb5cf4b786a4", "fitness": 0.034327841971774554, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced adaptive quantum step based on convergence to refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                adaptive_quantum_step = self.quantum_step * (1 - self.evaluations / self.budget)  # Adaptive quantum step\n                positions[i][random_dim] += adaptive_quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 53, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03433 with standard deviation 0.02320.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.06172269916253925, 0.036260826752784414]}}
{"id": "aeb22d7f-09d4-47e8-946b-3a3bde8f4feb", "fitness": 0.01497683091704031, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced dynamic neighborhood topology and adaptive mutation using elite opposition-based learning for improved convergence and exploration.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5 \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Dynamic neighborhood topology\n                local_best_score = np.inf\n                local_best_position = None\n                for j in range(self.population_size):\n                    if np.linalg.norm(positions[i] - positions[j]) < np.random.uniform(0.1, 0.5):\n                        if personal_best_scores[j] < local_best_score:\n                            local_best_score = personal_best_scores[j]\n                            local_best_position = personal_best_positions[j]\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (local_best_position - positions[i])\n                )\n\n                # Elite opposition-based learning\n                elite_position = personal_best_positions[np.argmin(personal_best_scores)]\n                opposition_position = lb + ub - elite_position\n                if func(opposition_position) < global_best_score:\n                    global_best_position = opposition_position\n                    global_best_score = func(opposition_position)\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 54, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01498 with standard deviation 0.01240.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.007470401976685803, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "d90f5887-caa3-49e2-899e-e740283e7833", "fitness": 0.01781210089474435, "name": "EnhancedDynamicQuantumSwarmOptimizer", "description": "Enhanced dynamic multi-phase exploration-exploitation balance using diversity-guided strategies and adaptive quantum-inspired updates.", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 60\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_rate = 0.1\n        self.memory_size = 7\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Quantum-inspired and diversity-based position update\n            diversity = np.std(positions, axis=0).mean()\n\n            for i in range(self.population_size):\n                if diversity > self.diversity_threshold:\n                    random_dim = np.random.randint(self.dim)\n                    positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                else:\n                    positions[i] += np.random.rand(self.dim) * (global_best_position - positions[i])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.5, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    if self.evaluations / self.budget < 0.5:\n                        positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedDynamicQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01781 with standard deviation 0.01743.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.005973945016770621, 0.0050000000000000044, 0.042462357667462425]}}
{"id": "30bf4afb-a5d9-48f6-9180-d523766670fb", "fitness": 0.07520320899585664, "name": "QuantumInformedAdaptiveSwarmSearch", "description": "Quantum-Informed Adaptive Swarm Search with Dynamic Memory and Enhanced Exploration for Improved Convergence.", "code": "import numpy as np\n\nclass QuantumInformedAdaptiveSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n            \n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                \n                # Introduce exploration boost based on diversity\n                if np.std(positions, axis=0).mean() < self.diversity_threshold:\n                    velocities[i] += np.random.normal(0, 0.1, self.dim)\n\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm QuantumInformedAdaptiveSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "cb41c146-5dc5-4cb3-ad6d-c1699765d85d", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce adaptive memory influence on swarm individuals for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i]) * 0.5  # Introduce memory influence\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "339fdfa1-d81e-4564-a946-87f0cae25bfb", "fitness": 0.01475446232497013, "name": "EnhancedQuantumMemorySwarmOptimization", "description": "Enhanced Quantum Memory Swarm Optimization with Adaptive Learning and Dynamic Memory Integration for improved convergence in diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedQuantumMemorySwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n            for i in range(self.population_size):\n                delta_memory = self.learning_rate * np.random.rand() * (memory_best_position - positions[i])\n                positions[i] += delta_memory\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedQuantumMemorySwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01475 with standard deviation 0.01254.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.006803296200475262, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "ef77e8fe-ce5c-4a58-b700-46613ff264b9", "fitness": 0.014153363591478377, "name": "CooperativeQuantumAdaptiveMemorySwarmSearch", "description": "Introduce cooperative co-evolution and adaptive neighborhood search to enhance exploration and exploitation balance in swarm intelligence.", "code": "import numpy as np\n\nclass CooperativeQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.group_size = 5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Cooperative co-evolution - divide into subgroups\n                subgroup_indices = np.random.choice(self.population_size, self.group_size, replace=False)\n                subgroup_best_index = subgroup_indices[np.argmin(personal_best_scores[subgroup_indices])]\n                subgroup_best_position = personal_best_positions[subgroup_best_index]\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (subgroup_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm CooperativeQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "ed42e449-49c5-4c51-a18e-b870d0e28fcc", "fitness": 0.029886605006678685, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "DynamicQuantumAdaptiveMemorySwarmSearch with adaptive mutation rate and enhanced quantum step control for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update with adaptive quantum step\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                adaptive_step = self.quantum_step * (1 - np.abs(global_best_position[random_dim] - positions[i][random_dim]) / (ub[random_dim] - lb[random_dim]))\n                positions[i][random_dim] += adaptive_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))  # Adaptive mutation rate\n\n        return global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02989 with standard deviation 0.01935.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.05219972424560093, 0.032460090774435124]}}
{"id": "8f5a5785-299a-4546-898e-7dcebf6bd9f3", "fitness": 0.07520320899585664, "name": "EnhancedDynamicSwarmSearch", "description": "Incorporate adaptive swarm size and neighborhood search to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedDynamicSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.shrink_factor = 0.95\n        self.neighborhood_radius = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    if np.random.rand() < self.neighborhood_radius:\n                        positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n            if self.evaluations > self.budget * 0.5:\n                self.population_size = max(10, int(self.shrink_factor * self.population_size))\n                positions = positions[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n        return global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedDynamicSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "dbced188-898b-4426-9770-28400a57e215", "fitness": 0.016541152436460777, "name": "EnhancedQuantumAdaptiveMemorySwarmSearch", "description": "Introducing adaptive hybrid mutation with a dynamic diversity control mechanism and enhanced quantum-inspired adjustments for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8) \n        self.quantum_step = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                # Adaptive hybrid mutation strategy\n                if np.random.rand() < self.mutation_rate:\n                    diversity = np.mean(np.std(positions, axis=0))\n                    mutation_strength = 0.1 * (diversity / self.diversity_threshold)\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Enhanced quantum-inspired position update\n            for i in range(self.population_size):\n                if np.random.rand() < 0.5:\n                    random_dim = np.random.randint(self.dim)\n                    positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                else:\n                    quantum_adjustment = self.quantum_step * (np.random.rand(self.dim) - 0.5)\n                    positions[i] += quantum_adjustment\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            # Dynamic social coefficient adjustment\n            fitness_variance = np.var(personal_best_scores)\n            self.social_coeff = min(2.0, max(1.5, 2.0 - (fitness_variance / (np.mean(personal_best_scores) + 1e-8)) * 0.1))\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01654 with standard deviation 0.01498.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.006924074505301081, 0.0050000000000000044, 0.03769938280408125]}}
{"id": "3074f17f-013c-4e27-a437-5b768836c2f1", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introducing adaptive quantum-inspired search dynamics with enhanced diversity mechanisms for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8) \n        self.quantum_step = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  \n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement adaptive quantum-inspired positional update with diversity check\n            diversity = np.mean(np.std(positions, axis=0))\n            if diversity < self.diversity_threshold:\n                self.quantum_step *= 1.1\n            \n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "947c3c3a-788e-4efb-b86b-f53512b43ae6", "fitness": 0.019018006794286595, "name": "AdaptiveQuantumMemorySwarmSearch", "description": "Adaptive Quantum Memory Swarm Search with dynamic neighborhood influence to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveQuantumMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8) \n        self.quantum_step = 0.05\n        self.neighborhood_radius = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                local_best = self.find_local_best(i, positions, personal_best_scores)\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                    + np.random.rand(self.dim) * (local_best - positions[i]) \n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position\n\n    def find_local_best(self, index, positions, scores):\n        distances = np.linalg.norm(positions - positions[index], axis=1)\n        neighborhood_indices = np.where(distances < self.neighborhood_radius)[0]\n        if len(neighborhood_indices) > 1:\n            local_best_index = neighborhood_indices[np.argmin(scores[neighborhood_indices])]\n            return positions[local_best_index]\n        else:\n            return positions[index]", "configspace": "", "generation": 64, "feedback": "The algorithm AdaptiveQuantumMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01902 with standard deviation 0.01046.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.017642438853177733, 0.006951490755246925, 0.032460090774435124]}}
{"id": "21e0ddf6-cc5d-4ccb-be0a-ad5b73ff5a1d", "fitness": 0.031080282924647557, "name": "AdaptiveQuantumMemoryGuidedSwarmSearch", "description": "Integrate adaptive social coefficient and enhanced memory-based guidance for improved convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveQuantumMemoryGuidedSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.social_coeff_base = 1.5\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i] + np.random.normal(0, 0.1, self.dim) * (global_best_position - positions[i])\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = self.social_coeff_base + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1\n            self.social_coeff = min(2.0, self.social_coeff)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveQuantumMemoryGuidedSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03108 with standard deviation 0.01818.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.021874661181491617, 0.014895760054031704, 0.056470427538419354]}}
{"id": "10a6b7b6-a540-4131-8bd5-74aa47bc5803", "fitness": 0.05582402363220481, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce a dynamic quantum step size adjustment for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += (self.quantum_step + 0.01 * self.evaluations / self.budget) * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05582 with standard deviation 0.03788.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.09589225065271267, 0.06657982024390174]}}
{"id": "6c66cdcb-52c2-4583-bb9b-b6308954022c", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Improved convergence control by dynamically adjusting the quantum step size based on the best score.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05  # Original initial step size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n            # Change: Dynamically adjust quantum_step based on performance\n            self.quantum_step = 0.05 * (1 - (global_best_score / (np.min(personal_best_scores) + 1e-8)))\n\n        return global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "53ba9cfb-8935-4e90-9be6-69fb78ac0cc6", "fitness": 0.02066056916514251, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced dynamic cognitive and social coefficients based on iteration progress for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n            \n            # Adjust cognitive and social coefficients dynamically\n            self.cognitive_coeff = 1.5 + 0.5 * (self.evaluations / self.budget)\n            self.social_coeff = 1.5 - 0.5 * (self.evaluations / self.budget)\n\n        return global_best_position", "configspace": "", "generation": 68, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02066 with standard deviation 0.01343.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01919169304787105, 0.037790014447556475]}}
{"id": "4a923995-c14f-44ee-8b83-3ef6b06cb464", "fitness": 0.019171991605025435, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce adaptive cognitive coefficient to enhance local search capabilities dynamically.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n            \n            self.cognitive_coeff = 1.5 + 0.5 * np.random.rand()  # Adaptive cognitive coefficient\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 69, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01917 with standard deviation 0.01123.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.02005588404064118, 0.032460090774435124]}}
{"id": "142172ed-a58e-4b90-aa0e-ec5c5f222d21", "fitness": 0.03585593695116348, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Quantum-enhanced memory retention and exploration balance for adaptive swarm intelligence.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.15 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.2)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 70, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03586 with standard deviation 0.02185.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0499455315435412, 0.05262227930994923]}}
{"id": "a0fbe085-0d9c-4cef-99ea-3b8af7cccfd1", "fitness": 0.0744702913096047, "name": "EnhancedQuantumDiverseSwarmSearch", "description": "Integrating diversity enhancement and elite preservation for robust global exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumDiverseSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        elite_position = global_best_position\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Enhance exploration by dynamic social coefficient adjustment\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n            # Diversity enhancement\n            if np.std(positions, axis=0).mean() < self.diversity_threshold:\n                positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                elite_position = global_best_position\n\n            # Preserve elite solution\n            if func(elite_position) < global_best_score:\n                global_best_position = elite_position\n                global_best_score = func(elite_position)\n\n        return global_best_position", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedQuantumDiverseSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07447 with standard deviation 0.06479.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.16094053870713543, 0.05747033522167866]}}
{"id": "8920d60e-8092-42b7-a6aa-e976d8881397", "fitness": 0.07520320899585664, "name": "EnhancedAdaptiveQuantumSwarmSearch", "description": "Adaptive Memory-Enhanced Quantum Swarm Optimization with Dynamic Parameter Control for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.5:  # Randomly exploit the memory\n                        positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveQuantumSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "c3d6f08c-8784-4c9b-80d0-d26ee5022e00", "fitness": 0.023211514534107414, "name": "EnhancedQuantumMemorySwarmOptimizer", "description": "Introduce adaptive quantum swarm dynamics with memory-based perturbations for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedQuantumMemorySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.9) # Adjusted decay rate\n        self.quantum_step = 0.05\n        self.convergence_factor = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n            avg_position = np.mean(positions, axis=0)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                    + self.convergence_factor * np.random.rand(self.dim) * (avg_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Enhanced quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedQuantumMemorySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02321 with standard deviation 0.01288.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.03217445282788711, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "7427e38a-6076-48d9-9bc1-27364d469b53", "fitness": 0.02512191396124334, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Adaptive convergence balancing through dynamic swarm intelligence and elite retention.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n                    \n            # Enhanced elite retention strategy\n            elite_indices = np.argsort(personal_best_scores)[:5]\n            elite_positions = positions[elite_indices]\n            for pos in elite_positions:\n                mutated_elite = np.random.normal(pos, 0.1, self.dim)\n                positions = np.vstack((positions, np.clip(mutated_elite, lb, ub)))\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02512 with standard deviation 0.01931.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01919169304787105, 0.051174048835858965]}}
{"id": "0fbb036e-8658-4b49-8fbe-9c251ee17463", "fitness": 0.0237434066708991, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Improved quantum step size for enhanced exploration in diverse landscapes.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.1  # Modified quantum step size\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02374 with standard deviation 0.01326.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.033427890562446105, 0.03280232945025119]}}
{"id": "de237d3d-3e53-4771-aa20-78bdac900020", "fitness": 0.030745595453344692, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced a dynamic quantum step size to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += (self.quantum_step + self.evaluations/self.budget * 0.1) * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03075 with standard deviation 0.01851.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.04772125804123617, 0.0395155283187979]}}
{"id": "0cbebafb-250a-4e30-ad12-fd1844262e1b", "fitness": 0.01936603373096213, "name": "HybridQuantumEnhancedAdaptiveSwarm", "description": "Hybrid Quantum-Enhanced Adaptive Swarm with Dynamic Learning for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridQuantumEnhancedAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n        self.learning_rate = 0.1  # New learning rate for dynamic adjustment\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n            # Dynamic adjustment of cognitive and social coefficients\n            exploration_factor = np.mean(np.std(positions, axis=0)) / (np.std(global_best_position) + 1e-8)\n            self.cognitive_coeff = 1.5 + self.learning_rate * (1 - exploration_factor)\n            self.social_coeff = 1.5 - self.learning_rate * (1 - exploration_factor)\n\n        return global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm HybridQuantumEnhancedAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01937 with standard deviation 0.01125.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.020638010418451258, 0.032460090774435124]}}
{"id": "7a7ce3c0-7042-4b97-91d4-5399de5cb756", "fitness": 0.02505363363689339, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced adaptive quantum step size based on personal best scores to improve exploration.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update with adaptive step size\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                adaptive_quantum_step = self.quantum_step * (personal_best_scores[i] / (global_best_score + 1e-8))\n                positions[i][random_dim] += adaptive_quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02505 with standard deviation 0.01434.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.037700810136245044, 0.032460090774435124]}}
{"id": "deaf2460-96d6-4d09-9b29-b896e4fb6697", "fitness": 0.05153009087866026, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Enhance convergence by modifying the inertia weight decay strategy for more adaptive control.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.6)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05153 with standard deviation 0.03595.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.09253161711722901, 0.05705865551875178]}}
{"id": "83575cee-75f1-4837-8c7c-298939c1e54d", "fitness": 0.034327841971774554, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduced dynamic quantum step scaling to enhance global exploration capability.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n            \n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                self.quantum_step = 0.05 * (1 - (self.evaluations / self.budget))  # Dynamic quantum step scaling\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03433 with standard deviation 0.02320.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.06172269916253925, 0.036260826752784414]}}
{"id": "8ed23cdf-d304-4dbd-8aea-7d635cc07af5", "fitness": 0.07520320899585664, "name": "AdaptiveQuantumSwarmOptimizer", "description": "Adaptive Quantum-Inspired Swarm Optimization with Strategic Memory Reinforcement for enhanced convergence and diversity balance.", "code": "import numpy as np\n\nclass AdaptiveQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (self.inertia_weight - self.inertia_weight_min) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * r1 * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                perturbation_factor = 0.5 * (1 - self.evaluations / self.budget)\n                for i in range(self.population_size):\n                    positions[i] += perturbation_factor * np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 * (1 - self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "a77a20ac-bb9e-43d9-86fa-867b400d27cf", "fitness": -Infinity, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce adaptive velocity limits and dynamic topology for improved exploration and exploitation balance in swarm optimization.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n        self.velocity_limit = 0.2 * (func.bounds.ub - func.bounds.lb)  # Velocity limit based on search space\n        \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Apply velocity limits\n                velocities[i] = np.clip(\n                    velocities[i],\n                    -self.velocity_limit,\n                    self.velocity_limit\n                )\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 82, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {}}
{"id": "50a260f6-62ba-4c1c-bfe5-dae7f2457c8d", "fitness": 0.0710233052937815, "name": "QuantumSwarmHybridMemorySearch", "description": "Quantum-inspired swarm search with hybrid memory dynamics for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumSwarmHybridMemorySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.adaptive_quantum_step = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Enhanced quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    hybrid_step = np.random.rand() * (memory_best_position - positions[i]) + np.random.rand() * (global_best_position - positions[i])\n                    positions[i] += self.adaptive_quantum_step * hybrid_step / np.linalg.norm(hybrid_step)\n                    positions[i] = np.clip(positions[i], lb, ub)\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm QuantumSwarmHybridMemorySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07102 with standard deviation 0.06645.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0, 0.15983033055103757, 0.05323958533030693]}}
{"id": "3cfbc783-a867-4842-be7a-42aa1f64bd3f", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce an adaptive quantum-inspired mechanism leveraging historical best positions to enhance exploration and convergence speed.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Introduce an adaptive quantum-inspired update mechanism\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                quantum_shift = self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i][random_dim] += quantum_shift\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "f38f77b7-b91e-46a3-8c8a-0f23f23aa37f", "fitness": 0.014153363591478377, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introducing a differential evolution-inspired crossover operation for enhanced exploration and convergence control.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.crossover_rate = 0.7  # New crossover rate for differential evolution\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                # Differential evolution crossover operation\n                if np.random.rand() < self.crossover_rate:\n                    idxs = np.random.choice(np.arange(self.population_size), 3, replace=False)\n                    a, b, c = positions[idxs]\n                    mutant = a + 0.8 * (b - c)\n                    positions[i] = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, positions[i])\n                \n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "87f1a4a3-4134-48aa-ab66-a0dddf20d235", "fitness": 0.04845656780933986, "name": "HybridQuantumMomentumSearch", "description": "Hybrid Quantum Momentum Search with Adaptive Memory for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridQuantumMomentumSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.7  # Slightly increased for better social influence\n        self.mutation_rate = 0.1\n        self.memory_size = 10  # Increased memory size for better historical information\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.7)  # Adjusted decay rate\n        self.quantum_step = 0.05\n        self.momentum_factor = 0.2  # Introduced momentum factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        momentum = np.zeros((self.population_size, self.dim))\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                momentum[i] = self.momentum_factor * velocities[i] + (1 - self.momentum_factor) * momentum[i]\n                velocities[i] = (\n                    self.inertia_weight * momentum[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm HybridQuantumMomentumSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04846 with standard deviation 0.04128.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.016441405911324813, 0.022187736484494125, 0.10674056103220064]}}
{"id": "f6ee6961-160c-4ca4-b46b-7eb1ca40cddd", "fitness": 0.03118590270229508, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce adaptive quantum step to improve exploration capabilities dynamically.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                quantum_step_adaptive = self.quantum_step * (1 + 0.5 * np.sin(2 * np.pi * self.evaluations / self.budget))  # Adaptive quantum step\n                positions[i][random_dim] += quantum_step_adaptive * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03119 with standard deviation 0.01873.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.04772125804123617, 0.040836450065649066]}}
{"id": "0f8bc48b-204f-402f-bcb1-91d8f834facd", "fitness": 0.024831543793386257, "name": "AdaptiveQuantumExplorationSwarm", "description": "Utilize adaptive quantum-inspired exploration strategies with dynamic mutation and memory for improved convergence in complex optimization landscapes.", "code": "import numpy as np\n\nclass AdaptiveQuantumExplorationSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.05 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = 0.4 + 0.5 * np.sin(np.pi * self.evaluations / self.budget)\n            self.social_coeff = 1.5 + 0.5 * np.cos(np.pi * self.evaluations / self.budget)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    if np.random.rand() < 0.5:\n                        positions[i] += np.random.rand() * (memory_best_position - positions[i])\n                    else:\n                        positions[i] += np.random.rand() * (global_best_position - positions[i])\n\n            self.mutation_rate = 0.1 * (1 - self.evaluations / self.budget)\n\n        return global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveQuantumExplorationSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02483 with standard deviation 0.01415.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.03703454060572364, 0.032460090774435124]}}
{"id": "52ea6b1c-a556-438b-8e35-c92eabec7eff", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Quantum-inspired swarm search with enhanced elitism and adaptive parameters.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    # Ensure enhanced elitism by reducing random influence\n                    positions[i] += 0.5 * np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "15e68f83-4b38-4f72-82e3-ca1770735a99", "fitness": 0.006866550262869382, "name": "DynamicQuantumAdaptiveMemorySwarmSearchWithChaos", "description": "Integrating chaotic maps with quantum-inspired dynamics for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearchWithChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.chaos_map = self.init_chaos_map()\n\n    def init_chaos_map(self):\n        x = np.random.rand()\n        chaos_map = [x]\n        for _ in range(self.budget):\n            x = 4 * x * (1 - x)  # Logistic map\n            chaos_map.append(x)\n        return chaos_map\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                c1 = self.cognitive_coeff * self.chaos_map[self.evaluations]\n                c2 = self.social_coeff * self.chaos_map[self.evaluations]\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + c1 * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + c2 * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearchWithChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00687 with standard deviation 0.00213.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.009849712329877636, 0.005749938458730508, 0.0050000000000000044]}}
{"id": "9eb1e7c4-ef24-4cd8-a8a8-883ebe1e5cdf", "fitness": 0.035698961922648396, "name": "EnhancedLeaderAdaptiveMemorySwarmSearch", "description": "Incorporate leader-based adaptive control and elite preservation for enhanced convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedLeaderAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.leader_update_rate = 0.05\n        self.elite_preservation_rate = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n            # Elite preservation strategy\n            elite_count = int(self.elite_preservation_rate * self.population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            elite_positions = personal_best_positions[elite_indices]\n\n            # Update the leader position based on elite positions\n            if np.random.rand() < self.leader_update_rate:\n                global_best_position = np.mean(elite_positions, axis=0)\n                global_best_score = func(global_best_position)\n\n        return global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedLeaderAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03570 with standard deviation 0.02649.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.06963679499351005, 0.032460090774435124]}}
{"id": "00e6d822-839d-4527-957e-739724bb51e2", "fitness": 0.02993676058594304, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce velocity damping and adaptive mutation scaling for improved convergence precision.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Updated velocity equation with damping\n                velocities[i] = (\n                    0.95 * self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                # Adaptive mutation scaling based on global best score\n                if np.random.rand() < self.mutation_rate:\n                    mutation_scale = 0.1 * (1 - global_best_score / (np.mean(personal_best_scores) + 1e-8))\n                    mutation = np.random.normal(0, mutation_scale * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02994 with standard deviation 0.01768.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.04401900628721933, 0.04079127547060979]}}
{"id": "0da40ac9-6983-414f-a828-b38fa61de614", "fitness": 0.06202651490349368, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Integrate dynamic learning rates and memory-based perturbation strategies for enhanced adaptive behavior in variable environments.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        learning_rate_decay = 0.99\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n            self.cognitive_coeff *= learning_rate_decay\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    perturbation = np.random.randn(self.dim) * 0.1 * (memory_best_position - positions[i])\n                    positions[i] += perturbation\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 93, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06203 with standard deviation 0.04491.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.11475226688143336, 0.06632727782904768]}}
{"id": "a516ee72-8a6c-41aa-a63b-2501a59938ca", "fitness": 0.014153363591478377, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introduce adaptive inertia weight and social coefficient based on population diversity to enhance exploration-exploitation balance in dynamic environments.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            diversity = np.mean(np.std(positions, axis=0))\n            self.inertia_weight = 0.4 + 0.5 * (1 - diversity) # Adaptive inertia weight based on diversity\n            self.social_coeff = 1.5 + 0.5 * diversity # Adaptive social coefficient based on diversity\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "db55ea76-caf1-48d0-bb3b-a7e319934a0a", "fitness": 0.02680349807639763, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Integrate adaptive cognitive coefficient based on personal best improvements.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)  # Adjusted decay rate\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)  # Enhanced mutation\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    # Modify cognitive coefficient based on improvement\n                    self.cognitive_coeff = min(2.0, self.cognitive_coeff + 0.05)   \n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Implement quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02680 with standard deviation 0.01557.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.04038435215919034, 0.03502614207000254]}}
{"id": "9621177e-3f22-45c6-92f7-d437e5ee01e4", "fitness": 0.020374107060004754, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introducing adaptive memory-driven perturbations and multi-dimensional quantum leaps for enhanced global exploration.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            # Multi-dimensional quantum-inspired position update\n            for i in range(self.population_size):\n                for d in range(self.dim):\n                    if np.random.rand() < 0.1:  # Quantum leap probability\n                        positions[i][d] += self.quantum_step * np.sign(global_best_position[d] - positions[i][d])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    # Adaptive memory-driven perturbation\n                    if np.random.rand() < 0.5:  # Perturbation probability\n                        perturbation = np.random.rand() * (memory_best_position - positions[i])\n                        positions[i] += perturbation\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02037 with standard deviation 0.01145.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.023662230405579132, 0.032460090774435124]}}
{"id": "75a2061b-c619-4f3e-a3c4-111a23e89e63", "fitness": 0.03733706797374051, "name": "EnhancedDynamicQuantumAdaptiveMemorySwarmSearch", "description": "Introducing adaptive neighborhood search and chaotic initialization to enhance global exploration and convergence in DynamicQuantumAdaptiveMemorySwarmSearch.", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.neighborhood_radius = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Chaotic initialization\n        positions = lb + (ub - lb) * np.mod(np.random.rand(self.population_size, self.dim) + 0.5 * np.sin(np.pi * np.random.rand(self.population_size, self.dim)), 1)\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                # Adaptive neighborhood search\n                neighbors = positions[\n                    np.linalg.norm(positions - positions[i], axis=1) < self.neighborhood_radius\n                ]\n                if len(neighbors) > 0:\n                    positions[i] += np.mean(neighbors - positions[i], axis=0)\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedDynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03734 with standard deviation 0.02135.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.03535699271990722, 0.06441885114533308, 0.012235360055981248]}}
{"id": "695c0b7b-0f34-49f2-b02c-b44241f95c18", "fitness": 0.07520320899585664, "name": "DynamicQuantumAdaptiveMemorySwarmSearch", "description": "Dynamic Quantum Adaptive Swarm Search with Adaptive Social Cognition and Quantum Memory for enhanced convergence.", "code": "import numpy as np\n\nclass DynamicQuantumAdaptiveMemorySwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5  \n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            self.inertia_weight = max(0.4, self.inertia_weight - self.inertia_weight_decay)\n\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            best_memory_score = min(self.memory, key=lambda x: x[1])[1]\n            self.quantum_step = max(0.01, 0.05 * (1 - best_memory_score / (global_best_score + 1e-8)))\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm DynamicQuantumAdaptiveMemorySwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07520 with standard deviation 0.06560.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.1628305233159254, 0.057779103671644516]}}
{"id": "3866f774-ab9d-456d-854b-4b204e931138", "fitness": 0.04529558661545097, "name": "EnhancedDynamicQuantumSwarmSearch", "description": "Introduce dynamic inertia control and enhanced social memory infusion for improved convergence in volatile search spaces.  ", "code": "import numpy as np\n\nclass EnhancedDynamicQuantumSwarmSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.evaluations = 0\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.inertia_weight_decay = (0.9 - 0.4) / (self.budget * 0.8)\n        self.quantum_step = 0.05\n        self.dynamic_inertia_control = True\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        while self.evaluations < self.budget:\n            previous_global_best_position = np.copy(global_best_position)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    + self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1 * np.std(positions, axis=0), self.dim)\n                    positions[i] += mutation\n\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                self.evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            # Dynamic inertia control\n            if self.dynamic_inertia_control:\n                if np.std(personal_best_scores) < 0.01:\n                    self.inertia_weight = max(0.4, self.inertia_weight - 0.01)\n                else:\n                    self.inertia_weight = min(0.9, self.inertia_weight + 0.01)\n\n            # Quantum-inspired position update\n            for i in range(self.population_size):\n                random_dim = np.random.randint(self.dim)\n                positions[i][random_dim] += self.quantum_step * np.sign(global_best_position[random_dim] - positions[i][random_dim])\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if func(previous_global_best_position) < global_best_score:\n                global_best_position = previous_global_best_position\n\n            self.social_coeff = min(2.0, self.social_coeff + (global_best_score / (np.mean(personal_best_scores) + 1e-8)) * 0.1)\n\n            self.memory.append((global_best_position, global_best_score))\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n            \n            if len(self.memory) > 1:\n                memory_best_position = min(self.memory, key=lambda x: x[1])[0]\n                for i in range(self.population_size):\n                    positions[i] += np.random.rand() * (memory_best_position - positions[i])\n\n            self.mutation_rate = max(0.01, 0.1 - 0.09 * (self.evaluations / self.budget))\n\n        return global_best_position", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedDynamicQuantumSwarmSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04530 with standard deviation 0.02883.", "error": "", "parent_ids": ["37aca4f8-bc26-4f13-ba32-b58c7db4271a"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.07081402372017143, 0.06007273612618147]}}
