{"id": "3caf4749-967e-465e-8493-69a71b3b711f", "fitness": 0.02800000825283448, "name": "HybridPSO_GA", "description": "The algorithm combines particle swarm and genetic algorithms to explore and exploit the search space efficiently.", "code": "import numpy as np\n\nclass HybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.5   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02800 with standard deviation 0.01189.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.011797662605088188, 0.032194375754135085, 0.04000798639928016]}}
{"id": "2ec66a7c-8aa0-45f6-a14f-2a45f905bbb1", "fitness": 0.022114348270701762, "name": "EnhancedHybridPSO_GA", "description": "Incorporate a dynamic adjustment of key parameters (inertia weight, cognitive, and social parameters) and use differential evolution strategies for crossover to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.w = 0.9   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n        self.f = 0.8  # differential weight for mutation in DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adjust parameters dynamically\n            self.w = 0.9 - (0.5 * evaluations / self.budget)\n            self.c1 = 1.5 + (0.5 * evaluations / self.budget)\n            self.c2 = 1.5 - (0.5 * evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step with DE Crossover)\n            for i in range(0, self.population_size):\n                if np.random.rand() < self.cross_over_rate:\n                    indices = list(range(self.population_size))\n                    indices.remove(i)\n                    a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                    mutant = np.clip(a + self.f * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.cross_over_rate\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, population[i])\n                    population[i] = trial\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02211 with standard deviation 0.01242.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.02724916299146063, 0.0050000000000000044, 0.034093881820644656]}}
{"id": "bf2a9708-550e-4f18-9912-973f130a480f", "fitness": 0.019947060545699353, "name": "EnhancedHybridPSO_GA", "description": "Enhanced HybridPSO_GA with adaptive parameters and a local search component to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.0  # initial cognitive parameter\n        self.initial_c2 = 2.0  # initial social parameter\n        self.w = 0.9  # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n        self.local_search_rate = 0.2\n\n    def adaptive_parameters(self, evaluations):\n        \"\"\"Adapt parameters based on the number of evaluations.\"\"\"\n        progress = evaluations / self.budget\n        c1 = self.initial_c1 * (1 - progress) + 1.5 * progress\n        c2 = self.initial_c2 * progress + 1.5 * (1 - progress)\n        w = 0.9 - 0.5 * progress\n        return c1, c2, w\n\n    def local_search(self, individual, func, lb, ub):\n        \"\"\"Refine individual using a simple local search strategy.\"\"\"\n        for _ in range(int(self.local_search_rate * self.dim)):\n            candidate = individual + np.random.uniform(-0.1, 0.1, self.dim)\n            candidate = np.clip(candidate, lb, ub)\n            if func(candidate) < func(individual):\n                individual = candidate\n        return individual\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adapt parameters\n            c1, c2, w = self.adaptive_parameters(evaluations)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best - population) +\n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Local Search\n            for i in range(self.population_size):\n                population[i] = self.local_search(population[i], func, lb, ub)\n\n        return global_best, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01995 with standard deviation 0.01203.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.020384210378587064, 0.0050000000000000044, 0.03445697125851099]}}
{"id": "485d0850-492d-4bdc-93e7-b466cd6bd479", "fitness": 0.015041434515665123, "name": "EnhancedHybridPSO_GA", "description": "Integrate adaptive dynamic parameter tuning with the HybridPSO_GA to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5\n        self.initial_c2 = 0.5\n        self.w = 0.9\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            c1 = self.initial_c1 - ((self.initial_c1 - 1.5) * (evaluations / self.budget))\n            c2 = self.initial_c2 + ((2.5 - self.initial_c2) * (evaluations / self.budget))\n            \n            # Update velocities and population positions (Adaptive PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01504 with standard deviation 0.01420.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.03512430354699536]}}
{"id": "c4233621-3eca-4eb4-970e-e1122733cbdd", "fitness": 0.022621747772628376, "name": "AdaptiveHybridPSO_GA", "description": "Adaptive Hybrid PSO-GA algorithm with dynamic parameter tuning to enhance exploration and exploitation balance effectively.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.5\n        self.initial_c2 = 0.5\n        self.w = 0.5\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic adaptation of cognitive and social parameters\n            c1 = self.initial_c1 - (self.initial_c1 - 1.5) * (evaluations / self.budget)\n            c2 = self.initial_c2 + (2.0 - self.initial_c2) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02262 with standard deviation 0.01381.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.019966921534956827, 0.007189765185254382, 0.04070855659767392]}}
{"id": "813a2d30-4f7a-4ede-8e6f-6c077e474f3b", "fitness": 0.023002622301701952, "name": "AdaptiveHybridPSO_GA", "description": "An adaptive hybrid algorithm combining dynamic particle swarm optimization and genetic algorithm with adaptive parameters to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.0  # initial cognitive parameter\n        self.final_c1 = 0.5  # final cognitive parameter\n        self.initial_c2 = 0.5  # initial social parameter\n        self.final_c2 = 2.0  # final social parameter\n        self.w = 0.5   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Linearly interpolate c1 and c2 over time\n            progress = evaluations / self.budget\n            c1 = self.initial_c1 * (1 - progress) + self.final_c1 * progress\n            c2 = self.initial_c2 * (1 - progress) + self.final_c2 * progress\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size - 1, 2):  # Ensure an even number of pairs\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02300 with standard deviation 0.01356.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.006828079823061994, 0.02215797623305238, 0.04002181084899148]}}
{"id": "b815157c-bfb5-4055-9229-3cfd51d8526f", "fitness": 0.023813269809575544, "name": "HybridPSO_GA_Adaptive", "description": "The algorithm integrates adaptive inertia weight in PSO and dynamic mutation in GA to enhance convergence and diversity balance.", "code": "import numpy as np\n\nclass HybridPSO_GA_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.mutation_rate_initial = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust inertia weight\n            w = self.w_max - (evaluations / self.budget) * (self.w_max - self.w_min)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Dynamic Mutation\n            mutation_rate = self.mutation_rate_initial * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_GA_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02381 with standard deviation 0.00959.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.028544580635051386, 0.01043513801924012, 0.032460090774435124]}}
{"id": "6edcdca5-b2e2-4fc1-98f8-4a392a2cd549", "fitness": 0.019947060545699353, "name": "EnhancedHybridPSO_GA", "description": "The algorithm enhances the hybrid of PSO and GA by incorporating adaptive parameters and a dynamic mutation strategy to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.1\n        self.mutation_rate_final = 0.01\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.w = self.w_initial - progress * (self.w_initial - self.w_final)\n            self.c1 = self.c1_initial + progress * (2.0 - self.c1_initial)\n            self.c2 = self.c2_initial + progress * (2.0 - self.c2_initial)\n            self.mutation_rate = self.mutation_rate_initial - progress * (self.mutation_rate_initial - self.mutation_rate_final)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - population) +\n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01995 with standard deviation 0.01203.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.020384210378587064, 0.0050000000000000044, 0.03445697125851099]}}
{"id": "f906e67e-0785-4ce4-b4ba-57310fe53065", "fitness": 0.014153363591478377, "name": "ImprovedHybridPSO_GA", "description": "The algorithm introduces a dynamic adjustment of PSO parameters and adaptive genetic operator selection for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic adjustment of PSO parameters\n            progress = evaluations / self.budget\n            self.w = self.w_initial - (self.w_initial - self.w_final) * progress\n            self.c1 = self.c1_initial * (1 - progress)\n            self.c2 = self.c2_initial * progress\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best - population) +\n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Adaptive Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm ImprovedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "63ef10fe-c33f-49d8-8c52-e6ceb3645c56", "fitness": 0.027380557389997378, "name": "EnhancedHybridPSO_GA", "description": "Enhanced HybridPSO_GA with dynamic parameter adjustment and adaptive mutation to improve search efficiency and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.initial_c1 = 2.0\n        self.initial_c2 = 2.0\n        self.final_c1 = 0.5\n        self.final_c2 = 0.5\n        self.w = 0.5\n        self.initial_mutation_rate = 0.3\n        self.final_mutation_rate = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adapt parameters\n            t = evaluations / self.budget\n            c1 = self.initial_c1 * (1 - t) + self.final_c1 * t\n            c2 = self.initial_c2 * (1 - t) + self.final_c2 * t\n            mutation_rate = self.initial_mutation_rate * (1 - t) + self.final_mutation_rate * t\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities +\n                          c1 * r1 * (personal_best - population) +\n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Adaptive Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02738 with standard deviation 0.01044.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.026807215116178784, 0.014890197939573802, 0.040444259114239545]}}
{"id": "462eff5c-d6d8-4ea3-b4f6-b696247d701c", "fitness": 0.019453196237631715, "name": "EnhancedHybridPSO_GA", "description": "The algorithm integrates a dynamic adjustment of parameters and a differential evolution step to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.5   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n        self.f = 0.5    # differential weight\n        self.cr = 0.9   # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust parameters\n            self.w = 0.9 - 0.4 * (evaluations / self.budget)\n            self.c1 = 1.5 + (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                idxs = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = np.clip(a + self.f * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                if trial_score < scores[i]:\n                    population[i] = trial\n                    scores[i] = trial_score\n\n        return global_best, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01945 with standard deviation 0.00960.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.016333412410959758, 0.009566085527500268, 0.032460090774435124]}}
{"id": "225b7f01-3225-4952-84b6-b2d8e9e4de5e", "fitness": 0.024375567541230492, "name": "EnhancedHybridPSO_GA", "description": "Enhanced HybridPSO_GA with adaptive parameters and elite preservation to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # adaptive cognitive parameter\n        self.c2 = 2.0  # adaptive social parameter\n        self.w_init = 0.9  # initial inertia weight\n        self.w_final = 0.4  # final inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        num_elites = int(self.elite_fraction * self.population_size)\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Sort population based on scores for elitism\n            elite_indices = np.argsort(scores)[:num_elites]\n            elites = population[elite_indices]\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Preserve elites\n            population[:num_elites] = elites\n\n        return global_best, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02438 with standard deviation 0.02003.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.016163628940807917, 0.051963073682883554]}}
{"id": "ad5f4e5a-4eb6-4390-95f6-db0f8913505c", "fitness": 0.020010211362018044, "name": "AdaptiveHybridPSO_GA", "description": "Adaptive Hybrid PSO-GA with dynamic learning, leveraging adaptive parameters and elitism strategy to enhance convergence and solution quality.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.5   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        evaluations = self.population_size\n        elite_ratio = 0.2\n        elite_size = int(self.population_size * elite_ratio)\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            self.w = 0.9 - 0.4 * (evaluations / self.budget)\n            self.c1 = 1.5 + 1.0 * (evaluations / self.budget)\n            self.c2 = 1.5 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Elitism\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_population = personal_best[elite_indices]\n\n            # Crossover\n            for i in range(0, self.population_size - elite_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Reintroduce the elite back into the population\n            population[:elite_size] = elite_population\n\n        return global_best, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02001 with standard deviation 0.01136.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.022570543311619007, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "8debbc14-835a-40fd-b47b-f08e5cca4ec5", "fitness": 0.023813269809575544, "name": "HybridPSO_GA", "description": "Enhancing HybridPSO_GA by introducing adaptive inertia weight and crowding distance for diversity maintenance.", "code": "import numpy as np\n\nclass HybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w_max = 0.9  # adaptive inertia weight\n        self.w_min = 0.4  # adaptive inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight based on current evaluations\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02381 with standard deviation 0.00959.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.028544580635051386, 0.01043513801924012, 0.032460090774435124]}}
{"id": "346981e8-973b-4aa5-919d-e5f696029e62", "fitness": 0.021929284065339782, "name": "ImprovedHybridPSO_GA", "description": "The algorithm enhances exploration-exploitation balance by dynamically adjusting cognitive and social parameters based on convergence rate.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w = 0.7\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        iterations = 0\n\n        while evaluations < self.budget:\n            # Dynamic adjustment of cognitive and social parameters\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm ImprovedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02193 with standard deviation 0.01276.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.024978447498114176, 0.03580940469790517]}}
{"id": "8869c997-3d2e-4417-96f2-bd37e81b8879", "fitness": 0.02800000825283448, "name": "HybridPSO_GA", "description": "The algorithm combines particle swarm and genetic algorithms, with a refined strategy incorporating adaptive mutation rates based on search progress to explore and exploit the search space efficiently.", "code": "import numpy as np\n\nclass HybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.5   # inertia weight\n        self.initial_mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Adaptive Mutation\n            mutation_rate = self.initial_mutation_rate * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02800 with standard deviation 0.01189.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.011797662605088188, 0.032194375754135085, 0.04000798639928016]}}
{"id": "65bb201b-0aa1-4e78-840c-3e8d74aa1664", "fitness": 0.023813269809575544, "name": "HybridPSO_GA", "description": "The algorithm combines particle swarm and genetic algorithms to explore and exploit the search space, with an adaptive inertia weight for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.5   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02381 with standard deviation 0.00959.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.028544580635051386, 0.01043513801924012, 0.032460090774435124]}}
{"id": "dd7fbb37-c125-464e-9981-c6acb0cbe6cf", "fitness": 0.023813269809575544, "name": "ImprovedHybridPSO_GA", "description": "The algorithm utilizes adaptive inertia and mutation rates dynamically adjusted based on convergence speed to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.9   # initial inertia weight, adaptive\n        self.mutation_rate = 0.1  # initial mutation rate, adaptive\n        self.cross_over_rate = 0.7\n        self.min_w = 0.4\n        self.max_w = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        prev_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            # Adjust inertia weight dynamically based on progress\n            self.w = self.min_w + (self.max_w - self.min_w) * (1 - evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Adjust mutation rate based on convergence speed\n            convergence_speed = np.abs(prev_global_best_score - global_best_score)\n            self.mutation_rate = 0.1 * (1 - (convergence_speed / (1 + convergence_speed)))\n            prev_global_best_score = global_best_score\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size - 1, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm ImprovedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02381 with standard deviation 0.00959.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.028544580635051386, 0.01043513801924012, 0.032460090774435124]}}
{"id": "151e2fbe-4076-4bdf-9089-63cfb7c94fd6", "fitness": 0.023813269809575544, "name": "HybridPSO_GA", "description": "Enhance exploration by dynamically adjusting the inertia weight over iterations in the HybridPSO_GA algorithm.", "code": "import numpy as np\n\nclass HybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.w = 0.5   # inertia weight\n        self.mutation_rate = 0.1\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust the inertia weight\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.w * velocities + \n                          self.c1 * r1 * (personal_best - population) + \n                          self.c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02381 with standard deviation 0.00959.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.028544580635051386, 0.01043513801924012, 0.032460090774435124]}}
{"id": "ef4dc621-c4c8-464d-8765-0865b812caa7", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters and a dynamic mutation rate to enhance exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["3caf4749-967e-465e-8493-69a71b3b711f"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "9ecd4a86-5992-4aec-8722-ed17d786d402", "fitness": 0.02532721568013389, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters, a dynamic mutation rate, and an enhanced crossover strategy to improve exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Enhanced Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point1, cross_point2 = sorted(np.random.randint(1, self.dim, size=2))\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point1], parent2[cross_point1:cross_point2], parent1[cross_point2:]])\n                    child2 = np.concatenate([parent2[:cross_point1], parent1[cross_point1:cross_point2], parent2[cross_point2:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02533 with standard deviation 0.01083.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.01993817491197125, 0.01560504604666424, 0.04043842608176618]}}
{"id": "87bdd88e-9cdf-4943-9de3-2f4b450efa88", "fitness": 0.026135093113755652, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm combines adaptive swarm dynamics with a self-adaptive mutation rate and elitist selection to improve convergence and solution quality in a hybrid PSO-GA framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elitism_rate = 0.1  # Percentage of elite individuals to retain\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            elite_count = max(1, int(self.population_size * self.elitism_rate))\n            elites = population[np.argsort(scores)[:elite_count]]\n\n            for i in range(0, self.population_size - elite_count, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            population[:elite_count] = elites\n\n        return global_best, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02614 with standard deviation 0.00813.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.03129328211978788, 0.01465190644704395, 0.032460090774435124]}}
{"id": "dd6b7f34-c71e-49b5-b492-d06d4508b8c5", "fitness": 0.019897765748191427, "name": "EnhancedDynamicPSO_GA", "description": "EnhancedDynamicPSO_GA introduces nonlinear parameter adaptation and a multi-point crossover strategy to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedDynamicPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Nonlinear adaptation for inertia weight and mutation rate\n            fraction = (evaluations / self.budget) ** 2\n            w = self.w_initial - (self.w_initial - self.w_final) * fraction\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * fraction\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          self.c1_initial * r1 * (personal_best - population) +\n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Multi-point Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    parent1, parent2 = population[i], population[i + 1]\n                    mask = np.random.rand(self.dim) < 0.5\n                    child1 = np.where(mask, parent1, parent2)\n                    child2 = np.where(~mask, parent1, parent2)\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedDynamicPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01990 with standard deviation 0.01154.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.021571185246904268, 0.0050000000000000044, 0.03312211199767001]}}
{"id": "7d98dbf0-4fa3-4f5c-b330-fdaeb025081c", "fitness": 0.017784911703826862, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm enhances exploration by employing a nonlinear decay for inertia weight and mutation rate, fostering a robust balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Nonlinearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * ((evaluations / self.budget) ** 2)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * ((evaluations / self.budget) ** 2)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01778 with standard deviation 0.01129.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.01589464433704546, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "f66536b9-20b7-4ba6-a8c2-16f0e2954e70", "fitness": 0.01516276493758902, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Introduce a non-linear adaptive inertia weight and mutation schedule with elitism preservation to enhance the exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elitism = 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Non-linear adapt inertia weight and mutation rate\n            w = self.w_final + (self.w_initial - self.w_final) * np.exp(-5 * evaluations / self.budget)\n            mutation_rate = self.mutation_rate_final + (self.mutation_rate_initial - self.mutation_rate_final) * np.exp(-5 * evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Elitism - preserve the best individuals\n            elite_indices = np.argsort(scores)[:self.elitism]\n            elites = population[elite_indices]\n\n            # Crossover\n            for i in range(0, self.population_size - self.elitism, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Insert elites back into the population\n            population[-self.elitism:] = elites\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01516 with standard deviation 0.01229.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.008028204038331932, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "a81a907f-3142-4c99-929e-2a599bc2d867", "fitness": 0.014169173257660058, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm dynamically balances exploration and exploitation through adaptive velocity limits and a multi-point crossover mechanism to improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.velocity_limit = 0.2  # cap for velocity to prevent large jumps\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            velocities = np.clip(velocities, -self.velocity_limit, self.velocity_limit)\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Multi-point Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    points = np.random.choice(self.dim, 2, replace=False)\n                    points.sort()\n                    cut1, cut2 = points\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cut1], parent2[cut1:cut2], parent1[cut2:]])\n                    child2 = np.concatenate([parent2[:cut1], parent1[cut1:cut2], parent2[cut2:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01417 with standard deviation 0.01293.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.005047428998545045, 0.032460090774435124]}}
{"id": "c2d8ea35-5b27-4da2-8ae9-93c23ac20616", "fitness": 0.027783611380477136, "name": "RefinedAdaptiveHybridPSO_GA", "description": "The algorithm combines time-varying adaptive parameters in PSO and Bayesian-inspired mutation guidance to enhance convergence and solution quality.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            \n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Bayesian-inspired Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = global_best + np.random.normal(0, (ub - lb) * mutation_rate, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm RefinedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02778 with standard deviation 0.02146.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.021803054462509963, 0.05654777967892144]}}
{"id": "8e78d7b8-a961-4ff5-bec1-57e58cfa1e43", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA_Elitism", "description": "This algorithm enhances exploration and exploitation by adaptively adjusting the swarm parameters and incorporating elitism in the genetic algorithm step.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA_Elitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n            \n            # Elitism: Retain the best individual in the population\n            population[np.argmax(scores)] = global_best\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveHybridPSO_GA_Elitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "6bae0430-0699-4347-81f4-3c0d5ba04859", "fitness": 0.017370665740493025, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Introduce dynamic dimensional mutation and adaptive crossover strategies to enhance convergence and diversify the search space in AdaptiveHybridPSO_GA.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            crossover_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Adaptive Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < crossover_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Dynamic Dimensional Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            # Vary mutation extent depending on dimension proximity to solution\n            mutation_extent = np.abs(population - global_best) / (ub - lb)\n            mutation_values = population + np.where(mutation_mask, mutation_values * mutation_extent, 0)\n            population = np.clip(mutation_values, lb, ub)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "51f62d74-3bea-4304-92bf-190021aadb3b", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm adjusts crossover dynamically based on convergence speed to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9  # New final crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)  # Dynamic crossover rate\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "5ee9d58d-7af2-4a36-8aac-d17c2e041be4", "fitness": 0.022295343016384583, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm refines the mutation strategy by introducing a Gaussian mutation step to improve diversity and exploration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation with Gaussian step\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.normal(0, (ub-lb)/10, (self.population_size, self.dim))\n            population = np.where(mutation_mask, population + mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02230 with standard deviation 0.00826.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.01665586627727833, 0.016253615540831046, 0.033976547231044374]}}
{"id": "ef7be8e6-5fab-482f-8aa7-c16efe658186", "fitness": 0.02763692465197513, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm introduces a non-linear adaptive mutation rate and a decaying cognitive parameter, optimizing the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.c1_initial *= 0.99  # Decaying the cognitive parameter\n\n            # Non-linear adaptive mutation rate\n            mutation_rate = self.mutation_rate_initial * (1 - (evaluations / self.budget)**2)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02764 with standard deviation 0.00928.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.035798776734446314, 0.01465190644704395, 0.032460090774435124]}}
{"id": "4106adc8-2ccd-4b11-833f-7a26c1655f2d", "fitness": 0.017370665740493025, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm enhances exploration by randomly perturbing the global best with a small chance during the PSO step.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Randomly perturb the global best with a small chance\n            if np.random.rand() < 0.01:\n                global_best += np.random.normal(0, 0.1, self.dim)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "9b15515e-82bc-4b38-a7bb-afaf4437e30e", "fitness": 0.03486767870064041, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm combines adaptive inertia, dynamic crossover and mutation rates, and a diversity-enhancing restart mechanism to improve convergence and prevent premature stagnation in the optimization process.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.85\n        self.restart_threshold = 0.1  # threshold for stagnation detection\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n        last_improvement = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n                last_improvement = evaluations\n\n            # Detect stagnation and restart if needed\n            if evaluations - last_improvement > self.restart_threshold * self.budget:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                last_improvement = evaluations\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "2b3d2f72-43dc-4558-a5f4-6cc0756704bd", "fitness": 0.02234296637160893, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "EnhancedAdaptiveHybridPSO_GA: Incorporates a dynamic neighborhood topology and adaptive selection pressure to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.neighborhood_size = 5  # size of the neighborhood for local best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            for i in range(self.population_size):\n                local_best = self._get_local_best(population, personal_best_scores, i)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1_initial * r1 * (personal_best[i] - population[i]) +\n                                 self.c2_initial * r2 * (local_best - population[i]))\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            self._apply_crossover(population, lb, ub)\n            self._apply_mutation(population, mutation_rate, lb, ub)\n\n            t += 1\n\n        return global_best, global_best_score\n\n    def _get_local_best(self, population, personal_best_scores, index):\n        # Determine the neighbors indices\n        neighbors_indices = [(index + i) % self.population_size for i in range(-self.neighborhood_size//2, self.neighborhood_size//2 + 1)]\n        # Get the best among the neighbors\n        local_best_index = neighbors_indices[np.argmin(personal_best_scores[neighbors_indices])]\n        return population[local_best_index]\n\n    def _apply_crossover(self, population, lb, ub):\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.cross_over_rate:\n                cross_point = np.random.randint(1, self.dim)\n                parent1, parent2 = population[i], population[i + 1]\n                child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                population[i], population[i + 1] = child1, child2\n\n    def _apply_mutation(self, population, mutation_rate, lb, ub):\n        mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n        mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        np.copyto(population, np.where(mutation_mask, mutation_values, population))", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02234 with standard deviation 0.01411.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.022457209642129383, 0.0395716894726974]}}
{"id": "65f55ede-afda-49ef-a238-48b5dcdf9795", "fitness": -Infinity, "name": "AdaptiveHybridPSO_GA", "description": "Integrate adaptive swarm parameters and a dynamic mutation rate, while modifying the crossover point selection to enhance exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim - 1)  # Ensure cross_point is not at the boundary\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 35, "feedback": "An exception occurred: ValueError('low >= high').", "error": "ValueError('low >= high')", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "9cbf0536-31cf-4db9-8d36-86fbbcb70b34", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Enhance the AdaptiveHybridPSO_GA by introducing a self-adaptive mechanism that dynamically adjusts the population size and incorporates a local search step to refine solutions.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = 50\n        self.min_population_size = 20\n        self.max_population_size = 100\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.local_search_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.init_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            for i in range(0, population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            if np.random.rand() < self.local_search_rate:\n                for i in range(population_size):\n                    if np.random.rand() < self.local_search_rate:\n                        perturbation = np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(population[i] + perturbation, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < scores[i]:\n                            population[i] = candidate\n                            scores[i] = candidate_score\n\n            population_size = min(max(self.min_population_size, population_size + int(np.random.normal(0, 5))), self.max_population_size)\n            population = population[:population_size, :]\n            velocities = velocities[:population_size, :]\n            personal_best = personal_best[:population_size, :]\n            personal_best_scores = personal_best_scores[:population_size]\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 36, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (53,2) (50,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (53,2) (50,2) ')", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "3a973663-b7c7-41c9-b71b-096850041810", "fitness": 0.017370665740493025, "name": "AdaptiveHybridPSO_GA_WithElitism", "description": "AdaptiveHybridPSO_GA_WithElitism: Enhances the original algorithm by incorporating elitism and dynamic population resizing to maintain diversity and accelerate convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA_WithElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_count = 5  # Number of elite individuals to carry over\n        self.dynamic_pop = True  # Enable dynamic population resizing\n        self.min_population_size = 20  # Minimum population size for dynamic resizing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Elitism: Retain best individuals\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_count]\n            elite_individuals = personal_best[elite_indices]\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Reintroduce elite individuals\n            population[:self.elite_count] = elite_individuals\n\n            # Dynamic population size adjustment\n            if self.dynamic_pop and evaluations / self.budget > 0.5:\n                adjusted_size = max(self.min_population_size, self.population_size - t // 2)\n                if adjusted_size < self.population_size:\n                    indices = np.argsort(scores)[:adjusted_size]\n                    population = population[indices]\n                    velocities = velocities[indices]\n                    personal_best = personal_best[indices]\n                    personal_best_scores = personal_best_scores[indices]\n                    self.population_size = adjusted_size\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveHybridPSO_GA_WithElitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "d042c4a3-7169-4ee2-bb63-42506adb0f3a", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters and a dynamic mutation rate to enhance exploration and exploitation during the optimization process, with an increased crossover rate for improved diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.8  # Increased crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "a5a40f3a-1132-48b2-809d-e2798e9025d4", "fitness": 0.02532721568013389, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm optimizes convergence by dynamically adjusting the crossover rate based on population diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            # Dynamically adapt crossover rate based on diversity measure (variance in scores)\n            diversity = np.var(scores)\n            cross_over_rate = self.cross_over_rate_initial * (1 - diversity / (np.max(scores) - np.min(scores)))\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02533 with standard deviation 0.01083.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.01993817491197125, 0.01560504604666424, 0.04043842608176618]}}
{"id": "4b55d5b0-b0de-45db-842b-72071cd48273", "fitness": 0.0182279499084184, "name": "AdaptiveDynamicPSO_GA", "description": "The algorithm introduces a dynamic learning strategy that adapts the cognitive and social parameters based on the population's diversity to enhance convergence and robustness.", "code": "import numpy as np\n\nclass AdaptiveDynamicPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Calculate diversity\n            diversity = np.mean(np.std(population, axis=0))\n\n            # Adapt cognitive and social parameters based on diversity\n            c1 = self.c1_initial + (1.5 - self.c1_initial) * (diversity / np.max(diversity))\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (1 - diversity / np.max(diversity))\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveDynamicPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01823 with standard deviation 0.01252.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.03503194327821124]}}
{"id": "7c7d697e-8664-4ac8-a9cf-c3103c82c943", "fitness": 0.020710681492491816, "name": "RefinedHybridPSO_GA", "description": "Enhance exploration and exploitation by incorporating dynamic neighborhood topology and elitist selection strategies in the hybrid PSO-GA framework.", "code": "import numpy as np\n\nclass RefinedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elitism_rate = 0.1  # Elitism rate to retain the top performers\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Dynamic neighborhood topology\n            neighborhood_size = max(2, int(self.population_size * 0.3))\n            for i in range(self.population_size):\n                neighbors_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best = personal_best[neighbors_indices[np.argmin(personal_best_scores[neighbors_indices])]]\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] + \n                                 self.c1_initial * r1 * (personal_best[i] - population[i]) + \n                                 self.c2_initial * r2 * (local_best - population[i]))\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            \n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators\n            elite_size = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_individuals = population[elite_indices]\n            \n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Retain elite individuals\n            population[:elite_size] = elite_individuals\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm RefinedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02071 with standard deviation 0.02084.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.006975223244456985, 0.0050000000000000044, 0.050156821233018456]}}
{"id": "b26526e6-96d9-40a3-bf5b-36f373f60d8e", "fitness": 0.017784911703826862, "name": "AdaptiveHybridPSO_GA", "description": "Enhancing convergence by introducing a non-linear inertia weight adaptation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Non-linear adaptation of inertia weight\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget) ** 2\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01778 with standard deviation 0.01129.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.01589464433704546, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "f7ac590f-05e7-4d26-a392-649781b2c2ec", "fitness": 0.017275140430286145, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "EnhancedAdaptiveHybridPSO_GA combines adaptive parameters with dynamic multi-population and elite preservation strategies to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.sub_population_size = 10\n        self.num_sub_populations = self.population_size // self.sub_population_size\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_preservation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Divide population into sub-populations\n            sub_populations = np.array_split(population, self.num_sub_populations)\n            sub_velocities = np.array_split(velocities, self.num_sub_populations)\n            sub_personal_best = np.array_split(personal_best, self.num_sub_populations)\n            sub_personal_best_scores = np.array_split(personal_best_scores, self.num_sub_populations)\n\n            for i in range(self.num_sub_populations):\n                sub_pop = sub_populations[i]\n                sub_vel = sub_velocities[i]\n                sub_pbest = sub_personal_best[i]\n                sub_pbest_scores = sub_personal_best_scores[i]\n\n                # Update velocities and positions (PSO Step)\n                r1, r2 = np.random.rand(self.sub_population_size, self.dim), np.random.rand(self.sub_population_size, self.dim)\n                sub_vel = (w * sub_vel + \n                           self.c1_initial * r1 * (sub_pbest - sub_pop) + \n                           self.c2_initial * r2 * (global_best - sub_pop))\n                sub_pop += sub_vel\n                sub_pop = np.clip(sub_pop, lb, ub)\n\n                # Evaluate sub-population\n                sub_scores = np.array([func(ind) for ind in sub_pop])\n                evaluations += self.sub_population_size\n\n                # Update personal best and global best\n                improved = sub_scores < sub_pbest_scores\n                sub_pbest[improved] = sub_pop[improved]\n                sub_pbest_scores[improved] = sub_scores[improved]\n                if min(sub_scores) < global_best_score:\n                    global_best = sub_pop[np.argmin(sub_scores)]\n                    global_best_score = min(sub_scores)\n\n                # Apply Genetic Operators (GA Step)\n                # Crossover\n                for j in range(0, self.sub_population_size, 2):\n                    if np.random.rand() < self.cross_over_rate:\n                        cross_point = np.random.randint(1, self.dim)\n                        parent1, parent2 = sub_pop[j], sub_pop[j + 1]\n                        child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                        child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                        sub_pop[j], sub_pop[j + 1] = child1, child2\n\n                # Mutation\n                mutation_mask = np.random.rand(self.sub_population_size, self.dim) < mutation_rate\n                mutation_values = np.random.uniform(lb, ub, (self.sub_population_size, self.dim))\n                sub_pop = np.where(mutation_mask, mutation_values, sub_pop)\n\n                # Update sub-population\n                sub_populations[i] = sub_pop\n                sub_velocities[i] = sub_vel\n                sub_personal_best[i] = sub_pbest\n                sub_personal_best_scores[i] = sub_pbest_scores\n\n            # Merge sub-populations\n            population = np.vstack(sub_populations)\n            velocities = np.vstack(sub_velocities)\n            personal_best = np.vstack(sub_personal_best)\n            personal_best_scores = np.concatenate(sub_personal_best_scores)\n\n            # Elite Preservation\n            elite_count = int(self.population_size * self.elite_preservation_rate)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            elite_population = personal_best[elite_indices]\n            population[:elite_count] = elite_population\n\n        return global_best, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01728 with standard deviation 0.01140.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.014365330516423302, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "2e871d07-335a-47c1-9e4a-19eb56d4db68", "fitness": 0.018262324363195043, "name": "AdaptiveHybridPSO_GA", "description": "This algorithm integrates adaptive swarm parameters with a dynamic mutation rate, enhanced by a cosine inertia weight update to improve exploration and exploitation efficiency.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Cosine adapt inertia weight and linearly adapt mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (1 - (np.cos(t * np.pi / (self.budget // self.population_size)) + 1) / 2)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01826 with standard deviation 0.01123.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.017326882315150005, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "424c022f-f244-4218-8312-a60560bfddc5", "fitness": 0.03486767870064041, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm introduces a dynamic population size adjustment mechanism and adaptive crossover strategies to enhance convergence efficiency during optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9  # increasing crossover rate over time\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Dynamic population size adjustment\n            if t % 10 == 0 and self.population_size < 2 * self.initial_population_size:\n                additional_pop_size = min(10, self.initial_population_size - self.population_size)\n                additional_population = np.random.uniform(lb, ub, (additional_pop_size, self.dim))\n                additional_velocities = np.random.uniform(-1, 1, (additional_pop_size, self.dim))\n                population = np.vstack([population, additional_population])\n                velocities = np.vstack([velocities, additional_velocities])\n                personal_best = np.vstack([personal_best, additional_population])\n                personal_best_scores = np.concatenate([personal_best_scores, [func(ind) for ind in additional_population]])\n                self.population_size += additional_pop_size\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "ac3ea82f-eeb6-4d75-9c62-461ded20d59d", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters and a dynamic mutation rate with a refined crossover mechanism to enhance exploration and exploitation during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.8  # Changed from 0.7 to 0.8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "eaf21e86-a586-403b-94ff-ec81bfcfa2b8", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Integrating adaptive swarm parameters and dynamic mutation rates with enhanced crossover strategies for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.8  # Increased crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "cf04e9f5-84c1-4317-93ad-8af8645c2412", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm introduces adaptive learning rates and elitism into the hybrid PSO-GA framework to enhance convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elitism_rate = 0.1  # percentage of elitism\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        num_elites = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            # Adaptive parameters\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            c1 = self.c1_initial * (1 - evaluations / self.budget)\n            c2 = self.c2_initial * (evaluations / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators\n            # Crossover with elitism\n            indices = np.argsort(scores)\n            elites = population[indices[:num_elites]]\n            \n            for i in range(num_elites, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n            \n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Reinsert elites\n            population[:num_elites] = elites\n\n        return global_best, global_best_score", "configspace": "", "generation": 48, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "6e842bf7-0468-4921-bccf-4b6ede7f2780", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Introduce adaptive inertia and learning rates for enhanced convergence, combined with elitist selection and multi-point crossover to boost exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.c1_final = 0.5\n        self.c2_final = 2.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            c1 = self.c1_initial - (self.c1_initial - self.c1_final) * (evaluations / self.budget)\n            c2 = self.c2_initial + (self.c2_final - self.c2_initial) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            num_elites = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(scores)[:num_elites]\n            elites = population[elite_indices]\n\n            for i in range(num_elites, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    parents = np.random.choice(num_elites, 2, replace=False)\n                    parent1, parent2 = elites[parents[0]], elites[parents[1]]\n                    cross_points = np.sort(np.random.choice(self.dim, 2, replace=False))\n                    child1 = np.concatenate([parent1[:cross_points[0]], parent2[cross_points[0]:cross_points[1]], parent1[cross_points[1]:]])\n                    child2 = np.concatenate([parent2[:cross_points[0]], parent1[cross_points[0]:cross_points[1]], parent2[cross_points[1]:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 49, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "8e349e7c-e43a-4f81-9ff2-f3bbb93777ac", "fitness": 0.017961599839813713, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm enhances exploration by introducing randomness in the cognitive parameter of the PSO, improving adaptability to dynamic landscapes.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            c1 = self.c1_initial * np.random.uniform(0.8, 1.2, self.population_size)[:, None]  # Modified line\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01796 with standard deviation 0.01074.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.006772802297962066, 0.01465190644704395, 0.032460090774435124]}}
{"id": "b923ae6e-fda2-4d1d-8b16-52209d293ab9", "fitness": 0.006249301130759277, "name": "ChaoticallyAugmentedPSO_GA", "description": "The algorithm combines chaotic maps to enhance the exploration-exploitation balance of PSO-GA by diversifying search dynamics.", "code": "import numpy as np\n\nclass ChaoticallyAugmentedPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.chaos_map = np.random.rand()  # Initialize chaotic map\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Apply chaotic perturbation to diversify search\n            self.chaos_map = self.logistic_map(self.chaos_map)\n            chaotic_perturbation = 0.01 * (self.chaos_map - 0.5)\n            population += chaotic_perturbation\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm ChaoticallyAugmentedPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00625 with standard deviation 0.00177.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.008747903392277823]}}
{"id": "d49504d6-d744-42f4-b255-b654773c545e", "fitness": 0.014153363591478377, "name": "AdaptiveHybridPSO_GA", "description": "Introduce self-adaptive velocity control and elitism to enhance convergence and solution diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Adapt learning factors based on progress\n            c1 = self.c1_initial * (1 - evaluations / self.budget)\n            c2 = self.c2_initial * (evaluations / self.budget)\n            \n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Elitism: preserve best solution in next generation\n            if evaluations + self.population_size <= self.budget:\n                population[np.argmax(scores)] = global_best\n\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "83c41302-4bd6-410a-9505-fca01747b05a", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Integrating adaptive swarm parameters with dynamic mutation and crossover rates to enhance both exploration and exploitation during optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7  # Initial crossover rate\n        self.cross_over_rate_final = 0.1    # Final crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial - (self.cross_over_rate_initial - self.cross_over_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "9b52a676-04cd-45f9-b3b5-b127018d2270", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm refines the balance between exploration and exploitation by adjusting the crossover rate dynamically based on the iteration progress.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9  # Increased final cross_over_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "3f3e6710-26db-4cc3-9798-90a9d1b8cab3", "fitness": 0.018341684333563462, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters and a dynamic mutation rate to enhance exploration and exploitation, with momentum introduced into velocity updates for improved convergence stability.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            momentum = 0.1  # Introduce momentum to the velocity update\n            velocities = (momentum * velocities + w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01834 with standard deviation 0.01122.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.017564962226255254, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "166b90af-5ac2-495e-8203-0f75a78d270a", "fitness": 0.012444054555796632, "name": "ImprovedAdaptiveHybridPSO_GA", "description": "The algorithm combines adaptive swarm intelligence with a dynamically evolving genetic algorithm to enhance exploration and exploitation through adaptive learning factors and a refined mutation strategy.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.fitness_sharing_sigma = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation with fitness sharing\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Implement fitness sharing to promote diversity\n            shared_fitness = np.zeros(self.population_size)\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    distance = np.linalg.norm(population[i] - population[j])\n                    if distance < self.fitness_sharing_sigma:\n                        shared_fitness[i] += 1 - (distance / self.fitness_sharing_sigma)\n\n            scores = scores / (shared_fitness + 1e-8)  # Adjust scores based on shared fitness\n            evaluations += self.population_size\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm ImprovedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01244 with standard deviation 0.01144.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0, 0.009720359684256996, 0.0276118039831329]}}
{"id": "2138b330-38c9-48fa-ac05-fc0b5547858c", "fitness": 0.014153363591478377, "name": "EnhancedHybridPSO_GA", "description": "The algorithm introduces an adaptive learning rate schedule and diversity preservation mechanism to enhance convergence speed and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.learning_rate_schedule = lambda t: 0.5 + 0.5 * np.cos(np.pi * t / self.budget)  # cosine annealing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Adaptive learning rate using cosine annealing\n            lr = self.learning_rate_schedule(evaluations)\n\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # PSO Step with adaptive learning rate\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          lr * self.c1_initial * r1 * (personal_best - population) +\n                          lr * self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step) with diversity preservation\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation with a diversity preservation mechanism\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "1119e5bb-8f19-4c1b-8404-f9cbd17b25f1", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm refines the balance between exploration and exploitation by dynamically adjusting the crossover rate during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "28fa3e93-1d4e-44c3-afea-212cbab12af5", "fitness": 0.0146054340436896, "name": "AdaptiveHybridPSO_GA", "description": "Improved inertia weight adaptation for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - evaluations / self.budget)**2  # Improved inertia adaptation\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01461 with standard deviation 0.01264.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0063562113566336675, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "22088a21-a690-4610-93c4-4b1a03570e5b", "fitness": 0.017370665740493025, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm combines adaptive inertia weight, mutation rate, and a crowding distance mechanism to balance exploration and exploitation while maintaining diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Apply Crowding Distance Mechanism to maintain diversity\n            distances = np.zeros(self.population_size)\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if i != j:\n                        distances[i] += np.linalg.norm(population[i] - population[j])\n            crowding_sorted_indices = np.argsort(distances)\n            population = population[crowding_sorted_indices[:self.population_size]]\n\n        return global_best, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "bb464493-161e-446c-9c0e-41e52fad28b4", "fitness": 0.014153363591478377, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "EnhancedAdaptiveHybridPSO_GA introduces an adaptive learning rate and a diversity-preserving mechanism to balance exploration and exploitation, aiming to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.min_diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Compute population diversity\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n\n            # Adapt cognitive and social parameters based on diversity\n            c1 = self.c1_initial * (1 - diversity)\n            c2 = self.c2_initial + diversity\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "523164b1-b470-450b-9713-e3d69f5cd175", "fitness": 0.034223166919362114, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Integrate chaotic maps for parameter adaptation in PSO-GA to enhance convergence speed and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n        chaos_param = np.random.rand()\n\n        while evaluations < self.budget:\n            # Chaos-adapted inertia weight and mutation rate\n            w = self.w_final + (self.w_initial - self.w_final) * self.logistic_map(chaos_param)\n            mutation_rate = self.mutation_rate_final + (self.mutation_rate_initial - self.mutation_rate_final) * self.logistic_map(chaos_param)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Update chaos parameter\n            chaos_param = self.logistic_map(chaos_param)\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03422 with standard deviation 0.00669.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.04244473480325628, 0.02605862529227987, 0.03416614066255019]}}
{"id": "32e18fc6-d0ec-49e2-868c-e8c218aff62a", "fitness": 0.031776976880755536, "name": "AdaptiveHybridPSO_GA2", "description": "AdaptiveHybridPSO_GA2: A refined hybrid algorithm that incorporates dynamic learning factors and an adaptive mutation scheme for enhanced convergence in diverse optimization tasks.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Dynamic adjustment of c1 and c2 parameters\n            c1 = self.c1_initial - (self.c1_initial - 1.5) * (evaluations / self.budget)\n            c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm AdaptiveHybridPSO_GA2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03178 with standard deviation 0.00826.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.028439335888101436, 0.023748005791544013, 0.04314358896262116]}}
{"id": "7b4f42bd-4b73-4ff8-bf58-090e36f87b6d", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Introduce a dynamic crossover rate based on evaluations to enhance adaptability during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial - (self.cross_over_rate_initial - self.cross_over_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "a1cc2508-c330-4703-8670-471f4ccc7684", "fitness": 0.017229633095638297, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm leverages dynamic neighborhood topology in PSO and a self-adaptive mutation strategy in GA to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.topology_neighbors = 5  # Number of neighbors in dynamic topology\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions with dynamic topology (PSO Step)\n            for i in range(self.population_size):\n                neighbors_idx = np.random.choice(self.population_size, self.topology_neighbors, replace=False)\n                local_best = personal_best[neighbors_idx[np.argmin(personal_best_scores[neighbors_idx])]]\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 self.c1_initial * r1 * (personal_best[i] - population[i]) +\n                                 self.c2_initial * r2 * (local_best - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation with self-adaptive strategy\n            mutation_strength = np.random.rand(self.population_size, self.dim) * (ub - lb) * mutation_rate\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            population = population + mutation_strength * mutation_mask\n\n        return global_best, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01723 with standard deviation 0.01141.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.014228808512479763, 0.032460090774435124]}}
{"id": "b9b4ba61-dc91-470f-beed-46068fd4f07c", "fitness": 0.017747039978351586, "name": "EnhancedAdaptiveHybridPSO_DE", "description": "Introduce a dynamically adjusting learning factor and differential evolution strategy to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.de_factor = 0.8  # Differential Evolution factor\n        self.learning_factor = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Differential Evolution Strategy\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant_vector = x1 + self.de_factor * (x2 - x3)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cross_over_rate\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                if func(trial_vector) < scores[i]:\n                    population[i] = trial_vector\n                    scores[i] = func(trial_vector)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01775 with standard deviation 0.01097.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.006129122713575685, 0.01465190644704395, 0.032460090774435124]}}
{"id": "4e32598e-883a-403c-b14e-ac9d7429a130", "fitness": 0.014153363591478377, "name": "EnhancedMultiPopAdaptivePSO_GA", "description": "Incorporate a multi-population strategy with adaptive learning rates to enhance diversity and convergence in the optimization process.", "code": "import numpy as np\n\nclass EnhancedMultiPopAdaptivePSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.sub_populations = 3\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        sub_pop_size = self.population_size // self.sub_populations\n        populations = [np.random.uniform(lb, ub, (sub_pop_size, self.dim)) for _ in range(self.sub_populations)]\n        velocities = [np.random.uniform(-1, 1, (sub_pop_size, self.dim)) for _ in range(self.sub_populations)]\n        personal_bests = [pop.copy() for pop in populations]\n        personal_best_scores = [np.array([func(ind) for ind in pop]) for pop in populations]\n        global_best = np.vstack(personal_bests)[np.argmin([min(scores) for scores in personal_best_scores])]\n        global_best_score = min([min(scores) for scores in personal_best_scores])\n\n        evaluations = sub_pop_size * self.sub_populations\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            for i, (population, velocity, personal_best, personal_best_score) in enumerate(zip(populations, velocities, personal_bests, personal_best_scores)):\n                r1, r2 = np.random.rand(sub_pop_size, self.dim), np.random.rand(sub_pop_size, self.dim)\n                velocities[i] = (w * velocity +\n                                 self.c1_initial * r1 * (personal_best - population) +\n                                 self.c2_initial * r2 * (global_best - population))\n                populations[i] = population + velocities[i]\n                populations[i] = np.clip(populations[i], lb, ub)\n\n                scores = np.array([func(ind) for ind in populations[i]])\n                evaluations += sub_pop_size\n\n                improved = scores < personal_best_score\n                personal_best[improved] = populations[i][improved]\n                personal_best_score[improved] = scores[improved]\n\n                if min(scores) < global_best_score:\n                    global_best = populations[i][np.argmin(scores)]\n                    global_best_score = min(scores)\n\n                # Adaptive learning rate update\n                self.c1_initial += self.learning_rate * np.mean(scores - personal_best_score)\n                self.c2_initial -= self.learning_rate * np.mean(scores - global_best_score)\n\n            # Apply Genetic Operators\n            for population in populations:\n                for i in range(0, sub_pop_size, 2):\n                    if np.random.rand() < self.cross_over_rate:\n                        cross_point = np.random.randint(1, self.dim)\n                        parent1, parent2 = population[i], population[i + 1]\n                        child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                        child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                        population[i], population[i + 1] = child1, child2\n\n                mutation_mask = np.random.rand(sub_pop_size, self.dim) < mutation_rate\n                mutation_values = np.random.uniform(lb, ub, (sub_pop_size, self.dim))\n                population[:] = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedMultiPopAdaptivePSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "34e5144b-1382-4574-af3a-7c39c9231251", "fitness": 0.029276458756195223, "name": "AdaptiveHybridPSO_GA", "description": "Improved exploration by adjusting the randomization factors in the PSO velocity update.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          (self.c2_initial + 0.1) * r2 * (global_best - population))  # Adjusted randomization factor\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02928 with standard deviation 0.01717.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.04146614967997664, 0.0050000000000000044, 0.041363226588609026]}}
{"id": "d62d30aa-d0f8-4e86-8d01-036f3513c636", "fitness": 0.03486767870064041, "name": "RefinedAdaptiveHybridPSO_GA", "description": "The algorithm combines adaptive swarm parameters with an adaptive crossover mechanism and self-adaptive mutation rate to enhance exploration and exploitation in optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Adapt parameters\n            progress = evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * progress\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * progress\n            crossover_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * progress\n\n            # PSO Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # GA Step\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < crossover_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation (Self-Adaptive)\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "05f23cf8-fbb8-415d-8fae-0a039b40fcbe", "fitness": 0.023110777550816475, "name": "EnhancedAdaptivePSO_GA", "description": "The algorithm incorporates an adaptive learning factor strategy and elite selection to balance exploration and exploitation dynamically, enhancing convergence rates.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.1  # Fraction of population considered elite\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            c1 = self.c1_initial * (1 - evaluations / self.budget)  # Adaptive learning factor\n            c2 = self.c2_initial * (evaluations / self.budget)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Elite selection\n            elite_count = max(1, int(self.population_size * self.elite_fraction))\n            elite_indices = np.argsort(scores)[:elite_count]\n            elites = population[elite_indices]\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n            \n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Incorporate elites back into the population\n            population[:elite_count] = elites\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptivePSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02311 with standard deviation 0.01281.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.031872241878014296, 0.032460090774435124]}}
{"id": "6de07348-2110-417e-9e7a-a33abc103da9", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm enhances exploration and exploitation by dynamically adjusting the crossover rate throughout the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9  # Slightly increase final crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "53c4585d-9e3c-49af-aeef-80ea432e6f43", "fitness": 0.017370665740493025, "name": "RefinedAdaptiveHybridPSO_GA", "description": "The algorithm combines adaptive swarm parameters with a dynamic learning strategy and crowding-based genetic operators for enhanced convergence and diversity maintenance.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n        \n        # Initialize diversity based learning rate\n        diversity_learning_rate = 0.1\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Calculate diversity and adjust learning rate\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n            c1_adapted = self.c1_initial * (1 + diversity_learning_rate * diversity)\n            c2_adapted = self.c2_initial * (1 - diversity_learning_rate * diversity)\n\n            # Update velocities with adapted learning rates\n            velocities = (w * velocities + \n                          c1_adapted * r1 * (personal_best - population) + \n                          c2_adapted * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Apply Genetic Operators (GA Step)\n            # Crowding-based Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    d1 = np.linalg.norm(population[i] - global_best)\n                    d2 = np.linalg.norm(population[i+1] - global_best)\n                    if d1 < d2:\n                        cross_point = np.random.randint(1, self.dim)\n                        parent1, parent2 = population[i], population[i + 1]\n                        child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                        child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                        population[i], population[i + 1] = child1, child2\n                    else:\n                        population[i], population[i + 1] = population[i + 1], population[i]\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm RefinedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "9a31a101-bfaa-425c-bfec-e04ddc483383", "fitness": -Infinity, "name": "EnhancedHybridPSO_GA", "description": "Introduce local search with Lvy flights to enhance exploitation in the adaptive PSO-GA hybrid, improving convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.levy_beta = 1.5  # Lvy flight exponent\n\n    def levy_flight(self, scale=0.1):\n        \"\"\"Perform a Lvy flight with a given scale.\"\"\"\n        sigma_u = (np.sqrt(np.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2) /\n                  (np.gamma((1 + self.levy_beta) / 2) * self.levy_beta * (2 ** ((self.levy_beta - 1) / 2))))) ** (1 / self.levy_beta)\n        u = np.random.randn(self.dim) * sigma_u\n        v = np.random.randn(self.dim)\n        step = u / (np.abs(v) ** (1 / self.levy_beta))\n        return scale * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Lvy Flight Local Search\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # 10% chance to apply Lvy flight\n                    step = self.levy_flight()\n                    new_pos = population[i] + step\n                    new_pos = np.clip(new_pos, lb, ub)\n                    new_score = func(new_pos)\n                    evaluations += 1\n                    if new_score < scores[i]:\n                        population[i] = new_pos\n                        scores[i] = new_score\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 73, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "a4a2feff-9287-4db1-8e51-0814f1741d44", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters and a dynamic mutation rate to enhance exploration and exploitation, with an improved crossover rate to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.8  # Improved crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "9721676a-db9a-42cc-a4d9-b6d35e8a33fb", "fitness": 0.024641502709685386, "name": "EnhancedHybridPSO_GA", "description": "Introduce adaptive local search and elitism to the hybrid PSO-GA framework for improved convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.local_search_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Elitism: retain the best solutions\n            elite_size = int(self.population_size * 0.1)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            population[:elite_size] = personal_best[elite_indices]\n\n            # Local Search: fine-tune the best found solutions\n            if np.random.rand() < self.local_search_rate:\n                local_indices = np.random.choice(self.population_size, elite_size, replace=False)\n                for idx in local_indices:\n                    step = np.random.uniform(-0.1, 0.1, self.dim)\n                    candidate = np.clip(population[idx] + step, lb, ub)\n                    candidate_score = func(candidate)\n                    evaluations += 1\n                    if candidate_score < personal_best_scores[idx]:\n                        personal_best[idx] = candidate\n                        personal_best_scores[idx] = candidate_score\n                        if candidate_score < global_best_score:\n                            global_best = candidate\n                            global_best_score = candidate_score\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02464 with standard deviation 0.00919.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.022438761580235278, 0.01465190644704395, 0.03683384010177693]}}
{"id": "c6028fc1-b029-4bb8-9891-b6f2205d4a1b", "fitness": -Infinity, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm introduces a dynamic population size and adaptive learning rates to enhance exploration and exploitation across different optimization phases.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.final_population_size = 100\n        self.population_size = self.initial_population_size\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust population size based on budget usage\n            self.population_size = int(self.initial_population_size + \n                                       (self.final_population_size - self.initial_population_size) * (evaluations / self.budget))\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size - 1, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 76, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (28,2) (20,2) ').", "error": "ValueError('operands could not be broadcast together with shapes (28,2) (20,2) ')", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "dee00de7-7540-4e5b-a760-fb1f64849917", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Improve the algorithm by introducing a dynamic crossover rate that adapts linearly over time, enhancing exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9  # New final crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "836113bb-43d6-4843-9243-517b0c828f94", "fitness": 0.0162297784536084, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm dynamically integrates opposition-based learning and adaptive parameters in both PSO and GA phases to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Opposition-based learning\n            opposition_population = lb + (ub - population)\n            opposition_scores = np.array([func(ind) for ind in opposition_population])\n            evaluations += self.population_size\n\n            combined_population = np.vstack((population, opposition_population))\n            combined_scores = np.concatenate((personal_best_scores, opposition_scores))\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01623 with standard deviation 0.01175.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.011229244586390075, 0.032460090774435124]}}
{"id": "b0307543-025c-451c-8f7a-cf1a7e0ccd80", "fitness": 0.032397370846600625, "name": "EntropyBasedHybridPSO_GA", "description": "Introduce a dynamic learning strategy using entropy to balance exploration and exploitation in a hybrid PSO-GA framework for enhanced performance.", "code": "import numpy as np\n\nclass EntropyBasedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate entropy of population to adapt learning factors\n            normalized_pop = (population - lb) / (ub - lb)\n            entropy = -np.sum(normalized_pop * np.log(normalized_pop + 1e-9), axis=1).mean()\n            c1 = self.c1_initial * (1 - entropy)\n            c2 = self.c2_initial * entropy\n\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EntropyBasedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03240 with standard deviation 0.01187.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.017823968797778922, 0.04690805296758782, 0.032460090774435124]}}
{"id": "ff96fd76-8a84-4b5f-8a40-b4e665a34d22", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm slightly increases the crossover rate to enhance genetic diversity during optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        # Slight increase in crossover rate\n        self.cross_over_rate = 0.72\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "b826f111-9dbd-4090-9b80-b86046695e2f", "fitness": 0.03486767870064041, "name": "EnhancedHybridPSO_GA", "description": "The algorithm leverages adaptive penalties for convergence control and diversity preservation, enhancing exploration and exploitation with a multi-phase strategy.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n        adaptive_penalty = 1.0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            if t % 10 == 0:  # Adaptive penalty adjustment every 10 iterations\n                diversity = np.mean(np.std(population, axis=0))\n                adaptive_penalty = 1.0 + (1.0 / (1.0 + np.exp(-diversity)))\n            \n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate * adaptive_penalty:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate * adaptive_penalty\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "732390c9-2cfc-4e0a-849b-10131bcbbe0b", "fitness": 0.03486767870064041, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Enhance the adaptive hybrid PSO-GA by incorporating a dynamic local search phase to refine solutions near the end of the budget, improving exploitation and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.local_search_radius = 0.1  # radius for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Dynamic Local Search Phase near budget end\n            if evaluations > self.budget * 0.8:  # last 20% of evaluations\n                for i in range(self.population_size):\n                    local_search_point = global_best + np.random.uniform(-self.local_search_radius, self.local_search_radius, self.dim)\n                    local_search_point = np.clip(local_search_point, lb, ub)\n                    local_score = func(local_search_point)\n                    if local_score < global_best_score:\n                        global_best = local_search_point\n                        global_best_score = local_score\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "443821b3-e4d4-4c67-b14c-a19f0b3a5a20", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Introduced dynamic adaptation of crossover rate based on the optimization process to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7  # renamed to indicate initial crossover rate\n        self.cross_over_rate_final = 0.3    # added final crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight, mutation rate, and crossover rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial - (self.cross_over_rate_initial - self.cross_over_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "771b6184-a9e5-435e-8c3f-b4413fec0e9e", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Introduce a dynamic crossover rate that decreases over time to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7  # renamed to initial\n        self.cross_over_rate_final = 0.3    # added final crossover rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial - (self.cross_over_rate_initial - self.cross_over_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:  # use dynamic crossover rate\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "8a7fd4e0-22f8-4f65-9671-d497258dc223", "fitness": 0.017370665740493025, "name": "AdaptiveHybridPSO_GA", "description": "Improved mutation strategy to balance exploration and exploitation in the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb - (ub - lb) * 0.05, ub + (ub - lb) * 0.05, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "d0937430-6a53-42bf-b14f-99c4b80943ff", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm integrates adaptive swarm parameters and a dynamic mutation rate, enhanced with elitism selection to improve retention of the best solutions during the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Apply elitism\n            population[np.argmax(scores)] = global_best\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "b96c3a66-e2aa-495e-ad95-451a750f3688", "fitness": 0.017370665740493025, "name": "AdaptiveElitePSO_GA", "description": "The algorithm employs an adaptive learning rate strategy and elite selection to enhance convergence and maintain diversity during optimization.", "code": "import numpy as np\n\nclass AdaptiveElitePSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.2  # Proportion of elite individuals to be retained\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n            \n            # Elite selection\n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = population[elite_indices]\n            elite_scores = scores[elite_indices]\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Reintroduce elite individuals to maintain diversity\n            population[:elite_size] = elite_population\n            personal_best_scores[:elite_size] = elite_scores\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm AdaptiveElitePSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "ee52d3ca-e21c-4a1e-9188-32ebfba8428e", "fitness": 0.020799240049373575, "name": "RefinedAdaptiveHybridPSO_GA", "description": "The algorithm incorporates an adaptive multi-phase approach with dynamically tuned exploration-exploitation balance to enhance convergence and diversity management.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.phase_split = int(budget * 0.5)  # Split budget into exploration and exploitation phases\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Determine current phase\n            if evaluations < self.phase_split:\n                # Exploration phase\n                w = self.w_initial\n                mutation_rate = self.mutation_rate_initial\n                c1 = self.c1_initial\n                c2 = self.c2_initial\n            else:\n                # Exploitation phase\n                w = self.w_final\n                mutation_rate = self.mutation_rate_final\n                c1 = self.c1_initial * 0.5\n                c2 = self.c2_initial * 1.5\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm RefinedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02080 with standard deviation 0.01159.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0249376293736856, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "1acfe0e4-5cb5-42ec-a21f-eeb11a3fa27d", "fitness": 0.023114054753819963, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "Enhanced AdaptiveHybridPSO_GA dynamically adjusts cognitive, social, and inertia parameters using a nonlinear decay schedule and introduces elitism to retain the best solutions across generations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Nonlinear decay for inertia weight and mutation rate\n            progress = evaluations / self.budget\n            w = self.w_initial - (self.w_initial - self.w_final) * (progress ** 2)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (progress ** 2)\n\n            # Adjust cognitive and social parameters\n            c1 = self.c1_initial * (1 - progress) + self.c2_initial * progress\n            c2 = self.c2_initial * (1 - progress) + self.c1_initial * progress\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best - population) +\n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Elitism: Retain a fraction of the best solutions\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argpartition(personal_best_scores, elite_count)[:elite_count]\n            population[:elite_count] = personal_best[elite_indices]\n\n        return global_best, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02311 with standard deviation 0.00794.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.013143715759707852, 0.02362046770105608, 0.03257798080069596]}}
{"id": "6ad6b3bf-5b8e-41d8-a7e4-a754f8636801", "fitness": 0.029768314586876937, "name": "EnhancedHybridPSO_GA", "description": "Enhancing exploration-exploitation balance by incorporating dynamic neighborhood topology in PSO combined with adaptive crossover and mutation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial - (self.cross_over_rate_initial - self.cross_over_rate_final) * (evaluations / self.budget)\n\n            # Dynamic neighborhood topology\n            for i in range(self.population_size):\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_scores[neighbors])]]\n                velocities[i] = (w * velocities[i] +\n                                 self.c1_initial * np.random.rand(self.dim) * (personal_best[i] - population[i]) +\n                                 self.c2_initial * np.random.rand(self.dim) * (local_best - population[i]))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02977 with standard deviation 0.01245.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.040616485323710094, 0.012332097265593478, 0.036356361171327234]}}
{"id": "003f69ff-e5ee-49f3-95d6-a6f7a0cb0b97", "fitness": 0.03486767870064041, "name": "AdaptiveHybridPSO_GA", "description": "Implement a temperature-based adaptive mutation rate to enhance exploration adaptively throughout the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            # Temperature-based adaptive mutation rate\n            temperature = 1 - (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial * temperature + self.mutation_rate_final * (1 - temperature)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03487 with standard deviation 0.01757.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.05749103888044216, 0.01465190644704395, 0.032460090774435124]}}
{"id": "69bc926d-6d21-40a3-85ad-45ef0dbfbcbe", "fitness": 0.017984873742097784, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm enhances exploration and exploitation by dynamically adapting both social and cognitive parameters in the PSO step.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            c1 = self.c1_initial - (self.c1_initial - self.c2_initial) * (evaluations / self.budget) # dynamically adapt c1\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01798 with standard deviation 0.01090.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.006159060906087421, 0.015335469545770808, 0.032460090774435124]}}
{"id": "ca93a135-5a8f-403a-ac78-d9f03cbbbdbf", "fitness": 0.025477302335729018, "name": "RefinedAdaptiveHybridPSO_GA", "description": "An adaptive hybrid algorithm combining dynamic inertia weight and mutation rate with elitism and adaptive crossover to enhance convergence and diversity.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate_initial = 0.7\n        self.cross_over_rate_final = 0.9\n        self.elitism_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            cross_over_rate = self.cross_over_rate_initial + (self.cross_over_rate_final - self.cross_over_rate_initial) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities +\n                          self.c1_initial * r1 * (personal_best - population) +\n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            elite_count = max(1, int(self.population_size * self.elitism_rate))\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            elite_individuals = personal_best[elite_indices]\n\n            for i in range(0, self.population_size - elite_count, 2):\n                if np.random.rand() < cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            population[:elite_count] = elite_individuals\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm RefinedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02548 with standard deviation 0.00776.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.029319909785707976, 0.01465190644704395, 0.032460090774435124]}}
{"id": "f45cb9a6-ef4e-4e92-8d99-4f0742e5f1bc", "fitness": 0.014153363591478377, "name": "ImprovedAdaptiveHybridPSO_GA", "description": "The algorithm incorporates a dynamic topology and adaptive parameter tuning for both PSO and GA components to improve convergence and robustness.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.topology = 'ring'  # Dynamic topology initialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            self.update_topology(evaluations / self.budget)  # Update topology dynamically\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            if self.topology == 'ring':\n                local_best = np.roll(population, 1, axis=0)\n            else:\n                local_best = global_best\n\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (local_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n        return global_best, global_best_score\n\n    def update_topology(self, progress):\n        if progress < 0.5:\n            self.topology = 'ring'\n        else:\n            self.topology = 'fully_connected'", "configspace": "", "generation": 94, "feedback": "The algorithm ImprovedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "080a061d-9347-4c33-bd6c-a179b3decd6f", "fitness": -Infinity, "name": "EnhancedAdaptivePSO_GA", "description": "Enhancing convergence through dynamic parameter tuning, a levy flight update mechanism, and elite selection for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.1  # fraction of elite individuals\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Dynamic parameter adaptation\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # PSO Step with Levy Flight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities + self.levy_flight(self.dim)\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Elite selection\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(scores)[:elite_count]\n            elite_population = population[elite_indices]\n\n            # GA Step: Crossover\n            for i in range(0, elite_count, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = elite_population[i], elite_population[min(i + 1, elite_count - 1)]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    elite_population[i], elite_population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            # Reintegration of elite individuals\n            population[:elite_count] = elite_population\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 95, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {}}
{"id": "0986e5ca-d021-4acb-88bb-cb81c11b444b", "fitness": 0.017370665740493025, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm dynamically adjusts swarm behavior and integrates an elite strategy to maintain diversity and drive convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.elite_fraction = 0.1  # Fraction of elite members\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elites = personal_best[np.argsort(personal_best_scores)[:elite_count]]\n\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            elite_indices = np.random.choice(self.population_size, elite_count, replace=False)\n            population[elite_indices[:elite_count]] = elites\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01737 with standard deviation 0.01137.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.01465190644704395, 0.032460090774435124]}}
{"id": "6c28e9f4-bb51-4a79-bdc2-8388832a320e", "fitness": 0.018262324363195043, "name": "AdaptiveHybridPSO_GA", "description": "The algorithm enhances exploration-exploitation balance by incorporating dynamic inertia weight adaptation based on the learning iterations.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (t / (self.budget / self.population_size))\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          self.c1_initial * r1 * (personal_best - population) + \n                          self.c2_initial * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01826 with standard deviation 0.01123.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.017326882315150005, 0.0050000000000000044, 0.032460090774435124]}}
{"id": "ca9e741b-2548-4114-86d0-c3d3af3858f3", "fitness": 0.03176157961948323, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm enhances convergence by introducing an adaptive learning factor and diversity preservation mechanism to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5  # initial cognitive parameter\n        self.c2_initial = 0.5  # initial social parameter\n        self.w_initial = 0.9   # initial inertia weight\n        self.w_final = 0.4     # final inertia weight\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.learning_factor_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            # Linearly adapt inertia weight and mutation rate\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n            \n            # Decay learning factors\n            c1 = self.c1_initial * (self.learning_factor_decay ** t)\n            c2 = self.c2_initial * (self.learning_factor_decay ** t)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (w * velocities + \n                          c1 * r1 * (personal_best - population) + \n                          c2 * r2 * (global_best - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal best and global best\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            # Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            # Mutation\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03176 with standard deviation 0.01369.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.048172741636970606, 0.01465190644704395, 0.032460090774435124]}}
{"id": "79868bb8-dd6c-46c3-9eda-03ceed5202c8", "fitness": 0.014153363591478377, "name": "EnhancedAdaptiveHybridPSO_GA", "description": "The algorithm utilizes an adaptive neighborhood topology and a strategy of multi-velocity layer control to enhance information sharing and balance global-local search dynamics during optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.mutation_rate_initial = 0.2\n        self.mutation_rate_final = 0.05\n        self.cross_over_rate = 0.7\n        self.neighborhood_size = 5  # New parameter for neighborhood-based velocity update\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n        t = 0\n\n        while evaluations < self.budget:\n            w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            mutation_rate = self.mutation_rate_initial - (self.mutation_rate_initial - self.mutation_rate_final) * (evaluations / self.budget)\n\n            # Update velocities and population positions (PSO Step)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            local_best_neighbors = np.array([np.min(personal_best_scores[max(0, i - self.neighborhood_size): min(self.population_size, i + self.neighborhood_size + 1)]) for i in range(self.population_size)])\n            velocities = (w * velocities +\n                          self.c1_initial * r1 * (personal_best - population) +\n                          self.c2_initial * r2 * (global_best - population) +\n                          np.random.uniform(-0.1, 0.1) * (local_best_neighbors[:, None] - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            improved = scores < personal_best_scores\n            personal_best[improved] = population[improved]\n            personal_best_scores[improved] = scores[improved]\n            if min(scores) < global_best_score:\n                global_best = population[np.argmin(scores)]\n                global_best_score = min(scores)\n\n            # Apply Genetic Operators (GA Step)\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.cross_over_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    parent1, parent2 = population[i], population[i + 1]\n                    child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]])\n                    child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]])\n                    population[i], population[i + 1] = child1, child2\n\n            mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n            mutation_values = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            population = np.where(mutation_mask, mutation_values, population)\n\n            t += 1\n\n        return global_best, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveHybridPSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01415 with standard deviation 0.01294.", "error": "", "parent_ids": ["ef4dc621-c4c8-464d-8765-0865b812caa7"], "operator": null, "metadata": {"aucs": [0.0050000000000000044, 0.0050000000000000044, 0.032460090774435124]}}
