{"id": "23038dcf-3f47-43fa-85cc-99c19d0eb3cc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic combining Differential Evolution and Simulated Annealing to efficiently explore and exploit the search space for black-box optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "eebc0edd-a3f4-4b3b-aeb4-71167c0706bc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive crossover rate to efficiently explore and exploit the search space for black-box optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                # Adaptive crossover rate: adjust based on current best fitness\n                current_crossover_rate = crossover_rate * (1 - best_fitness / (1 + np.abs(best_fitness)))\n                cross_points = np.random.rand(self.dim) < current_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 1, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "b33ab9e9-8b36-4e3f-9966-ea7abd0c9c7e", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for efficient exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation = mutation_factor * (1 - evaluations / self.budget)\n                mutant = clip(population[a] + adaptive_mutation * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 2, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "30d9833f-f7f0-4b6d-b881-b7e6f0b7472e", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic that enhances exploration by introducing dynamic mutation factor adaptation based on fitness diversity.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, fitness):\n            nonlocal mutation_factor\n            if evaluations < self.budget * 0.75:  # Dynamic mutation factor adaptation\n                fitness_std = np.std(fitness)\n                mutation_factor = 0.5 + 0.5 * (fitness_std / (fitness_std + 1))\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, fitness)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 3, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "46eb3745-af47-4118-a4b1-50548db4dd95", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic integrating Differential Evolution and Simulated Annealing with adaptive mutation factor and dynamic cooling schedule for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Change 1: Adaptive mutation factor\n                adaptive_mutation_factor = mutation_factor * (1 - (evaluations/self.budget))\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            # Change 2: Dynamic cooling schedule\n            dynamic_temperature = temperature / (1 + evaluations/self.budget)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / dynamic_temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 4, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "fb023949-52eb-40a3-b390-683c886d8175", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic with adaptive mutation factor and cooling rate to enhance convergence in black-box optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            nonlocal mutation_factor  # Allow mutation_factor to be modified\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            mutation_factor = max(0.5, mutation_factor * 0.99)  # Adaptive mutation factor\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            nonlocal cooling_rate  # Allow cooling_rate to be modified\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            cooling_rate = max(0.95, cooling_rate * 1.001)  # Adaptive cooling rate\n            \n        return best", "configspace": "", "generation": 5, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "3e391e43-8742-4348-8509-8c057b4ed5b3", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using an adaptive mutation factor dynamically adjusted based on the search progress.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Initial mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, eval_ratio):\n            new_population = np.copy(population)\n            adaptive_mutation_factor = mutation_factor * (1 - eval_ratio)  # Adaptive mutation factor\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            # Differential Evolution step\n            population = differential_evolution_step(population, eval_ratio)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 6, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "54f4f4ed-8a17-4ae0-abea-8754cc8c3926", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive mutation and crossover rates for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation = mutation_factor * (1 - (evaluations / self.budget))\n                adaptive_crossover = crossover_rate * (1 - (evaluations / self.budget))\n                \n                mutant = clip(population[a] + adaptive_mutation * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < adaptive_crossover\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 7, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "5fd46277-9360-4bb2-a86c-cb9c260291aa", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic combining Differential Evolution and Simulated Annealing with enhanced mutation factor adaptivity to efficiently explore and exploit the search space for black-box optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.9  # Adjusted mutation factor for improved exploration\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 8, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "004e759b-6ab5-4268-aa63-1a8a8a65394f", "fitness": 0.7258064331403119, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 9, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.12 on the real problem.", "error": "", "parent_ids": ["23038dcf-3f47-43fa-85cc-99c19d0eb3cc"], "operator": null, "metadata": {"aucs": [0.8678333681569282, 0.7294674320217317, 0.5801184992422755]}}
{"id": "fe7081d3-eab5-4ff0-9f3d-458e1311e22f", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic integrating Differential Evolution and Simulated Annealing with a dynamic population size strategy based on remaining budget for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population_size = initial_population_size  # Changed line: Dynamic population size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 10, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "d2068778-e751-4881-995f-5f8a287095a9", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor and enhanced cooling rate for improved exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.98  # Changed line: Enhanced cooling rate\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 11, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "68baa0de-432c-49fe-ab56-33a02bccce05", "fitness": -Infinity, "name": "HybridMetaheuristic", "description": "Enhanced exploration through dynamic population size and adaptive mutation factor tuning in a hybrid metaheuristic algorithm.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor based on budget consumption\n                dynamic_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                mutant = clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Changed line: Dynamic population sizing\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size + int(evaluations / self.budget * population_size), self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            population = differential_evolution_step(population)\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 12, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'evaluations' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'evaluations' referenced before assignment\")", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {}}
{"id": "5fbbd86f-8075-4b2f-b758-5b7d18047c43", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor for enhanced exploration and exploitation, now with dynamic population size.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 20  # Changed line: Dynamic population size\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 13, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "ffcc5511-49a5-41bb-b128-36b1b0e10a6a", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic integrating adaptive population sizing with dynamic mutation strategies for robust exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        # Adaptive population size\n        initial_population_size = 10\n        population_size = initial_population_size\n        mutation_factor = 0.8  \n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Dynamic mutation strategies\n                dynamic_mutation_factor = mutation_factor * np.random.uniform(0.5, 1.5)\n                mutant = clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n            # Adjust population size adaptively\n            if evaluations < self.budget // 2:  \n                population_size = int(initial_population_size * (evaluations / self.budget + 0.5))\n            \n        return best", "configspace": "", "generation": 14, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "827c744c-2588-4ff0-816c-3e05ed1d5612", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by reducing mutation factor to increase solution precision in local searches.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.7  # Changed line: Reduced mutation factor to increase precision\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 15, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "8714b069-1190-4d5b-aea3-fd7193b18ee8", "fitness": 0.16666666666666666, "name": "HybridMetaheuristic", "description": "Enhanced coupling of DE and SA by introducing early stopping based on stagnation detection for improved convergence speed.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        stagnation_counter = 0  # Added line: Introduce stagnation counter\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n                stagnation_counter = 0  # Reset stagnation counter if improvement\n            else:\n                stagnation_counter += 1  # Increment stagnation counter\n\n            if stagnation_counter >= 5:  # Early stopping\n                break\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    stagnation_counter = 0  # Reset stagnation counter if improvement\n                else:\n                    stagnation_counter += 1  # Increment stagnation counter\n                if stagnation_counter >= 5:  # Early stopping\n                    break\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 16, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0]}}
{"id": "e644dadb-1028-4437-91b3-00ae1e3d7d71", "fitness": -Infinity, "name": "EnhancedMetaheuristic", "description": "A co-evolutionary metaheuristic integrating Particle Swarm Optimization into the existing Differential Evolution and Simulated Annealing framework, enhancing convergence speed and global search capabilities.", "code": "import numpy as np\n\nclass EnhancedMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        inertia_weight = 0.5  # New line: Inertia weight for PSO\n        cognitive_coeff = 1.5  # New line: Cognitive coefficient for PSO\n        social_coeff = 2.0  # New line: Social coefficient for PSO\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            velocities = np.random.uniform(-1, 1, (population_size, self.dim))  # New line: Initial velocities for PSO\n            personal_best_positions = np.copy(population)  # New line: Personal best positions for PSO\n            personal_best_fitness = np.full(population_size, np.inf)  # New line: Personal best fitness for PSO\n            global_best_position = np.copy(population[0])  # New line: Global best position for PSO\n            global_best_fitness = np.inf  # New line: Global best fitness for PSO\n            \n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n                \n                # PSO update\n                r1, r2 = np.random.rand(), np.random.rand()  # New line: Random coefficients for PSO\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_coeff * r1 * (personal_best_positions[i] - population[i])\n                                 + social_coeff * r2 * (global_best_position - population[i]))  # New line: PSO velocity update\n                new_population[i] = clip(population[i] + velocities[i])  # New line: PSO position update\n                \n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        for i in range(population_size):  # New line: Initialize personal bests\n            personal_best_positions[i] = population[i]\n            personal_best_fitness[i] = fitness[i]\n            if fitness[i] < global_best_fitness:\n                global_best_fitness = fitness[i]\n                global_best_position = population[i]\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        while evaluations < self.budget:\n            population = differential_evolution_step(population)\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            for i in range(population_size):  # New line: Update personal and global bests\n                if new_fitness[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = new_fitness[i]\n                    personal_best_positions[i] = population[i]\n                if new_fitness[i] < global_best_fitness:\n                    global_best_fitness = new_fitness[i]\n                    global_best_position = population[i]\n            \n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 17, "feedback": "An exception occurred: NameError(\"name 'personal_best_positions' is not defined\").", "error": "NameError(\"name 'personal_best_positions' is not defined\")", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {}}
{"id": "4987226f-8b40-41dd-ae8e-9922de6c1b13", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor and dynamic population size for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 20  # Changed line: Dynamic population size\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 18, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "a7c44091-c682-42ff-a793-9972e9ad0dc8", "fitness": 0.7152899538782119, "name": "HybridMetaheuristic", "description": "An enhanced variant utilizing adaptive population size and dynamic crossover rate adjustments for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.7  # Changed line: Dynamic crossover rate\n        temperature = 1000.0\n        cooling_rate = 0.98  # Changed line: Adjusted cooling rate\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population.shape[0]):\n                candidates = list(range(population.shape[0]))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population_size = initial_population_size + int(self.budget / 100)  # Changed line: Adaptive population size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population.shape[0]  # Changed line: Use dynamic population size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population.shape[0]):  # Changed line: Use dynamic population size\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 19, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.34 on the real problem.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.9070723000753845, 0.24109968259571335, 0.9976978789635378]}}
{"id": "0af2f711-fba7-4e3e-9829-0ff157a269f0", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor and enhanced cooling schedule for improved global search capability.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.98  # Modified cooling rate for improved convergence\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 20, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "efcf4c80-446c-45b5-88c6-17df1762336a", "fitness": -Infinity, "name": "HybridMetaheuristic", "description": "Enhance exploration by introducing Levy flight-based mutation in Differential Evolution.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n\n        def levy_flight(Lambda):\n            sigma = (np.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) / \n                     (np.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.normal(0, sigma, self.dim)\n            v = np.random.normal(0, 1, self.dim)\n            step = u / abs(v) ** (1 / Lambda)\n            return step\n\n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]) + levy_flight(1.5)) # Changed line: Introduce Levy flight\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 21, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {}}
{"id": "761e307d-9a56-428e-a335-e515010fa844", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor and a stochastic crossover rate for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = np.random.uniform(0.5, 1.0)  # Changed line: Stochastic crossover rate\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 22, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "c588c159-844b-44ba-9a26-13d1ccf72e82", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive cooling rate and dynamic population size for better convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 15  # Changed line: Increased initial population size\n        population_size = initial_population_size\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        base_cooling_rate = 0.98  # Changed line: Adaptive cooling rate base\n        dynamic_cooling_factor = 0.0001  # New line: Factor for temperature adjustment\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply dynamic cooling to temperature\n            temperature *= base_cooling_rate - dynamic_cooling_factor * (evaluations / self.budget)  # Changed line\n            \n            # Adapt population size\n            if evaluations < self.budget // 2:  # Changed line: Dynamic population adaptation\n                population_size = initial_population_size\n            else:\n                population_size = max(5, initial_population_size // 2)\n            \n        return best", "configspace": "", "generation": 23, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "a0a047fe-2cea-4376-a03d-c8cf5be32a4c", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with a dynamically adjusted mutation factor for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                updated_mutation_factor = mutation_factor * (1 - i / population_size)  # Changed line: Dynamically adjust mutation factor\n                mutant = clip(population[a] + updated_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 24, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "7067d452-0a39-4920-84f7-8d3ce7fb9fb9", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population size adjustment for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 12  # Changed line: Dynamic population size adjustment\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 25, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "9eb8701d-ea6f-4611-9c3a-6ffc821707c8", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic blending Differential Evolution and Simulated Annealing with a dynamic mutation factor and adaptive population size for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.995  # Modified: Adjusted cooling rate\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def dynamic_population_size(evaluations):\n            max_population = 20  # New line: Maximum population size\n            return min(initial_population_size + evaluations // 100, max_population)  # New line: Increase population size over time\n        \n        def differential_evolution_step(population):\n            pop_size = len(population)  # New line: Dynamic population size\n            new_population = np.copy(population)\n            for i in range(pop_size):\n                candidates = list(range(pop_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = initial_population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Adjust population size\n            population_size = dynamic_population_size(evaluations)  # New line: Adjust population size\n            if len(population) < population_size:\n                additional_pop = np.random.uniform(self.lower_bound, self.upper_bound, (population_size - len(population), self.dim))\n                population = np.vstack((population, additional_pop))\n                fitness = np.append(fitness, [func(ind) for ind in additional_pop])\n                evaluations += len(additional_pop)\n            \n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(len(population)):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 26, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "d92c34f3-5927-4d17-a566-a750b5555820", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining Differential Evolution and Simulated Annealing with adaptive mutation factor for enhanced exploration and exploitation, now using adaptive cooling rate.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.995  # Changed line: Adaptive cooling rate\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 27, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "9ee795a8-53e4-4dd1-b260-e043295e1ea8", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic by adjusting the cooling rate for better convergence in meta-surface design.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.97  # Changed line: Adjusted cooling rate from 0.99 to 0.97\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 28, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "1166f83f-a7b9-4e2e-af2e-a1a71768ed4b", "fitness": 0.8918137637936011, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with dynamic crossover rate adjustment for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 29, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.05 on the real problem.", "error": "", "parent_ids": ["004e759b-6ab5-4268-aa63-1a8a8a65394f"], "operator": null, "metadata": {"aucs": [0.8647767868328905, 0.9580350018535534, 0.8526295026943593]}}
{"id": "39a7ca27-3752-4b18-8268-2429feab1b62", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Improved exploration by varying mutation factor based on iteration progress.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  \n        crossover_rate = 0.9  # Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, iteration, max_iterations):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Adjust mutation factor dynamically based on iteration progress\n                dynamic_mutation_factor = mutation_factor * (1 - iteration / max_iterations)\n                \n                mutant = clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        iteration = 0\n        max_iterations = self.budget // population_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, iteration, max_iterations)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            iteration += 1\n            \n        return best", "configspace": "", "generation": 30, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "711ca4c3-e9d1-483d-836b-e465492e463b", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with an adaptive mutation factor for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation_factor = mutation_factor * (1 - (evaluations / self.budget))  # Changed line\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))  # Changed line\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 31, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "c7705290-22fc-477e-9436-969d4dec6b71", "fitness": -Infinity, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive population size for improved convergence speed.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population_size = min(population_size + 1, self.budget - evaluations)  # Changed line: Adaptive population size\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 32, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {}}
{"id": "e6005ff6-997a-4288-bcee-dfee7aca95fc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic with adaptive population size and temperature modulation for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        initial_temperature = 1000.0\n        cooling_rate = 0.99\n\n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value, temperature):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        temperature = initial_temperature  # Changed line: Dynamic temperature modulation\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i], temperature)\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            population_size = max(5, population_size - 1)  # Changed line: Adaptive population size\n            \n        return best", "configspace": "", "generation": 33, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "bab347a4-2e66-4db6-a2a4-ee850fa000cf", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm now includes a dynamically adjusted mutation factor for better adaptation during optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Dynamic mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 34, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "b44f1be5-7078-47a1-8b37-93559a3a6612", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation factor for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor based on iteration\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Adapt the mutation factor based on remaining budget\n                adaptive_mutation_factor = mutation_factor + (self.budget - evaluations) / self.budget * 0.2\n                \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 35, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "f0c8e709-4bcb-4912-8aeb-bfd254c7395b", "fitness": 0.49303333333333327, "name": "HybridMetaheuristic", "description": "Improved convergence by adjusting the mutation factor dynamically based on current fitness diversity.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Dynamic mutation factor adjustment\n        crossover_rate = 0.9  # Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, fitness):\n            nonlocal mutation_factor  # Access the outer variable\n            fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n            mutation_factor = 0.5 + 0.3 * fitness_diversity  # Dynamically adjust mutation factor\n            \n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, fitness)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 36, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.49 with standard deviation 0.40 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 0.9855, 0.50005, 4.999999999999449e-05, 0.95345, 0.50005, 4.999999999999449e-05, 0.9855, 0.50005, 4.999999999999449e-05, 0.9855, 0.50005, 4.999999999999449e-05, 0.98505]}}
{"id": "416714a8-8e3d-40b0-8fb7-c1fb4a836b09", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced exploration through adaptive mutation scaling based on iteration progress.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, iteration):\n            new_population = np.copy(population)\n            adaptive_factor = mutation_factor * (1 - iteration / self.budget)  # Changed line: Adaptive mutation factor\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + adaptive_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, evaluations)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 37, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "1030bb60-61c5-40a2-8c71-b5a964756111", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced exploration by adjusting mutation factor and crossover rate dynamically based on fitness improvement.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n                mutation_factor = min(1.0, mutation_factor + 0.1)  # Dynamic adjustment\n                crossover_rate = min(1.0, crossover_rate + 0.05)  # Dynamic adjustment\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 38, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "ddc1aab7-7b64-4f8e-aa02-43e5de82aad9", "fitness": 0.57890018249701, "name": "HybridMetaheuristic", "description": "Enhanced exploration by adjusting mutation factor dynamically based on evaluation progress.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Dynamic mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                current_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                mutant = clip(population[a] + current_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 39, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58 with standard deviation 0.34 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.13932317100830782, 0.9559972263873588, 0.6413801500953635]}}
{"id": "ace36c31-cb9b-48f6-aba2-1c6d24085981", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor scaling for enhanced exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor scaling\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Adaptive mutation factor\n                current_mutation_factor = mutation_factor * (0.5 + 0.5 * np.random.rand())\n                mutant = clip(population[a] + current_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 40, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "eecfc9cc-8b93-42b8-89cf-358542a21edb", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced differential evolution with adaptive mutation factor based on population diversity for better global search capabilities.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor based on population diversity\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            nonlocal mutation_factor\n            diversity = np.std(population)  # Calculate diversity as standard deviation\n            mutation_factor = 0.5 + 0.3 * (diversity / self.upper_bound)  # Adjust mutation factor based on diversity\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 41, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "0f487e8b-6f9e-4c8e-a2b6-edffe610cf2d", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive dynamically adjusting mutation factor and temperature cooling for better convergence.  ", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.98  # Changed line: Modified cooling rate for gradual reduction\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor based on population diversity\n                adaptive_mutation_factor = mutation_factor * np.std(population, axis=0)\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            # Changed line: Dynamic temperature adjustment based on fitness improvement\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / (temperature * (1 - cooling_rate))):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 42, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "382b0790-3c1c-41bb-8aa3-59a6be4c1686", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor to improve convergence and exploration.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor \n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation = mutation_factor * (1 - evaluations/self.budget)\n                mutant = clip(population[a] + adaptive_mutation * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 43, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "265c90a5-5c7c-4f7a-9066-ab657820a4bc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive mutation factor adjustment for better convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.9  # Changed line: Adaptive mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 44, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "1e25daa0-dd5e-4c13-8e59-3a6434937202", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor based on success rate\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, success_rate):\n            nonlocal mutation_factor\n            mutation_factor = 0.5 + success_rate * 0.5  # Adaptive based on success rate\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        success_count = 0\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, success_count / population_size)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n                success_count += 1\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 45, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "e084d71b-74ab-42d9-826b-acbb40391547", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive population size for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10 + self.dim // 10  # Changed line: Adaptive population size\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 46, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "98f74451-49fe-48f7-9195-ab516b4693f0", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive population size and improved mutation strategy to balance exploration and exploitation for better optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 10\n        min_population_size = 5\n        mutation_factor = 0.9  # Changed line: Improved mutation strategy\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        adaptive_factor = 0.95  # New line: adaptive population size factor\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(len(population)):  # Changed line: adapt to dynamic population size\n                candidates = list(range(len(population)))  # Changed line: adapt to dynamic population size\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = len(population)  # Changed line: adapt to dynamic population size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += len(population)  # Changed line: adapt to dynamic population size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(len(population)):  # Changed line: adapt to dynamic population size\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n            # Adaptive population size change\n            if len(population) > min_population_size:  # New block: adaptive population size\n                population = population[:int(len(population) * adaptive_factor)]\n                \n        return best", "configspace": "", "generation": 47, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "cf8cde9a-47af-4dfc-a56f-38ebd92a9717", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor adjustment for better diversity and convergence in the search process.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Adjust mutation factor based on the current iteration\n                current_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                \n                mutant = clip(population[a] + current_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 48, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "5d789ed9-9f61-4c21-b2bd-92b3dcc3511a", "fitness": 0.17480737748716038, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic mutation factor for improved adaptability.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Change line: Introduce dynamic mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n            # Adjust mutation factor dynamically\n            mutation_factor = 0.5 + 0.5 * (best_fitness / max(fitness))\n            \n        return best", "configspace": "", "generation": 49, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.06 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.1409502861532348, 0.26550343375279883, 0.11796841255544754]}}
{"id": "79657fa2-aadf-47f8-9e39-41aef9f88bdc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive population dynamics and gradient-based exploitation to improve optimization efficiency.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 20  # Changed line: Adaptive population size\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.95  # Changed line: Adjusted cooling rate\n\n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        def gradient_based_exploitation(individual):\n            gradient = np.random.uniform(-0.1, 0.1, self.dim)  # Changed line: Introduced gradient-based exploration\n            new_point = clip(individual + gradient)\n            return new_point\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n                # Gradient-based exploitation\n                new_point = gradient_based_exploitation(population[i])  # Changed line: Utilize gradient-based exploitation\n                new_value = func(new_point)\n                evaluations += 1\n                if new_value < new_fitness[i]:\n                    population[i] = new_point\n                    new_fitness[i] = new_value\n                    if new_value < best_fitness:\n                        best_fitness = new_value\n                        best = new_point\n            \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 50, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "da774448-8354-450e-87d3-f01b9d6e7821", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced mutation factor management by dynamically adjusting based on population diversity for improved exploratory performance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Dynamic mutation factor based on population diversity\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            nonlocal mutation_factor\n            diversity = np.mean(np.std(population, axis=0))\n            mutation_factor = max(0.5, min(1.0, 1.5 - diversity)) # dynamically adjust based on diversity\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 51, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "75ef099a-2151-4ab4-b97f-f32e86bb653e", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 52, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "e60591e8-14f1-48d8-a69c-9ea1f387a77e", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor based on iteration progress to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            nonlocal mutation_factor  # Access the non-local mutation_factor\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Adapt mutation factor based on remaining budget\n            mutation_factor = 0.8 * (1 - evaluations / self.budget)\n            \n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 53, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "6ea33a52-7ea0-4163-9b7d-05226865e289", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduction of adaptive mutation factor based on search progress to balance exploration and exploitation more efficiently.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adjusted mutation factor dynamically\n        crossover_rate = 0.9  # Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                progress = i / population_size  # Calculate search progress\n                adaptive_mutation_factor = mutation_factor * (1 - progress)  # Adaptive mutation factor\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 54, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "bb2e40dc-d6cc-4d8b-b88e-ed32f3c72865", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive mutation factor for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.6  # Changed line: Adaptive mutation factor for better balance\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 55, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "7e5babf0-3398-42c2-bfba-c304d8f5890e", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with an adaptive mutation factor for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.7 + 0.3 * np.random.rand()  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9  # Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 56, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "273c71ce-38d2-4e4f-af2f-d66f928fd27a", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive mutation factor based on fitness variance for better convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            nonlocal mutation_factor  # Changed line: Make mutation_factor adaptive\n            fitness_variance = np.var(fitness)  # Changed line: Calculate fitness variance\n            mutation_factor = 0.5 + 0.3 * (1 - np.tanh(fitness_variance))  # Changed line: Adapt mutation factor\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            fitness = new_fitness  # Changed line: Update fitness array for variance calculation\n            \n        return best", "configspace": "", "generation": 57, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "85887979-676e-4c6d-bd1d-fa167904b333", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Improved mutation strategy for enhanced exploration in HybridMetaheuristic algorithm.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]) + np.random.normal(0, 0.1, self.dim))  # Changed line: Enhanced exploration with added noise\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 58, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "78fa39f2-4e55-4487-b0f2-0487f186ceee", "fitness": 0.07229514106336576, "name": "HybridMetaheuristic", "description": "Enhanced Hybrid Metaheuristic with adaptive mutation factor and annealing cooling rate for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.995  # Changed line: Adjusted cooling rate\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            mutation_factor *= 0.99  # Changed line: Adaptive mutation factor adjustment\n            \n        return best", "configspace": "", "generation": 59, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.09662948335212573, 0.05822531694795219, 0.06203062289001937]}}
{"id": "28234275-d79c-4162-81c8-9d20365ede65", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive mutation factor for enhanced search efficiency and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 60, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "245bb45a-26fd-414b-9c8e-567e0f1160c9", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy with adaptive mutation factor to improve convergence speed.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            mutation_factor = 0.5 + np.random.rand() * 0.5  # Adjusted line: Adaptive mutation factor\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 61, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "24cec79e-f996-4eb1-a642-aa1e5b7db9a8", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor scaling based on fitness diversity to enhance exploration and exploitation dynamics.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                fitness_variance = np.std([func(ind) for ind in population])\n                mutation_factor = 0.5 + (fitness_variance / 10.0)  # Adaptive mutation factor scaling\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 62, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "d5a67fe1-fd69-4b28-9b75-dd7fca929a6a", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for improved convergence and balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor\n                adaptive_factor = mutation_factor * (0.5 + np.random.rand() * 0.5)\n                mutant = clip(population[a] + adaptive_factor * (population[b] - population[c]))\n                \n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 63, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "35f32b16-8052-4d4d-b556-647f8d106309", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced the mutation factor for improved diversity and convergence speed.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.9  # Changed line: Enhanced mutation factor for improved performance\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 64, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "f56ff28c-ef73-4dcd-87df-4786fe62c733", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation_factor = mutation_factor * (1 - (evaluations / self.budget))  # Adaptive mutation factor\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 65, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "03337af3-62e9-4543-802f-0c97cdf7b797", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for improved search efficiency.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Adaptive mutation factor based on current evaluations\n                adaptive_mutation_factor = mutation_factor * (1 - (evaluations / self.budget))\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                \n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 66, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "c280dc23-db6e-4448-97ab-49ba2fa0bd85", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic integrating adaptive mutation strategy for improved exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Modified line for adaptive mutation strategy\n                adapt_mutation_factor = mutation_factor * (1 - (evaluations / self.budget))\n                mutant = clip(population[a] + adapt_mutation_factor * (population[b] - population[c]))\n                \n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 67, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "bf7c644b-a321-4f2c-a157-a5f4b7a3a3ca", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for dynamic exploration and fine-tuned search precision.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor adjustment\n                adaptive_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 68, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "86d85887-5bb3-4659-8c78-812aa4aff8c5", "fitness": 0.575210333298852, "name": "HybridMetaheuristic", "description": "Introducing adaptive mutation factor adjustment for enhanced exploration dynamics and faster convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor adjustment\n                adaptive_mutation_factor = 0.5 + (np.random.rand() * 0.5) \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                \n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 69, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58 with standard deviation 0.26 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.8631930915520823, 0.6388263250521302, 0.2236115832923431]}}
{"id": "cadaaba5-099b-4562-90a7-d03694338937", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for improved convergence precision.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Change 1: Adaptive mutation factor based on evaluations\n                adaptive_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 70, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "66aeb362-33ef-4b08-bdc2-4244e7788679", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Incorporating an adaptive mutation factor to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Adaptive mutation factor adjustment\n            mutation_factor = 0.8 + 0.2 * (1 - evaluations / self.budget)  # Changed line\n\n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 71, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "32887158-78fa-4cf5-934b-f78a6cd1c66e", "fitness": 0.16668333333333332, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with adaptive mutation factor and selective annealing for increased convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Line changed: Adaptive mutation factor\n                mutant = clip(population[a] + (0.5 + 0.5 * np.random.rand()) * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value, idx):\n            # Line changed: Selective annealing based on index\n            if idx % 2 == 0:\n                neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n                neighbor_value = func(neighbor)\n                if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                    return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        while evaluations < self.budget:\n            population = differential_evolution_step(population)\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            for i in range(population_size):\n                # Line changed: Pass index to annealing step\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i], i)\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 72, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 0.0, 0.0, 0.50005, 0.0, 0.0, 0.50005, 0.0, 0.0, 0.50005, 0.0, 0.0, 0.50005, 0.0, 0.0]}}
{"id": "12bf8e9d-b36c-4b8f-b74e-1c6975bf1c64", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation and crossover strategies based on population diversity for improved convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        diversity_threshold = 0.1\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def adaptive_mutation_factor(population):\n            diversity = np.mean([np.linalg.norm(ind - np.mean(population, axis=0)) for ind in population])\n            return mutation_factor * (1 + diversity / diversity_threshold)\n        \n        def adaptive_crossover_rate(fitness):\n            fitness_range = np.max(fitness) - np.min(fitness)\n            return 0.5 + 0.5 * np.tanh(fitness_range)\n        \n        def differential_evolution_step(population, fitness):\n            new_population = np.copy(population)\n            local_mutation_factor = adaptive_mutation_factor(population)\n            local_crossover_rate = adaptive_crossover_rate(fitness)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + local_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < local_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, fitness)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 73, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "152bd2e5-5000-4db3-8381-d875addc651f", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Improve exploration by adapting the mutation factor dynamically based on current diversity.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Dynamic mutation factor based on diversity\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            diversity = np.std(population)\n            adj_mutation_factor = mutation_factor * (1 + diversity / (self.upper_bound - self.lower_bound))\n\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + adj_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 74, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "1cd6d886-2007-413f-a3a4-2da06bc8316b", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive mutation factor for improved diversity and solution quality.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9  # Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor based on i\n                mutant = clip(population[a] + (mutation_factor + 0.1 * np.sin(i)) * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 75, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "8e23c30d-cf43-4a78-a3b1-ec881506b8fd", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic with a dynamic mutation factor to enhance adaptability in exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.5 + (0.3 * np.random.rand())  # Changed line: Dynamic mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 76, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "2d737f5d-ed99-4c19-a46a-c7602811bea2", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Incorporate adaptive mutation factor and population size to enhance exploration and exploitation dynamics.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, mutation_factor):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population_size = initial_population_size + int(self.budget / 1000)  # Changed line: Adaptive population size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            mutation_factor = 0.5 + 0.3 * (1 - evaluations / self.budget)  # Changed line: Adaptive mutation factor\n            population = differential_evolution_step(population, mutation_factor)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 77, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "6c9b5803-6a1d-4118-9e3d-1b3a76ca4090", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for improved solution diversity.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor \n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n            # Update mutation factor based on temperature\n            mutation_factor = 0.5 + (0.5 * (temperature / 1000.0))  # Changed line: Adaptive mutation factor\n\n        return best", "configspace": "", "generation": 78, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "7bddaf1b-2903-484c-8871-36cae4927a6d", "fitness": 0.5497955656830428, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for improved convergence dynamics.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation_factor = mutation_factor * (0.5 + np.random.rand())\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 79, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.55 with standard deviation 0.29 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.3826227347678539, 0.30349833393790837, 0.9632656283433659]}}
{"id": "b1df80ab-9b49-46bc-8210-3ec0f9793980", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with adaptive mutation factor and dynamic population sizing for improved convergence. ", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        initial_population_size = 10\n        mutation_factor_initial = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n\n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, mutation_factor):\n            new_population = np.copy(population)\n            for i in range(len(population)):\n                candidates = list(range(len(population)))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population_size = initial_population_size\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            mutation_factor = mutation_factor_initial * (1 - evaluations / self.budget)\n            population = differential_evolution_step(population, mutation_factor)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n\n            # Dynamic population sizing\n            if evaluations % 50 == 0 and population_size < 30:\n                population_size += 1\n                population = np.vstack([population, np.random.uniform(self.lower_bound, self.upper_bound, (1, self.dim))])\n                new_fitness = np.append(new_fitness, func(population[-1]))\n                evaluations += 1\n            \n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 80, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "14abdbe0-ef20-4286-9ac3-7630b10613e6", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptively adjusted mutation factor for improved search efficiency.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n                mutation_factor *= 1.05  # Changed line: Increase mutation factor slightly if improvement is found\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 81, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "b327777f-a5ea-4293-a500-95e3a328866f", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced adaptive cooling rate for simulated annealing integration in hybrid metaheuristic.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.995  # Changed line: Enhanced adaptive cooling rate for simulated annealing\n\n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 82, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "7fc84579-2979-466b-aaa0-2c51081fc5cc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive mutation factor for enhanced convergence and diversity.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.5 + 0.3 * np.random.rand()  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 83, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "bc186c83-bfc7-464c-a9de-f19c3ddb3513", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor and dynamic population sizing to enhance exploration capabilities and solution diversity.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(len(population)):  # Changed line: Dynamic population sizing\n                candidates = list(range(len(population)))  # Changed line: Dynamic population sizing\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += len(population)  # Changed line: Dynamic population sizing\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(len(population)):  # Changed line: Dynamic population sizing\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            mutation_factor = 0.5 + 0.3 * np.random.rand()  # Changed line: Adaptive mutation factor\n            \n        return best", "configspace": "", "generation": 84, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "510af79c-f11b-4b2d-b860-047c62fe7678", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation and crossover rates for balanced exploration and exploitation.  ", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 12  # Changed line: Slightly larger population size for better diversity\n        mutation_factor = 0.8\n        crossover_rate = 0.8  # Changed line: Initial crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.97  # Changed line: More aggressive cooling for faster convergence\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                adaptive_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                \n                adaptive_crossover_rate = crossover_rate + 0.1 * (1 - fitness[i] / np.max(fitness))  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 85, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "a20936ba-6b68-4d07-a8fb-b7bae4a56ad6", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive population size and dynamic mutation factor for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                # Changed line: Adjusted mutation factor calculation\n                adaptive_mutation_factor = mutation_factor * (1 - i / population_size) \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Changed line: Adaptive population size initialization\n        population_size = min(10, self.budget // (2 * self.dim))  \n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            population = differential_evolution_step(population)\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 86, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "d5580cb9-b5f0-4245-b435-4f4e64e46776", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with adaptive population size scaling for enhanced dynamic adaptation.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = max(10, int(self.budget / self.dim))  # Changed line: Adaptive population size scaling\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 87, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "7d22f243-7e4b-4357-a9c9-682679da4f0c", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Integrates adaptive mutation strategy to enhance exploration in initial stages.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation strategy\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 88, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "323ffe8f-d259-4e3c-885c-03bc2b728d3b", "fitness": 0.5077837746190458, "name": "HybridMetaheuristic", "description": "Improved solution diversity by introducing adaptive mutation based on fitness variance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation based on fitness variance\n                mutation_factor_adaptive = mutation_factor * (1 + np.var(fitness) / np.mean(fitness))\n                \n                mutant = clip(population[a] + mutation_factor_adaptive * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 89, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.51 with standard deviation 0.21 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.20963101230090264, 0.6718722862762394, 0.6418480252799952]}}
{"id": "4484a1d0-80ea-41cc-88d8-1a2d04756fbe", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced dynamic mutation factor for improved exploration in the refined hybrid metaheuristic algorithm.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Enhanced dynamic mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 90, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "179275eb-8c52-456e-aecd-ee2392161b11", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor for enhanced convergence by dynamically adjusting it based on iteration progress.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor\n                adaptive_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 91, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "4b70981b-6445-466c-b176-dc1bf846d5fc", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor based on iteration progress for improved convergence in the hybrid metaheuristic algorithm.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population, iteration):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Changed line: Adaptive mutation factor based on iteration progress\n                mutation_factor = 0.8 * (1 - iteration / self.budget)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        iteration = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population, iteration)\n            iteration += population_size\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 92, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "969b7921-4793-4a00-91d8-ea9ebd24ca58", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic integrating adaptive mutation factor for improved convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.9  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 93, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "5e04f03f-8add-4160-96f6-d5fa9d95b25b", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation factor for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n            # Adaptive mutation factor adjustment\n            mutation_factor = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            \n        return best", "configspace": "", "generation": 94, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "fdec5977-fadf-4061-826f-b483b36cd292", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with adaptive mutation factor based on the population diversity to improve convergence.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor based on diversity\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                diversity = np.mean(np.std(population, axis=0))\n                adaptive_mutation_factor = mutation_factor * (1 + diversity)\n                \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 95, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "6ef435f9-b931-42b0-bbc6-b0ead2b83ff2", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhance the hybrid metaheuristic by introducing adaptive mutation factor adjustment to improve convergence speed.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8\n        crossover_rate = 0.9  # Changed line: Dynamic crossover rate adjustment\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n                mutation_factor = max(0.5, mutation_factor * 0.95)  # Change: Adaptive mutation factor adjustment\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 96, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "d77699ef-a7c9-4eb9-a780-006595eda5cd", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Introduce a dynamic mutation factor adjustment based on iteration progress for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Dynamic mutation factor adjustment\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n            # Adjust mutation factor based on progress\n            mutation_factor = 0.5 + 0.3 * (self.budget - evaluations) / self.budget\n            \n        return best", "configspace": "", "generation": 97, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "b4610791-4570-443c-a476-801798bec3e2", "fitness": 0.1667166666666666, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by refining the mutation strategy for improved convergence speed.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.9  # Changed line: Refined mutation strategy\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                mutant = clip(population[a] + mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 98, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "7c803a78-8708-4b9a-9eff-a774a5546cfc", "fitness": 0.632704787768486, "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation factor for enhanced convergence and optimization balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        \n    def __call__(self, func):\n        population_size = 10\n        mutation_factor = 0.8  # Changed line: Adaptive mutation factor\n        crossover_rate = 0.9\n        temperature = 1000.0\n        cooling_rate = 0.99\n        \n        def clip(x):\n            return np.clip(x, self.lower_bound, self.upper_bound)\n        \n        def differential_evolution_step(population):\n            new_population = np.copy(population)\n            for i in range(population_size):\n                candidates = list(range(population_size))\n                candidates.remove(i)\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n                \n                # Adjust mutation factor based on evaluations\n                adaptive_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                \n                mutant = clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]))\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                new_population[i] = trial\n            return new_population\n        \n        def simulated_annealing_step(individual, current_value):\n            neighbor = clip(individual + np.random.normal(0, 0.1, self.dim))\n            neighbor_value = func(neighbor)\n            if neighbor_value < current_value or np.random.rand() < np.exp((current_value - neighbor_value) / temperature):\n                return neighbor, neighbor_value\n            return individual, current_value\n        \n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Differential Evolution step\n            population = differential_evolution_step(population)\n            \n            # Evaluate new population\n            new_fitness = np.array([func(ind) for ind in population])\n            evaluations += population_size\n            \n            # Update best solution\n            current_best_idx = np.argmin(new_fitness)\n            if new_fitness[current_best_idx] < best_fitness:\n                best_fitness = new_fitness[current_best_idx]\n                best = population[current_best_idx]\n            \n            # Simulated Annealing step\n            for i in range(population_size):\n                population[i], new_fitness[i] = simulated_annealing_step(population[i], new_fitness[i])\n                evaluations += 1\n                if new_fitness[i] < best_fitness:\n                    best_fitness = new_fitness[i]\n                    best = population[i]\n                    \n            # Apply cooling to temperature\n            temperature *= cooling_rate\n            \n        return best", "configspace": "", "generation": 99, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.32 on the real problem.", "error": "", "parent_ids": ["1166f83f-a7b9-4e2e-af2e-a1a71768ed4b"], "operator": null, "metadata": {"aucs": [0.7479257049187571, 0.1996814095160946, 0.9505072488706066]}}
