{"id": "fb768fa1-bff5-4795-8884-975836184f0b", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "A hybrid Particle Swarm Optimization and Simulated Annealing algorithm that balances exploration and exploitation for effective black box optimization.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "2975a5b3-65c2-4350-bf02-22175a18357e", "fitness": 0.27438333333333337, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA with dynamic parameter adjustments improving convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0  # Increased\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.95  # Adjusted\n        self.min_inertia_weight = 0.4  # New line\n        self.max_inertia_weight = 0.9  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget  # New line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.16 on similar problems with similar landscape features.", "error": "", "parent_ids": ["fb768fa1-bff5-4795-8884-975836184f0b"], "operator": null, "metadata": {"aucs": [0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997]}}
{"id": "3feae07f-3264-4359-a44b-a7e0a19fae12", "fitness": 0.2450833333333333, "name": "HybridPSO_SA", "description": "Introduced an adaptive velocity limit to prevent premature convergence and enhance exploration capabilities.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0  # Increased\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.95  # Adjusted\n        self.min_inertia_weight = 0.4  # New line\n        self.max_inertia_weight = 0.9  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget  # New line\n            velocity_limit = 0.1 * (self.upper_bound - self.lower_bound)  # New line for adaptive velocity limit\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_velocity[i] = np.clip(particles_velocity[i], -velocity_limit, velocity_limit)  # Adaptive velocity limit\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.18 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2975a5b3-65c2-4350-bf02-22175a18357e"], "operator": null, "metadata": {"aucs": [0.50005, 0.12595, 0.12595, 0.50005, 0.12595, 0.12595, 0.50005, 0.11739999999999995, 0.11739999999999995, 0.50005, 0.11739999999999995, 0.11739999999999995, 0.50005, 0.10129999999999995, 0.10129999999999995]}}
{"id": "bb778637-6f40-45b2-a6d9-58b70d7d8087", "fitness": 0.31582333333333334, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA with adaptive cooling and dynamic particle adjustment to improve convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.13 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2975a5b3-65c2-4350-bf02-22175a18357e"], "operator": null, "metadata": {"aucs": [0.50005, 0.23655000000000004, 0.23655000000000004, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.23655000000000004, 0.23655000000000004]}}
{"id": "ef90468c-24f1-4ce7-8f54-f369666b5d22", "fitness": 0.31582333333333334, "name": "HybridPSO_SA", "description": "Improved inertia weight decay formula for smoother convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)  # Changed\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.13 on similar problems with similar landscape features.", "error": "", "parent_ids": ["bb778637-6f40-45b2-a6d9-58b70d7d8087"], "operator": null, "metadata": {"aucs": [0.50005, 0.23655000000000004, 0.23655000000000004, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.23655000000000004, 0.23655000000000004]}}
{"id": "26ef31db-59c8-4549-9efc-99ea94aec93a", "fitness": 0.27438333333333337, "name": "HybridPSO_SA", "description": "A refined hybrid PSO-SA algorithm with an improved cooling strategy to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.95  # Modified\n            \n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.16 on similar problems with similar landscape features.", "error": "", "parent_ids": ["bb778637-6f40-45b2-a6d9-58b70d7d8087"], "operator": null, "metadata": {"aucs": [0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997, 0.50005, 0.16154999999999997, 0.16154999999999997]}}
{"id": "c7209c1c-280d-43e0-853b-4f012bc1e4bf", "fitness": 0.31582333333333334, "name": "HybridPSO_SA", "description": "Enhanced particle diversity with random reinitialization to avoid premature convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    self.cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations % (self.budget // 5) == 0:  # New line\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.13 on similar problems with similar landscape features.", "error": "", "parent_ids": ["bb778637-6f40-45b2-a6d9-58b70d7d8087"], "operator": null, "metadata": {"aucs": [0.50005, 0.23655000000000004, 0.23655000000000004, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.21514999999999995, 0.21514999999999995, 0.50005, 0.23655000000000004, 0.23655000000000004]}}
{"id": "e09bcd44-c46e-4ad6-a58c-a4e7cc1c4197", "fitness": 0.34641000000000005, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA with improved particle velocity update using adaptive cognitive and social coefficients for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)  # Changed line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.12 on similar problems with similar landscape features.", "error": "", "parent_ids": ["bb778637-6f40-45b2-a6d9-58b70d7d8087"], "operator": null, "metadata": {"aucs": [0.50005, 0.33125000000000004, 0.33125000000000004, 0.50005, 0.33125000000000004, 0.33125000000000004, 0.50005, 0.33125000000000004, 0.33125000000000004, 0.50005, 0.17710000000000004, 0.17710000000000004, 0.50005, 0.17710000000000004, 0.17710000000000004]}}
{"id": "4eaca4e1-160a-415e-b263-8f5506f4523a", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by adjusting the cooling rate dynamically based on the evaluation ratio for better exploitation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)  # Changed line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    self.social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate * (evaluations / self.budget)  # Modified line\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["e09bcd44-c46e-4ad6-a58c-a4e7cc1c4197"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "32093484-6d6f-4414-97a3-de057b9ef804", "fitness": 0.7310242898845701, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by integrating adaptive social coefficient and periodic particle position re-initialization for enhanced exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)  # Changed line\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)  # New line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])  # Changed line\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations % (self.budget // 5) == 0:  # New line\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["e09bcd44-c46e-4ad6-a58c-a4e7cc1c4197"], "operator": null, "metadata": {"aucs": [0.7310242898845701, 0.7310242898845701, 0.7310242898845701]}}
{"id": "cf99b6eb-b98a-440f-aa67-2cf623b3489a", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhance particle diversity and convergence rate by introducing mutation and adaptive annealing schedule based on evaluations.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            # Introduce mutation to enhance diversity\n            if evaluations % (self.budget // 20) == 0:  # New line\n                particles_position += np.random.normal(0, 0.1, particles_position.shape)  # New line\n                particles_position = np.clip(particles_position, self.lower_bound, self.upper_bound)  # New line\n\n            # Adaptive annealing schedule based on evaluations\n            self.temperature *= self.cooling_rate * (1 - evaluations / self.budget)  # Changed line\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["32093484-6d6f-4414-97a3-de057b9ef804"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "5da17a18-2574-4921-9bc7-9707d800d287", "fitness": 0.17371666666666657, "name": "HybridPSO_SA", "description": "Enhanced exploration-exploitation balance in HybridPSO_SA using chaotic maps for dynamic coefficient adaptation and improved particle diversity.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n        chaotic_factor = np.random.rand()  # New line\n\n        while evaluations < self.budget:\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # New line\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * chaotic_factor  # Changed line\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.23 on similar problems with similar landscape features.", "error": "", "parent_ids": ["32093484-6d6f-4414-97a3-de057b9ef804"], "operator": null, "metadata": {"aucs": [0.50005, 0.010549999999999948, 0.010549999999999948, 0.50005, 0.010549999999999948, 0.010549999999999948, 0.50005, 0.010549999999999948, 0.010549999999999948, 0.50005, 0.010549999999999948, 0.010549999999999948, 0.50005, 0.010549999999999948, 0.010549999999999948]}}
{"id": "6f677826-e381-4321-b88e-d85338b4449f", "fitness": 0.3193766666666666, "name": "HybridPSO_SA", "description": "Optimized HybridPSO_SA by introducing a stochastic adjustment to the cooling rate and utilizing diversity-increasing particle reinitialization.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)  # Changed line\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)  # New line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])  # Changed line\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate * (1 + np.random.normal(0, 0.05))  # Changed line\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations % (self.budget // 5) == 0:  # New line\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 12, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.13 on similar problems with similar landscape features.", "error": "", "parent_ids": ["32093484-6d6f-4414-97a3-de057b9ef804"], "operator": null, "metadata": {"aucs": [0.50005, 0.23234999999999995, 0.23234999999999995, 0.50005, 0.23234999999999995, 0.23234999999999995, 0.50005, 0.23234999999999995, 0.23234999999999995, 0.50005, 0.23234999999999995, 0.23234999999999995, 0.50005, 0.2158, 0.2158]}}
{"id": "786a26e9-c9b2-412f-b56a-13b6661db91a", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA by adjusting the cooling rate dynamically based on evaluations for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9  # Adjusted\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True  # New line\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (self.budget - evaluations) / self.budget\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)  # Changed line\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)  # New line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])  # Changed line\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate * ((self.budget - evaluations) / self.budget)  # Modified line\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:  # New line\n                self.num_particles = max(10, self.num_particles - 1)  # New line\n\n            if evaluations % (self.budget // 5) == 0:  # New line\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))  # New line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["32093484-6d6f-4414-97a3-de057b9ef804"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "2a884255-0dab-4a87-b31d-720b4e1c7505", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA by introducing inertia weight decay and random particle communication for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["32093484-6d6f-4414-97a3-de057b9ef804"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "b98bcd56-58fd-4fc6-9caa-1d2f7897d3b7", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by integrating adaptive learning rates and enhanced particle diversity for robust optimization.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n                # New line to reinitialize velocities for enhanced diversity\n                particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n            \n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "0d3d3d63-0b30-4585-95ce-20ddce7bdde0", "fitness": 0.16666666666666666, "name": "HybridPSO_SA", "description": "Enhance HybridPSO_SA by incorporating dynamic velocity bounds and early convergence detection for faster optimization.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.velocity_bound = 1.0  # New line for dynamic velocity bounds\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-self.velocity_bound, self.velocity_bound, (self.num_particles, self.dim))  # Modified line\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n        previous_global_best = global_best_value  # New line for early convergence detection\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if abs(global_best_value - previous_global_best) < 1e-6:  # Check for early convergence\n                break\n            previous_global_best = global_best_value\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0]}}
{"id": "f89c21b0-f786-4aba-90cb-f04d2b946df1", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Integrated dynamic neighborhood-based learning and enhanced diversity mechanisms to improve exploitation and exploration balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.neighbor_size = 5  # New line for neighborhood size\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                local_best_idx = np.argmin(personal_best_value[np.max([0, i - self.neighbor_size]): np.min([self.num_particles, i + self.neighbor_size + 1])])  # New line for local best\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] + \n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        \n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "49d25e0d-40c9-466c-9498-75cc67d71fb9", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Enhanced convergence by introducing learning rate adaptation and particle diversity maintenance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # Introduce diversity by repositioning a particle\n                particles_position[np.random.randint(self.num_particles)] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n            \n            if np.linalg.norm(particles_velocity) < 1e-5:  # Change 1\n                particles_velocity *= 2  # Change 2\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "6c3f53b4-934a-401a-8828-50e43ad5399d", "fitness": 0.16733538387511104, "name": "HybridPSO_SA", "description": "Refined the inertia weight decay and random communication strategy to enhance convergence and maintain diversity.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * ((self.budget - evaluations) / self.budget)  # Refined inertia weight\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                random_particle_indices = np.random.choice(range(self.num_particles), 2, replace=False)  # Choose two particles for communication\n                for idx in random_particle_indices:\n                    random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    particles_position[idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 19, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.16733538387511104, 0.16733538387511104, 0.16733538387511104]}}
{"id": "0cbbeeac-71fd-4c96-bbff-2721ba984c5c", "fitness": 0.40065, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by modifying the inertia weight update formula and adding adaptive temperature cooling for enhanced efficiency.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)  # Changed inertia weight update\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate - 0.1 * (evaluations / self.budget)  # Changed temperature cooling\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095]}}
{"id": "e3694274-ca5f-4485-9579-e6ee85507990", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Introduced adaptive cooling rate and dynamic inertia bounds for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * 0.99)  # Changed line for adaptive inertia weight\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= max(0.9, self.cooling_rate * (evaluations / self.budget))  # Changed line for adaptive cooling rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 21, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "9f153484-79b6-44ae-bd43-afe211d6dfdc", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Accelerate convergence using adaptive annealing and stochastic velocity perturbation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i]) +\n                    np.random.normal(0, 0.1, self.dim)  # New line for stochastic velocity perturbation\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / (self.temperature * 0.9)) > np.random.rand():  # Modified line for adaptive annealing\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 22, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "e87d8ac6-8f0c-4d07-830e-735f4e79f3cb", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Introduced adaptive cooling for temperature decay in Simulated Annealing to enhance exploration efficiency.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            # Adaptive cooling for temperature\n            self.temperature *= (self.cooling_rate - 0.1 * evaluations / self.budget)\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 23, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "f3fd439b-9742-4c24-8671-8dca046c25ca", "fitness": 0.6993900000000001, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA by dynamically adjusting social coefficient for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * np.random.rand()  # Modified line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.681, 0.681, 0.681, 0.71165, 0.71165, 0.71165, 0.71165, 0.71165, 0.71165, 0.71165, 0.71165, 0.71165, 0.681, 0.681, 0.681]}}
{"id": "da0ba2f3-7daf-44eb-bc3c-d6ed169c4390", "fitness": 0.6315500000000002, "name": "HybridPSO_SA", "description": "Introduced velocity clamping to prevent particle velocities from exceeding a dynamic threshold based on the evaluation budget, enhancing stability and exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                # Velocity clamping\n                max_velocity = (self.upper_bound - self.lower_bound) * (1 - evaluations / self.budget)\n                particles_velocity[i] = np.clip(particles_velocity[i], -max_velocity, max_velocity)\n                \n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 25, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001, 0.6315500000000001]}}
{"id": "e8c87c79-075b-43ca-9165-3f9761dbf0f2", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Introduce adaptive particle count and random velocity reset to enhance exploration-exploitation balance.  ", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n                \n                # Newly added line for random velocity reset\n                particles_velocity[random_particle_idx] = np.random.uniform(-1, 1, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "ea78cdaa-ea3d-484d-ae44-cefd3b325d16", "fitness": 0.40065, "name": "HybridPSO_SA", "description": "Improved exploration and exploitation balance by adjusting inertia weight dynamically and enhancing random particle communication.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            # Adjusted line for dynamic inertia weight adjustment\n            self.inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # Enhanced line for better random particle communication\n                random_particle_idx = np.random.choice(self.num_particles, size=2, replace=False)\n                for idx in random_particle_idx:\n                    particles_position[idx] = global_best_position + np.random.normal(0, 1, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095]}}
{"id": "7e31c965-420d-4477-b17b-63c51b66f89c", "fitness": 0.6618499999999999, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by introducing a dynamic cooling rate for simulated annealing and adaptive cognitive-social balancing to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            # Dynamic cooling rate adjustment\n            self.cooling_rate = 0.9 * (1 - evaluations / self.budget)\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 28, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185, 0.66185]}}
{"id": "93b29fed-04db-4a92-940e-d68de0060ed9", "fitness": 0.16071561418823144, "name": "HybridPSO_SA", "description": "Improve convergence by dynamically adjusting social and cognitive coefficients using a new exponential decay strategy.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * np.exp(-evaluations / (self.budget / 5))  # Change 1\n            adaptive_social_coefficient = self.social_coefficient * (1 - np.exp(-evaluations / (self.budget / 5)))  # Change 2\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 29, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.16071561418823144, 0.16071561418823144, 0.16071561418823144]}}
{"id": "307df28b-64c8-4ea8-971b-4efe11848f0c", "fitness": 0.40065, "name": "HybridPSO_SA", "description": "Introduced dynamic inertia weight adjustment and incorporated elite retention for improved convergence and stability.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (1 - evaluations / self.budget)  # Dynamic inertia weight\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                elite_index = np.argmin(personal_best_value)  # Elite retention\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                particles_position[elite_index] = personal_best_position[elite_index]\n\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095, 0.50005, 0.35095, 0.35095]}}
{"id": "6e68eab8-bf41-4f96-9c60-39ec8b71e6db", "fitness": 0.67058, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by introducing adaptive cooling in Simulated Annealing and adjusting cognitive-social coefficient balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.cooling_rate *= 0.995  # Change to adaptive cooling rate\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6452, 0.6452, 0.6452, 0.6452, 0.6452, 0.6452, 0.6875, 0.6875, 0.6875]}}
{"id": "4ede35e2-c8a8-42b6-a929-d13b1d5c6531", "fitness": 0.4889099999999999, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by introducing a non-linear inertia weight decay and adaptive temperature adjustment for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 + 0.01 * (1 - evaluations / self.budget))\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= (self.cooling_rate + 0.01 * (evaluations / self.budget))\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.49 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 0.4657, 0.4657, 0.50005, 0.4657, 0.4657, 0.50005, 0.4657, 0.4657, 0.50005, 0.4657, 0.4657, 0.5359499999999999, 0.5359499999999999, 0.5359499999999999]}}
{"id": "afb3ba71-7f7a-473b-aa88-7587d4179113", "fitness": 0.6660000000000001, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA with adaptive mutation and restart strategies for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.mutation_probability = 0.1  # New line for mutation probability\n        self.restart_threshold = self.budget // 3  # New line for adaptive restart strategy\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n                # Mutation step\n                if np.random.rand() < self.mutation_probability:\n                    mutated_position = particles_position[i] + np.random.normal(0, 0.1, self.dim)\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_value = func(mutated_position)\n                    evaluations += 1\n                    if mutated_value < personal_best_value[i]:\n                        personal_best_position[i] = mutated_position\n                        personal_best_value[i] = mutated_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # Restart strategy\n            if evaluations >= self.restart_threshold:\n                if evaluations % self.restart_threshold == 0:\n                    particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 33, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999, 0.6659999999999999]}}
{"id": "c22dc6d9-1295-42df-ad0a-9784aea11aef", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA by adding mutation to particle velocities for increased exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_velocity[i] += np.random.normal(0, 0.1, self.dim)  # Mutation step\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "84c4827d-bf08-4ee5-b8de-15a87f84a045", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA by introducing dynamic neighborhood topology and adaptive mutation for diversified exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.mutation_probability = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        neighbor_best_position = np.copy(personal_best_position)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                if np.random.rand() < self.mutation_probability:\n                    neighbor_idx = np.random.randint(self.num_particles)\n                    neighbor_best_position[i] = personal_best_position[neighbor_idx]\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (neighbor_best_position[i] - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 35, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "8c8ea44d-0c5b-448e-adf0-730daa5df546", "fitness": 0.5167999999999999, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by introducing a non-linear cooling schedule and dynamic adaptation of cognitive and social parameters.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget) ** 2  # Non-linear adaptation\n            adaptive_social_coefficient = self.social_coefficient * (1 - (evaluations / self.budget) ** 2)  # Non-linear adaptation\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= 1 - (0.1 * evaluations / self.budget)  # Non-linear cooling schedule\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 36, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999, 0.5167999999999999]}}
{"id": "6e338486-8ac6-4c8e-8195-547db51e2944", "fitness": 0.7318999999999998, "name": "HybridPSO_SA", "description": "Improved HybridPSO_SA by increasing diversity through periodic reinitialization of particle velocities.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random reinitialization of particle velocities\n                particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 37, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319, 0.7319]}}
{"id": "28d5765a-2f14-448c-8470-e6cbfdde4b18", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhanced particle diversity by introducing probabilistic velocity reinitialization and random bias in particle updates.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # New line for inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                if np.random.rand() < 0.05:  # New line for probabilistic velocity reinitialization\n                    particles_velocity[i] = np.random.uniform(-1, 1, self.dim)\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) + np.random.normal(0, 0.1, self.dim)  # New line for random bias in particle update\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 38, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8", "fitness": 0.9860765626973396, "name": "HybridPSO_SA", "description": "Enhanced convergence by incorporating non-linear inertia weight decay.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.99 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["2a884255-0dab-4a87-b31d-720b4e1c7505"], "operator": null, "metadata": {"aucs": [0.9860765626973396, 0.9860765626973396, 0.9860765626973396]}}
{"id": "d2a140e7-dcdd-4a48-b091-ac25ee4c47d0", "fitness": 0.7158499999999999, "name": "HybridPSO_SA", "description": "Introduce adaptive cooling in the Simulated Annealing to enhance exploration in early iterations.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate * (0.99 + 0.01 * (evaluations / self.budget))  # Adaptive cooling\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 40, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585]}}
{"id": "1ac07b0f-cf12-4798-8cec-6c84718d1826", "fitness": 0.7158499999999999, "name": "HybridPSO_SA", "description": "Enhanced exploration by dynamic particle interaction and adaptive mutation strategy.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n                # Random particle interaction\n                random_particle_index = np.random.choice(self.num_particles, 2, replace=False)\n                particles_position[random_particle_index[0]] = particles_position[random_particle_index[1]]\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 41, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585, 0.71585]}}
{"id": "e92fa290-e1a0-47f8-8dbc-a4be87b0f051", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhance exploration and exploitation by introducing dynamic randomness in velocity update.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Modified line for dynamic randomness in velocity\n                random_factor = np.random.rand(self.dim) * (1 - evaluations / self.budget)\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i]) +\n                    random_factor\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 42, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "6898414d-849c-4079-bb11-2bc491cf4372", "fitness": 0.7064500000000001, "name": "HybridPSO_SA", "description": "Introduced adaptive temperature cooling to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= (self.cooling_rate * (1 - evaluations/self.budget) + 0.1)\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 43, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645, 0.70645]}}
{"id": "64ee55cf-1a65-40bd-86ff-22031eca8d77", "fitness": 0.6609499999999998, "name": "HybridPSO_SA", "description": "Introduced dynamic particle velocity scaling based on budget utilization to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling = 1 + (0.5 * evaluations / self.budget)  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_velocity[i] *= velocity_scaling  # Apply dynamic scaling\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 44, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999, 0.6609499999999999]}}
{"id": "7a285a2a-ae97-47d4-a4b5-770f5923bc15", "fitness": 0.60135, "name": "HybridPSO_SA", "description": "Introduced a mutation strategy to enhance exploration in the optimization process.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # Mutation strategy to enhance exploration\n            mutation_prob = 0.05\n            for i in range(self.num_particles):\n                if np.random.rand() < mutation_prob:\n                    particles_position[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135, 0.60135]}}
{"id": "5d4c8449-d48e-46f1-87c8-407a12a1ae3b", "fitness": 0.6852999999999999, "name": "HybridPSO_SA", "description": "Enhanced PSO by dynamically adjusting the cooling rate for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= (self.cooling_rate + 0.1 * (1 - evaluations / self.budget))\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853, 0.6853]}}
{"id": "ccc0b75a-46b5-4ab5-88d0-1348436afadc", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Improved exploration and exploitation balance by dynamic inertia and learning adjustments.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.95  # Modified\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.min_inertia_weight + (self.max_inertia_weight - self.min_inertia_weight) * (1 - evaluations / self.budget)**2  # Modified\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (1 + np.cos(np.pi * evaluations / self.budget))  # Modified\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 47, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "a3e4f623-a433-4b98-8219-1498765a2e92", "fitness": 0.47359000000000007, "name": "HybridPSO_SA", "description": "Introduced dynamic cognitive and social coefficients to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (1 + np.sin(evaluations / self.budget * np.pi))\n            adaptive_social_coefficient = self.social_coefficient * (1 - np.sin(evaluations / self.budget * np.pi))\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                )\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 48, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47 with standard deviation 0.10 on similar problems with similar landscape features.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.5124500000000001, 0.50005, 0.22719999999999996, 0.22719999999999996]}}
{"id": "83a60ad0-daf1-4782-9406-7251fabe8ec6", "fitness": 0.994153845034275, "name": "HybridPSO_SA", "description": "Introduced dynamic velocity scaling to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.99 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["29e3ddd3-6bcd-4930-b7d1-3cd714aa02b8"], "operator": null, "metadata": {"aucs": [0.9941538450342751, 0.9941538450342751, 0.9941538450342751]}}
{"id": "eaab0e53-5d0e-4e28-b4be-65951e60a784", "fitness": 0.6358499999999998, "name": "HybridPSO_SA", "description": "Improved adaptive coefficients and enhanced exploration through modified random particle communication.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (1 - evaluations / self.budget)  # Modified line\n            adaptive_social_coefficient = self.social_coefficient * (evaluations / self.budget)  # Modified line\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585, 0.63585]}}
{"id": "28d9fd81-f169-4857-998b-ec1e579b528a", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Added random velocity boost to diversify exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                \n                # Line Changed: Added random velocity boost\n                if np.random.rand() < 0.1:\n                    particles_velocity[i] += np.random.uniform(-0.5, 0.5, self.dim)\n                    \n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 51, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "29585b3c-3315-4ea0-b1d8-83069c888550", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced particle diversity with randomized velocity initialization at key intervals.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations % (self.budget // 2) == 0:  # New line for randomized velocity initialization\n                particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 52, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "e873ead2-1ccc-4812-831d-d8c6d86f90d9", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Integrated a strategic momentum reset to enhance convergence speed and avoid local minima.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations % (self.budget // 3) == 0:  # Strategic momentum reset every third of the budget\n                particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 53, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "dbeedd57-9d3c-4128-8fbe-bead4467d7e5", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduced stochastic velocity adjustment to enhance diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # New line for stochastic velocity adjustment\n            particles_velocity += np.random.normal(0, 0.1, particles_velocity.shape)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 54, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "dead6212-2677-43ce-bcbe-af8f58d62d2d", "fitness": 0.7612000000000001, "name": "HybridPSO_SA", "description": "Introduced adaptive velocity scaling with gradient-based perturbation for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                gradient_perturbation = 0.001 * np.sign(candidate_position - personal_best_position[i])  # Gradient-based perturbation\n                candidate_position += gradient_perturbation  # Apply perturbation\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612, 0.7612]}}
{"id": "eec39040-ed90-48f1-9975-8a1198953e57", "fitness": 0.7252499999999997, "name": "HybridPSO_SA", "description": "Enhanced diversity by injecting random particles periodically and adjusted velocity scaling for improved exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - 0.8 * (evaluations / self.budget)  # Adjusted velocity scaling for better exploration\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                random_particle_idx = np.random.randint(self.num_particles)\n                particles_position[random_particle_idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)  # Mixed updated random particle line\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525, 0.72525]}}
{"id": "97bc8455-d892-410d-a752-34f50229b0d0", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Introduced uniform random restart to enhance exploration after convergence stagnation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations % (self.budget // 2) == 0:  # Introducing uniform random restart\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 57, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "c803a685-835e-4898-b143-ddf3edaa12ea", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Enhanced particle velocity update by integrating inertia weight decay with non-linear velocity scaling.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = (1 - (evaluations / self.budget)) * self.inertia_weight # Modified line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 58, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "583e6dbd-7668-4fcf-a5f9-9839b1366ec0", "fitness": 0.1710299648381648, "name": "HybridPSO_SA", "description": "Introduced adaptive velocity scaling factor for dynamic exploration and exploitation based on evaluation progress.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (0.5 * evaluations / self.budget)  # Adjusted dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 59, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.1710299648381648, 0.1710299648381648, 0.1710299648381648]}}
{"id": "3c5bda74-ce9d-40bb-a3ea-711f5b6234ba", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Improved exploration by introducing occasional random re-initialization of the worst-performing particle.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations % (self.budget // 3) == 0:  # Re-initialize the worst-performing particle occasionally\n                worst_particle_idx = np.argmax(personal_best_value)\n                particles_position[worst_particle_idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 60, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "2de90eab-82df-4124-9a32-d3cd6e248576", "fitness": 0.6608999999999999, "name": "HybridPSO_SA", "description": "Introduced dynamic global best influence scaling to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            global_best_influence_scaling = 1 + 0.1 * (evaluations / self.budget)  # Dynamic global best influence scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i]) * global_best_influence_scaling\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 61, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609, 0.6609]}}
{"id": "9c275cb7-1bf5-48fa-9e26-dcc7e6786c23", "fitness": 0.7417999999999998, "name": "HybridPSO_SA", "description": "Improved convergence by introducing adaptive cognitive and social coefficients based on the current best performance.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (global_best_value / np.mean(personal_best_value))\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 62, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418, 0.7418]}}
{"id": "89a2d8d8-8fdb-47c2-9f50-decd3deb0924", "fitness": 0.7140799999999997, "name": "HybridPSO_SA", "description": "Introduced elite particles preservation and adaptive cooling rate to enhance convergence stability.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step with elite particles preservation\n            elite_threshold = np.percentile(personal_best_value, 5)\n            for i in range(self.num_particles):\n                if personal_best_value[i] > elite_threshold:  # Preserve elite particles\n                    candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                    candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                    candidate_value = func(candidate_position)\n                    evaluations += 1\n\n                    if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                        personal_best_position[i] = candidate_position\n                        personal_best_value[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best_position = candidate_position\n                        global_best_value = candidate_value\n\n            # Adaptive cooling rate\n            self.temperature *= self.cooling_rate * (1.0 - evaluations / self.budget)\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 63, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.7342, 0.7342, 0.7342, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905, 0.70905]}}
{"id": "99048255-0987-4980-8431-f8713298d005", "fitness": 0.7208500000000002, "name": "HybridPSO_SA", "description": "Enhanced particle diversity by incorporating Levy flights for better exploration in the HybridPSO_SA algorithm.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                # Modified line to use Levy flight instead of normal distribution\n                levy_flight = np.random.standard_cauchy(self.dim)\n                candidate_position = particles_position[i] + levy_flight\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 64, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085, 0.72085]}}
{"id": "c3f41143-9c6b-45a5-bf95-3f3f20e7f692", "fitness": 0.6520600000000001, "name": "HybridPSO_SA", "description": "Enhanced exploration and exploitation by introducing an adaptive velocity scaling factor and stochastic particle seeding.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = np.random.rand()  # Changed line for stochastic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # Changed line for stochastic particle seeding\n                random_particle_idx = np.random.randint(self.num_particles)\n                particles_position[random_particle_idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 65, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.61705, 0.61705, 0.61705, 0.7921, 0.7921, 0.7921, 0.61705, 0.61705, 0.61705, 0.61705, 0.61705, 0.61705, 0.61705, 0.61705, 0.61705]}}
{"id": "9d832edd-88ef-491c-91b8-eb47cc9d81e4", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduced adaptive velocity scaling based on function value trends to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = np.exp(-np.abs(global_best_value - np.mean(personal_best_value)))  # Modified line for adaptive velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 66, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "699e127c-c8db-4ee7-b1b0-1b127a631b1c", "fitness": 0.6862999999999998, "name": "HybridPSO_SA", "description": "Enhanced HybridPSO_SA with adaptive cooling and selective reinitialization to bolster exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            # Adaptive cooling rate adjustment\n            self.cooling_rate = 0.85 + 0.05 * (evaluations / self.budget) if evaluations < self.budget // 2 else 0.9\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            # Selective reinitialization of worst-performing particles\n            if evaluations % (self.budget // 5) == 0:\n                worst_particle_idx = np.argmax(personal_best_value)\n                particles_position[worst_particle_idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 67, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863, 0.6863]}}
{"id": "40bb0049-0d2f-4dbe-a0a7-19c3545476d4", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced exploration by introducing velocity perturbation on best particles.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # Velocity perturbation on global best particle\n            if evaluations % (self.budget // 5) == 0:\n                global_best_position += np.random.normal(0, 0.1, global_best_position.shape)\n                global_best_position = np.clip(global_best_position, self.lower_bound, self.upper_bound)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 68, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "ae14fadb-303b-4b0c-b7e2-7bb3baaac996", "fitness": 0.14487282517767763, "name": "HybridPSO_SA", "description": "Introduced a periodic velocity reset to enhance exploration when stagnation is detected.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations % (self.budget // 7) == 0:  # Periodic velocity reset\n                particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 69, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.14487282517767763, 0.14487282517767763, 0.14487282517767763]}}
{"id": "d69e439a-cf83-4535-9caa-be4b42c0ade9", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduced random velocity perturbation to enhance exploration capacity.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor + np.random.normal(0, 0.1, self.dim)  # Added random velocity perturbation\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 70, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "763a939e-fcf2-4d61-916a-ab5bfe83883a", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduced adaptive temperature scaling in Simulated Annealing to refine exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate * (1 - (evaluations / self.budget))  # Changed line for adaptive temperature scaling\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 71, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "5ff2b89e-450b-4f7c-ade0-422e14af7037", "fitness": 0.7224500000000001, "name": "HybridPSO_SA", "description": "Enhanced the balance of exploration and exploitation by introducing adaptive velocity bounds and a crossover mechanism inspired by genetic algorithms.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.velocity_bound = 0.5  # New line to introduce velocity bounds\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = np.clip(  # Modified line to clip velocity\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i]),\n                    -self.velocity_bound, self.velocity_bound\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            # New crossover mechanism inspired by genetic algorithms\n            if evaluations % (self.budget // 10) == 0:\n                for j in range(self.num_particles // 2):  # Crossover between first half of particles\n                    idx1, idx2 = np.random.choice(self.num_particles, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    particles_position[idx1] = alpha * particles_position[idx1] + (1 - alpha) * particles_position[idx2]\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 72, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245, 0.72245]}}
{"id": "d737ca41-467f-4343-84c7-20b8952a222b", "fitness": 0.6565499999999999, "name": "HybridPSO_SA", "description": "Added a convergence acceleration factor to increase the likelihood of escaping local minima.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            convergence_acceleration = 1 + (0.1 * (1 - evaluations / self.budget))  # Added convergence acceleration factor\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor * convergence_acceleration  # Modified line to apply acceleration\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 73, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655, 0.65655]}}
{"id": "499eed49-02de-46f0-b22c-c66baee2525e", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduced stochastic factor in velocity update and increased randomness in simulated annealing for enhanced exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand() * 0.1  # Added stochastic factor r3\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i]) +\n                    r3 * np.random.uniform(-1, 1, self.dim)  # Applied stochastic factor\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1.5, self.dim)  # Increased randomness\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 74, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "09503e67-7ff0-4bac-8838-348bd7b88a6b", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduced elite particle preservation and enhanced adaptive parameter tuning for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.95 - 0.02 * (evaluations/self.budget))  # Line changed for more adaptive decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (1.2 - 0.4 * (evaluations / self.budget))  # Line changed\n            adaptive_social_coefficient = self.social_coefficient * (1.1 - 0.6 * (evaluations / self.budget))  # Line changed\n            velocity_scaling_factor = 1 - (evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # New line for elite particle preservation\n            elite_indices = personal_best_value.argsort()[:5] \n            elite_positions = personal_best_position[elite_indices]\n            particles_position[:5] = elite_positions\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 75, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "27b283dc-2747-40a0-a487-21f5f533da83", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Introduced adaptive exploration and exploitation control using diversity measure and neighborhood communication to improve convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            diversity = np.std(particles_position) / (self.upper_bound - self.lower_bound)  # Diversity measure\n            if diversity < 0.2:  # Adaptive exploration and exploitation\n                velocity_scaling_factor *= 1.1\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n                # New line for neighbor communication\n                neighbor_idx = (random_particle_idx + 1) % self.num_particles\n                particles_position[neighbor_idx] += 0.5 * (particles_position[random_particle_idx] - particles_position[neighbor_idx])\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 76, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "55fd8816-8128-4661-9a40-799c7a5b4974", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Introduced a convergence-triggered global best reset to escape local optima.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # NEW LINE: Global best reset if no improvement\n            if evaluations % (self.budget // 10) == 0 and global_best_value == np.min(personal_best_value):\n                global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 77, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "16c08046-e418-4ebe-9b32-b2d5e31a2db2", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Introduced random inertia weight resetting for enhanced exploration during stagnation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n                # Randomly reset inertia weight to boost exploration\n                self.inertia_weight = np.random.uniform(self.min_inertia_weight, self.max_inertia_weight)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 78, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "68522faa-c933-420f-9d2e-af3a0d90d7fb", "fitness": 0.14487282517767763, "name": "HybridPSO_SA", "description": "Enhanced exploration by introducing time-varying random particle communication. ", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:  # Modified line for time-varying communication\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 79, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.14487282517767763, 0.14487282517767763, 0.14487282517767763]}}
{"id": "225d991d-9363-45c7-894f-7f1f298e0858", "fitness": 0.35674999999999996, "name": "HybridPSO_SA", "description": "Enhanced personal best update condition with stochastic influence to increase diversity.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best with stochastic influence\n                if new_value < personal_best_value[i] or np.random.rand() < 0.1:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 80, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.30 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.6417999999999999, 0.6417999999999999, 0.6417999999999999, 0.6417999999999999, 0.6417999999999999, 0.6417999999999999, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "b32d37f5-e86d-47e6-b8a0-44b2fd1d4968", "fitness": -Infinity, "name": "HybridPSO_SA", "description": "Enhanced particle update strategy by integrating gradient-based guidance for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n\n                # Gradient-based guidance\n                gradient_estimate = np.gradient(lambda x: func(x), particles_position[i])\n                particles_velocity[i] += -0.01 * gradient_estimate\n\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 81, "feedback": "An exception occurred: TypeError('invalid number of arguments').", "error": "TypeError('invalid number of arguments')", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {}}
{"id": "0eda7aec-3a4e-4740-92df-767607b5ad26", "fitness": 0.7005499999999999, "name": "RefinedHybridPSO_SA", "description": "Enhanced with adaptive particle re-initialization and elitism to bolster convergence robustness.", "code": "import numpy as np\n\nclass RefinedHybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.dynamic_particles = True\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                indices = np.random.choice(self.num_particles, size=self.num_particles//3, replace=False)\n                for idx in indices:\n                    particles_position[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 82, "feedback": "The algorithm RefinedHybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "b19c31c5-9989-449a-b86a-d4e377a0d557", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced performance by introducing dynamic particle count adjustment based on temperature.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, int(self.num_particles * (self.temperature / 1000)))  # Enhanced line for dynamic particle count adjustment\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 83, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "1c4605a5-b3d7-458e-91dd-2ecc9a7f1689", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Introduced adaptive particle size adjustment to dynamically enhance search precision.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n                # New adaptive particle size adjustment\n                self.dim = max(1, int(self.dim * (evaluations / self.budget)))\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 84, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "f76613dc-4d34-4cc6-b8ef-4658b88e3c19", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Introduced adaptive temperature cooling in the Simulated Annealing step to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / (self.temperature * (1 - evaluations / self.budget))) > np.random.rand():  # Adaptive cooling\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 85, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "aa16c9b6-c28a-4b31-bd6c-7fe6c1fde150", "fitness": 0.66877, "name": "HybridPSO_SA", "description": "Included adaptive mutation scaling in the Simulated Annealing step to enhance diversity.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            mutation_scale = np.exp(-evaluations / (self.budget / 5))  # Adaptive mutation scaling\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, mutation_scale, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 86, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.6802, 0.6802, 0.6802, 0.66115, 0.66115, 0.66115, 0.66115, 0.66115, 0.66115, 0.66115, 0.66115, 0.66115, 0.6802, 0.6802, 0.6802]}}
{"id": "b49ee402-79a5-49c3-95f4-8143403689ed", "fitness": 0.7058699999999999, "name": "HybridPSO_SA", "description": "Enhanced dynamic swarm strategy with adaptive annealing and diversity preservation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.95  # Adjusted cooling rate\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.alpha = 0.01  # New line for annealing rate adjustment\n        self.diversity_threshold = 0.1  # New line for diversity management\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step with adaptive temperature\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, self.alpha, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            # Adding diversity preservation strategy\n            if np.std(particles_position) < self.diversity_threshold:\n                particles_position += np.random.normal(0, 0.1, particles_position.shape)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 87, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.7464999999999999, 0.7464999999999999, 0.7464999999999999, 0.70585, 0.70585, 0.70585, 0.66525, 0.66525, 0.66525, 0.66525, 0.66525, 0.66525, 0.7464999999999999, 0.7464999999999999, 0.7464999999999999]}}
{"id": "526f3c72-8f9d-42a2-88ff-6b527175ab0a", "fitness": 0.6919800000000003, "name": "HybridPSO_SA", "description": "Enhanced solution diversity by introducing stochastic adaptive social and cognitive coefficients.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            \n            # Modified line for stochastic adaptive coefficients\n            adaptive_cognitive_coefficient *= np.random.uniform(0.9, 1.1)\n            adaptive_social_coefficient *= np.random.uniform(0.9, 1.1)\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 88, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.68215, 0.7313000000000001, 0.7313000000000001, 0.7313000000000001]}}
{"id": "929ad397-396c-4033-89bb-c29180def0ff", "fitness": 0.11323049294372722, "name": "HybridPSO_SA", "description": "Enhanced adaptive learning and diversity mechanisms to further optimize balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.diversity_factor = 0.1  # New parameter for adaptive diversity\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim) * (1 + self.diversity_factor * np.random.randn(self.dim))  # Increased diversity factor\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 89, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.11323049294372722, 0.11323049294372722, 0.11323049294372722]}}
{"id": "92aea489-79b3-4a76-a916-18324e54410f", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced particle reincarnation strategy to improve exploration by periodically resetting a portion of particles to random positions.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            # Change: Reset 10% of particles to random positions every 1/5th of the budget\n            if evaluations % (self.budget // 5) == 0:\n                num_reset_particles = max(1, self.num_particles // 10)\n                reset_indices = np.random.choice(self.num_particles, num_reset_particles, replace=False)\n                particles_position[reset_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (num_reset_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 90, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "133dc488-1f33-469c-99aa-92311dbd2466", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Introduce nonlinear cooling in Simulated Annealing for adaptive exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate * (1 - evaluations / self.budget)  # Modified line for nonlinear cooling\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 91, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "2e9a03ac-177e-4f4e-b3d7-10df4e415a91", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced particle diversity and convergence by adapting velocity parameters and introducing an elite reinitialization step.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget) \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                elite_position = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)  # Elite reinitialization\n                particles_position[np.random.randint(self.num_particles)] = elite_position\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 92, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "ebf9a441-aa9a-4196-838d-7c2096034f8e", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced local exploration by adding adaptive mutation based on velocity magnitude.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for adaptive mutation based on velocity magnitude\n                for i in range(self.num_particles):\n                    if np.linalg.norm(particles_velocity[i]) > 2.0:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        particles_position[i] += mutation\n                        particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 93, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "1046b0cf-252a-407d-aefc-e65b9fba0e1e", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced global exploration by introducing periodic random velocity reset.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations % (self.budget // 3) == 0:  # New line for periodic random velocity reset\n                particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 94, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "26eb6f54-5b5c-4912-913a-d661a1f8abd4", "fitness": 0.6986300000000001, "name": "HybridPSO_SA", "description": "Introduced a small perturbation to the velocity scaling factor for enhanced exploration.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            # Add a small perturbation to the velocity scaling factor\n            velocity_scaling_factor = 1 - (evaluations / self.budget) + 0.01 * np.sin(evaluations)  # Modified line\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 95, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.7007, 0.69035, 0.69035, 0.69035]}}
{"id": "90eb1783-9b08-45cb-9762-c66c912ddc6a", "fitness": 0.7304999999999997, "name": "HybridPSO_SA", "description": "Enhanced hybrid algorithm by introducing adaptive particle reset and optimized inertia weight decay.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight = max(self.min_inertia_weight, self.inertia_weight * (0.95 - 0.01 * (evaluations/self.budget)))  # Adjusted inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                reset_rate = 0.1  # Adaptive particle reset\n                for j in np.random.choice(self.num_particles, int(self.num_particles * reset_rate), replace=False):\n                    particles_position[j] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 96, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999, 0.7304999999999999]}}
{"id": "deeb588b-dedd-4e4d-8a0e-e0a3fe8fd3dd", "fitness": 0.1667166666666666, "name": "HybridPSO_SA", "description": "Incorporated stochastic velocity perturbation and adaptive particle count to enhance diversity and convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                \n                if np.random.rand() < 0.05:  # Stochastic velocity perturbation\n                    particles_velocity[i] += np.random.normal(0, 0.1, self.dim)\n                \n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, int(50 * (1 - evaluations / self.budget)))  # Adaptive particle count\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 97, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "cdae7381-06cc-4d29-872c-b72b18bd9ade", "fitness": 0.7005499999999999, "name": "HybridPSO_SA", "description": "Enhanced adaptive strategy by introducing multi-stage dynamic velocity scaling and adaptive particle reduction.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            stage = evaluations / self.budget\n            self.inertia_weight *= (0.99 - 0.01 * stage)\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (stage)\n            adaptive_social_coefficient = self.social_coefficient * (1 - stage)\n            velocity_scaling_factor = 1 - stage  # Dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, int(self.num_particles - 1.5 * stage * self.num_particles))\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 98, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.00 on similar problems with similar landscape features.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055, 0.70055]}}
{"id": "6629ba42-5e55-4688-9b05-7e11e8136fe5", "fitness": 0.14487282517767763, "name": "HybridPSO_SA", "description": "Introduced memory for global best values to aid convergence.", "code": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 1.5\n        self.temperature = 1000.0\n        self.cooling_rate = 0.9\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.dynamic_particles = True\n        self.global_best_memory = None  # Added line for global best memory\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        particles_velocity = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_position = np.copy(particles_position)\n        personal_best_value = np.array([func(p) for p in personal_best_position])\n        global_best_position = personal_best_position[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            self.inertia_weight *= (0.99 - 0.01 * (evaluations/self.budget))  # Non-linear inertia weight decay\n            adaptive_cognitive_coefficient = self.cognitive_coefficient * (evaluations / self.budget)\n            adaptive_social_coefficient = self.social_coefficient * (1 - evaluations / self.budget)\n            velocity_scaling_factor = 1 - (evaluations / self.budget)  # New line for dynamic velocity scaling\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                particles_velocity[i] = (\n                    self.inertia_weight * particles_velocity[i] +\n                    adaptive_cognitive_coefficient * r1 * (personal_best_position[i] - particles_position[i]) +\n                    adaptive_social_coefficient * r2 * (global_best_position - particles_position[i])\n                ) * velocity_scaling_factor  # Modified line to apply scaling factor\n                particles_position[i] += particles_velocity[i]\n                particles_position[i] = np.clip(particles_position[i], self.lower_bound, self.upper_bound)\n                \n                # Evaluate new position\n                new_value = func(particles_position[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_value < personal_best_value[i]:\n                    personal_best_position[i] = particles_position[i]\n                    personal_best_value[i] = new_value\n\n                # Update global best\n                if new_value < global_best_value:\n                    global_best_position = particles_position[i]\n                    global_best_value = new_value\n\n            # Simulated Annealing step\n            for i in range(self.num_particles):\n                candidate_position = particles_position[i] + np.random.normal(0, 1, self.dim)\n                candidate_position = np.clip(candidate_position, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                evaluations += 1\n\n                if candidate_value < personal_best_value[i] or np.exp((personal_best_value[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best_position[i] = candidate_position\n                    personal_best_value[i] = candidate_value\n\n                if candidate_value < global_best_value:\n                    global_best_position = candidate_position\n                    global_best_value = candidate_value\n\n            self.temperature *= self.cooling_rate\n\n            if evaluations % (self.budget // 10) == 0 and self.dynamic_particles:\n                self.num_particles = max(10, self.num_particles - 1)\n\n            if evaluations % (self.budget // 5) == 0:\n                particles_position = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n                \n                # New line for random particle communication\n                random_particle_idx = np.random.randint(self.num_particles)\n                random_particle = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                particles_position[random_particle_idx] = random_particle\n\n            if self.global_best_memory is None or global_best_value < self.global_best_memory:\n                self.global_best_memory = global_best_value\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, global_best_value", "configspace": "", "generation": 99, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00 on the real problem.", "error": "", "parent_ids": ["83a60ad0-daf1-4782-9406-7251fabe8ec6"], "operator": null, "metadata": {"aucs": [0.14487282517767763, 0.14487282517767763, 0.14487282517767763]}}
