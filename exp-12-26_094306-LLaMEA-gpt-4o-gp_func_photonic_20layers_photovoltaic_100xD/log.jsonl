{"id": "b0c487d2-0662-48a5-95c3-c6eb88780755", "fitness": 0.08845503995309495, "name": "AdaptiveSwarmDifferentialEvolution", "description": "Adaptive Swarm-Driven Differential Evolution using Dynamic Dimensionality Reduction for efficient exploration and exploitation across varied dimensional landscapes.", "code": "import numpy as np\n\nclass AdaptiveSwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)  # Ensures sufficient diversity\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                trial_vector = np.clip(population[a] + self.mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n                \n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSwarmDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08846 with standard deviation 0.04105.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.061241235943552574, 0.06098989043503822, 0.07368708901825949, 0.14073941549347935, 0.14023099620572832, 0.15537877705092185, 0.048345254702865104, 0.051968129790703865, 0.06351457093730584]}}
{"id": "8bf421f8-7000-4cd6-8ced-40fbb46927a4", "fitness": 0.08922252224281765, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Dynamic Learning Rate and Adaptive Crossover to improve convergence speed and solution precision across diverse dimensional spaces.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08922 with standard deviation 0.04202.", "error": "", "parent_ids": ["b0c487d2-0662-48a5-95c3-c6eb88780755"], "operator": null, "metadata": {"aucs": [0.0664456946581441, 0.06349346373943221, 0.06469184535958816, 0.15847473375177645, 0.1415326464313763, 0.14392140118296826, 0.05857586847435625, 0.05043756102468355, 0.05542948556303362]}}
{"id": "391c7271-9ed5-4c46-a02f-fd610fe564fc", "fitness": 0.0801388147769482, "name": "AdaptiveSwarmDEWithOBL", "description": "Adaptive Swarm Differential Evolution with Opposition-Based Learning to augment diversity and convergence speed through the entire search space.", "code": "import numpy as np\n\nclass AdaptiveSwarmDEWithOBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n            # Opposition-Based Learning \n            opposition_population = lower_bound + upper_bound - population\n            opposition_fitness = np.array([func(op) for op in opposition_population])\n            self.evaluations += len(opposition_population)\n\n            combined_population = np.concatenate((population, opposition_population))\n            combined_fitness = np.concatenate((fitness, opposition_fitness))\n            \n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSwarmDEWithOBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08014 with standard deviation 0.04175.", "error": "", "parent_ids": ["8bf421f8-7000-4cd6-8ced-40fbb46927a4"], "operator": null, "metadata": {"aucs": [0.05839152529644098, 0.05488191892979055, 0.054878652304711784, 0.13826519240854507, 0.1377874688679146, 0.14043753501163403, 0.04763879648561686, 0.04309364644530178, 0.04587459724257814]}}
{"id": "20c13bc7-5332-44f4-8995-9814460717e1", "fitness": 0.08743015508267406, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Dynamic Mutation and Crossover Intensification for superior convergence and exploration balance across varied dimensions.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Dynamic intensification of mutation factor based on fitness variance\n                pop_std = np.std(fitness)\n                dynamic_mutation_factor = self.base_mutation_factor * (1 - (self.evaluations / self.budget)) * (1 + pop_std / (1 + np.mean(fitness)))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate with increased probability for exploration\n                dynamic_crossover_rate = self.base_crossover_rate + 0.15 * (1 - (fitness[i] / (1 + np.max(fitness))))\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08743 with standard deviation 0.04011.", "error": "", "parent_ids": ["8bf421f8-7000-4cd6-8ced-40fbb46927a4"], "operator": null, "metadata": {"aucs": [0.059409764726222614, 0.06042407862228805, 0.07148848695045484, 0.14272721961469848, 0.14373525256198172, 0.14467934356264212, 0.05355100773251775, 0.05734331093029954, 0.0535129310429614]}}
{"id": "627d360e-e30b-4ebc-b0ea-0719a85fc268", "fitness": 0.08639509512781841, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Integrative Mutation and Adaptive Population Size for improved exploration and exploitation balance and faster convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * \n                                       ((population[b] - population[c]) + np.random.rand(self.dim) * \n                                        (population[np.random.randint(self.population_size)] - population[i])), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08640 with standard deviation 0.04121.", "error": "", "parent_ids": ["8bf421f8-7000-4cd6-8ced-40fbb46927a4"], "operator": null, "metadata": {"aucs": [0.06285337609368491, 0.06093715099803776, 0.06353488372385363, 0.14007791708326078, 0.14444171342381207, 0.14827979697346616, 0.056164655775227224, 0.049319037742580174, 0.051947324336443]}}
{"id": "53b24436-38f5-42e3-b802-b31b450e57f5", "fitness": 0.08922252224281765, "name": "EnhancedAdaptiveSwarmDE", "description": "Introducing adaptive population size scaling and elite preservation to enhance diversity and prevent premature convergence in Enhanced Adaptive Swarm DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n            # Introduce adaptive population scaling and elite preservation\n            elite_idx = np.argmin(fitness)\n            population = np.append(population, population[elite_idx:elite_idx+1], axis=0)\n            fitness = np.append(fitness, fitness[elite_idx])\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08922 with standard deviation 0.04202.", "error": "", "parent_ids": ["8bf421f8-7000-4cd6-8ced-40fbb46927a4"], "operator": null, "metadata": {"aucs": [0.0664456946581441, 0.06349346373943221, 0.06469184535958816, 0.15847473375177645, 0.1415326464313763, 0.14392140118296826, 0.05857586847435625, 0.05043756102468355, 0.05542948556303362]}}
{"id": "ae764124-7c9b-4764-93a6-4835a446735e", "fitness": 0.09176682042849521, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Dynamic Learning Rate, Adaptive Crossover, and Elite Preservation to maintain diversity and accelerate convergence in high-dimensional spaces.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09177 with standard deviation 0.03971.", "error": "", "parent_ids": ["8bf421f8-7000-4cd6-8ced-40fbb46927a4"], "operator": null, "metadata": {"aucs": [0.07607855596342605, 0.06265626296337612, 0.06821904234666287, 0.1505933718481186, 0.14060782973580022, 0.15029961542889125, 0.06626357669554017, 0.05390140686942824, 0.05728172200521342]}}
{"id": "2fa2a7ce-bafe-4708-92f7-7b767b22a1fc", "fitness": 0.08883842944119906, "name": "ImprovedEnhancedAdaptiveSwarmDE", "description": "Improved Enhanced Adaptive Swarm Differential Evolution with Dynamic Strategy Adaptation and Fitness Memory to enhance convergence and robustness in diverse optimization landscapes.", "code": "import numpy as np\n\nclass ImprovedEnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.memory_factor = 0.1\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        fitness_memory = fitness.copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.uniform()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Dynamic Strategy Adaptation: update population based on historical fitness memory\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                if fitness[worst_index] > (1 - self.memory_factor) * fitness_memory[worst_index]:\n                    population[worst_index] = best_individual\n                    fitness[worst_index] = func(best_individual)\n                    self.evaluations += 1\n\n            # Update fitness memory with a decay factor\n            fitness_memory = (1 - self.memory_factor) * fitness_memory + self.memory_factor * fitness\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 7, "feedback": "The algorithm ImprovedEnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08884 with standard deviation 0.03947.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.07042701480495239, 0.06285731625852409, 0.06442554023111813, 0.14500664821294773, 0.13888956654074858, 0.14840762985095957, 0.06231398639451469, 0.050700199236223265, 0.056517963440803065]}}
{"id": "e14a21a5-b090-419c-b176-4b78b2a359fd", "fitness": 0.08608315134242069, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduced stochastic component in mutation factor to enhance diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget)) * (1 + 0.1 * np.random.rand())\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08608 with standard deviation 0.04146.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.05538900759814003, 0.061195856877885646, 0.06018961673374679, 0.14348801425720037, 0.14688866907061715, 0.14344327073100915, 0.05368752254341169, 0.05554020131382664, 0.054926202955948744]}}
{"id": "25bf1650-4a9a-4893-af3b-155ff5261c51", "fitness": 0.08588332353450236, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Improved Diversity through Modified Mutation Strategy to ensure robust exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Modified mutation strategy for enhanced diversity\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                random_individual = population[np.random.randint(self.population_size)]\n                trial_vector = np.clip(random_individual + dynamic_mutation_factor * (population[a] - population[b]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08588 with standard deviation 0.04413.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.05800518632406526, 0.05810728308334934, 0.06411678791035713, 0.14501266998783113, 0.14438010879556862, 0.1541066243495436, 0.0476983807038559, 0.05270153819893675, 0.04882133245701348]}}
{"id": "ba7ae3a6-918a-4b11-9156-a18440943c01", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Adaptive Population Resizing, Dynamic Learning and Crossover Rates, and Elite Reinsertion for improved diversity and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lower_bound, upper_bound, (population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget)**0.5)\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite reinsertion: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n            # Adaptive population resizing\n            if self.evaluations % (self.budget // 4) == 0:\n                new_population_size = max(4, population_size // 2)\n                indices = np.argsort(fitness)[:new_population_size]\n                population = population[indices]\n                fitness = fitness[indices]\n                population_size = new_population_size\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 10, "feedback": "An exception occurred: IndexError('index 54 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 54 is out of bounds for axis 0 with size 50')", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {}}
{"id": "63687c95-bb33-4407-a177-ccd60971ec3a", "fitness": 0.08810148131105412, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduced Self-Adaptive Mechanisms and Local Search to the Enhanced Adaptive Swarm Differential Evolution for refined exploration and exploitation, thus improving convergence accuracy and speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Self-adaptive mutation factor\n                dynamic_mutation_factor = self.mutation_factor * np.exp(-0.1 * (self.evaluations / self.budget))\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                # Self-adaptive crossover rate\n                dynamic_crossover_rate = self.crossover_rate * (1 - 0.5 * (fitness[i] - fitness[best_index]) / (fitness.max() - fitness.min() + 1e-12)) + 0.1 * np.random.rand()\n\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Local search around the best individual found\n            if self.evaluations < self.budget:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                local_trial = np.clip(best_individual + perturbation, lower_bound, upper_bound)\n                local_fitness = func(local_trial)\n                self.evaluations += 1\n\n                if local_fitness < fitness[best_index]:\n                    fitness[best_index] = local_fitness\n                    best_individual = local_trial.copy()\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08810 with standard deviation 0.04143.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.060253442374391675, 0.05856263087543745, 0.06402759427243432, 0.1476858857625416, 0.1461376985647127, 0.1453274219833548, 0.050130828086477286, 0.06540369604532104, 0.05538413383481622]}}
{"id": "014b150e-9562-4f79-bc37-256a269a5765", "fitness": 0.07589395328730869, "name": "ModifiedAdaptiveSwarmDE", "description": "Modified Adaptive Swarm Differential Evolution with Dynamic Group Strategies and Enhanced Diversity to improve exploration and convergence in varied dimensional landscapes.", "code": "import numpy as np\n\nclass ModifiedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.initial_mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = np.array([j for j in range(self.population_size) if j != i])\n                chosen_indices = np.random.choice(indices, 3, replace=False)\n                a, b, c = chosen_indices\n\n                # Adjust mutation factor dynamically\n                dynamic_mutation_factor = self.initial_mutation_factor * (0.5 + 0.5 * np.random.rand()) * (1 - (self.evaluations / self.budget))\n                \n                # Group-based dynamic mutation strategy\n                group_center = (population[a] + population[b] + population[c]) / 3\n                trial_vector = np.clip(group_center + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                # Adjust crossover rate dynamically\n                dynamic_crossover_rate = self.crossover_rate + 0.2 * (np.random.rand() - 0.5)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                if fitness[worst_index] > fitness[best_index]:\n                    population[worst_index] = best_individual\n                    fitness[worst_index] = func(best_individual)\n                    self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 12, "feedback": "The algorithm ModifiedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07589 with standard deviation 0.04249.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.05178176649547972, 0.050510662136674545, 0.049697832219887994, 0.13566691268810827, 0.13418320102501224, 0.13730108177984313, 0.04269061559937892, 0.04184524254175359, 0.039368265099639754]}}
{"id": "f51f401e-3e7d-49f8-a050-2ab1c924629f", "fitness": 0.09164534384218095, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Optimized Elite Replacement Strategy to boost convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                if func(best_individual) < fitness[worst_index]: # Only replace if better\n                    population[worst_index] = best_individual\n                    fitness[worst_index] = func(best_individual)\n                    self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09165 with standard deviation 0.03975.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.07591221709736817, 0.0626077340316662, 0.06808145534087917, 0.15048935176770295, 0.1405529642686657, 0.15026073113837057, 0.06602821356238064, 0.05364905842826484, 0.05722636894433031]}}
{"id": "4cf4920f-0fa5-457b-b569-b4c31b37e23f", "fitness": 0.08337106813261175, "name": "MultiStrategyAdaptiveSwarmDE", "description": "Multi-Strategy Adaptive Swarm Differential Evolution with Hybrid Dynamic Parameters and Neighborhood Learning for Enhanced Exploration and Exploitation Balance in Diverse Search Spaces.", "code": "import numpy as np\n\nclass MultiStrategyAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            neighborhood = np.zeros((self.population_size, self.dim))\n            \n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Incorporate neighborhood learning\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                neighbors = [population[j] for j in indices if np.linalg.norm(population[j] - population[i]) < (upper_bound - lower_bound).mean() / 2]\n                if neighbors:\n                    neighborhood[i] = np.mean(neighbors, axis=0)\n                    trial = np.clip(neighborhood[i] + dynamic_mutation_factor * (best_individual - neighborhood[i]), \n                                    lower_bound, upper_bound)\n\n                    trial_fitness = func(trial)\n                    self.evaluations += 1\n\n                    if trial_fitness < fitness[i]:\n                        fitness[i] = trial_fitness\n                        population[i] = trial\n\n                        if trial_fitness < fitness[best_index]:\n                            best_index = i\n                            best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 14, "feedback": "The algorithm MultiStrategyAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08337 with standard deviation 0.04046.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.06395269826916494, 0.056814615871989216, 0.05663338980370425, 0.1425458078624129, 0.13682834113899456, 0.1402254351316129, 0.06278159654714266, 0.04235419196571355, 0.04820353660277077]}}
{"id": "f763e21c-86d4-4e1e-b27c-73602fa69507", "fitness": 0.08702008620610256, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Dynamic Learning Rate, Adaptive Crossover, Elite Preservation, and Stochastic Reinitialization to maintain diversity and prevent premature convergence in high-dimensional spaces.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.reinitialization_threshold = 0.2\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n            # Stochastic Reinitialization to maintain diversity\n            if np.random.rand() < self.reinitialization_threshold:\n                reinit_index = np.argmax(fitness)\n                population[reinit_index] = np.random.uniform(lower_bound, upper_bound, self.dim)\n                fitness[reinit_index] = func(population[reinit_index])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08702 with standard deviation 0.04088.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.06705201257870519, 0.05775976350117562, 0.06122930239942437, 0.15059429287930115, 0.13978022781007815, 0.14287667642597812, 0.0588791339964706, 0.05329755215920717, 0.0517118141045827]}}
{"id": "979727b7-7099-41ff-bc90-586e71fffcde", "fitness": 0.09659914621685116, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm Differential Evolution with Dynamic Learning Rate, Adaptive Crossover, Elite Preservation, and Partially Informed Dynamic Mutation for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n                # Change: Adjust trial vector using the mean of selected individuals for mutation\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09660 with standard deviation 0.03750.", "error": "", "parent_ids": ["ae764124-7c9b-4764-93a6-4835a446735e"], "operator": null, "metadata": {"aucs": [0.08120455680153782, 0.07372663950807212, 0.0782537600562192, 0.14827473904982968, 0.14791427835044102, 0.15004940138334044, 0.07018953884423673, 0.058294812842319854, 0.06148458911566357]}}
{"id": "9679c20b-ca56-4ec1-8c45-9dd0e0539e02", "fitness": 0.08863753967760397, "name": "RefinedAdaptiveSwarmDE", "description": "\"Refined Adaptive Swarm DE with Adaptive Step Size Control and Shared Information for Improved Convergence.\"", "code": "import numpy as np\n\nclass RefinedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor_base = 0.8\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        while self.evaluations < self.budget:\n            global_best = np.mean(population, axis=0)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Dynamic mutation factor based on progress and shared information\n                progress = self.evaluations / self.budget\n                dynamic_mutation_factor = self.mutation_factor_base * (1 - progress) + 0.1 * np.linalg.norm(global_best - population[i]) / (upper_bound - lower_bound).max()\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n\n            # Elite preservation: replace the worst individual with the best known if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = best_individual\n                fitness[worst_index] = func(best_individual)\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 17, "feedback": "The algorithm RefinedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08864 with standard deviation 0.03904.", "error": "", "parent_ids": ["979727b7-7099-41ff-bc90-586e71fffcde"], "operator": null, "metadata": {"aucs": [0.07471333893914367, 0.06271004791275692, 0.067338250583025, 0.14707467948203823, 0.14063864714879815, 0.14147358498797546, 0.05683808459638373, 0.05397305718865664, 0.05297816625965801]}}
{"id": "f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0", "fitness": 0.09792731991167064, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Adaptive Population Reshaping and Historical Best Influence for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09793 with standard deviation 0.03581.", "error": "", "parent_ids": ["979727b7-7099-41ff-bc90-586e71fffcde"], "operator": null, "metadata": {"aucs": [0.07295265698219633, 0.08152386551153312, 0.08060403151951523, 0.1503681958884422, 0.14575828677821523, 0.14768266046258338, 0.06905942809754095, 0.0716717210555099, 0.06172503290949938]}}
{"id": "6c425d78-72bc-4ac1-b1cb-02d1376d0c29", "fitness": 0.09524746641666174, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Dynamic Learning Rate and Elite Recombination for improved exploration-exploitation balance and solution refinement.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            dynamic_learning_rate = 0.5 * (1 - self.evaluations / self.budget)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + dynamic_learning_rate * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                recombination_factor = np.random.rand()\n                population[worst_index] = recombination_factor * self.history_best[0] + (1 - recombination_factor) * population[worst_index]\n                fitness[worst_index] = func(population[worst_index])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09525 with standard deviation 0.03663.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.06902720102456972, 0.07177330350007671, 0.07345360245401855, 0.1440310838634823, 0.14856534208376304, 0.14809620012528857, 0.06358090721217224, 0.06931453542356458, 0.06938502206301989]}}
{"id": "c17b4cb1-709e-4e73-b65e-46cc3fd92d83", "fitness": 0.08498125349297087, "name": "AdvancedCompositeSwarmDE", "description": "AdvancedCompositeSwarmDE utilizes dynamic adaptive mutation, historical influence, and elite preservation with random reinitialization for enhanced convergence and solution diversity.", "code": "import numpy as np\n\nclass AdvancedCompositeSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + np.random.rand())\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.1 if np.random.rand() < 0.3 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                if np.random.rand() < 0.1:\n                    # Random reinitialization for diversity\n                    population[worst_index] = np.random.uniform(lower_bound, upper_bound, self.dim)\n                else:\n                    population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(population[worst_index])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 20, "feedback": "The algorithm AdvancedCompositeSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08498 with standard deviation 0.04200.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.059475895142120816, 0.05822347412504447, 0.05982405253904899, 0.14248655446372727, 0.14082186647103678, 0.14910996561000078, 0.05114792930049694, 0.05151336065949497, 0.052228183125766714]}}
{"id": "a9780404-0214-4dbc-8c2b-93e56f32c8ec", "fitness": 0.09715957197218877, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduced Dynamic Local Search and Self-Adaptive Historical Best Influence for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adjusted self-adaptive influence\n                historical_influence = 0.1 * (1 - (self.evaluations / self.budget)) if np.random.rand() < 0.3 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                # Local search improvement\n                if np.random.rand() < 0.1:\n                    trial = np.clip(trial + 0.05 * np.random.randn(self.dim), lower_bound, upper_bound)\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09716 with standard deviation 0.03865.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07264304763818386, 0.08074888385689794, 0.06814173928104172, 0.14914983370239765, 0.15215988894657173, 0.1530041355088484, 0.06822300017568417, 0.06571714722999711, 0.06464847141007635]}}
{"id": "e2397dcc-7e34-4186-b4e6-9ef1a01a394b", "fitness": 0.08527448302487647, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Local Search and Improved Crossover for refined solution exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.15 * (best_individual - population[i]),\n                                       lower_bound, upper_bound)\n\n                # Improved crossover with probability adjustment based on iteration\n                iteration_factor = (self.evaluations / self.budget)\n                dynamic_crossover_rate = self.crossover_rate * (1 - iteration_factor) + np.random.rand() * iteration_factor\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n                # Local search enhancement if within budget\n                if self.evaluations < self.budget:\n                    random_idx = np.random.randint(0, self.dim)\n                    local_perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    candidate = np.clip(population[i] + local_perturbation, lower_bound, upper_bound)\n                    candidate_fitness = func(candidate)\n                    self.evaluations += 1\n                    if candidate_fitness < fitness[i]:\n                        population[i] = candidate\n                        fitness[i] = candidate_fitness\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08527 with standard deviation 0.04113.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.05762523428392141, 0.05724281915985541, 0.057474896704361345, 0.13868742120942912, 0.1448445124697081, 0.14629488171019456, 0.04976042856186813, 0.05639524390593964, 0.0591449092186106]}}
{"id": "ff69ae5a-e9c4-4709-8ce0-e5d2a6352e05", "fitness": 0.09679906866272227, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Adaptive Mutation Rate based on Fitness Diversity for improved exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            fitness_diversity = np.std(fitness) / np.mean(fitness) # New line\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand() * (1 + fitness_diversity) # Modified line\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09680 with standard deviation 0.03563.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07269873897319012, 0.08520876990668513, 0.07209601125660525, 0.14677594477012368, 0.14810918609319934, 0.14493468083687977, 0.06462449244824386, 0.06785220377924217, 0.06889158990033106]}}
{"id": "9b01d35e-b200-4729-9a07-b9f31a3ee2db", "fitness": 0.09407804886643284, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Adaptive Population Reshaping, Historical Best Influence, and Dynamic Scaling for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adjusted mutation factor with dynamic scaling\n                scale = 1 + 0.5 * (1 - (self.evaluations / self.budget))\n                dynamic_mutation_factor = scale * self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09408 with standard deviation 0.04030.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07009699746836617, 0.06755350068023935, 0.06894056978630347, 0.1511041446397563, 0.15422565133113608, 0.14735871379643328, 0.0627362364636751, 0.061651846383403375, 0.06303477924858236]}}
{"id": "ab8928fe-454d-495c-b0ed-a6b176329392", "fitness": 0.08528227426390979, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Dynamic Recombination and Time-Varying Strategy for Improved Global Search and Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            current_phase = self.evaluations / self.budget  # Tracking the progress through the budget\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Dynamic mutation factor based on current phase\n                dynamic_mutation_factor = self.mutation_factor * (1 - current_phase) * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                # Time-varying crossover rate with historical best influence\n                dynamic_crossover_rate = self.crossover_rate + 0.1 * current_phase * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08528 with standard deviation 0.04176.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.060543050692767664, 0.05235065663431182, 0.06653748014074146, 0.1423788856477457, 0.1413818836096966, 0.14765186457358503, 0.05444065520453356, 0.04530149705779973, 0.056954494814006495]}}
{"id": "8bcb35f6-472a-45e4-8510-bfb1b0d2cf04", "fitness": 0.0958186488316393, "name": "EnhancedAdaptiveSwarmDE", "description": "Improved adaptive mutation factor and crossover probability using historical best weighted influence for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand() * (1 + 0.1 * (self.history_best[1] / (fitness[i] + 1e-8)))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand() * (1 - 0.1 * (self.history_best[1] / (fitness[i] + 1e-8)))\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09582 with standard deviation 0.04041.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.072072784629723, 0.0679690850951099, 0.07481752201859737, 0.15535197541053059, 0.14745816656601884, 0.15501752854369633, 0.06569971715015999, 0.06304549405390214, 0.06093556601701555]}}
{"id": "09381852-0454-414f-8ad7-b10119f65b16", "fitness": 0.09761711623454586, "name": "AdaptiveHistoricalMemoryDE", "description": "Adaptive Historical Memory Differential Evolution introduces a dynamic memory component to adaptively adjust control parameters based on past successful solutions for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveHistoricalMemoryDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.memory = []\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(\n                    population[a] + dynamic_mutation_factor * (population[b] - population[c]) + \n                    0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                    lower_bound, upper_bound)\n\n                historical_influence = 0.1 * np.random.rand() if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                    self.memory.append((trial.copy(), trial_fitness))\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n                # Use historical memory to fine-tune parameters\n                if len(self.memory) > 0:\n                    best_mem = min(self.memory, key=lambda x: x[1])\n                    if best_mem[1] < trial_fitness:\n                        self.crossover_rate = np.clip(self.crossover_rate + 0.01 * np.random.randn(), 0.6, 1.0)\n                        self.mutation_factor = np.clip(self.mutation_factor + 0.01 * np.random.randn(), 0.5, 1.0)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveHistoricalMemoryDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09762 with standard deviation 0.03697.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07034032313276573, 0.07223823425163389, 0.08234745668312515, 0.15092498610643967, 0.14865735186866735, 0.14887576636160038, 0.06294044908963758, 0.07186690701060139, 0.07036257160644155]}}
{"id": "57d7cfa2-014f-4d4a-817a-53f30455f265", "fitness": 0.08719405294556594, "name": "ImprovedEnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Dynamic Strategy Adaptation and Local Search Integration to improve the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedEnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.strategy_probabilities = np.array([0.5, 0.5])  # Probabilities for mutation strategies\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Strategy selection based on adaptive probabilities\n                strategy = np.random.choice([0, 1], p=self.strategy_probabilities)\n\n                if strategy == 0:  # Classic DE mutation\n                    dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                    trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                           lower_bound, upper_bound)\n                else:  # Alternative mutation strategy\n                    trial_vector = np.clip(population[a] + 0.5 * np.random.rand() * (best_individual - population[b]),\n                                           lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n                    # Update strategy probabilities based on success\n                    self.strategy_probabilities[strategy] += 0.1\n                    self.strategy_probabilities = self.strategy_probabilities / np.sum(self.strategy_probabilities)\n\n            # Elite preservation with local search: replace the worst with the historical best if budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n                # Local search around historical best\n                if self.evaluations < self.budget:\n                    perturbation = np.random.uniform(-0.1, 0.1, self.dim)\n                    local_trial = np.clip(self.history_best[0] + perturbation, lower_bound, upper_bound)\n                    local_trial_fitness = func(local_trial)\n                    self.evaluations += 1\n                    if local_trial_fitness < self.history_best[1]:\n                        self.history_best = (local_trial.copy(), local_trial_fitness)\n                        best_individual = local_trial.copy()\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 28, "feedback": "The algorithm ImprovedEnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08719 with standard deviation 0.04096.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.0598111889152656, 0.0719126051882889, 0.059877072847096535, 0.14264086102528928, 0.14710880663468884, 0.14382750323690852, 0.04919928186879352, 0.05620180268352226, 0.054167354110239985]}}
{"id": "aaf33c14-0d25-4616-a53b-be8201670611", "fitness": 0.09742247354841822, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with Dynamic Learning Strategy and Stochastic Elite Preservation for improved convergence rate and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + \n                                       0.1 * (population[a] + population[b] + population[c]) / 3.0,\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Stochastic elite preservation\n            if self.evaluations < self.budget and np.random.rand() < 0.5:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09742 with standard deviation 0.03661.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07261425795911547, 0.0821669578648273, 0.07745527700219323, 0.14822808310112767, 0.14891453482020767, 0.14892191651608722, 0.06499453863719684, 0.06637866211681787, 0.06712803391819078]}}
{"id": "a58c78de-ebed-4b60-9408-a1e98321e980", "fitness": 0.09220079174609991, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with modified mutation strategy for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 + 0.2 * np.random.randn())  # Modified mutation strategy\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.1 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09220 with standard deviation 0.04096.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07207413539530128, 0.06597590817106258, 0.06174792521581873, 0.15527028722316183, 0.14455766915849289, 0.14954026982724966, 0.06038595177955819, 0.0597411973898363, 0.06051378155441778]}}
{"id": "58bc2e60-ed16-4a2b-b32b-2b90690cee36", "fitness": 0.09869784770842048, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with improved historical best influence for better convergence speed and stability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.2 else 0  # Changed the historical influence factor\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09870 with standard deviation 0.03595.", "error": "", "parent_ids": ["f40ef5c1-86ec-4f5e-8523-7bde6c17fbf0"], "operator": null, "metadata": {"aucs": [0.07951891243717468, 0.07659488531037051, 0.07398339001721943, 0.14622167737856295, 0.1512850738671465, 0.1502773144859112, 0.06644227231048938, 0.07444596641577095, 0.06951113715313872]}}
{"id": "37e2b3f8-4e35-4aab-b8b4-b7f38759ba93", "fitness": 0.08592160966911234, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with dynamic adaptive parameters and elite re-initialization for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor\n                dynamic_mutation_factor = self.mutation_factor + 0.1 * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.3 else 0  # Increased historical influence probability\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite re-initialization\n            if self.evaluations < self.budget and np.random.rand() < 0.1:  # Re-initialize elite with probability\n                worst_index = np.argmax(fitness)\n                population[worst_index] = np.random.uniform(lower_bound, upper_bound, self.dim)\n                fitness[worst_index] = func(population[worst_index])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08592 with standard deviation 0.04169.", "error": "", "parent_ids": ["58bc2e60-ed16-4a2b-b32b-2b90690cee36"], "operator": null, "metadata": {"aucs": [0.060543635555816544, 0.060083416137508894, 0.05823355215891346, 0.14617587009030897, 0.14304192615653155, 0.1447298145648036, 0.04781798301632223, 0.05825931226650927, 0.05440897707529657]}}
{"id": "90313b0b-5106-47c1-9fe1-dc1592570adf", "fitness": 0.08692746158346608, "name": "EnhancedAdaptiveSwarmDE", "description": "EnhancedAdaptiveSwarmDE with adaptive scaling factor and opposition-based learning for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on success rate\n                success_rate = np.clip((self.evaluations / self.budget), 0, 1)\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + 0.5 * success_rate)\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.2 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                # Opposition-based learning\n                opposite_trial = lower_bound + upper_bound - trial\n                opposite_fitness = func(opposite_trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i] or opposite_fitness < fitness[i]:\n                    if opposite_fitness < trial_fitness:\n                        population[i] = opposite_trial\n                        fitness[i] = opposite_fitness\n                    else:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n\n                    if fitness[i] < fitness[best_index]:\n                        best_index = i\n                        best_individual = population[i].copy()\n                        if fitness[i] < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), fitness[i])\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08693 with standard deviation 0.04081.", "error": "", "parent_ids": ["58bc2e60-ed16-4a2b-b32b-2b90690cee36"], "operator": null, "metadata": {"aucs": [0.058850186440795316, 0.06165423920349011, 0.06063951804421586, 0.1436766084418788, 0.14717665418160542, 0.1421801113116692, 0.05772923195786783, 0.0480208789782014, 0.062419725691470807]}}
{"id": "fb565f1c-16c0-4cfe-bcbc-79df69809130", "fitness": 0.10100873681512762, "name": "EnhancedAdaptiveSwarmDE", "description": "Minor enhancement of Adaptive Swarm DE by adjusting historical influence frequency for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10101 with standard deviation 0.03497.", "error": "", "parent_ids": ["58bc2e60-ed16-4a2b-b32b-2b90690cee36"], "operator": null, "metadata": {"aucs": [0.0771143799690599, 0.07222545110287093, 0.08630262890598528, 0.15320420904829524, 0.1474774360047305, 0.14668663701787754, 0.0687593387837403, 0.09246752801172664, 0.0648410224918623]}}
{"id": "180c21dc-20dc-4bd0-b452-de1ff477ebcf", "fitness": 0.10100873681512762, "name": "EnhancedAdaptiveSwarmDE", "description": "Introducing a dynamic learning rate in Enhanced Adaptive Swarm DE to further balance exploration and exploitation, improving convergence rate and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    learning_rate = np.tanh(1 - (self.evaluations / self.budget))  # Dynamic learning rate\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10101 with standard deviation 0.03497.", "error": "", "parent_ids": ["fb565f1c-16c0-4cfe-bcbc-79df69809130"], "operator": null, "metadata": {"aucs": [0.0771143799690599, 0.07222545110287093, 0.08630262890598528, 0.15320420904829524, 0.1474774360047305, 0.14668663701787754, 0.0687593387837403, 0.09246752801172664, 0.0648410224918623]}}
{"id": "8d823d35-36e8-44ec-9756-d8ca6916184a", "fitness": 0.10100873681512762, "name": "EnhancedAdaptiveSwarmDE", "description": "Refined Adaptive Swarm DE with dynamic learning rate and random subset selection for enhanced convergence precision.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.learning_rate = 0.1  # New dynamic learning rate\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                subset_size = max(3, int(0.1 * self.population_size))  # Random subset size\n                subset_indices = np.random.choice(indices, subset_size, replace=False)\n                a, b, c = subset_indices[:3]\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + self.learning_rate * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10101 with standard deviation 0.03497.", "error": "", "parent_ids": ["fb565f1c-16c0-4cfe-bcbc-79df69809130"], "operator": null, "metadata": {"aucs": [0.0771143799690599, 0.07222545110287093, 0.08630262890598528, 0.15320420904829524, 0.1474774360047305, 0.14668663701787754, 0.0687593387837403, 0.09246752801172664, 0.0648410224918623]}}
{"id": "75a43648-09ee-4fcf-9bf8-ed00a0c21597", "fitness": 0.09656113976676811, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce a dynamic population size and adaptive mutation-crossover strategy in EnhancedAdaptiveSwarmDE for improved performance across diverse optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lower_bound, upper_bound, (population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 - self.evaluations / self.budget)\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adjust crossover rate dynamically based on progress\n                historical_influence = 0.15 if np.random.rand() < (0.25 * (self.evaluations / self.budget)) else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Adjust population size based on progress\n            if self.evaluations > self.budget * 0.5:\n                population_size = max(4, self.initial_population_size // 2)\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09656 with standard deviation 0.03688.", "error": "", "parent_ids": ["fb565f1c-16c0-4cfe-bcbc-79df69809130"], "operator": null, "metadata": {"aucs": [0.0667661166116098, 0.07434214634211667, 0.07297087638019173, 0.15187129232562557, 0.1463369327818842, 0.147475503208658, 0.06902157562283728, 0.06687698104244444, 0.07338883358554527]}}
{"id": "ab0b20c4-59c5-40b9-b450-f37115510f2a", "fitness": 0.10100873681512762, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced Adaptive Swarm DE with improved elite preservation by incorporating diversity check.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                # Introduced a diversity check\n                if np.linalg.norm(population[worst_index] - self.history_best[0]) > 1e-5: \n                    population[worst_index] = self.history_best[0]\n                    fitness[worst_index] = func(self.history_best[0])\n                    self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10101 with standard deviation 0.03497.", "error": "", "parent_ids": ["fb565f1c-16c0-4cfe-bcbc-79df69809130"], "operator": null, "metadata": {"aucs": [0.0771143799690599, 0.07222545110287093, 0.08630262890598528, 0.15320420904829524, 0.1474774360047305, 0.14668663701787754, 0.0687593387837403, 0.09246752801172664, 0.0648410224918623]}}
{"id": "20ba3898-39c0-4c28-975e-3d595a82a8c9", "fitness": 0.08974342199522498, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduces a dynamic scaling factor and adaptive selection pressure to balance exploration-exploitation more effectively in adaptive swarm DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Dynamic mutation factor with exploration-exploitation balance\n                scaling_factor = 1 - (self.evaluations / self.budget)\n                dynamic_mutation_factor = self.base_mutation_factor * np.random.rand() * scaling_factor\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced adaptive crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.base_crossover_rate - historical_influence * (1 - scaling_factor)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08974 with standard deviation 0.04177.", "error": "", "parent_ids": ["fb565f1c-16c0-4cfe-bcbc-79df69809130"], "operator": null, "metadata": {"aucs": [0.06435322250156672, 0.06193187568973191, 0.063643287392951, 0.1434043852698047, 0.15207403354875526, 0.14774203825789045, 0.04800234445499185, 0.050416001034898295, 0.07612360980643462]}}
{"id": "c111c6bc-8b3e-4dc0-870f-e83355e5490f", "fitness": 0.10136317989661395, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce dynamic population size adjustment based on convergence rate to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10136 with standard deviation 0.03560.", "error": "", "parent_ids": ["fb565f1c-16c0-4cfe-bcbc-79df69809130"], "operator": null, "metadata": {"aucs": [0.0778982351366656, 0.07671074042379578, 0.0872893220193357, 0.15095421571302214, 0.14647663076558892, 0.15273765406275752, 0.06757044889780939, 0.09246752801172664, 0.0601638440388238]}}
{"id": "a5e4fa40-0774-425f-984e-15a0a70600cb", "fitness": 0.09231020214204833, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhanced diversity introduction through adaptive mutation factor and selective lifetime strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + np.random.rand())  # Enhanced adaptive mutation\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09231 with standard deviation 0.03939.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06584118451684506, 0.07314762594633106, 0.07135368977459056, 0.1476142313307125, 0.14624593748027803, 0.148635400291386, 0.05328187948591656, 0.06272331233330364, 0.06194855811907152]}}
{"id": "d0246708-cd9e-43e0-a699-e618946311fa", "fitness": 0.09294607910539324, "name": "EnhancedAdaptiveSwarmDE", "description": "Integrate a dynamic mutation factor influenced by current fitness variance to enhance diversification and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Modify the dynamic mutation factor\n                fitness_variance = np.var(fitness)\n                dynamic_mutation_factor = self.mutation_factor * (1.0 + fitness_variance / 10.0) * np.random.rand()\n                \n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09295 with standard deviation 0.04166.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0651157222605715, 0.0700225171024692, 0.06638470245802519, 0.15826410319610473, 0.14755872740830822, 0.148817817189701, 0.06222243694222662, 0.057157753218956, 0.06097093217217664]}}
{"id": "c4477dbe-cab7-42f9-ae8b-cdb0e58cf0ca", "fitness": 0.09757980837515318, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance diversity by incorporating adaptive mutation and crossover rates based on population diversity metrics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                # Change 1: Adaptive crossover rate\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * (np.std(fitness) / np.mean(fitness))\n\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Change 2: Adjust mutation factor\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n                # Change 3: Diversity-based mutation factor\n                self.mutation_factor = 0.5 + 0.3 * (np.std(fitness) / np.mean(fitness))\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09758 with standard deviation 0.03664.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07226016930957302, 0.08793998426985083, 0.07673686264669954, 0.14862503328339827, 0.14694831586851032, 0.14979818190939131, 0.062194432708501, 0.06554593182115742, 0.06816936355929681]}}
{"id": "8ddd17de-a5d7-497e-9d72-19102939e33f", "fitness": 0.08608461969961127, "name": "EnhancedAdaptiveSwarmDE", "description": "Implement self-adaptive mutation factor and local search intensification to enhance convergence and diversification balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        mutation_factors = np.random.uniform(0.5, 1.0, self.population_size)\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                trial_mutation_factor = mutation_factors[i]\n                trial_vector = np.clip(population[a] + trial_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                    mutation_factors[i] = 0.5 * mutation_factors[i] + 0.5 * np.random.uniform(0, 1)\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                mutation_factors = np.concatenate((mutation_factors, np.random.uniform(0.5, 1.0, len(new_individuals))))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                mutation_factors = mutation_factors[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08608 with standard deviation 0.04110.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.060957563744831966, 0.06036187569823215, 0.06675597494093666, 0.1437982521781156, 0.1425101776422225, 0.14481966517967593, 0.0483849307444425, 0.058134411460842084, 0.049038725707202024]}}
{"id": "0135e3b0-d84e-48c0-9e98-daee3a83edc9", "fitness": 0.09199119530692555, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance mutation strategy with adaptive scaling based on iteration progress and improve information sharing.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            dynamic_mutation_factor = self.mutation_factor + (1 - self.mutation_factor) * (self.evaluations / self.budget)  # Adaptive scaling\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  \n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09199 with standard deviation 0.04109.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06289474088020552, 0.0621739159370257, 0.07508887822856147, 0.1501427065326456, 0.14680114092765117, 0.15216786500528878, 0.05884317980195375, 0.05808717491840254, 0.06172115553059543]}}
{"id": "312bcbb4-8246-4984-b621-e3578f03dc5b", "fitness": 0.08474454688134908, "name": "EnhancedAdaptiveSwarmDE", "description": "Incorporate adaptive mutation and crossover rates using diversity metrics to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on population diversity\n                diversity = np.std(population, axis=0).mean()\n                dynamic_mutation_factor = self.mutation_factor * (1 + 0.5 * diversity)\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate based on diversity\n                dynamic_crossover_rate = self.crossover_rate * (1 + 0.2 * diversity)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08474 with standard deviation 0.03830.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.05769739677108365, 0.05979208450296247, 0.05921813514581087, 0.13660484387314897, 0.13702160202887959, 0.1427289482750027, 0.05231791230827176, 0.058894219983392504, 0.058425779043589254]}}
{"id": "e6f66604-8f67-4fa3-9a21-bf1ccdda44ea", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Fine-tune dynamic mutation factor by introducing a bias towards lower values to enhance convergence in the later stages.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand() * 0.9  # Slight bias towards lower values\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 47, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "e91d9384-7fcd-484c-8df8-2d6d8ad9ec2b", "fitness": 0.09611769354671336, "name": "EnhancedAdaptiveSwarmDE", "description": "Integrate adaptive mutation factor scaling with fitness diversity consideration to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.diversity_threshold = 0.05\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            diversity = np.std(fitness) / np.mean(fitness)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor scaling with diversity consideration\n                dynamic_mutation_factor = self.mutation_factor * (1 + diversity) * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09612 with standard deviation 0.03853.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.076505283593719, 0.07554461665849332, 0.0684145129800543, 0.14765185222893362, 0.1471192742785884, 0.15571942208387113, 0.061684886163696606, 0.065883513617778, 0.0665358803152859]}}
{"id": "610bb5f7-feee-4c0f-8dec-623a83e3707b", "fitness": 0.08596011977358864, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance the mutation mechanism and adjust the convergence threshold to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.005  # Updated convergence threshold\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + 0.5 * np.random.rand())  # Enhanced mutation mechanism\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08596 with standard deviation 0.04328.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.056525397792917875, 0.06162446189173276, 0.05911868187464031, 0.14775894988412286, 0.1464492736600893, 0.14662764467154776, 0.05209742217814617, 0.05539371031328133, 0.048045535695819375]}}
{"id": "113bfc47-dc01-44b4-831b-d84e5f92b97e", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Integrate adaptive mutation and crossover strategies with entropy-based selection to enhance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor\n                diversity = np.std(population, axis=0)\n                dynamic_mutation_factor = self.mutation_factor + 0.5 * np.random.rand() * diversity.mean()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate based on entropy\n                entropy = -np.sum(fitness / np.sum(fitness) * np.log(fitness / np.sum(fitness) + 1e-12))\n                dynamic_crossover_rate = self.crossover_rate * (1 + entropy / self.dim)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 50, "feedback": "An exception occurred: IndexError('index 105 is out of bounds for axis 0 with size 105').", "error": "IndexError('index 105 is out of bounds for axis 0 with size 105')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "8572737b-e463-4132-af6a-2034a19655d3", "fitness": 0.09078344942732591, "name": "EnhancedAdaptiveSwarmDE", "description": "Utilize adaptive mutation factor scaling based on fitness improvement rate to enhance diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adjust mutation factor based on fitness improvement rate\n                improvement_rate = (fitness[i] - prev_best_fit) / (fitness[i] + 1e-10)\n                dynamic_mutation_factor = self.mutation_factor * (1 + 0.5 * improvement_rate)\n                \n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09078 with standard deviation 0.04057.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06387495472714744, 0.06549573604056957, 0.06664576203330386, 0.1427799882175298, 0.14835008537279415, 0.15253359576456837, 0.06313961958341341, 0.05601524856195561, 0.05821605454465095]}}
{"id": "eaa7aeb1-d9f2-4ad9-9a99-518ae7e81ba5", "fitness": 0.08964999355619646, "name": "EnhancedAdaptiveSwarmDE", "description": "Integrate adaptive mutation scaling based on historical fitness diversity to enhance exploration in diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.historical_fitness = []\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            self.historical_fitness.append(prev_best_fit)\n            mean_fitness = np.mean(self.historical_fitness[-10:])  # Consider last 10 evaluations\n            fitness_std = np.std(self.historical_fitness[-10:])\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                adaptive_mutation_factor = self.mutation_factor * (1 + fitness_std / mean_fitness)\n                trial_vector = np.clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08965 with standard deviation 0.03986.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06432290491514847, 0.06175059708705066, 0.0660390788170756, 0.1417277409104889, 0.14481317614519318, 0.15093865444791932, 0.06069328864075896, 0.05648706687004201, 0.060077434172091104]}}
{"id": "11c11b6a-ac95-4520-8397-88ac7de889e3", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation scaling based on fitness improvement rate for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on fitness improvement rate\n                improvement_rate = max(0.1, min(1.0, abs(prev_best_fit - fitness[best_index]))) \n                dynamic_mutation_factor = self.mutation_factor * improvement_rate \n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 53, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "99cbdb5c-1542-4d84-97a5-0e6b4ca86244", "fitness": 0.08324264573207488, "name": "EnhancedAdaptiveSwarmDEWithFeedback", "description": "Introduce adaptive learning rates and multi-strategy mutation based on performance feedback to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDEWithFeedback:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.learning_rate = 0.1  # New adaptive learning rate\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Multi-strategy mutation\n                if np.random.rand() < 0.5:\n                    dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                    trial_vector = population[a] + dynamic_mutation_factor * (population[b] - population[c])\n                else:\n                    trial_vector = population[a] + self.learning_rate * (population[b] - population[c])\n\n                trial_vector = np.clip(trial_vector, lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveSwarmDEWithFeedback got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08324 with standard deviation 0.04266.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.05574880110231384, 0.052357959102968366, 0.05746435620363022, 0.1397181476371694, 0.1467981302604101, 0.14384637234568243, 0.05091951392023142, 0.049813550364155246, 0.052516980652112855]}}
{"id": "5a9f1876-8a02-41ae-aefd-dac35b14cc9e", "fitness": 0.09548015445146572, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce a dynamic adaptive mutation factor based on iteration progress to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Introduce dynamic adaptive mutation factor based on iteration progress\n                progress = self.evaluations / self.budget\n                dynamic_mutation_factor = self.mutation_factor * (1 - progress) * np.random.rand()\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09548 with standard deviation 0.03870.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06900988437861255, 0.0686871580570273, 0.07045616134821175, 0.15282430002059377, 0.1506562683340258, 0.1467830596816715, 0.06908469289463726, 0.06934280617832522, 0.06247705917008639]}}
{"id": "c8505017-2b64-43f7-b8a5-5d815a6eabbf", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Incorporate adaptive learning and memory mechanisms to enhance the balance between exploration and exploitation by adjusting strategy parameters based on past performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.memory = []  # Memory to store past best solutions\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.uniform(0.5, 1.5)\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate influenced by memory\n                historical_influence = 0.15 * len(self.memory) / (self.memory[-1][1] - self.history_best[1] + 1e-8)\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n                            self.memory.append((best_individual.copy(), trial_fitness))  # Update memory\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 56, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "c25f3096-9772-4307-abeb-d5b1c7cad353", "fitness": 0.08738649845981757, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance DE with adaptive control of mutation and crossover rates based on population diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            fitness_std = np.std(fitness)  # Calculate population diversity\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                adaptive_mutation_factor = self.mutation_factor * (1 + fitness_std)  # Adapt mutation factor\n                trial_vector = np.clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08739 with standard deviation 0.04103.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.05824189831404314, 0.05912220744083718, 0.05982678294487309, 0.1455867403987232, 0.14529633322416668, 0.14534672515098424, 0.05808330426508368, 0.057622204618834605, 0.057352289780812304]}}
{"id": "d55a318b-6cc9-41e9-9fea-2e5cd82b60ef", "fitness": 0.08775188343687647, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance mutation strategy by integrating population variance to maintain diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Updated dynamic mutation factor incorporating population diversity\n                dynamic_mutation_factor = self.mutation_factor * (1 + np.var(population, axis=0).mean()) * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08775 with standard deviation 0.03699.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06227818102401228, 0.0640199113855826, 0.06025607709645797, 0.1384307072530777, 0.13739713795179953, 0.14402856532809805, 0.05802305779737038, 0.060827596656370275, 0.0645057164391194]}}
{"id": "8b5841cd-57de-48bb-9f04-0cfeaa449fb8", "fitness": 0.09835215995061168, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance exploitation by introducing a best-of-random selection strategy during trial vector generation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                candidates = np.random.choice(indices, 5, replace=False)  # Select 5 candidates\n                best_candidate = min(candidates, key=lambda idx: fitness[idx])  # Best of 5 selection\n                a, b, c = np.random.choice(candidates, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09835 with standard deviation 0.03697.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07599119250431152, 0.07304590670742217, 0.07528112393277886, 0.1525500963406281, 0.1477301445056305, 0.1507672979319583, 0.06490867214652563, 0.07719701755296937, 0.06769798793328063]}}
{"id": "85396bba-5ba3-41ed-9b71-733a294ebc17", "fitness": 0.08993616736757974, "name": "EnhancedAdaptiveSwarmDE", "description": "Implement adaptive mutation and crossover based on diversity and elite reintegration to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            population_std = np.std(population, axis=0).mean()\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on population diversity\n                dynamic_mutation_factor = self.mutation_factor * (1 + 0.5 * (population_std / (np.std(population[a]) + 1e-9)))\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate\n                dynamic_crossover_rate = self.crossover_rate * (1 + 0.5 * (1 - fitness[i] / (fitness[best_index] + 1e-9)))\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite reintegration: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08994 with standard deviation 0.04039.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06684434200682998, 0.0625560980558274, 0.06610173549538789, 0.14268832299692402, 0.1467112289303083, 0.1508359148726407, 0.05611766288587661, 0.054910410080608596, 0.06265979098381413]}}
{"id": "575adc51-5415-496f-b737-c89b291bbb4d", "fitness": -Infinity, "name": "AdaptiveDiversityDrivenSwarmDE", "description": "Introduce a feedback mechanism to adaptively tune mutation and crossover rates based on population diversity to enhance both convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveDiversityDrivenSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            population_std = np.std(population, axis=0)\n            diversity_score = np.mean(population_std)\n\n            mutation_factor = self.base_mutation_factor * (1 + diversity_score)\n            crossover_rate = self.base_crossover_rate * (1 - diversity_score)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 61, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "af50e360-65bf-4d5e-9057-9b61de153dfb", "fitness": 0.09421855256310314, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation and crossover rates based on convergence stagnation to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.stagnation_counter = 0\n        self.max_stagnation = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            if abs(prev_best_fit - self.history_best[1]) < self.convergence_threshold:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            dynamic_mutation_factor = self.base_mutation_factor + (0.2 * self.stagnation_counter / self.max_stagnation)\n            dynamic_crossover_rate = self.base_crossover_rate - (0.2 * self.stagnation_counter / self.max_stagnation)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09422 with standard deviation 0.03964.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0692307145801383, 0.06732413206251153, 0.07055671868607394, 0.1475627790660371, 0.1529051819839813, 0.1498346721695566, 0.06701904436199035, 0.06055567844402021, 0.06297805171361903]}}
{"id": "78029cd1-0e2e-4fea-8876-39dfeef3773c", "fitness": 0.09231020214204833, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance mutation diversity by incorporating an additional random scaling factor in the mutation process.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Changed line: Introduced an additional random scaling factor\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + np.random.rand())\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09231 with standard deviation 0.03939.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06584118451684506, 0.07314762594633106, 0.07135368977459056, 0.1476142313307125, 0.14624593748027803, 0.148635400291386, 0.05328187948591656, 0.06272331233330364, 0.06194855811907152]}}
{"id": "bac95964-42c4-4786-85fb-33c7df77ea2d", "fitness": 0.08813950626030503, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive learning rates and reinforcement-inspired selection mechanisms for enhanced convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.learning_rate = 0.05  # Introduce learning rate for adaptive strategies\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            \n            # Adaptive learning rate adjustment\n            self.learning_rate = max(0.01, self.learning_rate * (1.0 - 0.1 * (fitness[best_index] / self.history_best[1])))\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + self.learning_rate * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation with reinforcement selection\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                if func(self.history_best[0]) + np.random.uniform(-0.01, 0.01) < fitness[worst_index]:  # Reinforcement-inspired noise\n                    population[worst_index] = self.history_best[0]\n                    fitness[worst_index] = func(self.history_best[0])\n                    self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08814 with standard deviation 0.03986.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06373685266774265, 0.05941752681275081, 0.06589778868544538, 0.14243157785047522, 0.14205533715358398, 0.14816054599656225, 0.05516102957888702, 0.06288807508606398, 0.053506822511234065]}}
{"id": "6a344c16-96ff-4856-a925-0c3ab2e22328", "fitness": -Infinity, "name": "AdvancedAdaptiveSwarmDE", "description": "Implement a multi-phase mutation strategy and adaptively adjust mutation and crossover rates based on fitness improvement speed.", "code": "import numpy as np\n\nclass AdvancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.mutation_influence = 0.1\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                phase_mutation_factor = self.mutation_factor * (1 + 0.5 * np.random.rand())\n                trial_vector = np.clip(population[a] + phase_mutation_factor * (population[b] - population[c]) +\n                                       self.mutation_influence * np.random.randn(self.dim), lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate * (1 + 0.1 * np.random.rand())\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic parameter adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.mutation_factor = min(1.0, self.mutation_factor + 0.1)\n                self.crossover_rate = min(1.0, self.crossover_rate + 0.05)\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.mutation_factor = max(0.5, self.mutation_factor - 0.05)\n                self.crossover_rate = max(0.7, self.crossover_rate - 0.02)\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 65, "feedback": "An exception occurred: IndexError('index 101 is out of bounds for axis 0 with size 101').", "error": "IndexError('index 101 is out of bounds for axis 0 with size 101')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "d8767efa-cb49-4477-b0bc-2c72cebbe8fa", "fitness": 0.10136317989661395, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance dynamic population size adjustment by also considering the standard deviation of fitness changes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold or np.std(fitness) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10136 with standard deviation 0.03560.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0778982351366656, 0.07671074042379578, 0.0872893220193357, 0.15095421571302214, 0.14647663076558892, 0.15273765406275752, 0.06757044889780939, 0.09246752801172664, 0.0601638440388238]}}
{"id": "1eeeb195-35fc-4a2c-bd56-8323265f8576", "fitness": 0.08951066128536159, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation scaling based on population diversity to enhance convergence dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            # Calculate population diversity\n            population_mean = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - population_mean, axis=1))\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adapt dynamic mutation factor based on diversity\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand() * (1.0 + diversity / 100.0)\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08951 with standard deviation 0.03823.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0716535471556724, 0.068990681253848, 0.061402744323150404, 0.14377763607672078, 0.14410811275140445, 0.1409015708700707, 0.06650790775821813, 0.05745468815278465, 0.05079906322638472]}}
{"id": "9a11a7f5-27ba-41b9-8fad-8c1ec0629131", "fitness": 0.08809794225807259, "name": "EnhancedAdaptiveSwarmDE", "description": "Incorporate adaptive mutation factor scaling based on individual improvement rates to enhance diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on individual improvement\n                improvement_rate = (fitness[i] - prev_best_fit) / max(abs(prev_best_fit), 1e-9)\n                adaptive_mutation_factor = self.mutation_factor * (1 + improvement_rate)\n                \n                trial_vector = np.clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08810 with standard deviation 0.04021.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07036897775335238, 0.06225387554220474, 0.06239831120850281, 0.14194411004568264, 0.14247051745570216, 0.14872956667416182, 0.051475508623679334, 0.05141341587127246, 0.061827197148094926]}}
{"id": "4ae51cb3-ba8d-4849-9225-fb4f311ada64", "fitness": -Infinity, "name": "ChaoticEnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation and crossover strategies with chaotic maps to enhance diversity and convergence speed in dynamic environments.", "code": "import numpy as np\n\nclass ChaoticEnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.chaos_parameter = 0.7\n    \n    def chaotic_map(self, x):\n        # Logistic map for chaos: x_next = r * x * (1 - x)\n        r = 3.8  # Parameter that ensures chaotic behavior\n        return r * x * (1 - x)\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.base_mutation_factor * self.chaos_parameter\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Apply chaotic influence on crossover rate\n                self.chaos_parameter = self.chaotic_map(self.chaos_parameter)\n                dynamic_crossover_rate = self.base_crossover_rate + 0.25 * (self.chaos_parameter - 0.5)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 69, "feedback": "An exception occurred: IndexError('index 101 is out of bounds for axis 0 with size 101').", "error": "IndexError('index 101 is out of bounds for axis 0 with size 101')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "731a1f18-59dc-484b-9977-62a78d5c3fff", "fitness": 0.0944205157901245, "name": "EnhancedAdaptiveSwarmDE", "description": "Integrate an adaptive elite preservation strategy by dynamically adjusting elite influence based on convergence to enhance exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.elite_influence_alpha = 0.1  # Initial influence factor of historical best\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            convergence_rate = abs(prev_best_fit - fitness[best_index])\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate + 0.15 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Adaptive Elite Preservation Strategy\n            if convergence_rate < self.convergence_threshold:\n                self.elite_influence_alpha = min(self.elite_influence_alpha + 0.01, 0.2)  # Increase elite influence\n            else:\n                self.elite_influence_alpha = max(self.elite_influence_alpha - 0.01, 0.05)  # Decrease elite influence\n\n            # Elite preservation with adaptive influence\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                elite_candidate = self.history_best[0] + self.elite_influence_alpha * np.random.randn(self.dim)  # Apply small random perturbation\n                elite_candidate = np.clip(elite_candidate, lower_bound, upper_bound)\n                population[worst_index] = elite_candidate\n                fitness[worst_index] = func(elite_candidate)\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if convergence_rate < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09442 with standard deviation 0.03930.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07136183854696443, 0.06761870346123156, 0.0720922383895577, 0.14946370416336574, 0.1480580736918825, 0.15169500325676932, 0.06500671211839293, 0.058383775186822806, 0.0661045932961335]}}
{"id": "d3089d50-8b1a-4192-99e7-2faa60d4a316", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance dynamic adaptation by incorporating variance-based selection and adaptive parameter control to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.stagnation_threshold = 5\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        stagnation_counter = 0\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            population_variance = np.var(fitness)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (1 + np.random.rand() * population_variance)\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                stagnation_counter += 1\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n            else:\n                stagnation_counter = 0\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n\n            if stagnation_counter >= self.stagnation_threshold:\n                self.population_size = max(4, self.population_size // 2)\n                stagnation_counter = 0\n\n            new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n            population = np.vstack((population, new_individuals))\n            new_fitness = np.array([func(p) for p in new_individuals])\n            fitness = np.concatenate((fitness, new_fitness))\n            self.evaluations += len(new_individuals)\n\n            population = population[:self.population_size]\n            fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 71, "feedback": "An exception occurred: ValueError('negative dimensions are not allowed').", "error": "ValueError('negative dimensions are not allowed')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "43196f35-81e3-47ab-af81-cdcd796359d7", "fitness": 0.0957762181637903, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance trial generation by incorporating a noise factor for better exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                noise_factor = np.random.normal(scale=0.1, size=self.dim)  # Added noise factor\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0) + noise_factor,\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09578 with standard deviation 0.03963.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07066096760955753, 0.07185504908881934, 0.0679668723554554, 0.15074433008876909, 0.15420856750577994, 0.15015778428488802, 0.06313716863420515, 0.0679429282310392, 0.06531229567559904]}}
{"id": "a0b24605-11cb-4aa3-8b50-82854916ea9a", "fitness": 0.09074555100294807, "name": "EnhancedAdaptiveSwarmDE", "description": "Refine dynamic adjustment by increasing mutation factor variation and adjusting crossover rate influence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + np.random.rand())  # Increased variation in mutation factor\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.25 if np.random.rand() < 0.25 else 0  # Adjusted historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09075 with standard deviation 0.04012.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.065228460232992, 0.06437322597464923, 0.0686950538577229, 0.14583801141301678, 0.14805842771400057, 0.14796203021716192, 0.06100027706275035, 0.056414303482040684, 0.05914016907219821]}}
{"id": "f092841e-c5a4-4d73-960c-8eb1c7fb57d0", "fitness": 0.08830241920101849, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation factor based on fitness variance to enhance exploration in stagnant phases.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            fitness_variance = np.var(fitness)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                adaptive_mutation_factor = self.mutation_factor * (1 + fitness_variance)\n                trial_vector = np.clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08830 with standard deviation 0.04047.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.059504712653514535, 0.06092791381736706, 0.06222231817643409, 0.14722659419444528, 0.14302067847043953, 0.14612748012651122, 0.06069873074060517, 0.05547320147109125, 0.0595201431587582]}}
{"id": "70589334-077c-417f-8a46-e440bc84e719", "fitness": 0.09050792138682182, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptively scaled mutation and crossover operators based on fitness diversity to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            # Calculate fitness diversity\n            fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-9)\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptively scale mutation factor based on fitness diversity\n                dynamic_mutation_factor = self.mutation_factor + fitness_diversity * 0.5\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adaptively scale crossover rate based on fitness diversity\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * fitness_diversity\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09051 with standard deviation 0.04009.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06958852216131328, 0.060998230254050934, 0.06647160932878804, 0.15181168803773093, 0.14486232460990867, 0.14392110694880333, 0.061680291372355533, 0.0604958309103647, 0.05474168885808095]}}
{"id": "f6166597-548e-4dd1-9666-e8f4941d0977", "fitness": 0.10136317989661395, "name": "EnhancedAdaptiveSwarmDE", "description": "Integrate a diversity preservation mechanism by periodically introducing random individuals to maintain exploration in EnhancedAdaptiveSwarmDE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.diversity_preservation_interval = 50  # Introduce new individuals every 50 evaluations\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n            # Diversity preservation: introduce random individuals periodically\n            if self.evaluations % self.diversity_preservation_interval == 0:\n                diversity_count = int(0.1 * self.population_size)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (diversity_count, self.dim))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                self.evaluations += diversity_count\n\n                combined_population = np.vstack((population, new_individuals))\n                combined_fitness = np.concatenate((fitness, new_fitness))\n                best_indices = np.argsort(combined_fitness)[:self.population_size]\n\n                population = combined_population[best_indices]\n                fitness = combined_fitness[best_indices]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10136 with standard deviation 0.03560.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0778982351366656, 0.07671074042379578, 0.0872893220193357, 0.15095421571302214, 0.14647663076558892, 0.15273765406275752, 0.06757044889780939, 0.09246752801172664, 0.0601638440388238]}}
{"id": "938835ba-d2f7-448c-9e2c-f0a56991820e", "fitness": 0.09094231789380099, "name": "SelfAdaptiveSwarmDE", "description": "Introduce self-adaptive mutation and crossover rates to dynamically balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass SelfAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        mutation_factors = np.random.uniform(0.5, 1.0, self.population_size)\n        crossover_rates = np.random.uniform(0.1, 0.9, self.population_size)\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                trial_vector = np.clip(population[a] + mutation_factors[i] * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                cross_points = np.random.rand(self.dim) < crossover_rates[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                    mutation_factors[i] = 0.5 + 0.5 * np.random.rand()\n                    crossover_rates[i] = 0.1 + 0.8 * np.random.rand()\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                mutation_factors = np.concatenate((mutation_factors, np.random.uniform(0.5, 1.0, len(new_individuals))))\n                crossover_rates = np.concatenate((crossover_rates, np.random.uniform(0.1, 0.9, len(new_individuals))))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                mutation_factors = mutation_factors[:self.population_size]\n                crossover_rates = crossover_rates[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 77, "feedback": "The algorithm SelfAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09094 with standard deviation 0.04345.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06382644880720356, 0.06315247589185158, 0.07028394809959004, 0.1489352734606303, 0.1540830972776619, 0.1528783533705368, 0.05170042771125638, 0.05832253766695672, 0.05529829875852166]}}
{"id": "53d9f18c-518d-4bb9-b167-41f6e7621494", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance dynamic adaptive DE by introducing learning automata to self-tune mutation and crossover rates for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.learning_rate = 0.1  # Learning rate for the adaptive strategy\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate influenced by learning automata\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                self.crossover_rate += self.learning_rate * (1 if np.random.rand() < 0.5 else -1)\n                self.crossover_rate = np.clip(self.crossover_rate, 0.1, 0.9)\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    # Update learning automata based on improvement\n                    self.mutation_factor += self.learning_rate * (1 if trial_fitness < fitness[best_index] else -1)\n                    self.mutation_factor = np.clip(self.mutation_factor, 0.4, 1.2)\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 78, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "401d8c88-5815-48b9-8315-29ada2a46b96", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation based on fitness diversity for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adapt mutation factor based on fitness diversity\n                fitness_std = np.std(fitness)\n                dynamic_mutation_factor = self.mutation_factor * (1 + 0.5 * np.random.rand() * fitness_std)\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  \n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 79, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "fc4df761-8ac9-46fb-80eb-81f366df713d", "fitness": 0.0948186045076077, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive learning rates for mutation and crossover to enhance dynamic balance of exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.learning_rate_mf = 0.1  # Learning rate for mutation factor\n        self.learning_rate_cr = 0.1  # Learning rate for crossover rate\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                adaptive_mf = self.mutation_factor + self.learning_rate_mf * np.random.normal()\n                trial_vector = np.clip(population[a] + adaptive_mf * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                adaptive_cr = self.crossover_rate + self.learning_rate_cr * np.random.normal()\n                dynamic_crossover_rate = adaptive_cr + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09482 with standard deviation 0.04083.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06921364685436449, 0.06604507249028357, 0.07725177849714193, 0.14661752153605945, 0.1477157167238009, 0.16115736699732663, 0.06203905070603544, 0.05636853061981628, 0.06695875614364066]}}
{"id": "e60974d6-2b06-493d-a661-e45f9a33f855", "fitness": 0.0889690379033703, "name": "RefinedAdaptiveSwarmDE", "description": "Introduce adaptive mutation and crossover strategies influenced by population diversity and historical performance to enhance convergence and exploration.", "code": "import numpy as np\n\nclass RefinedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on population diversity\n                pop_std_dev = np.std(population, axis=0)\n                dynamic_mutation_factor = 0.5 + np.random.rand() * pop_std_dev.mean()\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate based on historical performance\n                historical_influence = min(0.2, np.abs(fitness[best_index] - self.history_best[1]) / self.history_best[1])\n                dynamic_crossover_rate = 0.9 + (0.1 - historical_influence) * np.random.rand()\n\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 81, "feedback": "The algorithm RefinedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08897 with standard deviation 0.03650.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06950600894809422, 0.05900122484347625, 0.06511834421435692, 0.14200332577938735, 0.13894520685347345, 0.14035759768565703, 0.06129066436951036, 0.06257197193596487, 0.061926996500412224]}}
{"id": "b6d5103b-8dba-4b17-8481-acfaed6adf03", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Implement a dual-phase mutation strategy to enhance exploration during stagnation and exploitation when near optimal solutions, boosting convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Dual-phase mutation strategy\n                if self.exploration_phase:\n                    dynamic_mutation_factor = self.mutation_factor * np.random.rand() * 2  # Enhance exploration\n                else:\n                    dynamic_mutation_factor = self.mutation_factor * np.random.rand() * 0.5  # Enhance exploitation\n\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n                self.exploration_phase = True  # Switch to exploration phase\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n                self.exploration_phase = False  # Switch to exploitation phase\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 82, "feedback": "An exception occurred: IndexError('index 102 is out of bounds for axis 0 with size 102').", "error": "IndexError('index 102 is out of bounds for axis 0 with size 102')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "107abcbf-4ef9-4abe-af1d-30eb9ad916f6", "fitness": 0.09337167452745182, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance balance between exploration and exploitation by integrating a feedback-driven mutation scaling and improved elite preservation strategy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                feedback_mutation_factor = self.mutation_factor * (1.0 + np.abs(prev_best_fit - fitness[best_index]) / prev_best_fit)\n                trial_vector = np.clip(population[a] + feedback_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0] if np.random.rand() < 0.5 else population[worst_index]\n                fitness[worst_index] = func(population[worst_index])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09337 with standard deviation 0.03784.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0699099791839698, 0.06287447191407514, 0.07771575672604658, 0.14644519599649197, 0.1440245822364784, 0.14898030338870238, 0.06389083499532333, 0.06345494067270196, 0.06304900563327676]}}
{"id": "b45f920f-a465-4dac-af8f-1364d66f8754", "fitness": 0.09481211494112772, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation and crossover rates based on population diversity to enhance exploration ability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            population_diversity = np.std(population, axis=0).mean()  # Calculate diversity\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor based on diversity\n                dynamic_mutation_factor = self.mutation_factor * (1 + 0.5 * (population_diversity / self.dim)) * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adapt crossover rate based on diversity\n                dynamic_crossover_rate = self.crossover_rate - 0.1 * (population_diversity / self.dim)  # Adjust crossover rate\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09481 with standard deviation 0.03901.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.08517000848585787, 0.0662579131258848, 0.06976903184410443, 0.14531596693175153, 0.14577796952236388, 0.15584644890850796, 0.06056498747762107, 0.061719347970613514, 0.06288736020344443]}}
{"id": "deaccbce-cda9-449f-96e9-7aa71d18a05c", "fitness": 0.09387844102358517, "name": "EnhancedAdaptiveSwarmDE", "description": "Refine mutation factor dynamics and elite preservation to enhance convergence reliability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * (0.5 + 0.5 * np.random.rand())  # Refined mutation factor dynamics\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                if fitness[worst_index] > self.history_best[1]:  # Enhance elite preservation reliability\n                    population[worst_index] = self.history_best[0]\n                    fitness[worst_index] = func(self.history_best[0])\n                    self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09388 with standard deviation 0.03849.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06765906498002539, 0.06805330906345108, 0.06959871955292929, 0.14987037676728854, 0.1494229476506288, 0.1453903379372259, 0.0627947203258219, 0.06659830720437898, 0.06551818573051671]}}
{"id": "3a93621a-5023-4d70-9393-d46724f11970", "fitness": 0.09773767390427318, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce probabilistic selection of historical best crossover rate to improve search capability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Probabilistic selection of historical best crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.5 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09774 with standard deviation 0.03773.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07781743384483397, 0.07689544105336887, 0.07162381635653159, 0.15355914486655986, 0.15061800359494615, 0.1476393194348794, 0.06392419909218705, 0.07497451208905881, 0.06258719480609298]}}
{"id": "39396610-d62e-4904-99e4-df846cc60ab0", "fitness": 0.0940577949015487, "name": "EnhancedAdaptiveLearningDE", "description": "Enhance the evolutionary dynamics by incorporating adaptive learning rates and a diversity-promoting mechanism to maintain robust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.learning_rate_decay = 0.9\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.uniform(0.5, 1.5) * self.learning_rate_decay\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                diversity_metric = np.mean([np.linalg.norm(population[i] - best_individual) for i in range(self.population_size)])\n                if diversity_metric < self.convergence_threshold:\n                    self.population_size = min(self.population_size + 2, self.initial_population_size * 2)\n                    new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                    population = np.vstack((population, new_individuals))\n                    new_fitness = np.array([func(p) for p in new_individuals])\n                    fitness = np.concatenate((fitness, new_fitness))\n                    self.evaluations += len(new_individuals)\n                else:\n                    self.population_size = max(self.initial_population_size, self.population_size - 1)\n                    population = population[:self.population_size]\n                    fitness = fitness[:self.population_size]\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.learning_rate_decay *= 0.95\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptiveLearningDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09406 with standard deviation 0.03796.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07575973769298217, 0.06490815786112769, 0.0741396353389302, 0.14537105557164354, 0.14913405066955776, 0.14730633909362878, 0.06657370895369752, 0.06558920782002253, 0.057738261112348144]}}
{"id": "830cd93d-f629-4847-a139-1b7d0c837cbb", "fitness": 0.09646373043058754, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance mutation diversity by introducing a noise component to the trial vector generation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                noise = 0.05 * np.random.randn(self.dim)  # Added noise component\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0) + noise,\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09646 with standard deviation 0.03757.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06852525740373949, 0.07688290672930709, 0.07942629033008541, 0.14863700317111694, 0.1523550379627332, 0.1462726128560553, 0.06398050089636009, 0.06325418473239863, 0.06883977979349165]}}
{"id": "c6720d78-85cd-4be1-976d-323de76c7f06", "fitness": 0.08419367968840517, "name": "EnhancedAdaptiveLearningSwarmDE", "description": "Introduce adaptive learning of mutation and crossover rates based on recent improvements to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLearningSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.crossover_rate = self.base_crossover_rate\n        self.mutation_factor = self.base_mutation_factor\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        recent_improvements = []\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                dynamic_crossover_rate = self.crossover_rate * (1 + 0.5 * np.random.rand())\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                    recent_improvements.append(trial_fitness - fitness[i])\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Adaptive learning for mutation and crossover rates\n            if recent_improvements:\n                avg_improvement = np.mean(recent_improvements)\n                if avg_improvement < self.convergence_threshold:\n                    self.mutation_factor = max(0.4, self.mutation_factor * 0.95)\n                    self.crossover_rate = min(1.0, self.crossover_rate * 1.05)\n                else:\n                    self.mutation_factor = min(1.2, self.mutation_factor * 1.05)\n                    self.crossover_rate = max(0.6, self.crossover_rate * 0.95)\n                recent_improvements = []\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveLearningSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08419 with standard deviation 0.04331.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.05803909349955094, 0.05541991070365937, 0.06531314086207118, 0.1430396270177111, 0.14614644933258858, 0.14479353177680188, 0.04424971846487935, 0.04157038645296662, 0.05917125908541754]}}
{"id": "9ad06465-f3fa-408d-b13b-6dc682c850fa", "fitness": 0.08975229864858329, "name": "EnhancedSelectiveMutationDE", "description": "Combine selective adaptive mutation and cross-point diversity techniques to enhance dynamic exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedSelectiveMutationDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Selective adaptive mutation\n                mutation_factor = self.base_mutation_factor * (0.5 + 0.5 * np.random.rand())\n                trial_vector = np.clip(population[a] + mutation_factor * (population[b] - population[c]), \n                                       lower_bound, upper_bound)\n\n                # Cross-point diversity technique\n                dynamic_crossover_rate = self.base_crossover_rate * (0.5 + 0.5 * (1 - np.random.rand()))\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedSelectiveMutationDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08975 with standard deviation 0.04140.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06287299915322908, 0.06420116343744287, 0.06221248299459181, 0.1478163111182882, 0.15103669535396458, 0.14523179358850524, 0.06568007477282223, 0.055213675698103426, 0.05350549172030217]}}
{"id": "bde55a64-d641-4f52-b936-3dd46592887d", "fitness": 0.08196553611332788, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation and crossover rates based on population diversity to enhance convergence in varying landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.base_crossover_rate = 0.9\n        self.base_mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n            diversity = np.mean(np.std(population, axis=0))  # Measure population diversity\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                adaptive_mutation_factor = self.base_mutation_factor * (1 + diversity)\n                trial_vector = np.clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]),\n                                       lower_bound, upper_bound)\n\n                adaptive_crossover_rate = self.base_crossover_rate * (1 - 0.5 * diversity)  # Adjust based on diversity\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08197 with standard deviation 0.04073.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.05306439920399131, 0.0614472809722616, 0.05592084406162756, 0.13654066108392982, 0.1396501987672577, 0.14159676647419506, 0.046782768737826164, 0.05476681246633863, 0.04792009325252311]}}
{"id": "b4025cde-841a-4fe0-ae73-b0a620e77758", "fitness": 0.09022961238303501, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance mutation diversity by introducing a variant mutation factor from a normal distribution to improve exploration capability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.normal(1, 0.1)  # Changed mutation factor distribution\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09023 with standard deviation 0.04010.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.061198482112938324, 0.06939554059498698, 0.06402786367635638, 0.1456196859259029, 0.147786653490099, 0.14690355882417672, 0.0595251750936584, 0.058886247203965514, 0.05872330452523089]}}
{"id": "f259dccd-2b1f-49ca-bcce-2288a19cd9fd", "fitness": 0.09393846298722096, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance dynamic crossover rate by introducing adaptive control based on population diversity for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate based on diversity\n                diversity = np.mean(np.std(population, axis=0))\n                dynamic_crossover_rate = self.crossover_rate + diversity * np.random.rand()  # Modified calculation\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09394 with standard deviation 0.03929.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.0730777965103917, 0.06692398926778365, 0.07021396238878885, 0.14857603244964634, 0.14817845393741802, 0.1506173019505791, 0.06174684480152759, 0.05668857782696057, 0.06942320775189281]}}
{"id": "3188f272-f44d-4623-9bc8-02848432a454", "fitness": 0.09727417866832341, "name": "EnhancedAdaptiveSwarmDE", "description": "Enhance exploration by introducing adaptive crossover rate adjustments based on diversity metrics. ", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adaptive crossover rate based on population diversity\n                diversity_metric = np.std(population, axis=0).mean() / (upper_bound - lower_bound).mean()\n                dynamic_crossover_rate = self.crossover_rate + (0.1 * diversity_metric)  # Adjust crossover rate\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09727 with standard deviation 0.03765.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06852817554358559, 0.07304613937133475, 0.07679721795948435, 0.15035451556089174, 0.14708974937994745, 0.15351436418923503, 0.06572435984760794, 0.0693130142152526, 0.07110007194757129]}}
{"id": "240fcd79-bfad-4e04-b3f3-5e93e7b56ce6", "fitness": 0.09980643749695005, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce a probabilistic factor to elite preservation for enhanced robustness against premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Probabilistic elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget and np.random.rand() < 0.75:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09981 with standard deviation 0.03696.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07192109798877211, 0.07503194526666335, 0.08664420130395634, 0.156741972745705, 0.15039529703233123, 0.14711321506514352, 0.07460881071795722, 0.07106300303829094, 0.06473839431373074]}}
{"id": "07141f8e-5269-4e78-9a30-cdb4c9ab195d", "fitness": 0.09426038754082867, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce environmental noise handling by adding perturbation to trial vectors to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Adding environmental noise\n                noise = 0.01 * np.random.randn(self.dim)\n                trial_vector += noise\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09426 with standard deviation 0.03869.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07205632846381749, 0.07417602536007506, 0.06989061963127463, 0.1502773039741092, 0.14805016939152416, 0.14748660287195847, 0.05914915032184076, 0.06553537375704765, 0.061721914095810626]}}
{"id": "5d1a622a-97c5-4948-afca-ada9cb6ec3c9", "fitness": 0.08885713064744584, "name": "EnhancedAdaptiveSwarmDE", "description": "Introduce adaptive mutation factor based on individual performance diversity to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                diversity = np.std(fitness)  # Calculate fitness diversity\n                adaptive_mutation_factor = self.mutation_factor + 0.5 * diversity  # Adapt based on diversity\n                trial_vector = np.clip(population[a] + adaptive_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08886 with standard deviation 0.04017.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.06732635842011603, 0.06548052049769115, 0.05878523832084914, 0.14843153960728028, 0.14124336912205404, 0.14654250921227696, 0.056407114780995915, 0.05778014917597307, 0.057717376689775945]}}
{"id": "4a053fdc-58ff-4459-9ee9-b96745632ac5", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmDE", "description": "Implement an adaptive learning rate with feedback mechanism to dynamically adjust mutation strength and balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n        self.learning_rate = 0.1  # Initial adaptive learning rate\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                # Adaptive mutation factor with feedback loop\n                improvement = fitness[best_index] - prev_best_fit\n                if improvement > 0:\n                    self.learning_rate = min(1.0, self.learning_rate + 0.01)\n                else:\n                    self.learning_rate = max(0.01, self.learning_rate - 0.01)\n                \n                dynamic_mutation_factor = self.mutation_factor * self.learning_rate * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.25 else 0\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 98, "feedback": "An exception occurred: IndexError('index 103 is out of bounds for axis 0 with size 103').", "error": "IndexError('index 103 is out of bounds for axis 0 with size 103')", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {}}
{"id": "30033a0a-934f-4aa6-8cef-8d70debe5957", "fitness": 0.09764909518479609, "name": "EnhancedAdaptiveSwarmDE", "description": "Improve convergence by adjusting the historical influence frequency in the crossover mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(4, dim * 5)\n        self.population_size = self.initial_population_size\n        self.crossover_rate = 0.9\n        self.mutation_factor = 0.8\n        self.evaluations = 0\n        self.history_best = None\n        self.convergence_threshold = 0.01\n\n    def __call__(self, func):\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(p) for p in population])\n        self.evaluations += self.population_size\n\n        best_index = np.argmin(fitness)\n        best_individual = population[best_index].copy()\n\n        if self.history_best is None or fitness[best_index] < self.history_best[1]:\n            self.history_best = (best_individual.copy(), fitness[best_index])\n\n        while self.evaluations < self.budget:\n            prev_best_fit = fitness[best_index]\n\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n\n                dynamic_mutation_factor = self.mutation_factor * np.random.rand()\n                trial_vector = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]) + 0.1 * np.mean([population[a], population[b], population[c]], axis=0),\n                                       lower_bound, upper_bound)\n\n                # Historical best influenced crossover rate\n                historical_influence = 0.15 if np.random.rand() < 0.3 else 0  # Modified historical influence frequency\n                dynamic_crossover_rate = self.crossover_rate + historical_influence * np.random.rand()\n                cross_points = np.random.rand(self.dim) < dynamic_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, trial_vector, population[i])\n\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                    if trial_fitness < fitness[best_index]:\n                        best_index = i\n                        best_individual = trial.copy()\n                        if trial_fitness < self.history_best[1]:\n                            self.history_best = (best_individual.copy(), trial_fitness)\n\n            # Elite preservation: replace the worst individual with the historical best if the budget allows\n            if self.evaluations < self.budget:\n                worst_index = np.argmax(fitness)\n                population[worst_index] = self.history_best[0]\n                fitness[worst_index] = func(self.history_best[0])\n                self.evaluations += 1\n\n            # Dynamic population size adjustment\n            if abs(prev_best_fit - fitness[best_index]) < self.convergence_threshold:\n                self.population_size = min(self.population_size + 1, self.initial_population_size * 2)\n                new_individuals = np.random.uniform(lower_bound, upper_bound, (self.population_size - len(population), self.dim))\n                population = np.vstack((population, new_individuals))\n                new_fitness = np.array([func(p) for p in new_individuals])\n                fitness = np.concatenate((fitness, new_fitness))\n                self.evaluations += len(new_individuals)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 1)\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n        return population[best_index], fitness[best_index]", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09765 with standard deviation 0.03641.", "error": "", "parent_ids": ["c111c6bc-8b3e-4dc0-870f-e83355e5490f"], "operator": null, "metadata": {"aucs": [0.07151476756946828, 0.07731695536904659, 0.0831602359179644, 0.14647325806957223, 0.1527958790171755, 0.14644979801683922, 0.0687964032410675, 0.06673519185452192, 0.06559936760750917]}}
