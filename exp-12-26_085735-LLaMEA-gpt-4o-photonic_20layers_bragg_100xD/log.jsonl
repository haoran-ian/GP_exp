{"id": "5639ccff-bbf4-46b1-b57d-5bfd7c1c2024", "fitness": 0.11742741398177133, "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) with Differential Evolution (DE) for robust search and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11743 with standard deviation 0.00563.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11086299818239564, 0.12460268341804615, 0.1168165603448722]}}
{"id": "12741f96-35a0-47aa-a498-f093c237601b", "fitness": 0.1043044171807133, "name": "AdaptiveHybridPSODE", "description": "Introducing adaptive parameter control to HybridPSODE for improved convergence by dynamically adjusting PSO and DE parameters based on performance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_mutation_factor = 0.9\n        self.final_mutation_factor = 0.5\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n\n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n\n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            inertia_weight = self.initial_inertia_weight - (\n                (self.initial_inertia_weight - self.final_inertia_weight) * \n                (self.curr_evaluations / self.budget)\n            )\n            mutation_factor = self.initial_mutation_factor - (\n                (self.initial_mutation_factor - self.final_mutation_factor) * \n                (self.curr_evaluations / self.budget)\n            )\n\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10430 with standard deviation 0.00762.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.1011378310760942, 0.11481415231984526, 0.09696126814620043]}}
{"id": "409b622e-3b7e-4291-859a-3d376fa85cfd", "fitness": 0.09605850275427714, "name": "HybridPSODEPlus", "description": "The HybridPSODE+ introduces adaptive parameters and dynamic population size for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.curr_evaluations = 0\n        self.inertia_weight = 0.9  # Start with higher inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            if self.curr_evaluations % (self.budget // 4) == 0:  # Dynamic population adjustment\n                self.pop_size = max(20, self.pop_size - 5)  # Decrease population size\n                swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n                vel = np.zeros((self.pop_size, self.dim))\n\n            for i in range(self.pop_size):\n                # Adaptive inertia weight\n                inertia = ((self.budget - self.curr_evaluations) / self.budget) * 0.5 + 0.4\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (inertia * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09606 with standard deviation 0.00443.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10230174681854542, 0.09256617244447429, 0.09330758899981173]}}
{"id": "a4bcea56-dd2a-4461-a101-b59c786367d4", "fitness": 0.10444235743015746, "name": "HybridPSODE", "description": "Introduce adaptive inertia weight in PSO for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.inertia_weight = 0.9 - 0.5 * (self.curr_evaluations / self.budget)  # Adaptive inertia weight\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10444 with standard deviation 0.01330.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10323695260773735, 0.12129606455434006, 0.088794055128395]}}
{"id": "4247de11-fc4e-4e0c-bb04-6ff803b2aa12", "fitness": 0.10189069612721331, "name": "HybridPSODE", "description": "An enhanced hybrid metaheuristic blending PSO and DE with adaptive parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            # Adaptive inertia weight\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - self.curr_evaluations / self.budget) + self.final_inertia_weight\n            \n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10189 with standard deviation 0.00614.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10190399522610172, 0.1094054037507719, 0.09436268940476633]}}
{"id": "0c845d4e-2537-4c26-959d-09dae3b97518", "fitness": 0.11111543035379816, "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (self.curr_evaluations / self.budget)\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                # Adaptive mutation factor\n                self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11112 with standard deviation 0.00405.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10561812662855807, 0.1124725811400693, 0.11525558329276708]}}
{"id": "5d3dde4d-c322-403d-9a03-48d6dfa2caf0", "fitness": 0.10444235743015746, "name": "HybridPSODE", "description": "Introduce adaptive inertia weight in PSO to improve exploration-exploitation balance dynamically.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = ((0.9 - 0.4) * (self.budget - self.curr_evaluations) / self.budget + 0.4) * vel[i] + \\\n                         self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) + \\\n                         self.social_coeff * r2 * (gbest_position - swarm[i])\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10444 with standard deviation 0.01330.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10323695260773735, 0.12129606455434006, 0.088794055128395]}}
{"id": "42239f48-0c8b-4403-8ea7-e03b56d7f30a", "fitness": 0.10830606383770532, "name": "AdaptiveHybridPSODE", "description": "A novel hybrid algorithm that adaptively combines PSO with DE while introducing dynamic inertia weight adjustment for improved convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.inertia_weight_decay = (self.inertia_weight - self.inertia_weight_min) / (0.5 * self.budget)\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            for i in range(self.pop_size):\n                # Dynamic inertia weight adjustment\n                if self.inertia_weight > self.inertia_weight_min:\n                    self.inertia_weight -= self.inertia_weight_decay\n                \n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10831 with standard deviation 0.00623.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.11711413188653175, 0.10399528303459804, 0.10380877659198617]}}
{"id": "9b586c5d-113d-435b-8671-0d589d6b8caa", "fitness": 0.08786819693455213, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid algorithm integrating an adaptive inertia weight in PSO and opposition-based learning to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            inertia_weight = self.inertia_weight_max - (\n                (self.inertia_weight_max - self.inertia_weight_min) *\n                (self.curr_evaluations / self.budget)\n            )\n            \n            for i in range(self.pop_size):\n                # PSO Update with adaptive inertia weight\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Opposition-based learning\n                opp_vector = lb + ub - trial_vector\n                opp_vector = np.clip(opp_vector, lb, ub)\n                \n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                opp_score = func(opp_vector)\n                self.curr_evaluations += 2\n                \n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                if opp_score < swarm_scores[i]:\n                    swarm[i] = opp_vector\n                    swarm_scores[i] = opp_score\n                \n                if swarm_scores[i] < pbest_scores[i]:\n                    pbest_scores[i] = swarm_scores[i]\n                    pbest_positions[i] = swarm[i]\n\n                    if swarm_scores[i] < pbest_scores[gbest_idx]:\n                        gbest_position = swarm[i]\n                        gbest_idx = i\n\n                if self.curr_evaluations >= self.budget:\n                    break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08787 with standard deviation 0.00367.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.08999991204084601, 0.09090172601220492, 0.08270295275060546]}}
{"id": "35f08d6b-fcd9-4cd1-8037-7cdd24a8ddc7", "fitness": 0.0926953740846247, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive strategy for PSO parameters and incorporate local search phases to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.9\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.pop_size, self.dim)) * (ub - lb)\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            adaptive_inertia = 0.9 - 0.5 * (self.curr_evaluations / self.budget)\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (adaptive_inertia * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                if self.curr_evaluations >= self.budget:\n                    break\n\n            # Local Search Phase\n            if self.curr_evaluations < self.budget and np.random.rand() < 0.1:\n                for _ in range(5):\n                    local_search = gbest_position + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    local_search = np.clip(local_search, lb, ub)\n                    local_score = func(local_search)\n                    self.curr_evaluations += 1\n\n                    if local_score < pbest_scores[gbest_idx]:\n                        gbest_position = local_search\n                        pbest_scores[gbest_idx] = local_score\n\n                    if self.curr_evaluations >= self.budget:\n                        break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09270 with standard deviation 0.01563.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.07335681932180027, 0.09309341250219316, 0.11163589042988065]}}
{"id": "89b85701-b34e-4220-8e91-fdb26ec37a47", "fitness": 0.09960134236788365, "name": "HybridPSODE", "description": "Enhanced hybrid PSO-DE with adaptive parameters for improved convergence and exploitation-exploration balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_coeff = 1.8  # Increased cognitive coefficient\n        self.social_coeff = 1.8  # Increased social coefficient\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n            # Adaptive parameters\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - self.curr_evaluations) / self.budget\n            self.cognitive_coeff = 1.2 + 0.6 * (self.curr_evaluations / self.budget)\n            self.social_coeff = 1.2 + 0.6 * (self.curr_evaluations / self.budget)\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09960 with standard deviation 0.00619.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.09656567540629524, 0.09400782478209568, 0.10823052691526003]}}
{"id": "29d25cf5-923f-4eb9-8a04-5c993419fc6b", "fitness": 0.10139875282033665, "name": "AdaptiveHybridPSODE", "description": "A refined hybrid of Particle Swarm Optimization (PSO) and Differential Evolution (DE) incorporating an adaptive inertia weight and differential mutation factor for enhanced convergence and adaptability.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            # Adapt inertia weight and mutation factor\n            self.inertia_weight = 0.4 + (0.5 * (self.budget - self.curr_evaluations) / self.budget)\n            self.mutation_factor = 0.5 + (0.3 * (self.budget - self.curr_evaluations) / self.budget)\n\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10140 with standard deviation 0.00634.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10718474856060967, 0.1044298451919321, 0.09258166470846818]}}
{"id": "304e6064-bb20-4430-9231-2360c078f8a4", "fitness": 0.11358487421083947, "name": "HybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm incorporating adaptive parameter tuning for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.3 * ((self.budget - self.curr_evaluations) / self.budget)\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 12, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11358 with standard deviation 0.00703.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.1060007103709758, 0.12294463414372558, 0.11180927811781705]}}
{"id": "9ffa8db6-e3d5-43fd-8f11-71714c24c2d8", "fitness": 0.10189069612721331, "name": "HybridPSODE", "description": "An enhanced hybrid algorithm with adaptive inertia weight and elitism strategy for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for initialization\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            # Adapt inertia weight\n            self.inertia_weight = 0.4 + 0.5 * ((self.budget - self.curr_evaluations) / self.budget)\n            \n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10189 with standard deviation 0.00614.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10190399522610172, 0.1094054037507719, 0.09436268940476633]}}
{"id": "9082d75b-8745-42ac-b01c-b60cf84a4308", "fitness": 0.10850854922412205, "name": "HybridPSODE", "description": "HybridPSODE with adaptive parameters for dynamic balance between exploration and exploitation in optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.curr_evaluations = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            inertia_weight = 0.9 - (0.7 * (self.curr_evaluations / self.budget))\n            cognitive_coeff = 1.5 + (1.0 * (self.curr_evaluations / self.budget))\n            social_coeff = 1.5 - (1.0 * (self.curr_evaluations / self.budget))\n            mutation_factor = 0.8 - (0.4 * (self.curr_evaluations / self.budget))\n            cross_prob = 0.7 + (0.2 * (self.curr_evaluations / self.budget))\n            \n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (inertia_weight * vel[i] + \n                          cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10851 with standard deviation 0.00733.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.11884318394663729, 0.10259569451187012, 0.10408676921385873]}}
{"id": "6f3d956e-833d-4381-a5e8-73408e8e9e04", "fitness": 0.09826055966436087, "name": "AdaptiveHybridPSODE", "description": "Integrate adaptive parameter control and local search into HybridPSODE for enhanced convergence and solution quality.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n            self.local_search(swarm, func, lb, ub)\n\n        return gbest_position, pbest_scores[gbest_idx]\n\n    def adapt_parameters(self):\n        progress_ratio = self.curr_evaluations / self.budget\n        self.inertia_weight = 0.9 - 0.5 * progress_ratio\n        self.mutation_factor = 0.8 + 0.2 * progress_ratio\n\n    def local_search(self, swarm, func, lb, ub):\n        # Simple local search by slight perturbation\n        for i in range(self.pop_size):\n            perturbation = np.random.uniform(-0.01, 0.01, self.dim)\n            candidate = np.clip(swarm[i] + perturbation, lb, ub)\n            candidate_score = func(candidate)\n            if candidate_score < func(swarm[i]):\n                swarm[i] = candidate", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09826 with standard deviation 0.00928.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.09556275666067149, 0.11072935091298719, 0.08848957141942393]}}
{"id": "0f9d2777-f5b7-48d5-b483-434df7998b07", "fitness": 0.09708915828957632, "name": "RefinedHybridPSODE", "description": "A refined hybrid metaheuristic combining PSO with DE, introducing adaptive parameters for dynamic search behavior adjustment for improved convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        self.inertia_min = 0.4\n        self.inertia_max = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = self.inertia_max - ((self.inertia_max - self.inertia_min) * (self.curr_evaluations / self.budget))\n\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                        if self.curr_evaluations >= self.budget:\n                            break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 16, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09709 with standard deviation 0.00815.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.08800773219354907, 0.09548091391138447, 0.10777882876379541]}}
{"id": "90343bc3-2c0e-45e3-b56c-504f7f648407", "fitness": 0.10857378144504481, "name": "HybridPSODE", "description": "Enhances the HybridPSODE algorithm by dynamically adjusting weights and introducing elitism for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.2 * np.random.rand()  # Dynamic inertia adjustment\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] +\n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n            best_idx = np.argmin(swarm_scores)  # Ensure elitism\n            gbest_position = swarm[best_idx]\n            if self.curr_evaluations >= self.budget:\n                break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10857 with standard deviation 0.01510.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.10411719170288469, 0.12889014668738863, 0.09271400594486112]}}
{"id": "3fa254c7-bc22-460e-befa-a0a075314326", "fitness": 0.12058599863697113, "name": "ImprovedHybridPSODE", "description": "Improved HybridPSODE with adaptive parameters and archiving mechanism to enhance global search and convergence.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        self.archive = []\n\n    def adapt_parameters(self):\n        # Adaptive inertia weight decreasing linearly\n        self.inertia_weight = 0.9 - 0.5 * (self.curr_evaluations / self.budget)\n        # Adaptive mutation factor based on success rate\n        if len(self.archive) > 0:\n            success_rate = sum(1 for _, succ in self.archive if succ) / len(self.archive)\n            self.mutation_factor = 0.5 + 0.3 * success_rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    self.archive.append((i, True))  # Archive success\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                else:\n                    self.archive.append((i, False))  # Archive failure\n\n                if self.curr_evaluations >= self.budget:\n                    break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 18, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12059 with standard deviation 0.00186.", "error": "", "parent_ids": ["5639ccff-bbf4-46b1-b57d-5bfd7c1c2024"], "operator": null, "metadata": {"aucs": [0.1179672342512097, 0.12208508764026882, 0.12170567401943488]}}
{"id": "0d86fdee-cea7-4a4e-b4ec-d6b7d34612af", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE incorporates an adaptive escape mechanism for local optima and dynamic parameter tuning to accelerate convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        self.archive = []\n        self.escape_prob = 0.1\n\n    def adapt_parameters(self):\n        # Adaptive inertia weight decreasing linearly\n        self.inertia_weight = 0.9 - 0.5 * (self.curr_evaluations / self.budget)\n        # Adaptive mutation factor based on success rate\n        if len(self.archive) > 0:\n            success_rate = sum(1 for _, succ in self.archive if succ) / len(self.archive)\n            self.mutation_factor = 0.5 + 0.3 * success_rate\n        # Update escape probability to encourage exploration\n        self.escape_prob = 0.1 + 0.2 * (1 - success_rate)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                new_position = swarm[i] + vel[i]\n                # Escape Strategy\n                if np.random.rand() < self.escape_prob:\n                    new_position = np.random.uniform(lb, ub, self.dim)\n                swarm[i] = np.clip(new_position, lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    self.archive.append((i, True))  # Archive success\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                else:\n                    self.archive.append((i, False))  # Archive failure\n\n                if self.curr_evaluations >= self.budget:\n                    break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 19, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'success_rate' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'success_rate' referenced before assignment\")", "parent_ids": ["3fa254c7-bc22-460e-befa-a0a075314326"], "operator": null, "metadata": {}}
{"id": "26c2962f-b1da-4c40-b06a-49cf19020219", "fitness": 0.12316884716503944, "name": "ImprovedHybridPSODE", "description": "Enhanced HybridPSODE by optimizing swarm initialization and refining parameter adaptation for better convergence.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_factor = 0.8\n        self.cross_prob = 0.7\n        self.curr_evaluations = 0\n        self.archive = []\n\n    def adapt_parameters(self):\n        # Adaptive inertia weight decreasing linearly\n        self.inertia_weight = 0.85 - 0.4 * (self.curr_evaluations / self.budget)  # slightly refined\n        # Adaptive mutation factor based on success rate\n        if len(self.archive) > 0:\n            success_rate = sum(1 for _, succ in self.archive if succ) / len(self.archive)\n            self.mutation_factor = 0.6 + 0.3 * success_rate  # slightly refined\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb + (ub - lb) * 0.1, ub - (ub - lb) * 0.1, (self.pop_size, self.dim))  # refined initialization\n        vel = np.zeros((self.pop_size, self.dim))\n        pbest_positions = np.copy(swarm)\n        pbest_scores = np.full(self.pop_size, np.inf)\n        \n        swarm_scores = np.apply_along_axis(func, 1, swarm)\n        self.curr_evaluations += self.pop_size\n        \n        for i in range(self.pop_size):\n            if swarm_scores[i] < pbest_scores[i]:\n                pbest_scores[i] = swarm_scores[i]\n                pbest_positions[i] = swarm[i]\n\n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n\n        while self.curr_evaluations < self.budget:\n            self.adapt_parameters()\n            for i in range(self.pop_size):\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel[i] = (self.inertia_weight * vel[i] + \n                          self.cognitive_coeff * r1 * (pbest_positions[i] - swarm[i]) +\n                          self.social_coeff * r2 * (gbest_position - swarm[i]))\n                swarm[i] += vel[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # DE Mutation and Crossover\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.cross_prob\n                trial_vector = np.where(crossover, mutant_vector, swarm[i])\n\n                # Evaluate and Select\n                trial_score = func(trial_vector)\n                self.curr_evaluations += 1\n\n                if trial_score < swarm_scores[i]:\n                    self.archive.append((i, True))  # Archive success\n                    swarm[i] = trial_vector\n                    swarm_scores[i] = trial_score\n                    \n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n\n                        if trial_score < pbest_scores[gbest_idx]:\n                            gbest_position = trial_vector\n                            gbest_idx = i\n\n                else:\n                    self.archive.append((i, False))  # Archive failure\n\n                if self.curr_evaluations >= self.budget:\n                    break\n\n        return gbest_position, pbest_scores[gbest_idx]", "configspace": "", "generation": 20, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12317 with standard deviation 0.01092.", "error": "", "parent_ids": ["3fa254c7-bc22-460e-befa-a0a075314326"], "operator": null, "metadata": {"aucs": [0.10856703660183098, 0.13482060151933084, 0.12611890337395648]}}
