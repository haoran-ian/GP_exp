{"id": "3605f1df-2023-4ded-a107-f51eba8f6255", "fitness": 0.09400133113593684, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic that combines differential evolution and simulated annealing to efficiently explore and exploit the search space for black box optimization problems.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 0, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11390647064563053, 0.11391668858776416, 0.11390793941922295, 0.07347734065771783, 0.07348094170544428, 0.07347786777406706, 0.09461254237676486, 0.09461874540845039, 0.09461344364836954]}}
{"id": "b6e8bc5c-a019-49fd-aeb1-b7452a10e15a", "fitness": 0.09399643289498448, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic incorporating adaptive mutation scaling and dynamic population resizing to improve exploration and exploitation balance for black box optimization problems.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.min_population_size = 5\n        self.temperature = 1.0\n        self.cooling_rate = 0.95\n        self.mutation_scale = 0.8\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize population\n        population_size = self.initial_population_size\n        population = np.random.uniform(lower_bound, upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = population_size\n        \n        while evals < self.budget:\n            for i in range(population_size):\n                # Adaptive mutation scaling\n                self.mutation_scale = 0.5 + (0.5 * (self.budget - evals) / self.budget)\n                \n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_scale * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if evals < self.budget and population_size > self.min_population_size:\n                top_k = int(population_size * 0.9)\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:top_k]]\n                fitness = fitness[sorted_indices[:top_k]]\n                population_size = len(population)\n                \n        return best_solution", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.11388896809377402, 0.11391670050633407, 0.11390303502468946, 0.07347109363846716, 0.07348094595778676, 0.07347611788099184, 0.09460183759229435, 0.09461875269629971, 0.09461044466422297]}}
{"id": "7ac20f75-7f04-4563-bfb6-2110f5b9d75f", "fitness": -Infinity, "name": "EnhancedHybridMetaheuristic", "description": "Enhanced hybrid metaheuristic integrating adaptive differential evolution and simulated annealing with dynamic population size adjustment for superior exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.scale_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        population_size = self.base_population_size\n\n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evals = population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evals < self.budget:\n            new_population = []\n            for i in range(population_size):\n                # Adaptive Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.scale_factor * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                offspring = np.where(cross_points, mutant, population[i])\n\n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    new_population.append(offspring)\n                    fitness[i] = offspring_fitness\n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                else:\n                    new_population.append(population[i])\n\n                # Adjust population size dynamically\n                if evals % (0.1 * self.budget) == 0:\n                    population_size = min(int(1.1 * population_size), self.budget - evals + population_size)\n\n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n            population = np.array(new_population)\n            if len(population) < population_size:\n                additional_individuals = np.random.uniform(lower_bound, upper_bound, (population_size - len(population), self.dim))\n                population = np.vstack((population, additional_individuals))\n\n        return best_solution", "configspace": "", "generation": 2, "feedback": "An exception occurred: IndexError('index 200 is out of bounds for axis 0 with size 200').", "error": "IndexError('index 200 is out of bounds for axis 0 with size 200')", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {}}
{"id": "c51a030b-9d24-4078-8684-f1ed3c064532", "fitness": 0.09399797787120835, "name": "HybridMetaheuristic", "description": "Optimized hybrid metaheuristic by adjusting the mutation factor and crossover rate for stronger exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.9 * (b - c), lower_bound, upper_bound)  # Adjusted mutation factor\n                cross_points = np.random.rand(self.dim) < 0.85  # Adjusted crossover rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.113900677561381, 0.11391739275613233, 0.11389769627542334, 0.07347527317744618, 0.07348119293966482, 0.07347421281784627, 0.09460899944920687, 0.09461917598553105, 0.0946071798782433]}}
{"id": "221a23b0-a8d5-47b6-8f73-f0a8b7693a90", "fitness": 0.09400133113593684, "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive population size based on budget consumption.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, min(10 * dim, budget // 5))  # Adjusted population size\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.11390647064563053, 0.11391668858776416, 0.11390793941922295, 0.07347734065771783, 0.07348094170544428, 0.07347786777406706, 0.09461254237676486, 0.09461874540845039, 0.09461344364836954]}}
{"id": "980dc48f-b658-41dc-9246-75e2a0f839af", "fitness": 0.09399313612975911, "name": "RefinedHybridMetaheuristic", "description": "A refined hybrid metaheuristic optimizing exploration and exploitation using adaptive crossover and self-adaptive parameter control in differential evolution and simulated annealing.", "code": "import numpy as np\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.F = 0.5 + np.random.rand() * 0.3  # Self-adaptive scaling factor\n        self.CR = 0.5 + np.random.rand() * 0.3  # Self-adaptive crossover rate\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.CR\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                        # Update parameters slightly to encourage diversity\n                        self.F = 0.9 * self.F + 0.1 * np.random.rand() * 0.3\n                        self.CR = 0.9 * self.CR + 0.1 * np.random.rand() * 0.3\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 5, "feedback": "The algorithm RefinedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.11389284477502848, 0.11390526597263229, 0.11389561870740073, 0.0734724838125631, 0.07347682005484524, 0.07347341371455629, 0.09460421532148922, 0.09461171268028978, 0.09460585012902689]}}
{"id": "9bfade49-a1e8-417b-a2bf-7dbdaf3ff0a5", "fitness": 0.09400003553666064, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid algorithm combining adaptive differential evolution with simulated annealing and crowding distance for diversification and intensification in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation with adaptive parameters\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + np.random.uniform(0.5, 1.0) * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.CR\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy with crowding distance\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                # Early stopping if the budget is exhausted\n                if evals >= self.budget:\n                    break\n\n            # Introduce crowding distance for diversification\n            crowding_distances = np.zeros(self.population_size)\n            for j in range(self.dim):\n                sorted_idx = np.argsort(population[:, j])\n                max_dist = population[sorted_idx[-1], j] - population[sorted_idx[0], j]\n                crowding_distances[sorted_idx[0]] = crowding_distances[sorted_idx[-1]] = np.inf\n                for k in range(1, self.population_size - 1):\n                    crowding_distances[sorted_idx[k]] += (population[sorted_idx[k + 1], j] - population[sorted_idx[k - 1], j]) / max_dist\n            \n            # Select the most diverse individuals\n            diverse_population_idx = np.argsort(crowding_distances)[::-1][:self.population_size]\n            population = population[diverse_population_idx]\n            fitness = fitness[diverse_population_idx]\n\n        return best_solution", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.11390030901660275, 0.11391674509393268, 0.11390812214332324, 0.07347514048853765, 0.07348096186580366, 0.07347793299693117, 0.0946087728547359, 0.0946187799602155, 0.09461355540986316]}}
{"id": "bba1c009-31f8-4bea-9be0-d9657e2425ff", "fitness": 0.09400133113593684, "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using adaptive differential evolution and simulated annealing with adjusted cooling rate for enhanced black box optimization.", "code": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / self.temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature\n                self.temperature *= self.cooling_rate\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 7, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.11390647064563053, 0.11391668858776416, 0.11390793941922295, 0.07347734065771783, 0.07348094170544428, 0.07347786777406706, 0.09461254237676486, 0.09461874540845039, 0.09461344364836954]}}
{"id": "039ec645-031c-4ae9-9e53-02ee3ad801b2", "fitness": 0.09400137406860996, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic combining differential evolution with an adaptive simulated annealing cooling schedule to optimize exploration and exploitation in black box problems.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["3605f1df-2023-4ded-a107-f51eba8f6255"], "operator": null, "metadata": {"aucs": [0.11390647064563053, 0.11391688490092022, 0.11390793941922295, 0.07347734065771783, 0.07348101174663124, 0.07347786777406706, 0.09461254237676486, 0.09461886544816545, 0.09461344364836954]}}
{"id": "bda29c3a-636b-41bb-a594-022a1b4e0fef", "fitness": 0.09400119394256704, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic leveraging improved crossover and adaptive cooling to optimize exploration and exploitation in black box problems.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < (0.9 + 0.1 * np.random.rand())  # Change 1: Improved crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature += 0.01  # Change 2: Slight temperature increase to avoid stagnation\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["039ec645-031c-4ae9-9e53-02ee3ad801b2"], "operator": null, "metadata": {"aucs": [0.11390782087184437, 0.11391668858776416, 0.1139059624390858, 0.07347782181439166, 0.07348094170544428, 0.07347716244707325, 0.0946133673988876, 0.09461874540845039, 0.09461223481016179]}}
{"id": "356292f7-5f61-46be-a411-cefb690049b2", "fitness": 0.09399900080980599, "name": "EnhancedHybridMetaheuristic", "description": "A refined hybrid metaheuristic incorporating adaptive mutation scaling in differential evolution for enhanced exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + np.random.rand() * 0.2  # Adaptive mutation scaling\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["039ec645-031c-4ae9-9e53-02ee3ad801b2"], "operator": null, "metadata": {"aucs": [0.11390235912455293, 0.11391692748188709, 0.11390115775055354, 0.07347587264490163, 0.07348102693871339, 0.07347544801399108, 0.0946100271727498, 0.094618891485032, 0.09460929667587237]}}
{"id": "fe61935b-161b-49f0-a165-b037a96f40d5", "fitness": 0.09400142828418884, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with improved mutation scaling factor for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.9 * (b - c), lower_bound, upper_bound)  # Change: Updated mutation scaling factor from 0.8 to 0.9\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["039ec645-031c-4ae9-9e53-02ee3ad801b2"], "operator": null, "metadata": {"aucs": [0.11390711285757171, 0.11391769728391299, 0.11390673289401732, 0.07347756960119556, 0.07348130158893462, 0.0734774373361956, 0.09461293487704348, 0.09461936219423361, 0.09461270592459459]}}
{"id": "a13aa98d-47a1-496f-8f3a-55bc04cc49bb", "fitness": 0.09399929252739223, "name": "AdaptiveHybridMetaheuristic", "description": "A novel adaptive hybrid metaheuristic combining strategic perturbation and dynamic scaling to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.995  # Slightly slower cooling for better exploration\n        self.temperature_threshold = 0.05  # Lower threshold for finer tuning\n        self.dynamic_scaling_factor = 0.9  # Base value for mutation scaling, will adjust dynamically\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def update_scaling_factor(self, iteration, max_iterations):\n        return self.dynamic_scaling_factor + (0.1 * (1 - (iteration / max_iterations)))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        max_iterations = self.budget // self.population_size\n\n        for iteration in range(max_iterations):\n            scaling_factor = self.update_scaling_factor(iteration, max_iterations)\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with dynamic scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + scaling_factor * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n\n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {"aucs": [0.11390743538203252, 0.11391681681501842, 0.11389752515115759, 0.07347768486333262, 0.07348098745442655, 0.07347415174985739, 0.0946131322887781, 0.09461882381530884, 0.09460707522661804]}}
{"id": "c0f4a8b9-0b33-4bf6-9a71-2aed26b1ae92", "fitness": -Infinity, "name": "RefinedHybridMetaheuristic", "description": "A refined hybrid metaheuristic with dynamic population scaling and self-adaptive mutation for enhanced convergence and diversity maintenance.", "code": "import numpy as np\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def dynamic_population_size(self, evals):\n        return int(self.base_population_size * (1 + 0.2 * np.sin(np.pi * evals / self.budget)))\n\n    def adaptive_mutation_factor(self, fitness, best_fitness):\n        return 0.8 + 0.2 * (best_fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-10)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize population\n        population_size = self.dynamic_population_size(0)\n        population = np.random.uniform(lower_bound, upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            population_size = self.dynamic_population_size(evals)\n            for i in range(population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = self.adaptive_mutation_factor(fitness, best_fitness)\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n\n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 13, "feedback": "An exception occurred: IndexError('index 201 is out of bounds for axis 0 with size 200').", "error": "IndexError('index 201 is out of bounds for axis 0 with size 200')", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {}}
{"id": "22c0fde7-05c4-4e6a-a32f-98ee79db0851", "fitness": 0.09399730136565745, "name": "AdaptiveHybridMetaheuristic", "description": "A novel adaptive hybrid metaheuristic combining dynamic mutation scaling and self-adaptive crossover rates for refined exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.mutation_scaling_factor = 0.5 + np.random.rand() / 2\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def adaptive_crossover_rate(self, current_fitness, best_fitness):\n        return 0.4 + 0.5 * (current_fitness / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_scaling_factor * (b - c), lower_bound, upper_bound)\n                crossover_rate = self.adaptive_crossover_rate(fitness[i], best_fitness)\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {"aucs": [0.1139074677416273, 0.1139126510216878, 0.11389793788501901, 0.07347474890136874, 0.07347951974810019, 0.0734777029123087, 0.09461318009390107, 0.09461472544297111, 0.09459777854393314]}}
{"id": "02bb4434-b190-410d-8d7e-f00303bdc73d", "fitness": 0.09399862335725999, "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with dynamically adjusted crossover probability for improved solution diversity.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.9 * (b - c), lower_bound, upper_bound)\n                \n                # Change: Use dynamically adjusted crossover probability\n                crossover_probability = 0.9 * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < crossover_probability\n                \n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {"aucs": [0.11389604093824024, 0.1139173124542483, 0.11390536494505399, 0.07347361828684862, 0.0734811642895048, 0.07347694929082804, 0.09460616364681151, 0.09461912688347751, 0.09461186948032685]}}
{"id": "da37ed35-02a3-4e41-9944-231937e3afd6", "fitness": 0.09399802165294607, "name": "EnhancedHybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adjusted population size and crossover probability for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim  # Change: Adjusted population size from 10 * dim to 8 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.9 * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.85  # Change: Adjusted crossover probability from 0.9 to 0.85\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {"aucs": [0.11390690575553875, 0.11391744332324971, 0.11389162031435562, 0.07347749568076356, 0.07348121097949512, 0.07347204211086833, 0.09461280820929996, 0.09461920690404346, 0.0946034615989001]}}
{"id": "af32812b-d59f-44d1-be20-5262a701142b", "fitness": 0.09399688839784331, "name": "AdaptivePopulationMetaheuristic", "description": "Introducing adaptive population resizing and improved exploration-exploitation balance to enhance convergence efficiency and solution quality.", "code": "import numpy as np\n\nclass AdaptivePopulationMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 5 * dim)\n        self.population_size = self.initial_population_size\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def resize_population(self, evals):\n        # Reduce population size over time to focus on exploitation in later stages\n        stage = evals / self.budget\n        return max(5, int(self.initial_population_size * (1 - stage)))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        \n        while evals < self.budget:\n            self.population_size = self.resize_population(evals)\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Dynamic scaling factor for mutation\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n        return best_solution", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptivePopulationMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {"aucs": [0.11389014186252266, 0.11391668858776416, 0.11390395962445399, 0.0734715105897692, 0.07348094170544428, 0.07347644608445625, 0.09460255342414958, 0.09461874540845039, 0.09461100829357927]}}
{"id": "94ca5c83-fb02-471e-ac14-c10c66549cc4", "fitness": 0.09400156333722522, "name": "AdvancedStochasticRanking", "description": "A novel metaheuristic algorithm combining adaptive differential mutation with stochastic ranking to enhance solution diversity and convergence rate.", "code": "import numpy as np\n\nclass AdvancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 18, "feedback": "The algorithm AdvancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe61935b-161b-49f0-a165-b037a96f40d5"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.1139167402836192, 0.11390408301963373, 0.07347907697889744, 0.07348096014959138, 0.07347649180040117, 0.09461551813731883, 0.09461877701888555, 0.09461108549518715]}}
{"id": "90980a9c-87ec-4704-98bd-92cd91ca129e", "fitness": 0.09399867262484243, "name": "EnhancedStochasticRanking", "description": "An enhanced stochastic ranking algorithm integrating adaptive differential mutation, simulated annealing, and Lvy flight to improve exploration and convergence for black box optimization.", "code": "import numpy as np\n\nclass EnhancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.levy_alpha = 1.5  # Control parameter for Lvy flight\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * (1 / np.power(np.random.rand(self.dim), 1/self.levy_alpha))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Incorporate Lvy flight for diversification\n                if np.random.rand() < 0.3:\n                    offspring += self.levy_flight()\n                    offspring = np.clip(offspring, lower_bound, upper_bound)\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.1138954845285195, 0.11391668858776416, 0.11390677054217235, 0.07347341980321453, 0.07348094170544428, 0.07347745070968303, 0.09460582345371815, 0.09461874540845039, 0.09461272888461547]}}
{"id": "ae666965-3e09-4408-9400-c92021e1dcf8", "fitness": 0.09399920584291982, "name": "AdvancedStochasticRanking", "description": "An enhanced metaheuristic algorithm refining adaptive cooling and mutation for improved convergence and diversity.", "code": "import numpy as np\n\nclass AdvancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.6 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor (changed from 0.5 to 0.6)\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 20, "feedback": "The algorithm AdvancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.11390503893669168, 0.11391668858776416, 0.11389965448015504, 0.07347682876093176, 0.07348094170544428, 0.07347491155480501, 0.09461166580368296, 0.09461874540845039, 0.09460837734835303]}}
{"id": "291e0bba-b9ae-4914-b9c6-3c716cb9495e", "fitness": 0.09399878974678183, "name": "AdvancedStochasticRanking", "description": "An enhanced variant of AdvancedStochasticRanking integrating adaptive mutation schemes and elite retention to improve solution quality and convergence speed.", "code": "import numpy as np\n\nclass AdvancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.elite_fraction = 0.1  # New parameter for elite retention\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_size]  # Identify elites\n            elite_population = population[elite_indices]  # Retain elite solutions\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                if i in elite_indices:\n                    continue  # Skip elites in mutation\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Integrate elite solutions back into the population\n            population[:elite_size] = elite_population\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 21, "feedback": "The algorithm AdvancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.11390404337647908, 0.11391668858776416, 0.11389874695660018, 0.0734764739980388, 0.07348094170544428, 0.07347458776521709, 0.0946110574992618, 0.09461874540845039, 0.09460782242378074]}}
{"id": "09dbf4ad-573f-4244-b31c-63130c791ba0", "fitness": 0.0939972996396214, "name": "AdvancedStochasticRanking", "description": "Enhanced adaptive mutation scaling by adjusting the mutation factor for potential exploration improvements.", "code": "import numpy as np\n\nclass AdvancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.45 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 22, "feedback": "The algorithm AdvancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.11389793338380738, 0.11391684443309413, 0.11389788856204408, 0.07347429307719444, 0.07348099730794289, 0.07347428142541279, 0.09460732040543696, 0.09461884070279736, 0.09460729745886265]}}
{"id": "b869728c-2542-40c8-a798-eee35dcf46e5", "fitness": 0.09399983526653431, "name": "HyperHeuristicStochasticRanking", "description": "Enhance convergence by integrating a hyperheuristic approach that dynamically adjusts mutation strategies based on performance feedback while preserving solution diversity.", "code": "import numpy as np\n\nclass HyperHeuristicStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.mutation_strategies = [self.differential_mutation, self.gaussian_mutation]\n        self.strategy_weights = np.ones(len(self.mutation_strategies))\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def differential_mutation(self, a, b, c, lower_bound, upper_bound):\n        F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n        return np.clip(a + F * (b - c), lower_bound, upper_bound)\n\n    def gaussian_mutation(self, individual, lower_bound, upper_bound):\n        mutation_strength = 0.1 * (upper_bound - lower_bound)\n        return np.clip(individual + np.random.normal(0, mutation_strength, self.dim), lower_bound, upper_bound)\n\n    def select_mutation_strategy(self):\n        probabilities = self.strategy_weights / np.sum(self.strategy_weights)\n        return np.random.choice(len(self.mutation_strategies), p=probabilities)\n\n    def update_strategy_weights(self, applied_strategy, success):\n        if success:\n            self.strategy_weights[applied_strategy] *= 1.1\n        else:\n            self.strategy_weights[applied_strategy] *= 0.9\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Select and apply a mutation strategy\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                strategy_idx = self.select_mutation_strategy()\n                if strategy_idx == 0:\n                    mutant = self.differential_mutation(a, b, c, lower_bound, upper_bound)\n                else:\n                    mutant = self.gaussian_mutation(population[i], lower_bound, upper_bound)\n\n                # Crossover operation\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                success = False\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    success = True\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update strategy weights\n                self.update_strategy_weights(strategy_idx, success)\n\n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 23, "feedback": "The algorithm HyperHeuristicStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.1139021288012303, 0.11391692637806583, 0.11390520491336309, 0.07347579027181916, 0.07348102654492428, 0.07347689205999786, 0.0946098861324216, 0.09461889081019947, 0.09461177148678723]}}
{"id": "5f26494e-290f-4ab1-ba94-1f20807b5195", "fitness": 0.09400063477586072, "name": "AdvancedStochasticRanking", "description": "Enhanced Stochastic Ranking using adaptive crossover probability to maintain diversity and improve convergence.", "code": "import numpy as np\n\nclass AdvancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                \n                # Changed line\n                cross_points = np.random.rand(self.dim) < (0.9 * (1.0 - evals/self.budget)) + 0.1  # Adaptive crossover probability\n                \n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 24, "feedback": "The algorithm AdvancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.11391150012416051, 0.11391695529282764, 0.11389945937210155, 0.07347913512403581, 0.07348103686123908, 0.07347484191353582, 0.09461561778962502, 0.09461890849076215, 0.09460825801445893]}}
{"id": "9498dd4f-5fe7-4af6-9b4f-74f717bc0495", "fitness": 0.09400155759324132, "name": "EnhancedStochasticRanking", "description": "An enhanced metaheuristic blending adaptive differential mutation with simulated annealing and a novel adaptive stochastic ranking system for dynamic exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.p_swap = 0.45\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def adaptive_stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(self.population_size)\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(self.population_size - 1):\n            swap_prob = self.p_swap * (1 - (ranked_fitness[i+1] - ranked_fitness[i]) / max(ranked_fitness[i+1], 1e-10))\n            if np.random.rand() < swap_prob or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply adaptive stochastic ranking to enhance exploration and diversity\n            population, fitness = self.adaptive_stochastic_ranking(population, fitness)\n\n        return best_solution", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390408301963373, 0.07347907697889744, 0.07348096014959138, 0.07347649180040117, 0.09461551813731883, 0.09461877701888555, 0.09461108549518715]}}
{"id": "5f22a8ef-3692-4c0b-b315-e802a8029a1a", "fitness": 0.09400236291723575, "name": "EnhancedStochasticRanking", "description": "An enhanced algorithm integrating adaptive differential mutation with simulated annealing and dynamic population sizing to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5  # to allow dynamic population sizing\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        # Dynamically adjust population size based on remaining budget\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n            # Dynamically adjust population size\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                # Reduce population by keeping the best individuals\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["94ca5c83-fb02-471e-ac14-c10c66549cc4"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391781251098876, 0.11390666685141593, 0.07347907697889744, 0.0734813426981622, 0.0734774137545472, 0.09461551813731883, 0.09461943265015937, 0.09461266552213954]}}
{"id": "d0c3f356-094e-4d4a-bfec-c7ba356d06ca", "fitness": 0.0940022142192214, "name": "EnhancedStochasticRanking", "description": "Integrates opposition-based learning and adaptive differential evolution to intensify exploration and enhance convergence speed in stochastic ranking.", "code": "import numpy as np\n\nclass EnhancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def opposition_based_learning(self, population, lb, ub):\n        opposite_population = lb + ub - population\n        return np.clip(opposite_population, lb, ub)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            opposite_population = self.opposition_based_learning(population, lower_bound, upper_bound)\n            opposite_fitness = np.array([func(ind) for ind in opposite_population])\n            evals += current_population_size\n\n            combined_population = np.vstack((population, opposite_population))\n            combined_fitness = np.hstack((fitness, opposite_fitness))\n            sorted_indices = np.argsort(combined_fitness)\n            population = combined_population[sorted_indices[:self.population_size]]\n            fitness = combined_fitness[sorted_indices[:self.population_size]]\n\n            if np.min(fitness) < best_fitness:\n                best_fitness = np.min(fitness)\n                best_solution = population[np.argmin(fitness)]\n\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {"aucs": [0.11391197835214872, 0.11391668858776416, 0.11390646954931027, 0.07347930578590967, 0.07348094170544428, 0.07347734340685552, 0.09461591025145755, 0.09461874540845039, 0.09461254492565208]}}
{"id": "e37c1a2e-1cb1-43ac-b956-52a85054c995", "fitness": -Infinity, "name": "ChaoticLvyStochasticRanking", "description": "Introducing a chaotic map-based adaptive strategy and Lvy flight-inspired perturbations to enhance exploration-exploitation balance and escape local optima in black-box optimization.", "code": "import numpy as np\n\nclass ChaoticLvyStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequences\n        r = 4.0\n        return r * x * (1 - x)\n\n    def levy_flight(self, size):\n        # Lvy flight perturbation\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        steps = u / np.abs(v) ** (1 / beta)\n        return steps\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        x_chaos = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * self.chaotic_map(x_chaos)  # Chaotic adaptive scaling\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Apply Lvy flight perturbation\n                lf_step = self.levy_flight(self.dim)\n                offspring += lf_step\n                offspring = np.clip(offspring, lower_bound, upper_bound)\n\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                x_chaos = self.chaotic_map(x_chaos)\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 28, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {}}
{"id": "a7cf649d-2b3d-4f1e-9950-77e61dfd861c", "fitness": 0.09399941517821327, "name": "CompetitiveSwarmEnhancedRanking", "description": "An improved metaheuristic blending adaptive differential evolution with simulated annealing and competitive swarm dynamics to boost convergence and solution discovery.", "code": "import numpy as np\n\nclass CompetitiveSwarmEnhancedRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98\n        self.temperature_threshold = 0.05\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.5 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def competitive_swarm(self, population, fitness):\n        sorted_indices = np.argsort(fitness)\n        best_half = sorted_indices[:len(population)//2]\n        worse_half = sorted_indices[len(population)//2:]\n        for i in worse_half:\n            if np.random.rand() < 0.5:\n                partner_idx = np.random.choice(best_half)\n                population[i] = 0.5 * (population[i] + population[partner_idx])\n        return population\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.5 * np.random.rand()  # More adaptive mutation scaling\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            population = self.competitive_swarm(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 29, "feedback": "The algorithm CompetitiveSwarmEnhancedRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {"aucs": [0.11390133360321952, 0.11391668858776416, 0.1139043179042667, 0.07347550562744953, 0.07348094170544428, 0.07347657565989951, 0.09460939892853903, 0.09461874540845039, 0.09461122917888631]}}
{"id": "762c33f2-86dc-4a28-8743-2f1f4f8432f0", "fitness": -Infinity, "name": "AdvancedStochasticRanking", "description": "An advanced algorithm integrating adaptive differential mutation, simulated annealing with dynamic scaling, and enhanced stochastic ranking with elitism and strategic reinitialization to improve exploration and convergence speed.", "code": "import numpy as np\n\nclass AdvancedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.elitism_rate = 0.1  # Proportion of elite solutions retained\n        self.reinitialization_threshold = 0.1  # Threshold to trigger reinitialization\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def reinitialize_population(self, population, fitness, lower_bound, upper_bound):\n        # Reinitialize a portion of the population to escape local optima\n        num_to_reinitialize = int(self.population_size * self.reinitialization_threshold)\n        reinit_indices = np.argsort(fitness)[-num_to_reinitialize:]\n        population[reinit_indices] = np.random.uniform(lower_bound, upper_bound, (num_to_reinitialize, self.dim))\n        fitness[reinit_indices] = np.array([func(ind) for ind in population[reinit_indices]])\n        return population, fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            num_elites = int(current_population_size * self.elitism_rate)\n            elite_indices = np.argsort(fitness)[:num_elites]\n            elites = population[elite_indices]\n\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            population, fitness = self.reinitialize_population(population, fitness, lower_bound, upper_bound)\n\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            population = np.vstack((elites, population[num_elites:]))\n            fitness = np.hstack((fitness[elite_indices], fitness[num_elites:]))\n\n        return best_solution", "configspace": "", "generation": 30, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {}}
{"id": "baa1d84c-a558-4b7b-8af5-bd81b45651a2", "fitness": 0.0940002092440691, "name": "RefinedAdaptiveRanking", "description": "A refined adaptive algorithm that integrates dynamic population strategies with hybrid differential mutation and simulated annealing, emphasizing enhanced elitism and diversity maintenance for improved optimization performance.", "code": "import numpy as np\n\nclass RefinedAdaptiveRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.995\n        self.temperature_threshold = 0.01\n        self.elitism_rate = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        population_size = self.initial_population_size\n        population = np.random.uniform(lower_bound, upper_bound, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            elite_count = max(1, int(self.elitism_rate * current_population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = population[elite_indices]\n            elite_fitness = fitness[elite_indices]\n\n            for i in range(current_population_size):\n                if i not in elite_indices:\n                    idxs = [idx for idx in range(current_population_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    F = 0.5 + 0.4 * np.random.rand()\n                    mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                    cross_points = np.random.rand(self.dim) < 0.9\n                    offspring = np.where(cross_points, mutant, population[i])\n                    offspring_fitness = func(offspring)\n                    evals += 1\n\n                    if offspring_fitness < fitness[i]:\n                        population[i] = offspring\n                        fitness[i] = offspring_fitness\n                        if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                            best_solution = offspring\n                            best_fitness = offspring_fitness\n\n                    temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                    if temperature < self.temperature_threshold:\n                        temperature = self.temperature_threshold\n\n                    if evals >= self.budget:\n                        break\n\n            population, fitness = self.stochastic_ranking(np.vstack((elite_population, population)), np.concatenate((elite_fitness, fitness)))\n\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 31, "feedback": "The algorithm RefinedAdaptiveRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {"aucs": [0.1139030313963113, 0.11391668858776416, 0.11390624939393912, 0.07347611291161216, 0.07348094170544428, 0.07347726483637906, 0.09461043867320551, 0.09461874540845039, 0.09461241028351586]}}
{"id": "0b9aac68-a801-479e-8cb1-1e14a2323c15", "fitness": 0.09400127338830429, "name": "ImprovedAdaptiveDifferential", "description": "An improved adaptive differential mutation algorithm incorporating dynamic elitism and progressive boundary shrinking for enhanced solution quality and robustness.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def progressive_boundary_shrink(self, lower_bound, upper_bound, evals):\n        shrink_factor = 0.1 * (1 - evals / self.budget)\n        lower_bound += shrink_factor * (upper_bound - lower_bound)\n        upper_bound -= shrink_factor * (upper_bound - lower_bound)\n        return lower_bound, upper_bound\n\n    def __call__(self, func):\n        lower_bound = np.copy(func.bounds.lb)\n        upper_bound = np.copy(func.bounds.ub)\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            lower_bound, upper_bound = self.progressive_boundary_shrink(lower_bound, upper_bound, evals)\n\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            \n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 32, "feedback": "The algorithm ImprovedAdaptiveDifferential got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {"aucs": [0.11390682412525344, 0.11391676588199828, 0.11390724478725478, 0.07347746650629583, 0.07348096928274161, 0.07347762001692404, 0.09461275824288562, 0.09461879267157436, 0.09461301897981067]}}
{"id": "576f1c20-70b4-4319-b36c-936f7cdc3f42", "fitness": 0.09400020613567049, "name": "ImprovedStochasticRanking", "description": "ImprovedStochasticRanking refines adaptive cooling by dynamically adjusting the mutation factor with fitness variance, incorporating a momentum factor to balance exploration-exploitation, and enhancing convergence.", "code": "import numpy as np\n\nclass ImprovedStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.momentum = 0.9  # New momentum term\n\n    def adaptive_cooling(self, current_fitness, best_fitness, fitness_variance):\n        # Dynamic cooling rate based on fitness variance\n        dynamic_cooling = (best_fitness - current_fitness) / max(best_fitness, 1e-10) + fitness_variance\n        return max(self.cooling_rate, dynamic_cooling)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        # Initialize population\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            fitness_variance = np.var(fitness)\n\n            for i in range(current_population_size):\n                # Differential Evolution mutation and crossover with adaptive scaling\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + self.momentum * np.random.rand() * (1 - fitness_variance)  # Adaptive mutation scaling factor influenced by variance\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate offspring\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                # Replacement strategy\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    # Simulated annealing acceptance criterion\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                # Update temperature with adaptive cooling\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness, fitness_variance)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            # Apply stochastic ranking to enhance exploration and diversity\n            population, fitness = self.stochastic_ranking(population, fitness)\n\n            # Dynamically adjust population size\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n        return best_solution", "configspace": "", "generation": 33, "feedback": "The algorithm ImprovedStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {"aucs": [0.11390361440117003, 0.11391811379071526, 0.11390642920262106, 0.07347632139447724, 0.07348145018884855, 0.07347573140294072, 0.0946107956566099, 0.09461961687314902, 0.09460978231050265]}}
{"id": "a6664d52-c4ff-4267-a670-87ae85a9f501", "fitness": 0.09400239608916773, "name": "AdvancedChaosStochasticRanking", "description": "An advanced metaheuristic algorithm combining adaptive differential mutation, dynamic simulated annealing, and a novel chaos-inspired population perturbation strategy to enhance convergence and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 34, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["5f22a8ef-3692-4c0b-b315-e802a8029a1a"], "operator": null, "metadata": {"aucs": [0.11391134541486925, 0.11391668858776416, 0.11390793411804223, 0.07347907992709068, 0.07348094170544428, 0.07347786596195804, 0.09461552319009325, 0.09461874540845039, 0.09461344048879727]}}
{"id": "142c871e-754a-418a-855b-dca69b1d94e7", "fitness": 0.09400003784478451, "name": "RefinedChaosStochasticRanking", "description": "A refined metaheuristic algorithm integrating adaptive differential mutation, dynamic simulated annealing, chaos-inspired population perturbation, and adaptive crossover probabilities to enhance convergence and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass RefinedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def adaptive_crossover_probability(self, current_fitness, best_fitness):\n        return 0.9 * (1.0 - (current_fitness - best_fitness) / max(best_fitness, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                crossover_probability = self.adaptive_crossover_probability(fitness[i], best_fitness)\n                cross_points = np.random.rand(self.dim) < crossover_probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 35, "feedback": "The algorithm RefinedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a6664d52-c4ff-4267-a670-87ae85a9f501"], "operator": null, "metadata": {"aucs": [0.11390353637846962, 0.11391668858776416, 0.11390552142519661, 0.07347486403275039, 0.07348094170544428, 0.0734760733113391, 0.09461256956674924, 0.09461874540845039, 0.09461140018689684]}}
{"id": "50ef7da9-85b1-488a-afc9-7d56ced2d917", "fitness": 0.09400239428201834, "name": "EnhancedChaosOptimization", "description": "Enhanced chaos-inspired optimization leveraging dynamic population control, adaptive parameter tuning, and intensified stochastic exploration for improved black-box function convergence.", "code": "import numpy as np\n\nclass EnhancedChaosOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.5 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedChaosOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a6664d52-c4ff-4267-a670-87ae85a9f501"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390793411804223, 0.07347907697889744, 0.07348094170544428, 0.07347786596195804, 0.09461551813731883, 0.09461874540845039, 0.09461344048879727]}}
{"id": "048dc616-5f87-40c1-a60e-90d862ab9779", "fitness": 0.09400250984679512, "name": "AdvancedChaosStochasticRanking", "description": "An enhanced metaheuristic algorithm with a refined population perturbation strategy to boost exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 37, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a6664d52-c4ff-4267-a670-87ae85a9f501"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391721701796875, 0.11390793411804223, 0.07347907697889744, 0.07348113023954594, 0.07347786596195804, 0.09461551813731883, 0.09461906852713509, 0.09461344048879727]}}
{"id": "1f5b2be9-38df-4020-bf3d-4d813a4b58bd", "fitness": 0.09399688067204034, "name": "AdvancedChaosStochasticRanking", "description": "Introduced a dynamic crossover rate strategy in the advanced chaos stochastic ranking algorithm to further enhance exploration and convergence properties.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                # Dynamic crossover rate based on current fitness\n                crossover_rate = 0.9 * (1 - fitness[i] / (best_fitness + 1e-10))\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 38, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.1138928861480416, 0.11391756370359563, 0.11390030233619708, 0.07347249063346373, 0.07348125392942229, 0.07347514277593648, 0.09460423243537552, 0.09461928051333057, 0.09460877357300024]}}
{"id": "66ffd43c-55ac-44af-8597-26c2eb7b0563", "fitness": 0.09400239428201834, "name": "DynamicChaosDifferentialEvolution", "description": "A dynamic chaos-enhanced differential evolution algorithm that adaptively adjusts mutation strategies and utilizes nonlinear chaotic maps to boost exploration and convergence efficiency in black-box optimization.", "code": "import numpy as np\n\nclass DynamicChaosDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Sine map for chaotic sequence generation\n        return np.sin(np.pi * x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1  # Balanced perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 39, "feedback": "The algorithm DynamicChaosDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390793411804223, 0.07347907697889744, 0.07348094170544428, 0.07347786596195804, 0.09461551813731883, 0.09461874540845039, 0.09461344048879727]}}
{"id": "b90749e2-2c58-41ac-a3d3-6435e162d1e8", "fitness": 0.09399835782150895, "name": "AdvancedDynamicStochasticRanking", "description": "A dynamic population adjustment and self-adaptive mutation strategy to enhance the efficiency and robustness of black-box optimization.", "code": "import numpy as np\n\nclass AdvancedDynamicStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.min_population_size = 5\n        self.alpha = 0.9  # Control parameter for self-adaptive mutation\n        self.cooling_rate = 0.98\n        self.temperature_threshold = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.initial_population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.initial_population_size\n        temperature = 1.0\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = self.alpha * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1  # Moderate perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 40, "feedback": "The algorithm AdvancedDynamicStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11389607384406975, 0.1139168461886213, 0.11390458398474324, 0.0734736302071558, 0.07348099793430907, 0.07347667060868401, 0.09460618395408993, 0.09461884177626656, 0.09461139189564083]}}
{"id": "1e44ba7a-ae3e-46f1-9035-a96cbb6a2aba", "fitness": 0.09400250745091634, "name": "EnhancedAdaptivePerturbationRanking", "description": "EnhancedAdaptivePerturbationRanking: An improved metaheuristic with adaptive perturbation and dynamic diversity maintenance for robust exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptivePerturbationRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.perturbation_factor = 0.15\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def update_perturbation_factor(self, diversity):\n        return self.perturbation_factor * (1 + 0.5 * (1 - diversity))\n\n    def compute_diversity(self, population):\n        mean_distance = np.mean(np.linalg.norm(population - np.mean(population, axis=0), axis=1))\n        return mean_distance / (np.max(population) - np.min(population))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            diversity = self.compute_diversity(population)\n            self.perturbation_factor = self.update_perturbation_factor(diversity)\n\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * self.perturbation_factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptivePerturbationRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11391140188809068, 0.11391668858776416, 0.11390838685254967, 0.07347910007540626, 0.07348094170544428, 0.07347802749314591, 0.09461555772142272, 0.09461874540845039, 0.09461371732597301]}}
{"id": "1aafddf7-eaf5-47ba-a399-47c7cffabb78", "fitness": 0.09399604259676636, "name": "AdvancedChaosStochasticRanking", "description": "A slightly refined algorithm that improves mutation diversity by adjusting the differential weight dynamically in the AdvancedChaosStochasticRanking.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.45 * np.random.rand()  # Adjusted differential weight range\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 42, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.1138875386072904, 0.11391668858776416, 0.11390269195017022, 0.07347058353556846, 0.07348094170544428, 0.07347599537967286, 0.09460096341389856, 0.09461874540845039, 0.09461023478263797]}}
{"id": "310f8063-8c3e-4856-b48b-391a82cb5b41", "fitness": 0.09399719225862538, "name": "EnhancedAdaptiveStochasticRanking", "description": "An improved metaheuristic algorithm utilizing adaptive learning rates and self-adaptive mutation strategies to enhance convergence speed and solution accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.min_population_size = 5\n        self.mutation_rate = 0.9\n        self.learning_rate = 0.1\n    \n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i + 1]:\n                ranked_population[i], ranked_population[i + 1] = ranked_population[i + 1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i + 1] = ranked_fitness[i + 1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + chaos_value * self.learning_rate  # Adaptive F\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.mutation_rate\n                offspring = np.where(cross_points, mutant, population[i])\n\n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness:\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                        self.learning_rate = 0.1 * (best_fitness / max(fitness[i], 1e-10))  # Update learning rate\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = max(self.min_population_size, len(population) * (self.budget - evals) // self.budget)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1  # Self-adaptive perturbation\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11389060896337044, 0.11391669040223473, 0.11390487612795552, 0.07347167938671806, 0.07348094235281666, 0.0734767748124725, 0.0946028412604677, 0.09461874651794555, 0.09461157050364721]}}
{"id": "43dd5e57-37f8-438e-bddb-4e2aa936e123", "fitness": 0.09400239428201834, "name": "AdvancedChaosStochasticRanking", "description": "A refined algorithm with modified perturbation and elitism strategies to improve convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1  # Reduced perturbation factor\n            population += np.random.uniform(-0.5, 0.5, population.shape) * perturbation  # Modified perturbation range\n            population = np.clip(population, lower_bound, upper_bound)\n\n            # Elitism: Retain a copy of the best solution in the population\n            population[0] = best_solution  # Ensure best solution retention\n\n        return best_solution", "configspace": "", "generation": 44, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390793411804223, 0.07347907697889744, 0.07348094170544428, 0.07347786596195804, 0.09461551813731883, 0.09461874540845039, 0.09461344048879727]}}
{"id": "44868e2d-ad9b-476f-b78a-05b5eac30337", "fitness": 0.09400169793606325, "name": "AdvancedChaosStochasticRanking", "description": "Introduced a dynamic crossover rate for offspring generation to enhance diversity and adaptability during the optimization process.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_probability = 0.9 * (1 - evals / self.budget) + 0.1 * (evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cross_probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 45, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11390638384729945, 0.11391668858776416, 0.11390970331780115, 0.07347730970252175, 0.07348094170544428, 0.07347849720939048, 0.09461248931559663, 0.09461874540845039, 0.09461452233030099]}}
{"id": "0f90a1b0-3b20-4f84-bbb6-7fd79d2c29bc", "fitness": 0.09400239608916773, "name": "AdvancedChaosStochasticRanking", "description": "Refined population perturbation strategy to improve exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.10  # Reduced perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 46, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11391134541486925, 0.11391668858776416, 0.11390793411804223, 0.07347907992709068, 0.07348094170544428, 0.07347786596195804, 0.09461552319009325, 0.09461874540845039, 0.09461344048879727]}}
{"id": "4a45a75c-2893-4aef-8258-4641e3c83119", "fitness": 0.09400256197515844, "name": "AdvancedChaosStochasticRanking", "description": "A refined metaheuristic algorithm with enhanced adjustment of chaotic perturbation to further improve exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2  # Slightly increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 47, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["048dc616-5f87-40c1-a60e-90d862ab9779"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390870090620153, 0.07347907697889744, 0.07348094170544428, 0.07347813954125226, 0.09461551813731883, 0.09461874540845039, 0.09461390935960456]}}
{"id": "c24ec017-4cf5-4e90-860e-226547d0f626", "fitness": 0.09400036519527702, "name": "AdvancedChaosStochasticRanking", "description": "An improved metaheuristic leveraging adaptive mutation and search direction alignment to enhance convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutation_factor = 0.6 + 0.3 * (evals / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + mutation_factor * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2\n            search_direction = np.random.uniform(-1, 1, population.shape)  # New search direction\n            population += search_direction * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 48, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {"aucs": [0.11390358078785379, 0.11391668858776416, 0.11390641299118409, 0.07347630903446667, 0.07348094170544428, 0.0734773232030761, 0.09461077472293622, 0.09461874540845039, 0.09461251031631746]}}
{"id": "0f3033cd-d56f-4fe2-a010-4c5bcff141e6", "fitness": 0.0939971531083256, "name": "AdvancedChaosStochasticRanking", "description": "Improved exploration capability by increasing mutation factor range for diversity.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.3 + 0.5 * np.random.rand()  # Increased mutation factor range\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2  # Slightly increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 49, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {"aucs": [0.1138884861099152, 0.11391668858776416, 0.11390682208816905, 0.0734709215796604, 0.07348094170544428, 0.07347746920699239, 0.09460154277482358, 0.09461874540845039, 0.09461276051371093]}}
{"id": "f6192247-9285-499b-b653-6e4163f3962e", "fitness": 0.09400239561719843, "name": "EnhancedChaosPopulationManagement", "description": "An enhanced metaheuristic algorithm integrating adaptive chaotic perturbation and dynamic population management for improved exploration and convergence efficiency in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedChaosPopulationManagement:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation_factor = chaos_value * (upper_bound - lower_bound) * 0.25  # Further increasing perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation_factor\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedChaosPopulationManagement got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {"aucs": [0.11391134325673757, 0.11391668858776416, 0.11390793411804223, 0.07347907915712248, 0.07348094170544428, 0.07347786596195804, 0.09461552187046951, 0.09461874540845039, 0.09461344048879727]}}
{"id": "594566ed-5a54-4ca8-bbde-0feed22167cd", "fitness": 0.09400243231021897, "name": "EnhancedChaosLocalSearch", "description": "An enhanced metaheuristic with adaptive chaotic exploration and dynamic local search, improving convergence and solution diversity in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedChaosLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def local_search(self, individual, func):\n        step = (func.bounds.ub - func.bounds.lb) * 0.01\n        new_individual = np.clip(individual + np.random.uniform(-step, step, self.dim), func.bounds.lb, func.bounds.ub)\n        if func(new_individual) < func(individual):\n            return new_individual\n        return individual\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population = np.array([self.local_search(ind, func) for ind in population])\n            fitness = np.array([func(ind) for ind in population])\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedChaosLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.1139168624751512, 0.11390793411804223, 0.07347907697889744, 0.07348100374519151, 0.07347786596195804, 0.09461551813731883, 0.09461885173512175, 0.09461344048879727]}}
{"id": "1ec0abb0-bf44-4bb7-81cc-adad0c5c5227", "fitness": -Infinity, "name": "EnhancedAdaptiveChaosRanking", "description": "Introducing an adaptive differential mutation strategy with learning rates to enhance convergence and exploration balance in chaotic stochastic ranking.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaosRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def adaptive_differential_mutation(self, a, b, c, chaos_value):\n        # Adaptive learning rate based on chaos value\n        F = 0.5 + 0.3 * chaos_value\n        return np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.adaptive_differential_mutation(a, b, c, chaos_value)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 52, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {}}
{"id": "b7259c17-19d0-415c-9ef1-e557febe246e", "fitness": 0.09400213565864395, "name": "EnhancedChaosAdaptiveStochasticRanking", "description": "An advanced chaotic perturbation metaheuristic with adaptive mutation and crossover rates to enhance convergence and exploration in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedChaosAdaptiveStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.9\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def adaptive_mutation_and_crossover(self, fitness, best_fitness):\n        improvement = (best_fitness - np.min(fitness)) / max(best_fitness, 1e-10)\n        self.mutation_rate = 0.4 + 0.1 * improvement\n        self.crossover_rate = 0.8 + 0.1 * improvement\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            self.adaptive_mutation_and_crossover(fitness, best_fitness)\n\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = self.mutation_rate + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedChaosAdaptiveStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {"aucs": [0.1139108943117948, 0.11391668858776416, 0.1139066525825011, 0.07347909513272699, 0.07348094170544428, 0.07347740868745378, 0.09461567176653818, 0.09461874540845039, 0.09461312274512179]}}
{"id": "14376924-056d-4d66-83cd-ab4e61a2638f", "fitness": 0.09400292895735221, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration through increased chaotic perturbation factor for improved optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 54, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["4a45a75c-2893-4aef-8258-4641e3c83119"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391768066380936, 0.11390938689151808, 0.07347907697889744, 0.073481295657705, 0.07347838428764808, 0.09461551813731883, 0.09461935202995753, 0.09461432881782306]}}
{"id": "d65c804e-30d7-473a-b7dd-e9dbe622f5ac", "fitness": 0.09399959268246118, "name": "AdvancedChaosStochasticRanking", "description": "Refined chaotic perturbation and population dynamics for improved exploration and convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted cooling rate\n        self.temperature_threshold = 0.05  # Lowered threshold for better precision\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.5 or ranked_fitness[i] < ranked_fitness[i+1]:  # Adjusted probability threshold\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.6 + 0.4 * np.random.rand()  # Adjusted scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.85  # Adjusted crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2  # Adjusted perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 55, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390556030795285, 0.11391668858776416, 0.11390090080462467, 0.07347701576401311, 0.07348094170544428, 0.07347535635721658, 0.09461198562788409, 0.09461874540845039, 0.09460913957880046]}}
{"id": "d7bb8bdc-04ca-4bfe-816c-3f31507b1a63", "fitness": 0.09399835270997182, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration and exploitation by optimizing mutation factor to improve convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + 0.2 * np.random.rand()  # Optimized mutation factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 56, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389958351952578, 0.11391668858776416, 0.11390120861494246, 0.07347488247254763, 0.07348094170544428, 0.07347546618570089, 0.09460833009247804, 0.09461874540845039, 0.09460932780289277]}}
{"id": "63bfa82b-633f-4226-a36e-bc4f2e838097", "fitness": 0.09399847698337783, "name": "AdvancedChaosStochasticRanking", "description": "Introduce a more dynamic crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.1 * np.random.rand())  # Slightly dynamic crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 57, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.1138992072552849, 0.11391668858776416, 0.11390215292601924, 0.07347474836337564, 0.07348094170544428, 0.07347580316107671, 0.09460810015828336, 0.09461874540845039, 0.09460990528470181]}}
{"id": "d158735a-3159-4a22-b22e-ce23977bd507", "fitness": 0.09400250865526422, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced chaos scaling factor to further boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.35  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 58, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.1139172115704632, 0.11390793411804223, 0.07347907697889744, 0.07348112829512854, 0.07347786596195804, 0.09461551813731883, 0.09461906519527996, 0.09461344048879727]}}
{"id": "6bb8b1b6-196c-4909-adcc-c2f62e041c2f", "fitness": 0.09400118950091224, "name": "AdvancedChaosStochasticRanking", "description": "Minor enhancement by slightly adjusting the crossover probability in differential evolution for improved convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.85  # Adjusted crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390660492491445, 0.11391668858776416, 0.11390715740627488, 0.07347738858290542, 0.07348094170544428, 0.07347758884132882, 0.09461262450181218, 0.09461874540845039, 0.09461296554931553]}}
{"id": "1d3793d5-2c3d-4b08-b682-4f234a815b17", "fitness": 0.09400274283899342, "name": "RefinedChaosStochasticRanking", "description": "Enhanced chaos-driven adaptive mutation and rank-based reduction strategy for efficient search space exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation_factor = 0.25 + 0.05 * chaos_value  # Dynamic perturbation factor\n            perturbation = perturbation_factor * (upper_bound - lower_bound)\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.1139176730407685, 0.11390854347037116, 0.07347907697889744, 0.0734812929386165, 0.07347808337134687, 0.09461551813731883, 0.09461934736936217, 0.09461381309276684]}}
{"id": "6e32fa2b-ab8b-4499-bf20-b79f9317c235", "fitness": 0.09400239608916773, "name": "HybridChaosAdaptiveDE", "description": "Utilizes hybrid chaotic perturbation with adaptive differential evolution for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridChaosAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1  # Reduced perturbation factor for stability\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 61, "feedback": "The algorithm HybridChaosAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391134541486925, 0.11391668858776416, 0.11390793411804223, 0.07347907992709068, 0.07348094170544428, 0.07347786596195804, 0.09461552319009325, 0.09461874540845039, 0.09461344048879727]}}
{"id": "5c6de910-eadf-4733-bda3-b64622ad32ea", "fitness": 0.09400292895735221, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced adaptive cooling strategy to accelerate convergence while maintaining diversity.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        # Changed the denominator to enhance cooling adaptation\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(abs(current_fitness - best_fitness), 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 62, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391768066380936, 0.11390938689151808, 0.07347907697889744, 0.073481295657705, 0.07347838428764808, 0.09461551813731883, 0.09461935202995753, 0.09461432881782306]}}
{"id": "3eea08eb-eb6a-4264-95c2-c7389f2508df", "fitness": 0.09400027627481507, "name": "AdvancedChaosStochasticRanking", "description": "Refined chaotic perturbations and differential weight adaptation for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 3.9 * x * (1.0 - x)  # Adjusted to enhance chaotic behavior\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.4 or ranked_fitness[i] < ranked_fitness[i+1]:  # Slightly adjusted ranking probability\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.6 + 0.3 * np.random.rand()  # Altered differential weight range\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.25  # Fine-tuned perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 63, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390683581970062, 0.11391668858776416, 0.113902751104762, 0.07347747082113665, 0.07348094170544428, 0.07347601650764368, 0.09461276554102749, 0.09461874540845039, 0.09461027097740637]}}
{"id": "46b951e2-0a1d-4aab-ad04-ef4a9df31e36", "fitness": 0.09399785655858112, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced mutation strategy with dynamic scaling factor for improved exploration.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand() * (1 - evals / self.budget)  # Dynamic scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 64, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389124105759063, 0.11391668858776416, 0.113907284408159, 0.0734719038888707, 0.07348094170544428, 0.07347763410254471, 0.09460322671374433, 0.09461874540845039, 0.09461304315466179]}}
{"id": "4f9ac469-2108-4afa-a69d-41a7c6b1aa08", "fitness": 0.09399847698337783, "name": "AdvancedChaosStochasticRanking", "description": "Improved exploration by adjusting the crossover probability to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.1 * np.random.rand())  # Adjusted crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 65, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.1138992072552849, 0.11391668858776416, 0.11390215292601924, 0.07347474836337564, 0.07348094170544428, 0.07347580316107671, 0.09460810015828336, 0.09461874540845039, 0.09460990528470181]}}
{"id": "eb7dc30b-b244-49d4-9498-62017db9df85", "fitness": 0.09399904534200432, "name": "EnhancedChaosDynamicRanking", "description": "Utilize adaptive chaos-enhanced differential mutation and dynamic stochastic ranking to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedChaosDynamicRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.995\n        self.temperature_threshold = 0.01\n        self.min_population_size = 5\n        self.mutation_factor_range = (0.5, 1.0)\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(abs(current_fitness - best_fitness), 1e-10))\n\n    def chaotic_map(self, x):\n        # Arnold's Cat Map for chaotic sequence generation\n        return (2 * x + 1) % 1\n    \n    def dynamic_stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.55 * (i / len(population)) or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n        \n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = np.random.uniform(*self.mutation_factor_range)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.dynamic_stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2  # Adjusted perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedChaosDynamicRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389511045254397, 0.11391668858776416, 0.11390885016561447, 0.07347328500386496, 0.07348094170544428, 0.07347819279305279, 0.09460559333549645, 0.09461874540845039, 0.09461400062580738]}}
{"id": "0a593405-49ad-4306-a615-f08dd93a5e2e", "fitness": 0.09400239608916773, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration through adaptive chaotic perturbation factor for improved optimization convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1  # Adjusted perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 67, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391134541486925, 0.11391668858776416, 0.11390793411804223, 0.07347907992709068, 0.07348094170544428, 0.07347786596195804, 0.09461552319009325, 0.09461874540845039, 0.09461344048879727]}}
{"id": "97af73db-eb59-403d-a481-3d29c5787757", "fitness": 0.09399617210729123, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration through increased chaotic perturbation factor for improved optimization with adaptive mutation factor.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.5 * np.random.rand()  # Slightly increased mutation factor range\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 68, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11388436035643812, 0.11391668858776416, 0.11390646469863297, 0.07346944720484783, 0.07348094170544428, 0.0734773415920954, 0.09459901753939437, 0.09461874540845039, 0.09461254187255363]}}
{"id": "48a3a51c-45f9-4230-9d99-35b7b926a7da", "fitness": 0.09399806768611102, "name": "AdaptiveChaosStochasticRanking", "description": "Introduce adaptive mutation and crossover rates with chaotic perturbation for dynamic exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + chaos_value * 0.5\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                crossover_rate = 0.9 + chaos_value * 0.1\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389964113245477, 0.11391668858776416, 0.11389984791521646, 0.07347490297542003, 0.07348094170544428, 0.07347498056229462, 0.09460836526687211, 0.09461874540845039, 0.09460849562108231]}}
{"id": "d1f04e90-7013-4a7f-9f80-986ba7ce113f", "fitness": 0.09399896944563631, "name": "AdvancedChaosStochasticRanking", "description": "Introduced dynamic mutation factor and adaptive chaotic perturbation to improve convergence and exploration.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.6 + 0.3 * chaos_value  # Dynamic mutation factor using chaos value\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.25  # Adaptive perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 70, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389893160610598, 0.11391668858776416, 0.11390468120863761, 0.07347464916750046, 0.07348094170544428, 0.07347670527523309, 0.09460793072848184, 0.09461874540845039, 0.094611451323109]}}
{"id": "53f1e2bd-353f-452b-ba5b-ef9c7d711aac", "fitness": 0.09399793026984149, "name": "AdvancedChaosStochasticRanking", "description": "Subtle tuning of crossover probability to refine solution quality.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.92  # Adjusted crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 71, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389856935771292, 0.11391692477619642, 0.11390005525122815, 0.07347452047657199, 0.0734810259726858, 0.0734750545512215, 0.09460770979656519, 0.09461888982990585, 0.0946086224164856]}}
{"id": "6b660d2b-8090-423f-90b9-a6b5a433e845", "fitness": 0.09400239561719843, "name": "AdvancedChaosStochasticRanking", "description": "Refined chaotic perturbation scaling for enhanced exploration.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.25  # Refined perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 72, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391134325673757, 0.11391668858776416, 0.11390793411804223, 0.07347907915712248, 0.07348094170544428, 0.07347786596195804, 0.09461552187046951, 0.09461874540845039, 0.09461344048879727]}}
{"id": "acbb1aa4-56bd-4daa-990c-83f815d34dd2", "fitness": 0.09400047601052443, "name": "AdvancedChaosStochasticRanking", "description": "Introduce adaptive mutation scaling to refine exploration capabilities for enhanced optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand() * (best_fitness - fitness[i]) / max(best_fitness, 1e-10)  # adaptive mutation scaling\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 73, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390859140157095, 0.11391701512367125, 0.11390729307279979, 0.07347490747415564, 0.07348094170544428, 0.0734766445162992, 0.09460833341271024, 0.09461874540845039, 0.0946118119796181]}}
{"id": "910fb34a-77b5-4ae9-ab3c-eb751ff7b636", "fitness": 0.09400013536607596, "name": "AdvancedChaosStochasticRanking", "description": "Improved mutation strategy through adaptive scaling factor for enhanced convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                F *= 1 - evals / self.budget  # Adaptive scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 74, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390862869099494, 0.11391668858776416, 0.11390031404542966, 0.07347811042809138, 0.07348094170544428, 0.07347514694082335, 0.09461386176793996, 0.09461874540845039, 0.09460878071974554]}}
{"id": "9d5763d9-b991-4ce0-8af8-704f20154d43", "fitness": 0.09399799558094654, "name": "EnhancedChaosDifferentialNiching", "description": "Incorporate adaptive differential evolution with chaotic perturbations and niching strategies for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedChaosDifferentialNiching:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.min_population_size = 5\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.temperature_threshold = 0.1\n        self.niche_radius = 0.1\n\n    def adaptive_scaling(self, current_fitness, best_fitness):\n        return min(0.8, max(0.4, (best_fitness - current_fitness) / max(abs(best_fitness), 1e-10) + 0.4))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def niche_selection(self, population, fitness):\n        niche_pop = []\n        niche_fit = []\n        for idx, ind in enumerate(population):\n            is_unique = True\n            for niche in niche_pop:\n                if np.linalg.norm(ind - niche) < self.niche_radius:\n                    is_unique = False\n                    break\n            if is_unique:\n                niche_pop.append(ind)\n                niche_fit.append(fitness[idx])\n        return np.array(niche_pop), np.array(niche_fit)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = self.adaptive_scaling(fitness[i], best_fitness)\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                temperature *= self.cooling_rate\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.niche_selection(population, fitness)\n            current_population_size = len(population)\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.1\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedChaosDifferentialNiching got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.1138911449225114, 0.11391672742804915, 0.11390799518655981, 0.07347186900612557, 0.07348095556295475, 0.07347788774579356, 0.09460316732623442, 0.09461874540845039, 0.09461346764183987]}}
{"id": "e9ca5ca3-adf8-42a7-aace-ecd54eced337", "fitness": 0.09399987029711979, "name": "EnhancedChaosEvolution", "description": "Introduce dynamic chaos control and adaptive crossover to enhance exploration and exploitation balance in chaotic evolutionary optimization.", "code": "import numpy as np\n\nclass EnhancedChaosEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i + 1]:\n                ranked_population[i], ranked_population[i + 1] = ranked_population[i + 1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i + 1] = ranked_fitness[i + 1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_rate = 0.9 if np.random.rand() < 0.5 else 0.7  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < cross_rate\n                offspring = np.where(cross_points, mutant, population[i])\n\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * (0.2 + 0.1 * np.random.rand())  # Dynamic chaos control\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedChaosEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.1138988619746214, 0.11391779956023262, 0.11390775819587085, 0.07347462508282776, 0.07348133807713297, 0.0734778031974127, 0.09460788893595684, 0.0946194247307921, 0.0946133329192308]}}
{"id": "eab60e72-5996-46f0-a652-e65aabd076c7", "fitness": 0.09400022853940809, "name": "EnhancedChaosStochasticRanking", "description": "Introduce multi-chaotic mapping and adaptive mutation scaling to enhance exploration and exploitation capabilities for better optimization performance.", "code": "import numpy as np\n\nclass EnhancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map_logistic(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def chaotic_map_sine(self, x):\n        return np.sin(np.pi * x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value_logistic = np.random.rand()\n        chaos_value_sine = 0.5  # Initial value for the sine map\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = np.random.uniform(0.4, 0.9)  # Adaptive scaling factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply multi-chaotic perturbation to enhance exploration\n            chaos_value_logistic = self.chaotic_map_logistic(chaos_value_logistic)\n            chaos_value_sine = self.chaotic_map_sine(chaos_value_sine)\n            perturbation_logistic = chaos_value_logistic * (upper_bound - lower_bound) * 0.2\n            perturbation_sine = chaos_value_sine * (upper_bound - lower_bound) * 0.1\n            total_perturbation = perturbation_logistic + perturbation_sine\n            population += np.random.uniform(-1, 1, population.shape) * total_perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391001936524592, 0.11391668858776416, 0.11389934937516388, 0.07347860670392636, 0.07348094170544428, 0.07347480269344431, 0.09461471223480633, 0.09461874540845039, 0.09460819078042726]}}
{"id": "3c62f9b1-1b8c-47a2-b356-ee7a7893d4b5", "fitness": 0.09400250865526422, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration through increased chaotic perturbation factor and improved diversity control for improved optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.35  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 78, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.1139172115704632, 0.11390793411804223, 0.07347907697889744, 0.07348112829512854, 0.07347786596195804, 0.09461551813731883, 0.09461906519527996, 0.09461344048879727]}}
{"id": "9265b524-3411-4bfe-85c4-761dab27a393", "fitness": 0.09399721791857277, "name": "EnhancedChaosAdaptiveMutation", "description": "Introducing dynamic chaos scaling and adaptive mutation strategies to enhance convergence and solution quality in complex optimization tasks.", "code": "import numpy as np\n\nclass EnhancedChaosAdaptiveMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.chaos_scaling_factor = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                F = 0.5 + 0.4 * np.random.rand() * (1 + self.chaos_scaling_factor * chaos_value)\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Dynamic chaos scaling for enhanced exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Adjusted perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedChaosAdaptiveMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.1138865581655868, 0.11391719554764423, 0.11390853951414259, 0.07347023363198679, 0.07348112257981498, 0.07347808195719963, 0.09460036380065462, 0.0946190553991999, 0.09461381067092534]}}
{"id": "7444722b-9aad-4361-a0ae-700d05450f5c", "fitness": -Infinity, "name": "EnhancedAdaptiveChaosDE", "description": "Integrate adaptive differential evolution with chaotic perturbation and elite preservation for robust optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaosDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.elite_fraction = 0.2\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            elite_size = max(1, int(current_population_size * self.elite_fraction))\n            elite_indices = np.argsort(fitness)[:elite_size]\n            elite_population = population[elite_indices]\n\n            for i in range(current_population_size):\n                if np.random.rand() < 0.9:  # Bias towards selecting from elite\n                    idxs = elite_indices\n                else:\n                    idxs = [idx for idx in range(current_population_size) if idx != i]\n\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 80, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {}}
{"id": "0051c60e-d02b-4b85-87f5-ed8ee62849a8", "fitness": 0.09399982633965626, "name": "EnhancedDynamicAdaptation", "description": "Enhanced dynamic adaptation through variable mutation and crossover rates for robust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()  # Dynamic mutation factor\n                cross_prob = 0.7 + 0.2 * np.random.rand()  # Dynamic crossover probability\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.15  # Adjusted perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedDynamicAdaptation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390344496353866, 0.11391668858776416, 0.11390408536881846, 0.07347626016032038, 0.07348094170544428, 0.07347649266352119, 0.0946106912414646, 0.09461874540845039, 0.09461108695758413]}}
{"id": "cee150ff-1eea-4b21-b316-1ea289759adf", "fitness": 0.09400002287724706, "name": "AdaptiveChaosStochasticRanking", "description": "Introduce an adaptive mutation strategy with dynamic step size control to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptiveChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.initial_step_size = 0.2\n        self.step_size_decay = 0.995\n        self.min_step_size = 0.05\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n        step_size = self.initial_step_size\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = step_size + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            step_size = max(self.min_step_size, step_size * self.step_size_decay)\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 82, "feedback": "The algorithm AdaptiveChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.1139043985049425, 0.11391672388970708, 0.11390399498480641, 0.07347660059713679, 0.07348095430053092, 0.07347646040403244, 0.09461127454151597, 0.09461876699455818, 0.09461103167799323]}}
{"id": "1f6ee5b9-9ea1-4771-b40c-35a3ed4f137c", "fitness": 0.09400159750835509, "name": "AdvancedChaosStochasticRanking", "description": "Improved exploration by increasing the differential weight for generating mutant vectors.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + 0.4 * np.random.rand()  # Increased differential weight\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 83, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390821170720566, 0.11391758103869443, 0.11390652398280543, 0.0734779617974799, 0.07348126011322798, 0.07347736275114625, 0.0946136069416389, 0.09461929111223188, 0.0946125781307654]}}
{"id": "88696092-bd5e-4760-bfc3-c9ba9bb6c996", "fitness": 0.09400239428201834, "name": "AdvancedChaosStochasticRanking", "description": "Improved exploration by adjusting the chaotic perturbation factor dynamically based on budget usage.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation_factor = (1.0 - evals / self.budget) * 0.3  # Dynamically adjust perturbation factor\n            perturbation = chaos_value * (upper_bound - lower_bound) * perturbation_factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 84, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390793411804223, 0.07347907697889744, 0.07348094170544428, 0.07347786596195804, 0.09461551813731883, 0.09461874540845039, 0.09461344048879727]}}
{"id": "5ca1475d-8d17-4f2f-9a09-4fae740e3dd3", "fitness": 0.09400082155553185, "name": "AdvancedChaosStochasticRanking", "description": "Incorporate adaptive mutation scaling and chaotic perturbation tuning for enhanced diversity and exploration.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def adaptive_mutation(self, fitness):\n        fitness_range = np.max(fitness) - np.min(fitness)\n        return 0.5 + 0.4 * (fitness_range / max(fitness_range, 1e-10))\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = self.adaptive_mutation(fitness)\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.2  # Reduced perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 85, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390728629654334, 0.11391769728391299, 0.11390378525109635, 0.07347763148397546, 0.07348130158893462, 0.07347638555582647, 0.09461304093264489, 0.09461936219423361, 0.09461090341261891]}}
{"id": "e8d0ed41-aa7f-4020-9de0-33e9e31b8f70", "fitness": 0.09400175079597263, "name": "AdvancedChaosStochasticRanking", "description": "Introduced adaptive mutation strategies and enhanced chaotic exploration for improved optimization performance.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def adaptive_mutation(self, mutant, best_solution, lower_bound, upper_bound):\n        mutation_strength = 0.2 * np.random.rand(self.dim) * (best_solution - mutant)\n        return np.clip(mutant + mutation_strength, lower_bound, upper_bound)\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                mutant = self.adaptive_mutation(mutant, best_solution, lower_bound, upper_bound)  # Adaptive mutation\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 86, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390839975528366, 0.11391668858776416, 0.11390792952379203, 0.07347802856025154, 0.07348094170544428, 0.073477864339493, 0.09461372158644021, 0.09461874540845039, 0.09461343769683439]}}
{"id": "9aa4b8de-e802-462b-836e-519c10b7fa17", "fitness": 0.09399785655858112, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration through increased chaotic perturbation factor and adaptive mutation scaling for improved optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = np.clip(0.5 + 0.4 * np.random.rand() * (1 - evals/self.budget), 0.1, 1.0)  # Changed mutation factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 87, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389124105759063, 0.11391668858776416, 0.113907284408159, 0.0734719038888707, 0.07348094170544428, 0.07347763410254471, 0.09460322671374433, 0.09461874540845039, 0.09461304315466179]}}
{"id": "e0e08607-efe4-4dce-88b8-5f80481865e3", "fitness": 0.09400275064420265, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploitation by slightly increasing the probability of ranking swaps to improve optimization.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.50 or ranked_fitness[i] < ranked_fitness[i+1]:  # Changed 0.45 to 0.50\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 88, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390956361294324, 0.07347907697889744, 0.07348094170544428, 0.0734784473383151, 0.09461551813731883, 0.09461874540845039, 0.09461443687719784]}}
{"id": "0ad38b85-9998-4d6a-8f93-3f99abc0f1b4", "fitness": 0.09399793026984149, "name": "AdvancedChaosStochasticRanking", "description": "Enhanced exploration by slightly increasing the crossover rate for better diversity.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.92  # Adjusted crossover rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 89, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389856935771292, 0.11391692477619642, 0.11390005525122815, 0.07347452047657199, 0.0734810259726858, 0.0734750545512215, 0.09460770979656519, 0.09461888982990585, 0.0946086224164856]}}
{"id": "d6202ee2-9280-4f28-9022-7261c7504676", "fitness": 0.09400033053455778, "name": "EnhancedChaosStochasticRanking", "description": "Incorporate dynamic mutation scaling and adaptive chaos intensity for enhanced convergence in stochastic ranking.", "code": "import numpy as np\n\nclass EnhancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.dynamic_mutation_scale = 0.5\n        self.chaos_intensity = 0.3\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n\n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            mutation_scale = self.dynamic_mutation_scale * (1 - evals / self.budget)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = mutation_scale + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n\n                offspring_fitness = func(offspring)\n                evals += 1\n\n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n\n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n\n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply dynamic chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * self.chaos_intensity\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390274114986709, 0.11391668858776416, 0.11390709427505463, 0.0734760094147352, 0.07348094170544428, 0.07347756619427714, 0.09461026125612615, 0.09461874540845039, 0.094612926819301]}}
{"id": "7d7ab346-dda6-4c83-a509-cf8dbf98ba20", "fitness": 0.09400088556598984, "name": "AdvancedChaosStochasticRanking", "description": "Refined chaotic perturbation and adaptive mutation strategies for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98  # Modified cooling rate\n        self.temperature_threshold = 0.05  # Lowered temperature threshold\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 3.9 * x * (1.0 - x)  # Modified chaotic map factor\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.5 * np.random.rand()  # Adjusted mutation factor\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.85  # Modified crossover probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.25  # Modified perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 91, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390529384450931, 0.11391668858776416, 0.11390707947521228, 0.0734769201077402, 0.07348094170544428, 0.07347756100979619, 0.09461182208613672, 0.09461874540845039, 0.09461291786885506]}}
{"id": "a3a12910-87b7-41ea-83b6-3e815ab69fd8", "fitness": 0.09399967759804945, "name": "AdvancedChaosStochasticRanking", "description": "Introduced a dynamic crossover rate to increase adaptability during exploration and exploitation phases.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < (0.7 + 0.2 * np.random.rand()) # Change: dynamic crossover rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 92, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390687924330656, 0.11391668858776416, 0.11389997040414335, 0.07347748621318917, 0.07348094170544428, 0.07347502428747099, 0.09461279198915251, 0.09461874540845039, 0.09460857054352356]}}
{"id": "e9ba112c-a416-418f-bdc3-16545dfee420", "fitness": 0.09399828055969899, "name": "AdvancedChaosStochasticRanking", "description": "Introducing a dynamic mutation factor and adaptive crossover probability to enhance the exploration-exploitation balance in chaotic stochastic ranking.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                dynamic_mutation_factor = 0.5 + 0.3 * (1 - evals / self.budget)\n                F = dynamic_mutation_factor * (0.5 + 0.5 * np.random.rand())\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                adaptive_crossover_probability = 0.9 * (1 - evals / self.budget) + 0.1\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_probability\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 93, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390198747987601, 0.11391780734199686, 0.11389735673201429, 0.07347573970989829, 0.07348134085475211, 0.07347409163704532, 0.09460979957273652, 0.09461942949035551, 0.09460697221861591]}}
{"id": "ab6070d0-b270-4a53-b541-d0308883a9b4", "fitness": 0.09399708934188784, "name": "AdvancedChaosStochasticRanking", "description": "Minor improvement in chaotic perturbation and crossover for enhanced solution diversity.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.95  # Slightly increased crossover rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.25  # Reduced perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 94, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389205577330563, 0.11391674864724155, 0.11390290103142886, 0.0734721951349282, 0.07348096313363328, 0.07347607004505774, 0.09460372547746809, 0.09461878213309782, 0.09461036270082945]}}
{"id": "d5d40995-6fbe-4c82-82b5-5c2f6209223a", "fitness": 0.09400158178015786, "name": "AdvancedChaosStochasticRanking", "description": "Introduce self-adaptive differential evolution with chaotic mutation and dynamic crossover to enhance search efficiency and convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.crossover_rate_initial = 0.9\n        self.F_min = 0.4\n        self.F_max = 0.9\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Sine map for chaotic sequence generation\n        return np.sin(np.pi * x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n        crossover_rate = self.crossover_rate_initial\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n            \n            # Dynamically adjust crossover rate\n            crossover_rate = self.crossover_rate_initial * (1 - (evals / self.budget))\n\n        return best_solution", "configspace": "", "generation": 95, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11390815047656189, 0.11391668858776416, 0.11390740576972991, 0.07347793991186402, 0.07348094170544428, 0.07347767737066058, 0.09461356946006982, 0.09461874540845039, 0.09461311733087563]}}
{"id": "98d22aca-45cc-4b1a-afd9-eb3fab8d22e8", "fitness": 0.09399785655858112, "name": "AdvancedChaosStochasticRanking", "description": "Advanced optimization utilizing dynamic mutation scaling for improved adaptation.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand() * (1 - evals / self.budget)  # Dynamic mutation scaling\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 96, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11389124105759063, 0.11391668858776416, 0.113907284408159, 0.0734719038888707, 0.07348094170544428, 0.07347763410254471, 0.09460322671374433, 0.09461874540845039, 0.09461304315466179]}}
{"id": "f5719468-0701-4fed-9c3f-300d76eb1f18", "fitness": 0.09400275064420265, "name": "AdvancedChaosStochasticRanking", "description": "Slightly increased probability for stochastic ranking to enhance exploration.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.5 or ranked_fitness[i] < ranked_fitness[i+1]:  # Changed probability from 0.45 to 0.5\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.3  # Increased perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 97, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391668858776416, 0.11390956361294324, 0.07347907697889744, 0.07348094170544428, 0.0734784473383151, 0.09461551813731883, 0.09461874540845039, 0.09461443687719784]}}
{"id": "d9009a34-d136-4445-9e06-462f47dab2ba", "fitness": 0.09400239561719843, "name": "AdvancedChaosStochasticRanking", "description": "Refined chaotic perturbation mechanism to improve solution diversity and convergence.", "code": "import numpy as np\n\nclass AdvancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        # Logistic map for chaotic sequence generation\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n\n        while evals < self.budget:\n            current_population_size = len(population)\n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            # Apply chaotic perturbation to enhance exploration\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * 0.25  # Reduced perturbation factor\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n\n        return best_solution", "configspace": "", "generation": 98, "feedback": "The algorithm AdvancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391134325673757, 0.11391668858776416, 0.11390793411804223, 0.07347907915712248, 0.07348094170544428, 0.07347786596195804, 0.09461552187046951, 0.09461874540845039, 0.09461344048879727]}}
{"id": "9d9f35b1-476c-4c69-ad30-a8d10f51bf48", "fitness": 0.09400295649229494, "name": "EnhancedChaosStochasticRanking", "description": "Introduce adaptive chaotic perturbations and elite retention to enhance both exploration and exploitation for improved optimization performance.", "code": "import numpy as np\n\nclass EnhancedChaosStochasticRanking:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99\n        self.temperature_threshold = 0.1\n        self.min_population_size = 5\n        self.elite_fraction = 0.1\n\n    def adaptive_cooling(self, current_fitness, best_fitness):\n        return max(self.cooling_rate, (best_fitness - current_fitness) / max(best_fitness, 1e-10))\n\n    def chaotic_map(self, x):\n        return 4.0 * x * (1.0 - x)\n    \n    def stochastic_ranking(self, population, fitness):\n        perm = np.random.permutation(len(population))\n        ranked_population = population[perm]\n        ranked_fitness = fitness[perm]\n        for i in range(len(population) - 1):\n            if np.random.rand() < 0.45 or ranked_fitness[i] < ranked_fitness[i+1]:\n                ranked_population[i], ranked_population[i+1] = ranked_population[i+1], ranked_population[i]\n                ranked_fitness[i], ranked_fitness[i+1] = ranked_fitness[i+1], ranked_fitness[i]\n        return ranked_population, ranked_fitness\n\n    def adjust_population_size(self, current_population_size, evals):\n        remaining_budget = self.budget - evals\n        adjusted_size = max(self.min_population_size, current_population_size * remaining_budget // self.budget)\n        return adjusted_size\n\n    def __call__(self, func):\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        \n        population = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evals = self.population_size\n        temperature = self.initial_temperature\n        chaos_value = np.random.rand()\n        \n        while evals < self.budget:\n            current_population_size = len(population)\n            elites_count = max(1, int(self.elite_fraction * current_population_size))\n            elites = population[np.argsort(fitness)[:elites_count]]\n            \n            for i in range(current_population_size):\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                F = 0.5 + 0.4 * np.random.rand()\n                mutant = np.clip(a + F * (b - c), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < 0.9\n                offspring = np.where(cross_points, mutant, population[i])\n                \n                offspring_fitness = func(offspring)\n                evals += 1\n                \n                if offspring_fitness < fitness[i]:\n                    population[i] = offspring\n                    fitness[i] = offspring_fitness\n                    \n                    if offspring_fitness < best_fitness or np.exp((best_fitness - offspring_fitness) / temperature) > np.random.rand():\n                        best_solution = offspring\n                        best_fitness = offspring_fitness\n                \n                temperature *= self.adaptive_cooling(offspring_fitness, best_fitness)\n                if temperature < self.temperature_threshold:\n                    temperature = self.temperature_threshold\n\n                if evals >= self.budget:\n                    break\n\n            population, fitness = self.stochastic_ranking(population, fitness)\n            adjusted_population_size = self.adjust_population_size(current_population_size, evals)\n            if adjusted_population_size < current_population_size:\n                sorted_indices = np.argsort(fitness)\n                population = population[sorted_indices[:adjusted_population_size]]\n                fitness = fitness[sorted_indices[:adjusted_population_size]]\n\n            chaos_value = self.chaotic_map(chaos_value)\n            perturbation = chaos_value * (upper_bound - lower_bound) * np.random.rand() * 0.3\n            population += np.random.uniform(-1, 1, population.shape) * perturbation\n            population = np.clip(population, lower_bound, upper_bound)\n            \n            # Reinsert elites\n            population[:elites_count] = elites\n\n        return best_solution", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedChaosStochasticRanking got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["14376924-056d-4d66-83cd-ab4e61a2638f"], "operator": null, "metadata": {"aucs": [0.11391133715149249, 0.11391694769023863, 0.1139102457683413, 0.07347907697889744, 0.07348103414869345, 0.07347869071923119, 0.09461551813731883, 0.09461890384189398, 0.09461485399454717]}}
