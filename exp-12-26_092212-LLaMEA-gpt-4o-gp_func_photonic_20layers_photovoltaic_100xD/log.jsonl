{"id": "af72b8bf-3264-419f-baee-96c8b7590469", "fitness": 0.07687818985828089, "name": "AQIDE", "description": "Adaptive Quantum-Inspired Differential Evolution (AQIDE) combining adaptive mutation strategies and quantum-inspired superposition states for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant):\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < self.CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 0, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07688 with standard deviation 0.04388.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.048394644035641976, 0.05081135673926185, 0.04955851653904564, 0.13997511713514343, 0.13813046819859032, 0.13823060151472621, 0.041172839526878224, 0.04221337985476881, 0.04341678518047154]}}
{"id": "24c858fe-1b71-4155-ac89-9e1e89df391b", "fitness": 0.07808318682035596, "name": "AQIDE", "description": "Enhanced AQIDE by introducing a variable crossover probability adaptive to current best solution and iteration.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 1, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07808 with standard deviation 0.04319.", "error": "", "parent_ids": ["af72b8bf-3264-419f-baee-96c8b7590469"], "operator": null, "metadata": {"aucs": [0.05398863251744246, 0.04997720461117938, 0.05186273839488387, 0.1421280476040696, 0.1370876123954916, 0.13731657724389112, 0.04478853835640384, 0.03836458348635308, 0.04723474677348871]}}
{"id": "b91d5457-8852-4cef-8341-115416cd91c2", "fitness": 0.07940016151607568, "name": "AQIDE", "description": "Enhanced AQIDE by modifying the mutation factor based on iteration and best score.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modify F based on iteration and best score\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 2, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07940 with standard deviation 0.04244.", "error": "", "parent_ids": ["24c858fe-1b71-4155-ac89-9e1e89df391b"], "operator": null, "metadata": {"aucs": [0.05724491180773017, 0.050445865638457654, 0.05633627677047681, 0.14000351903996033, 0.13698815582099588, 0.14009805612115833, 0.043440557185556616, 0.047886792284028035, 0.04215731897631725]}}
{"id": "0eb585b7-2a14-42bb-95ca-c7204d458c3a", "fitness": 0.07793187687189157, "name": "EnhancedAQIDE", "description": "Enhance AQIDE by incorporating an adaptive population size and dynamic mutation strategies based on progress.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(len(self.population))\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(len(self.population)) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            current_population_size = max(1, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n            self.population = self.population[:current_population_size]\n\n            for i in range(len(self.population)):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07793 with standard deviation 0.04235.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.051175782853402074, 0.050834796032799945, 0.05633627677047681, 0.13343033382188052, 0.13893852106855664, 0.14009805612115833, 0.04515070160267165, 0.043095618279478276, 0.04232680529659982]}}
{"id": "5f904d3c-2b1f-47a2-be8b-e74a7194d30c", "fitness": 0.07681449846534866, "name": "AQIDE", "description": "Adjust the mutation strategy to enhance exploration by integrating a competitive selection mechanism.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modify F based on iteration and best score\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        # Competitive selection for mutation\n        d = np.random.choice(indices) \n        mutant = (self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n                  if np.random.rand() < 0.5 else self.population[d])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07681 with standard deviation 0.04179.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.055259833980576545, 0.053044110007654854, 0.051162308341675344, 0.13360186129837215, 0.13791767989915804, 0.13499617065312952, 0.04072771334495473, 0.04306535577686588, 0.0415554528857508]}}
{"id": "3045f817-c225-4ae2-85cc-eae0ab30add1", "fitness": -Infinity, "name": "EnhancedAQIDE", "description": "Enhanced AQIDE with stochastic rank-based mutation and adaptive population resizing.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def mutate(self, idx):\n        sorted_indices = np.argsort([func(ind) for ind in self.population])\n        indices = [i for i in range(self.population_size) if i != idx]\n        weights = np.linspace(0, 1, len(indices))\n        a, b, c = np.random.choice(indices, 3, replace=False, p=weights)\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def adaptive_population_resize(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n                \n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                self.adaptive_population_resize()\n\n        return self.best_solution", "configspace": "", "generation": 5, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {}}
{"id": "98a6b5ab-6737-4121-a85b-af8b28de372f", "fitness": -Infinity, "name": "AQIDE", "description": "Enhanced AQIDE with an adaptive crossover probability based on the relative improvement in the score.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modify F based on iteration and best score\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        # Adapt CR based on relative improvement in best score\n        adaptive_CR = self.CR * (1 - (self.best_score / (func(target) + 1e-9)))\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 6, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {}}
{"id": "d81254a7-ccb6-40da-b1a7-195267c021a6", "fitness": 0.07625503560880731, "name": "AQIDE", "description": "Enhancement of AQIDE by refining the adaptive mutation factor for improved performance.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Refined adaptive F based on iteration, best score, and a dynamic dampening factor\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9) * 0.5)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 7, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07626 with standard deviation 0.04450.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.05023460495127863, 0.04821799383134151, 0.049666988166709336, 0.1382043282321822, 0.13808893042921389, 0.14050027559641332, 0.038601769454104096, 0.0384702763601692, 0.04431015345785361]}}
{"id": "ca5291c9-4977-4f6d-aa2a-567455a7991c", "fitness": 0.07778140970313707, "name": "AQIDE", "description": "Enhanced AQIDE by tuning crossover probability and adding elitism to improve solution quality.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.85  # Adjusted crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modify F based on iteration and best score\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 8, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07778 with standard deviation 0.04110.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.04724397000001468, 0.057201720125187316, 0.05431271570230334, 0.1354498334513875, 0.13736833982685603, 0.1338952269582402, 0.0431269524388731, 0.04335583920800856, 0.04807808961736293]}}
{"id": "6b100c5f-dadd-4efe-a608-b668bceb539b", "fitness": 0.07257783005045931, "name": "AQIDE", "description": "Refined AQIDE by adjusting both mutation and crossover probabilities adaptively based on evaluations and best score.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration * self.best_score / self.budget)  # Modified line\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 9, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07258 with standard deviation 0.04674.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.044227980263376154, 0.04422206490144809, 0.04457914752732184, 0.1420932108298507, 0.13715824627144269, 0.1359943458649191, 0.03513930798408349, 0.03307175238242588, 0.03671441442926582]}}
{"id": "c542db9a-92a6-4629-8b6f-01c6cca8c41d", "fitness": -Infinity, "name": "AQIDE", "description": "Improved AQIDE by dynamically adjusting the population size based on convergence rate to optimize exploration-exploitation balance.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modify F based on iteration and best score\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            # Adjust population size based on convergence rate\n            if self.evaluations % (self.budget // 10) == 0:\n                self.population_size = max(1, int(self.population_size * (1 - (self.best_score / (self.best_score + 1e-9)))))\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 10, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {}}
{"id": "104456c5-33ac-41b7-897b-ba74c326f47f", "fitness": 0.07940016151607568, "name": "AQIDE", "description": "Adaptive quantum superposition is integrated with mutation strategy to enhance exploration.", "code": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Scaling population size with dimensionality\n        self.CR = 0.9  # Crossover probability\n        self.F = 0.5  # Mutation factor\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        # Integrate with mutation for enhanced exploration\n        return np.random.normal(mean, std, self.dim) + self.F * (self.best_solution - mean)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        # Modify F based on iteration and best score\n        adaptive_F = self.F * (1 - (self.best_score * self.evaluations) / (self.budget + 1e-9))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 11, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07940 with standard deviation 0.04244.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.05724491180773017, 0.050445865638457654, 0.05633627677047681, 0.14000351903996033, 0.13698815582099588, 0.14009805612115833, 0.043440557185556616, 0.047886792284028035, 0.04215731897631725]}}
{"id": "24da88a4-1413-4649-8487-c98eef2cc1e0", "fitness": 0.09776848134129074, "name": "EnhancedAQIDE", "description": "Adaptive Quantum-Inspired Differential Evolution with Dynamic Population Adjustment for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  # Dynamic population scaling based on dimension\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        # Adjust population size dynamically based on progress and budget usage\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09777 with standard deviation 0.04068.", "error": "", "parent_ids": ["b91d5457-8852-4cef-8341-115416cd91c2"], "operator": null, "metadata": {"aucs": [0.06880151351462205, 0.07191829539325623, 0.07248245314424395, 0.15162643696816092, 0.1581402172562616, 0.15572388097554646, 0.06413960759764203, 0.06769371190216045, 0.06939021531972289]}}
{"id": "1cfccd88-49a9-420b-aa7a-9eb084c8281a", "fitness": 0.09123275555183163, "name": "EnhancedAQIDE", "description": "EnhancedAQIDE with Improved Mutation Strategy and Adaptive Parameters for Better Convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F_base = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F_base + (0.5 * np.random.rand())\n        # Incorporate best_solution for enhanced guidance\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) + 0.1 * (self.best_solution - self.population[a])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09123 with standard deviation 0.03786.", "error": "", "parent_ids": ["24da88a4-1413-4649-8487-c98eef2cc1e0"], "operator": null, "metadata": {"aucs": [0.0761507273175559, 0.06527698894814604, 0.07374113801523019, 0.14320377412609875, 0.1453455991952971, 0.1434438713333095, 0.06028081677198949, 0.05460947325415877, 0.05904241100469898]}}
{"id": "09e71982-aaa2-483c-8d3d-f671646d842d", "fitness": 0.0897971446846523, "name": "EnhancedAQIDEv2", "description": "EnhancedAQIDEv2: Improved Adaptive Quantum-Inspired Differential Evolution with Continual Population Rejuvenation and Adaptive Mutation Strategies for Better Convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  \n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n        self.best_score = float('inf')\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        # Introduce a jitter factor to escape local optima\n        jitter = np.random.normal(0, 0.01, self.dim)\n        mutant += jitter\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - iteration / self.budget)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def rejuvenate_population(self):\n        # Rejuvenate the population periodically to maintain diversity\n        if self.evaluations % (self.budget // 10) == 0:\n            lb, ub = self.bounds.lb, self.bounds.ub\n            rejuvenated = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            self.population = np.vstack((self.population, rejuvenated))\n            self.population_size = len(self.population)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.rejuvenate_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedAQIDEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08980 with standard deviation 0.03925.", "error": "", "parent_ids": ["24da88a4-1413-4649-8487-c98eef2cc1e0"], "operator": null, "metadata": {"aucs": [0.06132776732378742, 0.0682356309917791, 0.06324966222270201, 0.14685295895076056, 0.14567566872006332, 0.14289611218475684, 0.062253110628779806, 0.061081184132421806, 0.05660220700681984]}}
{"id": "a0d14fbb-5968-484c-aefd-02c0ff520e99", "fitness": 0.09847144665571417, "name": "EnhancedAQIDE", "description": "EnhancedAQIDE with Adaptive Crossover Rate and Quantum Superposition Adjustment for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  # Dynamic population scaling based on dimension\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)  # Adjusted adaptive CR using sqrt\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        # Adjust population size dynamically based on progress and budget usage\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95  # Adjust quantum superposition\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09847 with standard deviation 0.03760.", "error": "", "parent_ids": ["24da88a4-1413-4649-8487-c98eef2cc1e0"], "operator": null, "metadata": {"aucs": [0.07351026494839197, 0.07860469027087058, 0.07214310601769147, 0.15225776442944194, 0.14764586465481122, 0.15444282622839256, 0.07010971231000329, 0.06790191373968402, 0.06962687730214046]}}
{"id": "37ad0272-321b-47e7-b5d8-4a8661158d33", "fitness": -Infinity, "name": "EnhancedAQIDE", "description": "EnhancedAQIDE with Dynamic Learning Rate and Stochastic Evaluation to Improve Convergence Robustness.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  # Dynamic population scaling based on dimension\n        self.CR = 0.9\n        self.F = 0.5\n        self.learning_rate = 0.1  # Added dynamic learning rate\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)  # Adjusted adaptive CR using sqrt\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        # Adjust population size dynamically based on progress and budget usage\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def stochastic_evaluation(self, candidate):  # New function for stochastic evaluation\n        noise = np.random.normal(0, 0.01, self.dim)\n        return func(candidate + noise)\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = self.stochastic_evaluation(trial)  # Use stochastic evaluation\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95  # Adjust quantum superposition\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 16, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {}}
{"id": "34d253ac-7298-4470-89d1-f7a42ca5e087", "fitness": 0.09386286959969141, "name": "AdvancedAQIDE", "description": "AdvancedAQIDE uses adaptive strategies for parameter tuning and depopulation to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AdvancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(15 * np.log(dim + 1)))  # Increased initial population scaling\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 17, "feedback": "The algorithm AdvancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09386 with standard deviation 0.03705.", "error": "", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {"aucs": [0.07190178656814539, 0.06748659079148167, 0.07308564873312717, 0.1426526975671738, 0.14596596841890286, 0.1495198803273916, 0.06414536340977506, 0.0639909109752741, 0.06601697960595099]}}
{"id": "8bb809be-debb-4ab3-8aa5-7ed139f3a7de", "fitness": 0.09449365046150351, "name": "EnhancedAQIDE", "description": "EnhancedAQIDE with Dynamic F Adjustment for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  # Dynamic population scaling based on dimension\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        if self.evaluations < self.budget * 0.5:  # New adjustment for F\n            adaptive_F = 0.9\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)  # Adjusted adaptive CR using sqrt\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        # Adjust population size dynamically based on progress and budget usage\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95  # Adjust quantum superposition\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09449 with standard deviation 0.03930.", "error": "", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {"aucs": [0.07106344400592801, 0.0673168847591814, 0.07041753929837868, 0.14678049849969976, 0.15515774921102932, 0.14760170951870066, 0.06251691234604029, 0.06227676289434236, 0.0673113536202311]}}
{"id": "540af31a-20a3-4241-9c5f-c168d42c671d", "fitness": 0.09706875603905143, "name": "EnhancedAQIDE", "description": "Improved Dynamic Population and Adaptive Mechanisms for Enhanced Convergence in High-Dimension Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  # Dynamic population scaling based on dimension\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)  # Adjusted adaptive CR using sqrt\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6  # Adjusted shrink factor\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n        elif self.evaluations < self.budget * 0.3:  # Early diversification\n            self.population_size = min(int(15 * np.log(self.dim + 1)), self.population_size + 1)\n            new_individual = np.random.uniform(self.bounds.lb, self.bounds.ub, self.dim)\n            self.population = np.vstack((self.population, new_individual))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95  # Adjust quantum superposition\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09707 with standard deviation 0.03789.", "error": "", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {"aucs": [0.07458893018866708, 0.07568978190030495, 0.06728848134363519, 0.15337594002090216, 0.15020174506707729, 0.14781703885753017, 0.06832569895436857, 0.0668495971173898, 0.06948159090158768]}}
{"id": "19800cda-6148-408c-9cca-794293d2f653", "fitness": 0.0699639959227713, "name": "ImprovedAQIDE", "description": "Improved Adaptive Quantum-Inspired Differential Evolution (IAQIDE) with Enhanced Population Dynamics and Gradient-Based Mutation for Superior Convergence.", "code": "import numpy as np\n\nclass ImprovedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.gradient_weight = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx, func):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c])\n\n        # Gradient-based mutation enhancement\n        gradient = self.estimate_gradient(func, self.population[a])\n        mutant += self.gradient_weight * gradient\n\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def estimate_gradient(self, func, solution):\n        epsilon = 1e-8\n        gradient = np.zeros(self.dim)\n        for j in range(self.dim):\n            perturbed = np.copy(solution)\n            perturbed[j] += epsilon\n            gradient[j] = (func(perturbed) - func(solution)) / epsilon\n        return gradient\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i, func)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 20, "feedback": "The algorithm ImprovedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06996 with standard deviation 0.03802.", "error": "", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {"aucs": [0.04382562564613046, 0.05406445125690773, 0.04413575071929621, 0.12125264629727694, 0.1273878272866148, 0.12115527219000422, 0.03601574694813525, 0.04421432392502478, 0.0376243190355513]}}
{"id": "51482853-71e9-4275-bcee-f36c514a1597", "fitness": 0.09595594443925856, "name": "AQDE", "description": "Adaptive Quantum Differential Evolution (AQDE) with Dynamic Population and Stochastic Mutation for Enhanced Exploration and Convergence.", "code": "import numpy as np\n\nclass AQDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F_base = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F_base * (1 - (self.evaluations / self.budget))\n        stochastic_component = np.random.normal(0, 0.1, self.dim)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) + stochastic_component\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 21, "feedback": "The algorithm AQDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09596 with standard deviation 0.04010.", "error": "", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {"aucs": [0.0717859255747223, 0.06658536591741837, 0.06794660865330515, 0.1561878474269457, 0.15391642852365917, 0.1472791192575188, 0.06744400442187026, 0.06175543416511309, 0.07070276601277425]}}
{"id": "d2ce188c-9721-4d27-a244-45d5198e1fee", "fitness": 0.10149445527396626, "name": "EnhancedAQIDE", "description": "EnhancedAQIDE with Dynamic Mutation Strategy and Improved Quantum Superposition for Efficient Exploration and Exploitation.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))  # Dynamic population scaling based on dimension\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.9, self.dim)  # Improved quantum superposition\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.3 else 0.8\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor  # Dynamic mutation strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)  # Adjusted adaptive CR using sqrt\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        # Adjust population size dynamically based on progress and budget usage\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.5\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.95  # Adjust quantum superposition\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10149 with standard deviation 0.04176.", "error": "", "parent_ids": ["a0d14fbb-5968-484c-aefd-02c0ff520e99"], "operator": null, "metadata": {"aucs": [0.07214520452547679, 0.0790868355245331, 0.0762248454012403, 0.16343177983210955, 0.1503487690147718, 0.1664062883882218, 0.06638080124299794, 0.06958900835847603, 0.06983656517786907]}}
{"id": "b7861377-0035-4a67-9d46-3cdd0649f684", "fitness": 0.09812909023055277, "name": "QuantumAdaptiveAQIDE", "description": "QuantumAdaptiveAQIDE with Adaptive Quantum-Inspired Mutation and Dynamic Crossover for Enhanced Black Box Optimization Performance.", "code": "import numpy as np\n\nclass QuantumAdaptiveAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.85, self.dim)\n\n    def adaptive_mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.1 if self.evaluations < self.budget * 0.4 else 0.7\n        quantum_influence = self.quantum_superposition() * 0.1\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor + quantum_influence\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def dynamic_crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.4)\n        j_rand = np.random.randint(self.dim)\n        trial = np.array([mutant[j] if np.random.rand() < adaptive_CR or j == j_rand else target[j] \n                          for j in range(self.dim)])\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.6:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.adaptive_mutate(i)\n                trial = self.dynamic_crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.92\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 23, "feedback": "The algorithm QuantumAdaptiveAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09813 with standard deviation 0.04277.", "error": "", "parent_ids": ["d2ce188c-9721-4d27-a244-45d5198e1fee"], "operator": null, "metadata": {"aucs": [0.0679701637005915, 0.07386243925496871, 0.06930564158318986, 0.15789215974782644, 0.1638314387998968, 0.15342875329183303, 0.06299389947151701, 0.06923496521143802, 0.06464235101371352]}}
{"id": "ebd4462d-688c-4934-95ca-d9e309f939ad", "fitness": 0.1449594956546013, "name": "EnhancedAQIDE", "description": "Adaptive Quantum-Inspired Differential Evolution with Stochastic Discrete Recombination for Enhanced Global Search.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 0.9\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14496 with standard deviation 0.09556.", "error": "", "parent_ids": ["d2ce188c-9721-4d27-a244-45d5198e1fee"], "operator": null, "metadata": {"aucs": [0.0761350523135923, 0.10566503033370345, 0.08582234251179555, 0.20286994790527824, 0.3386503007973536, 0.27325032118757786, 0.07124522357930985, 0.07453732564848436, 0.0764599166143165]}}
{"id": "f0dcd08b-28c2-43ca-a232-5c7718294411", "fitness": 0.18907274066501295, "name": "EnhancedAQIDE", "description": "Minor enhancement in quantum candidate's influence by adjusting the quantum superposition scaling factor.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18907 with standard deviation 0.14455.", "error": "", "parent_ids": ["ebd4462d-688c-4934-95ca-d9e309f939ad"], "operator": null, "metadata": {"aucs": [0.07963857018398557, 0.4990755495983342, 0.08592751047029235, 0.20286994790527824, 0.3386503007973536, 0.27325032118757786, 0.0712452235794917, 0.07453732564848659, 0.0764599166143165]}}
{"id": "6ecc3028-5271-4b51-8005-3bfee493cf98", "fitness": 0.14909456052412567, "name": "EnhancedAQIDE", "description": "Enhanced convergence by amplifying the influence of quantum candidates with a refined scaling factor.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.85, self.dim)  # Changed scaling factor from 0.8 to 0.85\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14909 with standard deviation 0.09314.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.1100320251989394, 0.10566503033370345, 0.08627354539400178, 0.20286994790527824, 0.3386503007973536, 0.27325032118757786, 0.0712452235794917, 0.07453732564848659, 0.07932732467229864]}}
{"id": "52810dad-8371-416a-ac4f-63c1e9c93888", "fitness": 0.12703464936691009, "name": "EnhancedAQIDE", "description": "Introduce dynamic quantum influence scaling and adaptive mutation factors to enhance global exploration and convergence in diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        influence_factor = 1.0 + 0.2 * np.sin(np.pi * self.evaluations / self.budget)\n        return np.random.normal(mean, std * influence_factor, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        phase = np.sin(2 * np.pi * self.evaluations / self.budget)\n        dynamic_factor = 1.2 if phase > 0 else 0.8\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * dynamic_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12703 with standard deviation 0.05424.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.0761350523135923, 0.10634448031098531, 0.08582234251179555, 0.17794109075239828, 0.23193987735363275, 0.18843672489770802, 0.08621262035925192, 0.11401973918851027, 0.0764599166143165]}}
{"id": "6bc93462-cb95-4fbb-a826-f670118bfe60", "fitness": 0.1482789878252266, "name": "ImprovedAQIDE", "description": "Incorporate adaptive quantum superposition scaling and diversity-enhancing restart mechanism to improve convergence.", "code": "import numpy as np\n\nclass ImprovedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def adaptive_quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        adaptive_factor = 0.5 + 0.5 * (1 - (self.evaluations / self.budget))\n        return np.random.normal(mean, std * adaptive_factor, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def restart_mechanism(self):\n        if self.evaluations > self.budget * 0.75 and np.std(self.population) < 1e-5:\n            self.initialize_population(self.bounds)\n            self.best_score = float('inf')\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.restart_mechanism()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.adaptive_quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 28, "feedback": "The algorithm ImprovedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14828 with standard deviation 0.09397.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.08027422254163574, 0.12477651223971387, 0.08622763133416067, 0.20286994790527824, 0.3386503007973536, 0.27325032118757786, 0.07579207089998008, 0.07453732564848659, 0.07813255787285278]}}
{"id": "42f5471b-f580-41fb-9b17-dc9d0cc4e607", "fitness": 0.14776154630384825, "name": "EnhancedAQIDE", "description": "Optimize quantum superposition with a dynamic scaling factor based on budget usage.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        dynamic_factor = 1 + 0.5 * (self.evaluations / self.budget)\n        return np.random.normal(mean, std * 0.8 * dynamic_factor, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14776 with standard deviation 0.09450.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.08012187879098631, 0.1268966596993477, 0.08582234251179555, 0.20286994790527824, 0.3386503007973536, 0.27325032118757786, 0.0712452235794917, 0.07453732564848659, 0.0764599166143165]}}
{"id": "11119d5d-3c4a-4a91-82c8-3e4a9e57e5ce", "fitness": 0.16645300185241318, "name": "EnhancedAQIDE", "description": "Introduced a slight adjustment to the mutation logic by updating the adjustment_factor to adapt dynamically with population diversity.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = np.linalg.norm(np.std(self.population, axis=0)) / np.sqrt(self.dim)\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7 * diversity_factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16645 with standard deviation 0.13100.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.07963761642709888, 0.4990755495983342, 0.08592751047027636, 0.2062542303415873, 0.20401816389019967, 0.20092148010211175, 0.07124522357930985, 0.07453732564848436, 0.0764599166143165]}}
{"id": "11e023fe-e9d9-4df4-a5e9-4eb13314bb88", "fitness": 0.15228264908126662, "name": "EnhancedAQIDE", "description": "Introduce an incremental enhancement in adaptive mutation factor to improve global search capability.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget))) * 1.05\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15228 with standard deviation 0.08737.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.07317814029598746, 0.08690194851081146, 0.2778522098768952, 0.2725210029513563, 0.20015611650327636, 0.23768906240999677, 0.0769014962970801, 0.07165586817240832, 0.0736879967135875]}}
{"id": "f254bbf8-6256-471c-89d0-d92fb5d22339", "fitness": 0.15053366284155326, "name": "EnhancedAQIDE", "description": "Enhance the quantum superposition by increasing the quantum superposition scaling factor.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 1.0, self.dim)  # Changed scaling factor from 0.8 to 1.0\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15053 with standard deviation 0.09199.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.0761350523135923, 0.10566503033370345, 0.08582234251179555, 0.20286994790527824, 0.3386503007973536, 0.27325032118757786, 0.08747760537538729, 0.10847244853497451, 0.0764599166143165]}}
{"id": "0cf8c520-34b8-4102-84fe-2785b45eab81", "fitness": 0.20865976930478258, "name": "EnhancedAQIDE", "description": "Enhance mutation diversity by adding small Gaussian noise to the mutant vector.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        noise = np.random.normal(0, 0.05, self.dim)  # Added Gaussian noise\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20866 with standard deviation 0.06206.", "error": "", "parent_ids": ["f0dcd08b-28c2-43ca-a232-5c7718294411"], "operator": null, "metadata": {"aucs": [0.27274391044799895, 0.10166468980262433, 0.22121552043783954, 0.1881625742073184, 0.22280968212242425, 0.17309022603979463, 0.14087264411111844, 0.24219139539984047, 0.31518728117408434]}}
{"id": "411a0ee6-171c-472e-b01b-6a40df3fa06d", "fitness": 0.23211169632617, "name": "EnhancedAQIDE", "description": "Introduce an adaptive noise scaling factor to noise added during mutation for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        adjustment_factor = 1.2 if self.evaluations < self.budget * 0.4 else 0.7\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * adjustment_factor\n        noise = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), self.dim)  # Adaptive noise scaling\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23211 with standard deviation 0.07614.", "error": "", "parent_ids": ["0cf8c520-34b8-4102-84fe-2785b45eab81"], "operator": null, "metadata": {"aucs": [0.23159430980138873, 0.3444641739447959, 0.28373500167590193, 0.16491639248643686, 0.2606253656297187, 0.17046750757627682, 0.3073020481032518, 0.0837859382683318, 0.24211452944942746]}}
{"id": "82e60ece-912b-44e9-ba99-9e00e47933f3", "fitness": 0.27182052471583684, "name": "EnhancedAQIDEv2", "description": "Introduce diversity control mechanisms with adaptive mutation and crossover rates to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAQIDEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAQIDEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27182 with standard deviation 0.10886.", "error": "", "parent_ids": ["411a0ee6-171c-472e-b01b-6a40df3fa06d"], "operator": null, "metadata": {"aucs": [0.222843902245347, 0.20391792276485854, 0.3827371639687257, 0.17227465228606043, 0.17028455601600878, 0.1552998733262998, 0.3990847009415839, 0.46503827151908395, 0.2749036793745635]}}
{"id": "d4e5f3a9-9626-4aae-8fd1-ba9072c77310", "fitness": 0.17745202736776522, "name": "EnhancedAQIDEv3", "description": "Integrate adaptive swarm intelligence with diversity-enriched quantum mechanisms to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        swarm_attraction = 0.5 * (self.best_solution - self.population[idx])\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor + swarm_attraction\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17745 with standard deviation 0.03931.", "error": "", "parent_ids": ["82e60ece-912b-44e9-ba99-9e00e47933f3"], "operator": null, "metadata": {"aucs": [0.2228137963118494, 0.15458494774867837, 0.21438631708195743, 0.18118730047569853, 0.20268488051849298, 0.18300166679638208, 0.11313397177434392, 0.11414574412037548, 0.21112962148210845]}}
{"id": "632ee0e3-7f3a-4223-bc6d-762b19ec53e5", "fitness": 0.3219283023246059, "name": "EnhancedAQIDEv3", "description": "Implement a dynamic feedback mechanism to adjust population diversity and enhance exploration-exploitation trade-off over time.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32193 with standard deviation 0.15454.", "error": "", "parent_ids": ["82e60ece-912b-44e9-ba99-9e00e47933f3"], "operator": null, "metadata": {"aucs": [0.38238432318296933, 0.3548647521656946, 0.4680125225002235, 0.1623614055805065, 0.1839728879950191, 0.1655156591190463, 0.26026418116632444, 0.6574335263624866, 0.2625454628491828]}}
{"id": "369ff7f6-ea0d-403e-9eac-645f84ba0574", "fitness": 0.23352876799907307, "name": "EnhancedAQIDEv3", "description": "Enhance mutation strategy by increasing the influence of the diversity factor.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 1.0 + (0.5 * (1 - self.evaluations / self.budget))  # Changed from 0.5 to 1.0\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23353 with standard deviation 0.05353.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.2826727567758964, 0.3033064772147832, 0.32463853954042854, 0.18107100081742766, 0.20039730284251467, 0.19352702760860752, 0.24089794340824033, 0.1720955794445177, 0.20315228433924115]}}
{"id": "fd0b0b8c-433f-4744-b31e-5d633796bdfa", "fitness": 0.20899773803758925, "name": "EnhancedAQIDEv3", "description": "Enhance adaptive mutation factor to improve exploration in the latter part of the budget.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget**0.5)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20900 with standard deviation 0.07971.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.28606726108181413, 0.16114614812672057, 0.3647454308779081, 0.16517175761856628, 0.17801682038280497, 0.15609196632615352, 0.08156638641066982, 0.25668255539650897, 0.2314913161171568]}}
{"id": "c5e85220-e7b9-4a80-8fd6-019602de9d5b", "fitness": 0.3219283023246059, "name": "EnhancedAQIDEv4", "description": "Introduce adaptive population resizing and enhanced mutation strategies to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(10 * np.log(dim + 1)))\n        self.population_size = self.initial_population_size\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        self.bounds = bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def adaptive_population_resizing(self):\n        if self.evaluations > self.budget * 0.5 and self.population_size > 5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n        elif self.evaluations < self.budget * 0.2:\n            grow_factor = 1.2\n            additional_size = min(int(self.population_size * (grow_factor - 1)), self.initial_population_size - self.population_size)\n            additional_population = np.random.uniform(self.bounds.lb, self.bounds.ub, (additional_size, self.dim))\n            self.population = np.vstack((self.population, additional_population))\n            self.population_size = self.population.shape[0]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1\n            elif improvement_rate > 0.01:\n                self.F *= 0.9\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        while self.evaluations < self.budget:\n            self.adaptive_population_resizing()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAQIDEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32193 with standard deviation 0.15454.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.38238432318296933, 0.3548647521656946, 0.4680125225002235, 0.1623614055805065, 0.1839728879950191, 0.1655156591190463, 0.26026418116632444, 0.6574335263624866, 0.2625454628491828]}}
{"id": "72d7b4da-ed23-450b-9c53-7c5444a8590e", "fitness": 0.3219283023246059, "name": "EnhancedAQIDEv4", "description": "Introduce adaptive scaling for the quantum superposition to enhance convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAQIDEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        dynamic_scale = 0.8 * (1 + 0.2 * (self.evaluations / self.budget))\n        return np.random.normal(mean, std * dynamic_scale, self.dim)  # Line Change\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAQIDEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32193 with standard deviation 0.15454.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.38238432318296933, 0.3548647521656946, 0.4680125225002235, 0.1623614055805065, 0.1839728879950191, 0.1655156591190463, 0.26026418116632444, 0.6574335263624866, 0.2625454628491828]}}
{"id": "362c29ff-3bd9-4ac7-aa5d-b7ee56bf824c", "fitness": 0.3204839079485873, "name": "EnhancedAQIDEv3", "description": "Refine mutation factor adjustment strategy for better diversity control.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.015:  # Change from 0.01 to 0.015\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32048 with standard deviation 0.15604.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.38238432318296933, 0.3548647521656946, 0.4680125225002235, 0.16096958252073323, 0.1839728879950191, 0.1539079327946521, 0.26026418116632444, 0.6574335263624866, 0.2625454628491828]}}
{"id": "6de52ea8-2a47-4483-8fb3-2129d1e0b71e", "fitness": 0.14612094553096477, "name": "EnhancedAQIDEv3", "description": "Slightly increase the adaptive_CR decay speed to refine exploitation in the crossover phase.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.7)  # Changed decay exponent from 0.5 to 0.7\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14612 with standard deviation 0.05645.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.09400289276490625, 0.2335461306802401, 0.08832182384099552, 0.17540011780588605, 0.16468801139636957, 0.15646733280443326, 0.22734324060363098, 0.09851761930366953, 0.07680134057855181]}}
{"id": "eeca3465-520c-4881-9932-2d60de06c318", "fitness": 0.2799304134251964, "name": "EnhancedAQIDEv3", "description": "Slightly adjust the noise factor in mutation to improve exploration near the budget limit.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.15 * (1 - self.evaluations / self.budget), self.dim)  # Adjusted noise\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27993 with standard deviation 0.06922.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.17055026674001006, 0.3361096245525257, 0.3658564702764986, 0.31734190167895593, 0.27114584828819566, 0.17108505580151856, 0.3035640459789365, 0.3486648120253223, 0.23505569548480487]}}
{"id": "b2aa5a16-a172-40e3-94bc-f55c892cd46b", "fitness": 0.2042203756523659, "name": "EnhancedAQIDEv4", "description": "Introduce adaptive learning rates and inertia in mutation and crossover operations to enhance search efficiency and robustness.", "code": "import numpy as np\n\nclass EnhancedAQIDEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.learning_rate = 0.1\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n    \n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n    \n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        inertia = np.random.rand()\n        mutation_effect = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        mutant = inertia * self.population[idx] + (1 - inertia) * mutation_effect\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n    \n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n    \n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n    \n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            self.learning_rate = min(0.2, max(0.01, abs(improvement_rate)))\n            if improvement_rate < 0.001:\n                self.F *= (1 + self.learning_rate)  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= (1 - self.learning_rate)  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n        \n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n        \n        return self.best_solution", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAQIDEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20422 with standard deviation 0.08868.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.2619580112582587, 0.27449075082251684, 0.2917365727003485, 0.16462779004815764, 0.15729988719915977, 0.16437528457734296, 0.08705750867231343, 0.35120667801811245, 0.08523089757508273]}}
{"id": "f6e5a3d5-eb03-43d2-9156-83da9f0a87a8", "fitness": 0.18069917155164233, "name": "EnhancedAQIDEv3", "description": "Slightly adjust the crossover rate to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.88  # Adjusted\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18070 with standard deviation 0.07091.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.14514505536450373, 0.1602511974660059, 0.15898980959827302, 0.19239140196174842, 0.3243700809602986, 0.17282896021013971, 0.10137455672336548, 0.27469249977280863, 0.09624898190763753]}}
{"id": "260e73d7-2f74-4308-b5e0-c6c33e9e3eed", "fitness": 0.19418391381161937, "name": "EnhancedAQIDEv3", "description": "Tweak the mutation noise to enhance convergence towards optimal solutions.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), self.dim)  # Adjust noise factor here\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.001:\n                self.F *= 1.1  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19418 with standard deviation 0.06435.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.17060591898587174, 0.32730383369367955, 0.08884270291031016, 0.193454545203552, 0.17182700571111087, 0.21999452933425456, 0.2399251495894945, 0.20814391371099483, 0.1275576251653059]}}
{"id": "d8f60f04-0982-4968-90fc-ce18e3185921", "fitness": 0.2427062092400627, "name": "EnhancedAQIDEv3", "description": "Enhance performance by increasing mutation factor F when improvement rate is very low.", "code": "import numpy as np\n\nclass EnhancedAQIDEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR = 0.9\n        self.F = 0.5\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[-1] - recent_performance[0]) / 5\n            if improvement_rate < 0.0005:  # Adjusted threshold\n                self.F *= 1.2  # Increase mutation factor to enhance diversity\n            elif improvement_rate > 0.01:\n                self.F *= 0.9  # Decrease mutation factor to refine exploitation\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAQIDEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24271 with standard deviation 0.07636.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.24052378908944072, 0.27665200782174426, 0.17828161242702156, 0.17475761083253882, 0.17807047262719689, 0.18502301315068193, 0.3726482755317825, 0.20600336719034507, 0.37239573448981245]}}
{"id": "ed52ddf9-967c-424f-89b9-07454df0a0e0", "fitness": 0.41754869774353953, "name": "EnhancedAQIDEv4", "description": "Introduce adaptive learning mechanisms for F and CR using a history-based reinforcement strategy to further enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAQIDEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)\n                self.CR = max(self.CR_min, self.CR * 0.9)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)\n                self.CR = min(self.CR_max, self.CR * 1.1)\n    \n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition() * 1.0\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAQIDEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41755 with standard deviation 0.14035.", "error": "", "parent_ids": ["632ee0e3-7f3a-4223-bc6d-762b19ec53e5"], "operator": null, "metadata": {"aucs": [0.3849698437308502, 0.45996204754502157, 0.568509660701554, 0.5145206764558743, 0.17325382018282254, 0.17751975568566702, 0.5115402297519422, 0.42331910841516407, 0.5443431372229603]}}
{"id": "2bacb16c-f4d5-429d-9c71-387d41a9c8a4", "fitness": 0.4246272769743959, "name": "RefinedAQIDEv5", "description": "Integrate adaptive differential learning and dynamic exploration control to balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass RefinedAQIDEv5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)\n                self.CR = max(self.CR_min, self.CR * 0.9)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)\n                self.CR = min(self.CR_max, self.CR * 1.1)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 50, "feedback": "The algorithm RefinedAQIDEv5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42463 with standard deviation 0.11939.", "error": "", "parent_ids": ["ed52ddf9-967c-424f-89b9-07454df0a0e0"], "operator": null, "metadata": {"aucs": [0.3849698437308502, 0.45996204754502157, 0.568509660701554, 0.5145206764558743, 0.2842163756902564, 0.17751975568566702, 0.4642848873222155, 0.42331910841516407, 0.5443431372229603]}}
{"id": "b2dbb885-b6b1-4e0c-b4de-0629fca06333", "fitness": -Infinity, "name": "RefinedAQIDEv6", "description": "Implement stochastic parameter tuning and adaptive quantum exploration for enhanced convergence efficiency and robustness.", "code": "import numpy as np\n\nclass RefinedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(12 * np.log(dim + 1)))  # Changed from 10 to 12 for more robust initial exploration\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.3, 0.9  # Slightly adjusted range for F\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.bounds = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        adaptive_factor = 1.2 - (self.evaluations / self.budget)  # Added adaptive factor for exploration\n        return np.random.normal(mean, std * adaptive_factor, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        perturbation = np.random.uniform(-0.2, 0.2, self.dim)  # Added random perturbation\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor + perturbation\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)  # Removed noise addition\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.65  # Adjusted shrink factor\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 51, "feedback": "An exception occurred: AttributeError(\"'RefinedAQIDEv6' object has no attribute 'adapt_learning_rate'\").", "error": "AttributeError(\"'RefinedAQIDEv6' object has no attribute 'adapt_learning_rate'\")", "parent_ids": ["2bacb16c-f4d5-429d-9c71-387d41a9c8a4"], "operator": null, "metadata": {}}
{"id": "b98924fa-be50-4073-b92e-f3282827132b", "fitness": 0.37567804697317975, "name": "RefinedAQIDEv6", "description": "Enhance adaptive parameters and mutation strategy to improve convergence speed and solution quality in challenging landscapes.", "code": "import numpy as np\n\nclass RefinedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n    \n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.2)  # Increased adjustment factor\n                self.CR = max(self.CR_min, self.CR * 0.85)  # Slightly reduced adjustment factor\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)  # Slightly reduced adjustment factor\n                self.CR = min(self.CR_max, self.CR * 1.2)  # Increased adjustment factor\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 52, "feedback": "The algorithm RefinedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37568 with standard deviation 0.08558.", "error": "", "parent_ids": ["2bacb16c-f4d5-429d-9c71-387d41a9c8a4"], "operator": null, "metadata": {"aucs": [0.41315377546813314, 0.4520667823403619, 0.4065816638562382, 0.3172187196745898, 0.26310471030720184, 0.4062457637322896, 0.5207238407237855, 0.36619658693542056, 0.23581057972059727]}}
{"id": "db8d98e0-7a5d-4957-892a-91de41f5d550", "fitness": 0.119778072027025, "name": "EnhancedChaosAQIDE", "description": "Enhance exploration with chaos theory and refine exploitation via adaptive learning, improving convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedChaosAQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def chaos_map(self, x):\n        # Logistic map to introduce chaotic behavior\n        r = 4.0\n        return r * x * (1 - x)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1 - (self.evaluations / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.3:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)\n                self.CR = max(self.CR_min, self.CR * 0.9)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)\n                self.CR = min(self.CR_max, self.CR * 1.1)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                chaotic_candidate = self.chaos_map(np.random.rand(self.dim) * (self.bounds.ub - self.bounds.lb) + self.bounds.lb)\n                chaotic_candidate_score = func(chaotic_candidate)\n                self.evaluations += 1\n\n                if chaotic_candidate_score < self.best_score:\n                    self.best_score = chaotic_candidate_score\n                    self.best_solution = chaotic_candidate\n\n        return self.best_solution", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedChaosAQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11978 with standard deviation 0.07994.", "error": "", "parent_ids": ["2bacb16c-f4d5-429d-9c71-387d41a9c8a4"], "operator": null, "metadata": {"aucs": [0.07632134831093018, 0.07440455950508873, 0.07608799223654694, 0.3205122560397726, 0.16136178647134614, 0.16256498553172138, 0.06485083809866887, 0.06823713916910024, 0.0736617428800499]}}
{"id": "87fd162a-db9e-46c8-94f9-fa058522e80b", "fitness": 0.3137586324259892, "name": "RefinedAQIDEv5", "description": "Enhance adaptive parameter control by incorporating success-based adaptation and dynamic diversity maintenance into differential evolution.", "code": "import numpy as np\n\nclass RefinedAQIDEv5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.3 * (1 - self.evaluations / self.budget))  # Modified line\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.3 else self.best_solution[j]  # Modified line\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7  # Modified line\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)\n                self.CR = max(self.CR_min, self.CR * 0.9)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)\n                self.CR = min(self.CR_max, self.CR * 1.1)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 54, "feedback": "The algorithm RefinedAQIDEv5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31376 with standard deviation 0.12719.", "error": "", "parent_ids": ["2bacb16c-f4d5-429d-9c71-387d41a9c8a4"], "operator": null, "metadata": {"aucs": [0.27794372067985207, 0.4756121930649677, 0.15419691010594316, 0.1658317316132819, 0.3323104079635708, 0.17672838249799183, 0.416272166078007, 0.5165268482266924, 0.30840533160359607]}}
{"id": "45efe905-9c6b-4a69-9050-062896e00ae8", "fitness": -Infinity, "name": "ImprovedQuantumDEv1", "description": "Implement adaptive quantum-inspired differential evolution with population entropy-based diversity control for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedQuantumDEv1:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.8\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.entropy_threshold = 0.5\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.best_score * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**0.5)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def calculate_population_entropy(self):\n        if not self.population.size:\n            return 0\n        probs = np.histogramdd(self.population, bins=min(self.population_size, 10))[0].flatten()\n        probs = probs / np.sum(probs)\n        return -np.sum(probs * np.log(probs + 1e-10))\n\n    def dynamic_population_adjustment(self):\n        entropy = self.calculate_population_entropy()\n        if entropy < self.entropy_threshold:\n            expand_factor = 1.2\n            self.population_size = min(int(self.population_size * expand_factor), self.budget - self.evaluations)\n            if self.population_size > len(self.population):\n                self.population = np.vstack([self.population, np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size - len(self.population), self.dim))])\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)\n                self.CR = max(self.CR_min, self.CR * 0.9)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)\n                self.CR = min(self.CR_max, self.CR * 1.1)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 55, "feedback": "An exception occurred: ValueError('invalid dims: array size defined by dims is larger than the maximum possible size.').", "error": "ValueError('invalid dims: array size defined by dims is larger than the maximum possible size.')", "parent_ids": ["2bacb16c-f4d5-429d-9c71-387d41a9c8a4"], "operator": null, "metadata": {}}
{"id": "ba2b546e-9760-401d-b1c3-b5ebcb507ac5", "fitness": 0.45885981418342997, "name": "EnhancedAQIDEv6", "description": "Enhance adaptive differential evolution with adaptive mutation scaling and adaptive crossover to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45886 with standard deviation 0.13306.", "error": "", "parent_ids": ["2bacb16c-f4d5-429d-9c71-387d41a9c8a4"], "operator": null, "metadata": {"aucs": [0.5525055423148243, 0.6171436065719434, 0.5385531753723682, 0.20547622707226243, 0.5060978409228956, 0.5752273143160813, 0.469577082103929, 0.27268435353257414, 0.3924731854439911]}}
{"id": "e4a8d27a-1065-46e6-b2d0-8404faaa51e4", "fitness": 0.43652816392450816, "name": "EnhancedAQIDEv6", "description": "Refine adaptive mechanisms in EnhancedAQIDEv6 by adjusting mutation scaling and crossover rates based on performance feedback.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.2)  # Line change: adjust scaling factor\n                self.CR = max(self.CR_min, self.CR * 0.8)  # Line change: adjust crossover rate\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43653 with standard deviation 0.11861.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.6139795014413607, 0.3745909588609616, 0.33286636068783804, 0.4970064382005507, 0.1784551383731322, 0.5097756073207679, 0.4697988326406469, 0.4577489110040803, 0.4945317267912356]}}
{"id": "71e94f3f-a0f4-4c94-a4e2-618eba396bb6", "fitness": 0.3237257509379499, "name": "EnhancedAQIDEv7", "description": "Incorporate quantum-inspired superposition with dynamic strategy adaptation to enhance exploration and exploitation balance for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.enhancement_factor = 0.02\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * (1 + self.enhancement_factor))\n                self.CR = max(self.CR_min, self.CR * (1 - self.enhancement_factor))\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * (1 - self.enhancement_factor))\n                self.CR = min(self.CR_max, self.CR * (1 + self.enhancement_factor))\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAQIDEv7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32373 with standard deviation 0.15805.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5940303524935278, 0.5044559744013897, 0.1701881464239524, 0.5088285817502122, 0.19465173766922061, 0.2970528301788913, 0.25279096026458636, 0.25104024438224737, 0.1404929308775218]}}
{"id": "3998cedb-a22e-4fec-9987-9617d43c4683", "fitness": 0.44355078895917016, "name": "EnhancedAQIDEv6", "description": "Further optimize the balance between exploration and exploitation by adjusting the adaptation parameters.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.25  # Adjusted from 0.3 to 0.25 for better convergence control\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.55 + (0.45 * (1 - self.evaluations / self.budget))  # Adjusted from 0.5 and 0.5 to 0.55 and 0.45\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44355 with standard deviation 0.10921.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5610653628694551, 0.4732178552470666, 0.3020957637094269, 0.31663604139681933, 0.5286850367962961, 0.3351461628985529, 0.35698223063950296, 0.599971473257502, 0.5181571738179094]}}
{"id": "e654cefd-4eef-4611-be67-d06600842a19", "fitness": 0.4519021958416877, "name": "EnhancedAQIDEv6", "description": "Refine adaptive differential evolution by optimizing feedback control sensitivity to enhance convergence performance.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.0005:  # Modified improvement threshold\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.02:  # Modified improvement threshold\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45190 with standard deviation 0.15528.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5525055423148243, 0.6171436065719434, 0.5385531753723682, 0.332059343521527, 0.5060978409228956, 0.5752273143160813, 0.469577082103929, 0.0834826720076296, 0.3924731854439911]}}
{"id": "28c3ffb1-d7f5-4c0e-9d32-ad718db1e17d", "fitness": 0.21025866797980575, "name": "RefinedAQIDEv7", "description": "Refined adaptive differential evolution with enhanced dynamic population control and stochastic decision-making for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.gamma = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.3:\n            shrink_factor = 0.8\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.2)\n                self.CR = max(self.CR_min, self.CR * 0.8)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.8)\n                self.CR = min(self.CR_max, self.CR * 1.2)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.1)\n            self.F = max(self.F_min, self.F - 0.1)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.1)\n            self.F = min(self.F_max, self.F + 0.1)\n\n    def stochastic_decision(self, trial, score, target_score):\n        if score < target_score:\n            return True\n        if np.random.rand() < np.exp(-(score - target_score) / (self.best_score - score + 1e-9)):\n            return True\n        return False\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if self.stochastic_decision(trial, score, func(self.population[i])):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 61, "feedback": "The algorithm RefinedAQIDEv7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21026 with standard deviation 0.17176.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.06817278810994831, 0.09074454574231405, 0.4217000073029411, 0.1614678780420119, 0.14500129834619535, 0.5803663395019925, 0.07673337537155911, 0.27956008748703, 0.06858169191425945]}}
{"id": "5e0c62f8-1609-4434-98a7-a12bc0df3299", "fitness": 0.38309652070328887, "name": "EnhancedAQIDEv6", "description": "Introduced a slight adjustment to mutation noise to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.15 * (1 - self.evaluations / self.budget), self.dim)  # Adjusted noise\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38310 with standard deviation 0.08628.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.4159760363731798, 0.44316940608299105, 0.37959062609659, 0.31458124687712974, 0.19616271661628448, 0.5061311564363878, 0.33570746746498425, 0.4526809955479769, 0.40386903483407577]}}
{"id": "91577ca2-9ef9-4a3e-9e60-7d8f7362451f", "fitness": 0.3734828020666122, "name": "EnhancedAQIDEv6", "description": "Minor adjustments in the mutation and learning rate adaptation strategies for improved solution quality and convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget * 0.9), self.dim)  # Adjusted\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.25:  # Adjusted\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.75:  # Adjusted\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37348 with standard deviation 0.14793.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.4350030384654141, 0.5869041697220796, 0.5192456782532333, 0.21715595805621968, 0.43793722263937795, 0.23085687248272524, 0.4717068101637363, 0.11436347089802179, 0.34817199791870235]}}
{"id": "dad7c2b9-0a7b-47c1-b5e0-da59b1d716de", "fitness": 0.45885981418342997, "name": "EnhancedAQIDEv6", "description": "Enhance mutation operation by adding a dynamic noise scaling factor for robust exploration.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise_scale = 0.1 * (1 - self.evaluations / self.budget)  # Dynamic noise scale added\n        noise = np.random.normal(0, noise_scale, self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45886 with standard deviation 0.13306.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5525055423148243, 0.6171436065719434, 0.5385531753723682, 0.20547622707226243, 0.5060978409228956, 0.5752273143160813, 0.469577082103929, 0.27268435353257414, 0.3924731854439911]}}
{"id": "3d171d45-134c-42e0-ab60-95ef379990bf", "fitness": 0.3891440341035578, "name": "EnhancedAQIDEv6", "description": "Refine adaptive mechanisms in EnhancedAQIDEv6 to improve convergence by slightly adjusting mutation scaling and crossover rates.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.95  # Adjusted crossover rate upper bound\n        self.F_min, self.F_max = 0.45, 0.9  # Adjusted mutation scaling factor lower bound\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38914 with standard deviation 0.18830.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.3687754744907339, 0.6548540661258386, 0.5125935014284241, 0.17236224938365374, 0.21868287925910523, 0.6364333871403531, 0.4567198415956365, 0.39447905519353754, 0.08739585231473745]}}
{"id": "70d9b818-8fca-441b-8aae-dc08bb3dc48b", "fitness": 0.45885981418342997, "name": "EnhancedQuantumAdaptiveDE", "description": "Integrate adaptive differential evolution with a quantum-behavior-inspired exploration strategy and dynamic parameters tuning for enhanced optimization in diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedQuantumAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedQuantumAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45886 with standard deviation 0.13306.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5525055423148243, 0.6171436065719434, 0.5385531753723682, 0.20547622707226243, 0.5060978409228956, 0.5752273143160813, 0.469577082103929, 0.27268435353257414, 0.3924731854439911]}}
{"id": "b79b2fe8-4c16-4439-93c0-b2b87546517f", "fitness": 0.32364022296620476, "name": "EnhancedAQIDEv6", "description": "Refined adaptive parameter adjustment and diversified mutation strategy to enhance convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.15 * (1 - self.evaluations / self.budget), self.dim)  # Adjusted noise level\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)  # Slightly reduced growth rate\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32364 with standard deviation 0.11832.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.23517293447426868, 0.41934959537098315, 0.5277029775695539, 0.3254338005918236, 0.2516743526297873, 0.31762004978157843, 0.08528856742992208, 0.37227316939929544, 0.3782465594486303]}}
{"id": "05c87ceb-8707-4e10-9033-cd27bd783cfd", "fitness": 0.4333125008819691, "name": "EnhancedAQIDEv6", "description": "Enhance adaptive differential evolution by refining mutation noise for improved exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), self.dim)  # Changed noise level\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43331 with standard deviation 0.07257.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5178166247365434, 0.34688196504148117, 0.402319969589759, 0.3828531890248924, 0.5176769772948904, 0.37692236397325896, 0.3784553656086507, 0.4181158095048012, 0.5587702431634451]}}
{"id": "b916ce8d-e91f-4f4c-ade8-ee149742686d", "fitness": 0.3544165327398959, "name": "EnhancedAQIDEv7", "description": "Integrate a novel diversity-preserving mechanism and adaptive search strategy to further enhance convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.diversity_threshold = 0.1  # New parameter for diversity measurement\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = self.calculate_diversity_factor()  # Replaced the fixed factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def calculate_diversity_factor(self):\n        diversity = np.std(self.population, axis=0).mean()\n        if diversity < self.diversity_threshold:\n            return 1.5  # Encourage exploration\n        return 0.5  # Encourage exploitation\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAQIDEv7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35442 with standard deviation 0.10968.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.3209198261919245, 0.448656310710312, 0.30425148372524313, 0.1999911654548756, 0.4892447322415304, 0.3128507255937488, 0.20751278112001137, 0.37929435212668694, 0.5270274174947305]}}
{"id": "2ac25dea-85fa-4670-894a-337326ec859e", "fitness": 0.437849080573139, "name": "EnhancedAQIDEv6", "description": "Enhance adaptive differential evolution by slightly tweaking the adaptive mutation scaling for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-1.05 * self.evaluations / self.budget)))  # Slight tweak here\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43785 with standard deviation 0.17195.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5068432450138767, 0.4081710786258915, 0.33171875032477316, 0.6067973049648203, 0.46025513580555844, 0.4985208281219081, 0.7266710861335797, 0.3025994079341935, 0.09906488823364945]}}
{"id": "93c753c5-293d-4b01-a74f-1872619db0ff", "fitness": 0.3260743138045443, "name": "EnhancedAQIDEv7", "description": "Improve adaptive differential evolution by introducing probabilistic selection, dynamic parameter scaling, and enhanced diversity maintenance to optimize convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutation_probability = np.random.rand()\n        if mutation_probability < 0.7:\n            mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        else:\n            mutant = self.best_solution + adaptive_F * (self.population[b] - self.population[c])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant):\n        adaptive_CR = self.CR * (1 - (self.evaluations / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAQIDEv7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32607 with standard deviation 0.14372.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.16285270725665446, 0.4365516101799105, 0.31984843943544705, 0.22030967571762194, 0.18668957298798694, 0.5294331791276832, 0.14311650534325415, 0.44224250275222676, 0.49362463144011404]}}
{"id": "be0b908e-4a3a-4554-8190-1f2c7feecaa4", "fitness": 0.2564189447545301, "name": "EnhancedAQIDEv7", "description": "Integrate a localized search phase with adaptive parameters into Enhanced AQIDE to improve exploitation and exploration balance for better convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def localized_search(self, candidate):\n        local_CR = np.random.uniform(0.1, 0.9)\n        local_F = np.random.uniform(0.4, 0.9)\n        lb, ub = self.bounds.lb, self.bounds.ub\n        local_solution = candidate + local_F * (np.random.uniform(lb, ub, self.dim) - candidate)\n        local_solution = np.clip(local_solution, lb, ub)\n        return local_solution\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n\n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                for i in range(self.population_size):\n                    local_candidate = self.localized_search(self.population[i])\n                    local_score = func(local_candidate)\n                    self.evaluations += 1\n\n                    if local_score < self.best_score:\n                        self.best_score = local_score\n                        self.best_solution = local_candidate\n\n        return self.best_solution", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAQIDEv7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25642 with standard deviation 0.11447.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.12446521825734003, 0.28633617341777673, 0.20808818631316683, 0.3777224334956223, 0.46316032224006176, 0.31413298616456586, 0.0819996395760606, 0.27188817796777265, 0.17997736535840436]}}
{"id": "fb35c27b-eb98-49d9-af87-1194ff510619", "fitness": -Infinity, "name": "EnhancedAQIDEv7", "description": "Introduce an adaptive elitism strategy with stochastic restarts to enhance exploration and convergence precision in adaptive differential evolution.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.elitism_rate = 0.1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def apply_elitism(self):\n        best_indices = np.argsort(self.performance_history)[:int(self.elitism_rate * self.population_size)]\n        self.population = self.population[best_indices]\n        self.performance_history = [self.performance_history[i] for i in best_indices]\n    \n    def stochastic_restart(self, bounds):\n        if np.random.rand() < 0.01:\n            self.initialize_population(bounds)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n            self.apply_elitism()\n            self.stochastic_restart(self.bounds)\n\n        return self.best_solution", "configspace": "", "generation": 73, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {}}
{"id": "b89bcad7-b9eb-473b-99dd-db1987f4f929", "fitness": 0.45885981418342997, "name": "EnhancedAQIDEv6", "description": "Refined adaptive differential evolution with smarter dynamic population adjustment to enhance performance with minimal changes.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):  # Modified line\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAQIDEv6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45886 with standard deviation 0.13306.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5525055423148243, 0.6171436065719434, 0.5385531753723682, 0.20547622707226243, 0.5060978409228956, 0.5752273143160813, 0.469577082103929, 0.27268435353257414, 0.3924731854439911]}}
{"id": "28dda387-7441-45b4-8946-4f37b2fd611e", "fitness": -Infinity, "name": "EnhancedAQIDEv7", "description": "Enhanced adaptive differential evolution with dynamic cooperation among sub-populations to balance exploration and exploitation for improved convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.sub_population_count = max(1, self.population_size // 5)\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def subpopulation_exchange(self):\n        indices = np.arange(self.population_size)\n        np.random.shuffle(indices)\n        sub_population_size = self.population_size // self.sub_population_count\n        sub_populations = [self.population[indices[i:i + sub_population_size]] for i in range(0, self.population_size, sub_population_size)]\n        \n        if len(sub_populations[-1]) < sub_population_size:\n            sub_populations[-2] = np.concatenate((sub_populations[-2], sub_populations.pop()))\n\n        best_sub_individuals = np.array([min(sub, key=lambda ind: func(ind)) for sub in sub_populations])\n        for sub in sub_populations:\n            sub[np.random.randint(len(sub))] = best_sub_individuals[np.random.randint(len(best_sub_individuals))]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n\n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n            self.subpopulation_exchange()\n\n        return self.best_solution", "configspace": "", "generation": 75, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {}}
{"id": "416a4d4d-0c37-49fa-9636-b0b802bbe0d3", "fitness": 0.45999961910282156, "name": "EnhancedAQIDEv6_Refined", "description": "Enhance adaptive differential evolution with time-varying parameters and an advanced mutation strategy to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46000 with standard deviation 0.12670.", "error": "", "parent_ids": ["ba2b546e-9760-401d-b1c3-b5ebcb507ac5"], "operator": null, "metadata": {"aucs": [0.5339113015218293, 0.36888364699073106, 0.648793457825069, 0.20181463902356955, 0.3501963775325765, 0.5378670354321718, 0.49834083517633665, 0.4471273459728685, 0.5530619324502418]}}
{"id": "ce73eb5b-e0fa-4448-9671-922213b7d9f6", "fitness": -Infinity, "name": "EnhancedAQIDEv6_Levy", "description": "Integrate levy flights and adaptive inertia weights into enhanced adaptive differential evolution to boost exploration and exploitation dynamics.", "code": "import numpy as np\nimport scipy.stats\n\nclass EnhancedAQIDEv6_Levy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def levy_flight(self, step_size=0.1):\n        beta = 1.5\n        sigma = (scipy.stats.gamma.rvs(1 + beta) * np.sin(np.pi * beta / 2) / (scipy.stats.gamma.rvs((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / beta)\n        return step_size * step\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        levy_step = self.levy_flight()\n        return np.clip(mutant + noise + levy_step, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def adaptive_inertia_weights(self):\n        inertia_weight = 0.9 - 0.5 * (self.evaluations / self.budget)\n        self.F = self.F * inertia_weight\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n\n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                self.adaptive_inertia_weights()\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 77, "feedback": "An exception occurred: AttributeError(\"'EnhancedAQIDEv6_Levy' object has no attribute 'quantum_superposition'\").", "error": "AttributeError(\"'EnhancedAQIDEv6_Levy' object has no attribute 'quantum_superposition'\")", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {}}
{"id": "0c8e4c8c-b662-4c23-a6ce-e44e94c9b912", "fitness": 0.44504684427286584, "name": "EnhancedAQIDEv7_Improved", "description": "Introduce a dynamic learning rate modulation and adaptive quantum exploration to balance exploration-exploitation and enhance solution convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.gamma = 0.1  # New parameter for dynamic exploration\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        quantum_factor = 0.8 + 0.2 * np.sin(self.evaluations / self.budget * np.pi)  # New dynamic factor\n        return np.random.normal(mean, std * quantum_factor, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAQIDEv7_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44505 with standard deviation 0.12455.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.5339113015218293, 0.36888364699073106, 0.648793457825069, 0.20181463902356955, 0.3501963775325765, 0.4032920619625704, 0.49834083517633665, 0.4471273459728685, 0.5530619324502418]}}
{"id": "738f4a3f-7645-40d3-9085-5745e9129f57", "fitness": 0.33444408040975626, "name": "EnhancedAQIDEv6_Refined", "description": "Introduce adaptive mutation scaling and probabilistic selection for improved exploration.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.6 else self.best_solution[j] # Adjusted line\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    if np.random.rand() < 0.7: # Adjusted line\n                        self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n                self.F *= 0.95 # Adjusted line\n\n        return self.best_solution", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33444 with standard deviation 0.19245.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.2575741632906404, 0.24387071744139988, 0.46783393345379154, 0.17046922015929167, 0.6309089765242853, 0.45741958289918583, 0.5820294653029514, 0.08916829325265696, 0.11072237136360308]}}
{"id": "c4afbba4-53c1-49d3-89ee-53f1d87b4184", "fitness": 0.44298188866951316, "name": "EnhancedAQIDEv6_Refined", "description": "Slightly adjust the noise factor in the mutation process to enhance solution diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.15 * (1 - self.evaluations / self.budget), self.dim)  # Adjusted noise factor\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44298 with standard deviation 0.12772.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.4311490037795337, 0.5653572881573422, 0.5693359646250538, 0.3534802395549894, 0.43475481559277207, 0.18518530437556657, 0.3902347017632275, 0.41977497337514114, 0.6375647068019918]}}
{"id": "45e9b43c-ef4d-464f-a801-76282dc3e024", "fitness": 0.3379102848666229, "name": "EnhancedAQIDEv6_Refined", "description": "Refine crossover strategy by introducing a bias towards the current best solution.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = self.best_solution[j] if np.random.rand() > 0.3 else target[j]  # Minor change: bias towards best_solution\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33791 with standard deviation 0.21067.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.6531673654305641, 0.1002008224361437, 0.5238434495938177, 0.198768106780026, 0.26401796436716185, 0.1959930774921771, 0.6393287249253059, 0.07307737387665447, 0.3927956788977549]}}
{"id": "66c90f50-c47e-4f9a-97e4-55809409ebbb", "fitness": 0.3738042383258962, "name": "EnhancedAQIDEv7_Optimized", "description": "Introduce a learning-based parameter adaptation strategy and enhanced diversity control to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7_Optimized:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.success_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def learning_based_adaptation(self):\n        if len(self.success_history) > 10:\n            recent_success = np.mean(self.success_history[-10:])\n            if recent_success > 0.6:  # High success rate\n                self.CR = max(self.CR_min, self.CR - 0.02)\n                self.F = min(self.F_max, self.F + 0.02)\n            elif recent_success < 0.4:  # Low success rate\n                self.CR = min(self.CR_max, self.CR + 0.02)\n                self.F = max(self.F_min, self.F - 0.02)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            self.learning_based_adaptation()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n                    self.success_history.append(1)\n                else:\n                    self.success_history.append(0)\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAQIDEv7_Optimized got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37380 with standard deviation 0.18267.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.11510339176331186, 0.2518515723900372, 0.6386010334087502, 0.37244842815342316, 0.3582097342957331, 0.3243979113761688, 0.6535857009910684, 0.1479736517329845, 0.5020667208215885]}}
{"id": "b70607d1-6945-4514-a545-73d211752ce4", "fitness": 0.09410465685198022, "name": "EnhancedAQIDEv7_Optimized", "description": "Integrate a hierarchical adaptive learning rate mechanism and synergy-based crossover strategy to enhance global search and convergence efficiency in differential evolution.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7_Optimized:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        synergy_factor = 0.2 + 0.6 * (1 - self.evaluations / self.budget)\n        trial = np.where(\n            np.random.rand(self.dim) < adaptive_CR,\n            mutant * synergy_factor + self.best_solution * (1 - synergy_factor),\n            target * (1 if np.random.rand() < 0.5 else 0) + self.best_solution * 0.5\n        )\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        adjustment_factor = (1 - self.evaluations / self.budget)\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05 * adjustment_factor)\n            self.F = max(self.F_min, self.F - 0.05 * adjustment_factor)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05 * adjustment_factor)\n            self.F = min(self.F_max, self.F + 0.05 * adjustment_factor)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAQIDEv7_Optimized got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09410 with standard deviation 0.03479.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.06633458558838878, 0.06175350938352986, 0.07875493406264522, 0.15478368298061185, 0.13092708889046412, 0.1405749708209867, 0.07013045575385135, 0.06567737619595115, 0.07800530799139294]}}
{"id": "acf2429d-2bb6-4274-9566-692275b64e4b", "fitness": 0.524351169628185, "name": "EnhancedAQIDEv6_Refined", "description": "Introduce a decay factor to the mutation strategy for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))  # Introduced decay factor\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52435 with standard deviation 0.09355.", "error": "", "parent_ids": ["416a4d4d-0c37-49fa-9636-b0b802bbe0d3"], "operator": null, "metadata": {"aucs": [0.6585883366789538, 0.4975169716999599, 0.48796869401992204, 0.6134712592097652, 0.36995562386732295, 0.39167763709311376, 0.602932540631931, 0.5171499993655999, 0.5798994640870959]}}
{"id": "cf226136-a15a-4a62-9b15-7e53ce880adc", "fitness": 0.4744944000387022, "name": "EnhancedAQIDEv7_PhasedAdaptive", "description": "Introduce a phased adaptive learning strategy to dynamically adjust control parameters based on recent performance trends.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7_PhasedAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.phase = 1\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def phased_adaptive_control(self):\n        if len(self.performance_history) >= 10:\n            recent_trend = np.array(self.performance_history[-10:])\n            improvement_trend = np.diff(recent_trend)\n            if np.all(improvement_trend > 0):\n                self.phase = 1\n            elif np.all(improvement_trend < 0):\n                self.phase = 3\n            else:\n                self.phase = 2\n        \n        if self.phase == 1:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n        elif self.phase == 3:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            self.phased_adaptive_control()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAQIDEv7_PhasedAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47449 with standard deviation 0.14454.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.6595147270363517, 0.35203223984647614, 0.6121225684390144, 0.3319090287134733, 0.6399113486680207, 0.47137132984851227, 0.3144520496957831, 0.2949759891155106, 0.5941603189851777]}}
{"id": "bb1f6ca9-20d9-427e-a272-3ff857cb4595", "fitness": 0.3912970866373221, "name": "EnhancedAQIDEv6_Refined", "description": "Refine the mutation strategy by adjusting the decay factor's impact for enhanced diversity control.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget / 2))) * (1 - 0.1 * (self.evaluations / self.budget))  # Modified decay factor\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39130 with standard deviation 0.09454.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.48537852710260254, 0.45229163322071075, 0.4028106392587608, 0.17738207310133014, 0.3344151901164194, 0.39066120989252173, 0.4924655557924452, 0.45834957973328705, 0.3279193715178209]}}
{"id": "f3036d8d-94a9-4dca-8e68-07938d8d4b40", "fitness": 0.41594751331352686, "name": "EnhancedAQIDEv7_Memory", "description": "Integrate adaptive memory of historical performance to dynamically adjust mutation and crossover rates for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7_Memory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)\n                self.CR = max(self.CR_min, self.CR * 0.9)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)\n                self.CR = min(self.CR_max, self.CR * 1.1)\n\n    def adapt_learning_rate(self, success_rate):\n        if success_rate < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_rate > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n\n            if self.evaluations > 5:\n                success_counter = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]])\n                success_rate = success_counter / 5.0\n                self.adapt_learning_rate(success_rate)\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAQIDEv7_Memory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41595 with standard deviation 0.12595.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.5037140760046279, 0.16962974559108102, 0.5702712914358002, 0.4721476574826494, 0.4912075079369108, 0.40867761354346543, 0.23250569245226405, 0.39274546526155585, 0.5026285701133872]}}
{"id": "3cd6a2f2-52a7-46b6-8237-2b36ac1b8940", "fitness": 0.4437923693104572, "name": "EnhancedAQIDEv6_Refined", "description": "Improve population diversity by introducing a randomness factor in mutation and dynamic strategy adaptation.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        randomness_factor = np.random.uniform(0.9, 1.1)  # new randomness factor\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor * randomness_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44379 with standard deviation 0.17144.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.6598458553300892, 0.5664410554106393, 0.2803179844413437, 0.6042922624899207, 0.40922325663703674, 0.47614752644157676, 0.582070658911773, 0.30188993695517374, 0.11390278717656088]}}
{"id": "a247209a-1e9c-4828-9223-5fc9ec8e2762", "fitness": 0.45634028899556156, "name": "EnhancedAQIDEv6_Refined", "description": "Incorporate dynamic parameters adjustment based on convergence speed to enhance adaptive capabilities.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.2, 0.9  # Modified\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.6  # Modified\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)  # Modified\n                self.CR = max(self.CR_min, self.CR * 0.8)  # Modified\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.8)  # Modified\n                self.CR = min(self.CR_max, self.CR * 1.1)  # Modified\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAQIDEv6_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45634 with standard deviation 0.14087.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.5659531779302602, 0.4447046041740572, 0.4560843382830133, 0.6617555674058119, 0.41592941793771465, 0.2940640225486538, 0.17406603356976358, 0.5413482201060227, 0.5531572190047565]}}
{"id": "a0ed397f-e241-4052-9f00-7ec2d63cbe2f", "fitness": 0.524351169628185, "name": "EnhancedAQIDEv7", "description": "Optimize adaptive parameters by introducing dynamic success-based CR and F adjustment with noise variance control for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx, cr_decay=0.05, f_decay=0.05):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAQIDEv7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52435 with standard deviation 0.09355.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.6585883366789538, 0.4975169716999599, 0.48796869401992204, 0.6134712592097652, 0.36995562386732295, 0.39167763709311376, 0.602932540631931, 0.5171499993655999, 0.5798994640870959]}}
{"id": "ad7df64a-6033-4f99-9f07-62db994d6056", "fitness": 0.37078911260880804, "name": "EnhancedAQIDEv6_Refined_Improved", "description": "Incorporate an adaptive mutation scaling factor and enhance dynamic population adjustment for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_Refined_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.4:  # Changed from 0.5\n            shrink_factor = 0.6  # Changed from 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.1)  # Changed from 1.15\n                self.CR = max(self.CR_min, self.CR * 0.9)  # Changed from 0.85\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.9)  # Changed from 0.85\n                self.CR = min(self.CR_max, self.CR * 1.1)  # Changed from 1.15\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAQIDEv6_Refined_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37079 with standard deviation 0.11266.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.46296050379317955, 0.36454326255894653, 0.4852257807604283, 0.34245787178209286, 0.39077640963006843, 0.3448191045141191, 0.09994973084764025, 0.34612734863693173, 0.5002420009558652]}}
{"id": "fe2d6bc2-1791-40fe-9a63-a94f284f10db", "fitness": 0.35337136281238174, "name": "EnhancedAQIDEv7_DynamicOscillation", "description": "Introduce dynamic oscillation in control parameters for adaptive balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAQIDEv7_DynamicOscillation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * 0.8, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        oscillation = 0.5 * (1 + np.sin((2 * np.pi * self.evaluations) / self.budget))\n        adaptive_F = self.F * oscillation * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        oscillation = 0.5 * (1 + np.sin((2 * np.pi * iteration) / self.budget))\n        adaptive_CR = self.CR * oscillation * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum(1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n        return self.best_solution", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAQIDEv7_DynamicOscillation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35337 with standard deviation 0.19995.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.6818444743239147, 0.615633117623455, 0.2917486659733164, 0.3418020688613168, 0.21909801915333316, 0.4683752313753422, 0.0970487983414825, 0.3951375239139363, 0.06965436574533901]}}
{"id": "5050292c-6438-4e4d-bfd0-3e15cbe99e85", "fitness": 0.5367179235742566, "name": "EnhancedAQIDEv6_AdaptiveQuantum", "description": "Introduce adaptive quantum-inspired learning to enhance diversity and convergence in optimization.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_AdaptiveQuantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * (1 - self.quantum_influence), self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 0.99)\n\n        return self.best_solution", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAQIDEv6_AdaptiveQuantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.53672 with standard deviation 0.09526.", "error": "", "parent_ids": ["acf2429d-2bb6-4274-9566-692275b64e4b"], "operator": null, "metadata": {"aucs": [0.6585883366789538, 0.4975169716999599, 0.5992694795345668, 0.6134712592097652, 0.36995562386732295, 0.39167763709311376, 0.602932540631931, 0.5171499993655999, 0.5798994640870959]}}
{"id": "8c9fe875-83eb-4a12-b261-fdba5b8aaf41", "fitness": 0.5287981537828004, "name": "EnhancedAQIDEv6_AdaptiveQuantum", "description": "Enhance quantum-inspired learning by refining mutation and feedback control strategies for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_AdaptiveQuantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * (1 - self.quantum_influence), self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.2 * (self.evaluations / self.budget))  # Changed from 0.1 to 0.2\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.2 * (1 - self.evaluations / self.budget), self.dim)  # Changed from 0.1 to 0.2\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.8  # Changed from 0.7 to 0.8\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.002:  # Changed from 0.001 to 0.002\n                self.F = min(self.F_max, self.F * 1.2)  # Changed from 1.15 to 1.2\n                self.CR = max(self.CR_min, self.CR * 0.8)  # Changed from 0.85 to 0.8\n            elif improvement_rate > 0.02:  # Changed from 0.01 to 0.02\n                self.F = max(self.F_min, self.F * 0.8)  # Changed from 0.85 to 0.8\n                self.CR = min(self.CR_max, self.CR * 1.2)  # Changed from 1.15 to 1.2\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 0.99)\n\n        return self.best_solution", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAQIDEv6_AdaptiveQuantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52880 with standard deviation 0.09501.", "error": "", "parent_ids": ["5050292c-6438-4e4d-bfd0-3e15cbe99e85"], "operator": null, "metadata": {"aucs": [0.5218105576646889, 0.5431382977047468, 0.61455123386844, 0.4330810760473307, 0.6220389182480377, 0.45357563120957645, 0.508027061269213, 0.6890692778018623, 0.3738913302313077]}}
{"id": "afd04551-c318-46fd-a0ff-079dc5c25862", "fitness": 0.524351169628185, "name": "EnhancedAQIDv7_QuantumAdaptive", "description": "Enhance convergence through dynamic learning rates and quantum-inspired solutions with adaptive influence.", "code": "import numpy as np\n\nclass EnhancedAQIDv7_QuantumAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * self.quantum_influence, self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        if len(self.performance_history) >= 5:\n            success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n            if success_ratio < 0.2:\n                self.CR = min(self.CR_max, self.CR + 0.05)\n                self.F = max(self.F_min, self.F - 0.05)\n            elif success_ratio > 0.8:\n                self.CR = max(self.CR_min, self.CR - 0.05)\n                self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 1.01)\n\n        return self.best_solution", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAQIDv7_QuantumAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52435 with standard deviation 0.09355.", "error": "", "parent_ids": ["5050292c-6438-4e4d-bfd0-3e15cbe99e85"], "operator": null, "metadata": {"aucs": [0.6585883366789538, 0.4975169716999599, 0.48796869401992204, 0.6134712592097652, 0.36995562386732295, 0.39167763709311376, 0.602932540631931, 0.5171499993655999, 0.5798994640870959]}}
{"id": "e19c7ee6-b131-4968-a1dd-3d5d9f2429d3", "fitness": -Infinity, "name": "EnhancedAQIDEv7_TimeVaryingClustering", "description": "Enhance adaptive quantum-inspired optimization by integrating time-varying clustering to maintain diversity and focus globally.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedAQIDEv7_TimeVaryingClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * (1 - self.quantum_influence), self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def integrate_clustering(self):\n        if self.evaluations % 10 == 0 and self.evaluations > 0:\n            n_clusters = max(2, self.population_size // 5)\n            kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(self.population)\n            cluster_centers = kmeans.cluster_centers_\n\n            for i, center in enumerate(cluster_centers):\n                noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n                perturbed_center = np.clip(center + noise, self.bounds.lb, self.bounds.ub)\n                score = func(perturbed_center)\n                self.evaluations += 1\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = perturbed_center\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                self.integrate_clustering()\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 0.99)\n\n        return self.best_solution", "configspace": "", "generation": 96, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["5050292c-6438-4e4d-bfd0-3e15cbe99e85"], "operator": null, "metadata": {}}
{"id": "c4918062-88b3-4f58-8575-a3af3478b381", "fitness": 0.47783760299533007, "name": "EnhancedAQIDEv6_AdaptiveQuantum", "description": "Slightly increase mutation noise to enhance exploration in the search space.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_AdaptiveQuantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * (1 - self.quantum_influence), self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.15 * (1 - self.evaluations / self.budget), self.dim)  # Changed noise from 0.1 to 0.15\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 0.99)\n\n        return self.best_solution", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAQIDEv6_AdaptiveQuantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47784 with standard deviation 0.20166.", "error": "", "parent_ids": ["5050292c-6438-4e4d-bfd0-3e15cbe99e85"], "operator": null, "metadata": {"aucs": [0.3804731306435162, 0.5122808323296232, 0.5755231922102207, 0.7944154913898733, 0.2642308636856311, 0.5602832485677401, 0.44548726419079676, 0.08857495314935049, 0.6792694507912185]}}
{"id": "b9d0e83d-d450-4575-8e35-74b3efc3c7ab", "fitness": 0.524351169628185, "name": "EnhancedAQIDEv6_AdaptiveQuantum", "description": "Fine-tune quantum influence reduction for adaptive convergence in optimization.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_AdaptiveQuantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * (1 - self.quantum_influence), self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget))) * (1 - 0.1 * (self.evaluations / self.budget))\n        diversity_factor = 0.5 + (0.5 * (1 - self.evaluations / self.budget))\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget)**self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * 1.15)\n                self.CR = max(self.CR_min, self.CR * 0.85)\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * 0.85)\n                self.CR = min(self.CR_max, self.CR * 1.15)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 0.995)  # Adjusted here\n\n        return self.best_solution", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAQIDEv6_AdaptiveQuantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52435 with standard deviation 0.09355.", "error": "", "parent_ids": ["5050292c-6438-4e4d-bfd0-3e15cbe99e85"], "operator": null, "metadata": {"aucs": [0.6585883366789538, 0.4975169716999599, 0.48796869401992204, 0.6134712592097652, 0.36995562386732295, 0.39167763709311376, 0.602932540631931, 0.5171499993655999, 0.5798994640870959]}}
{"id": "ad79db60-e656-4396-99d7-288eb01be3f9", "fitness": 0.48147818099374323, "name": "EnhancedAQIDEv6_AdaptiveQuantum", "description": "Enhance dynamic feedback control and quantum influence adjustment to improve convergence and diversity in optimization.", "code": "import numpy as np\n\nclass EnhancedAQIDEv6_AdaptiveQuantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(10 * np.log(dim + 1)))\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR = self.CR_max\n        self.F = self.F_max\n        self.alpha = 0.5\n        self.beta = 0.3\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.performance_history = []\n        self.quantum_influence = 0.2\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.best_solution = self.population[0]\n\n    def quantum_superposition(self):\n        mean = np.mean(self.population, axis=0)\n        std = np.std(self.population, axis=0) / np.sqrt(self.population_size)\n        return np.random.normal(mean, std * (1 - self.quantum_influence), self.dim)\n\n    def mutate(self, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_F = self.F * (1 - (self.alpha * np.exp(-self.evaluations / self.budget)))\n        diversity_factor = 0.5 + 0.5 * (1 - self.evaluations / self.budget)\n        mutant = self.population[a] + adaptive_F * (self.population[b] - self.population[c]) * diversity_factor\n        d = np.random.choice(indices)\n        mutant += adaptive_F * (self.best_solution - self.population[d])\n        noise = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), self.dim)\n        return np.clip(mutant + noise, self.bounds.lb, self.bounds.ub)\n\n    def crossover(self, target, mutant, iteration):\n        adaptive_CR = self.CR * (1 - (iteration / self.budget) ** self.beta)\n        j_rand = np.random.randint(self.dim)\n        trial = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < adaptive_CR or j == j_rand:\n                trial[j] = mutant[j]\n            else:\n                trial[j] = target[j] if np.random.rand() > 0.5 else self.best_solution[j]\n        return trial\n\n    def dynamic_population_adjustment(self):\n        if self.evaluations > self.budget * 0.5:\n            shrink_factor = 0.7\n            self.population_size = max(5, int(self.population_size * shrink_factor))\n            self.population = self.population[:self.population_size]\n\n    def dynamic_feedback_control(self):\n        if len(self.performance_history) >= 5:\n            recent_performance = np.array(self.performance_history[-5:])\n            improvement_rate = (recent_performance[0] - recent_performance[-1]) / 5\n            dynamic_adjustment_factor = 1.05 if improvement_rate < 0.001 else 0.95\n            if improvement_rate < 0.001:\n                self.F = min(self.F_max, self.F * dynamic_adjustment_factor)\n                self.CR = max(self.CR_min, self.CR * (2 - dynamic_adjustment_factor))\n            elif improvement_rate > 0.01:\n                self.F = max(self.F_min, self.F * (2 - dynamic_adjustment_factor))\n                self.CR = min(self.CR_max, self.CR * dynamic_adjustment_factor)\n\n    def adapt_learning_rate(self):\n        success_ratio = sum([1 for i in range(-5, 0) if self.performance_history[i] < self.performance_history[i-1]]) / 5.0\n        if success_ratio < 0.2:\n            self.CR = min(self.CR_max, self.CR + 0.05)\n            self.F = max(self.F_min, self.F - 0.05)\n        elif success_ratio > 0.8:\n            self.CR = max(self.CR_min, self.CR - 0.05)\n            self.F = min(self.F_max, self.F + 0.05)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.initialize_population(self.bounds)\n\n        while self.evaluations < self.budget:\n            self.dynamic_population_adjustment()\n            self.dynamic_feedback_control()\n            \n            if self.evaluations > 5:\n                self.adapt_learning_rate()\n\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant, self.evaluations)\n\n                if self.evaluations >= self.budget:\n                    break\n\n                score = func(trial)\n                self.evaluations += 1\n                self.performance_history.append(score)\n\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = trial\n\n                if score < func(self.population[i]):\n                    self.population[i] = trial\n\n            if self.evaluations < self.budget:\n                quantum_candidate = self.quantum_superposition()\n                q_score = func(quantum_candidate)\n                self.evaluations += 1\n\n                if q_score < self.best_score:\n                    self.best_score = q_score\n                    self.best_solution = quantum_candidate\n\n                self.quantum_influence = max(0.05, self.quantum_influence * 0.98)\n\n        return self.best_solution", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAQIDEv6_AdaptiveQuantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48148 with standard deviation 0.11607.", "error": "", "parent_ids": ["5050292c-6438-4e4d-bfd0-3e15cbe99e85"], "operator": null, "metadata": {"aucs": [0.5685122188690428, 0.5317567618337902, 0.5992482228282167, 0.3770038385326273, 0.2914406521603651, 0.46909916349897407, 0.43216959284899703, 0.3861613720325262, 0.6779118063391496]}}
