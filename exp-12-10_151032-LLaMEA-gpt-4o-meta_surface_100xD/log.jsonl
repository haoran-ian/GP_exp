{"id": "cd91f486-70df-4f41-affe-411c7cc3f089", "fitness": 0.42319004803914523, "name": "HybridPSODE", "description": "A hybrid metaheuristic that combines Particle Swarm Optimization (PSO) with Differential Evolution (DE) to efficiently explore and exploit search spaces by dynamically adjusting strategies based on population diversity.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive constant for PSO\n        self.c2 = 1.5  # Social constant for PSO\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (personal_best - population) +\n                        self.c2 * r2 * (global_best - population))\n            population = population + velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42319 with standard deviation 0.35629.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.18529239955088028, 0.9268011499863927, 0.1574765945801625]}}
{"id": "65438a0c-e5b0-4b62-902f-ec3df1d60486", "fitness": 0.9526557617997828, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimization algorithm that integrates Adaptive Particle Swarm Optimization with Differential Evolution and dynamic parameter tuning to balance exploration and exploitation effectively for diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95266 with standard deviation 0.03134.", "error": "", "parent_ids": ["cd91f486-70df-4f41-affe-411c7cc3f089"], "operator": null, "metadata": {"aucs": [0.9112173176200266, 0.9597561684016596, 0.9869937993776624]}}
{"id": "43468f36-0565-49c8-9c97-738b3cd8c021", "fitness": 0.424740643024676, "name": "EnhancedHybridPSODE", "description": "An improved hybrid optimization algorithm that incorporates dynamic neighborhood selection and adaptive parameter scaling to enhance search capability and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.neighborhood_size = 5  # New: size of neighborhood for local best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n            adaptive_F = self.F * (1 - evaluations / self.budget)  # New: adaptive mutation factor\n\n            # Dynamic neighborhood selection\n            local_bests = np.zeros_like(personal_best)\n            for i in range(self.population_size):\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                best_neighbor = min(neighbors, key=lambda idx: personal_best_values[idx])\n                local_bests[i] = personal_best[best_neighbor]\n\n            # Particle Swarm Optimization update with local best\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (local_bests - population) +  # Modified: use local best\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + adaptive_F * (x1 - x2)  # Use adaptive_F\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42474 with standard deviation 0.34239.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.9087515443527736, 0.17057936661366924, 0.19489101810758513]}}
{"id": "6d90b565-6bc6-4fe7-8aa1-9687455d20bd", "fitness": 0.9181331584260879, "name": "EnhancedHybridPSODE", "description": "Integration of a novel adaptive inertia weight strategy and selective breeding for stronger convergence in EnhancedHybridPSODE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight strategy\n            w = self.w_max - ((self.w_max - self.w_min) * ((evaluations / self.budget) ** 2))\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91813 with standard deviation 0.07005.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.822026195738926, 0.9453794801616754, 0.9869937993776624]}}
{"id": "beeb828d-502f-456b-90c5-df5314e68271", "fitness": 0.7473194191020349, "name": "EnhancedHybridPSODE", "description": "Utilize Adaptive Levy Flight and Fitness Sharing to enhance exploration in diverse search spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.levy_alpha = 1.5\n        self.epsilon = 1e-8\n\n    def levy_flight(self, dim):\n        u = np.random.normal(0, 1, dim) * (self.epsilon / np.abs(np.random.normal(0, 1)))**(1/self.levy_alpha)\n        return u\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n            if evaluations < self.budget:\n                levy_steps = self.levy_flight(self.dim)\n                for i in range(self.population_size):\n                    population[i] += levy_steps * (population[i] - global_best)\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74732 with standard deviation 0.06868.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.6881451043761352, 0.8436034304007335, 0.7102097225292359]}}
{"id": "706a7926-8567-40b1-9d54-3b254848d9b3", "fitness": 0.8867476180166793, "name": "AdvancedMultiStrategyPSODE", "description": "An advanced multi-strategy optimizer combining Adaptive Particle Swarm Optimization, Differential Evolution, and a novel local search mechanism for enhanced convergence speed and accuracy across diverse problem landscapes.", "code": "import numpy as np\n\nclass AdvancedMultiStrategyPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Local search refinement on the global best\n            if evaluations < self.budget:\n                perturbation = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                local_trial = np.clip(global_best + perturbation, lb, ub)\n                local_trial_value = func(local_trial)\n                evaluations += 1\n\n                if local_trial_value < global_best_value:\n                    global_best = local_trial\n                    global_best_value = local_trial_value\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm AdvancedMultiStrategyPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88675 with standard deviation 0.05624.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8833562671288194, 0.8196236017817252, 0.9572629851394934]}}
{"id": "6067fe26-e370-49eb-89f8-d4da65ee6818", "fitness": 0.9337145040504402, "name": "RefinedHybridPSODE", "description": "A refined Hybrid PSO-DE algorithm with adaptive inertia weight decay and enhanced mutation strategy for improved convergence in diverse search spaces.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.2  # Reduced minimum inertia weight for more exploration\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w_decay_rate = (self.w_max - self.w_min) / self.budget\n            w = self.w_max - (w_decay_rate * evaluations)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Enhanced Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice([idx for idx in range(self.population_size) if idx != i], 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93371 with standard deviation 0.02060.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.96270866873734, 0.9216610407474816, 0.916773802666499]}}
{"id": "2f8f5046-2ed9-4a2c-b490-2f28521d9e93", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "A refined hybrid algorithm that adds local search with Lévy flight strategy to improve exploration capabilities, maintaining the balance of exploration and exploitation with adaptive parameter tuning.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Lévy flight local search\n            if evaluations < self.budget:\n                L = 0.01  # Scale factor for Lévy flight\n                for i in range(self.population_size):\n                    levy_step = self.levy_flight(L)\n                    candidate = personal_best[i] + levy_step\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_value = func(candidate)\n                    evaluations += 1\n                    if candidate_value < personal_best_values[i]:\n                        personal_best[i] = candidate\n                        personal_best_values[i] = candidate_value\n                        if candidate_value < global_best_value:\n                            global_best = candidate\n                            global_best_value = candidate_value\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {}}
{"id": "2569b92e-1d43-430b-b05b-cd1d79113a93", "fitness": 0.7375444115329621, "name": "EnhancedHybridPSODE", "description": "Optimized EnhancedHybridPSODE by incorporating a self-adaptive mutation factor and varying population size to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, self.dim * 2)  # Vary population size based on dim\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            # Self-adaptive mutation factor\n            F = self.F_base + (0.9 - self.F_base) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            population = np.clip(population, lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)  # Use self-adaptive F\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73754 with standard deviation 0.00323.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.733670628976383, 0.7415717700126195, 0.7373908356098837]}}
{"id": "28aaadcd-39aa-45c3-9b8c-98b1c2ab765c", "fitness": 0.9040364907782963, "name": "AdvancedHybridPSODE", "description": "Introducing an adaptive learning factor and chaotic mutation strategy to further improve exploration-exploitation balance in EnhancedHybridPSODE for diverse search spaces.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n        self.learning_rate = 0.1  # Learning rate for adaptive changes\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        r_adaptive = np.random.rand(self.population_size, self.dim)\n\n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Apply chaotic mutation\n                r_adaptive = self.learning_rate * r_adaptive * (1 - r_adaptive)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i] + r_adaptive[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90404 with standard deviation 0.01329.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8961436240877038, 0.9227573057852696, 0.8932085424619154]}}
{"id": "b5522ab7-db36-4ce6-863f-b92283a67f4a", "fitness": 0.9309124038858746, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid optimization algorithm that improves exploration by modifying the crossover probability dynamically in Differential Evolution while integrating Adaptive Particle Swarm Optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 2.5\n        self.c2_initial = 0.5\n        self.F = 0.8  # Mutation factor for DE\n        self.CR = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize the population\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = population.copy()\n        personal_best_values = np.array([func(ind) for ind in population])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Dynamic parameter adjustment\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_initial - ((self.c1_initial - 1.5) * evaluations / self.budget)\n            c2 = self.c2_initial + ((2.0 - self.c2_initial) * evaluations / self.budget)\n            CR = 0.9 - (0.5 * evaluations / self.budget)  # Modified line for dynamic CR\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (w * velocity +\n                        c1 * r1 * (personal_best - population) +\n                        c2 * r2 * (global_best - population))\n            population += velocity\n\n            # Boundary handling\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution update\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, population[i])\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93091 with standard deviation 0.04117.", "error": "", "parent_ids": ["65438a0c-e5b0-4b62-902f-ec3df1d60486"], "operator": null, "metadata": {"aucs": [0.8893143902880387, 0.9164290219919224, 0.9869937993776624]}}
