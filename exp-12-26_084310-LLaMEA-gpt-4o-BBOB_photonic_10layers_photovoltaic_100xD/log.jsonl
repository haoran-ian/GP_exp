{"id": "8f119e0f-3441-4769-9eda-b086c2c281e8", "fitness": 0.0964061092475403, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Success-Based Parameter Adaptation for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09641 with standard deviation 0.04671.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.03956263908255797, 0.07334194258700255, 0.03689394615581332, 0.16473332300368138, 0.16610614381970956, 0.1418670970708269, 0.08594193586186327, 0.08510943049184616, 0.07409852515456161]}}
{"id": "d58d8ab5-3968-4ab2-adcf-bd6a8e99676d", "fitness": 0.09119599210511951, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Gaussian Mutation and Dynamic Population Resizing for Improved Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        while self.eval_count < self.budget:\n            new_pop = []\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Mutation with Gaussian component\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.1, self.dim), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                else:\n                    new_pop.append(pop[i])\n\n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.05 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.05 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.05 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.05 * (np.random.rand() - 0.5))\n            \n            # Dynamic population resizing\n            if self.eval_count % (self.budget // 10) == 0:\n                self.pop_size = max(5, int(self.pop_size * 0.9))\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n\n            pop = np.array(new_pop)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09120 with standard deviation 0.04992.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.04688401036754153, 0.033340354351690804, 0.03494987458259369, 0.1509833625328072, 0.16610614381970956, 0.15495966281052065, 0.08622627788804083, 0.07940004781166177, 0.06791419478150962]}}
{"id": "e2c0dde1-29c1-417b-99ae-1e49054cf9b4", "fitness": 0.09339357958914947, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Opposition-Based Learning and Dynamic Populations for Improved Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.opposition_probability = 0.3  # Probability to perform opposition-based learning\n        self.dynamic_pop_adaptation_rate = 0.1  # Rate at which the population size can adapt\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Opposition-based learning\n                if np.random.rand() < self.opposition_probability:\n                    opposition_candidate = lb + ub - pop[i]\n                    opposition_fitness = func(opposition_candidate)\n                    eval_count += 1\n                    if opposition_fitness < fitness[i]:\n                        pop[i] = opposition_candidate\n                        fitness[i] = opposition_fitness\n\n                # Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n            # Dynamic population adaptation\n            if eval_count < self.budget:\n                fitness_std = np.std(fitness)\n                if fitness_std < 0.01:\n                    pop_size = max(4, int(pop_size * (1 - self.dynamic_pop_adaptation_rate)))\n                    pop = pop[:pop_size]\n                    fitness = fitness[:pop_size]\n                elif fitness_std > 0.05:\n                    new_individuals = np.random.uniform(lb, ub, (int(pop_size * self.dynamic_pop_adaptation_rate), self.dim))\n                    pop = np.vstack((pop, new_individuals))\n                    fitness = np.append(fitness, [func(ind) for ind in new_individuals])\n                    pop_size = len(pop)\n                    eval_count += len(new_individuals)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09339 with standard deviation 0.04588.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.046008959303123875, 0.04966395913230304, 0.04516611857750952, 0.15042610833428838, 0.16610614381970956, 0.14771773406478073, 0.08594193586186327, 0.08530525119982613, 0.06420600600894077]}}
{"id": "0d0000a8-12c8-4560-9822-533fe1cb90b8", "fitness": 0.09244763224599215, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Memory Mechanism for Improved Adaptation and Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.memory_size = 5\n        self.F_memory = np.full(self.memory_size, self.F)\n        self.CR_memory = np.full(self.memory_size, self.CR)\n        self.success_mem_index = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Update F and CR from memory\n                self.F = self.F_memory[np.random.randint(self.memory_size)]\n                self.CR = self.CR_memory[np.random.randint(self.memory_size)]\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    \n                    # Store successful F and CR\n                    self.F_memory[self.success_mem_index] = self.F\n                    self.CR_memory[self.success_mem_index] = self.CR\n                    self.success_mem_index = (self.success_mem_index + 1) % self.memory_size\n\n                # Adaptive F and CR based on success\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09245 with standard deviation 0.05006.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.0607670880936837, 0.030843380479890103, 0.03415278095689711, 0.16148065693299907, 0.16610614381970956, 0.1487896001481146, 0.08594193586186327, 0.07940004781166177, 0.06454705610911016]}}
{"id": "d90837ef-e58f-4651-9713-9bdf92615391", "fitness": 0.09171865359902195, "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with Adaptive Scaling Factor and Dynamic Population Sizing for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.dynamic_pop_size = True # Enable dynamic population sizing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            if self.dynamic_pop_size:\n                self.pop_size = max(4, int(0.9 * self.pop_size)) # Dynamic resizing\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n                \n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_dynamic = self.F + 0.3 * np.sin(eval_count / self.budget * np.pi) # Adaptive F\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09172 with standard deviation 0.05179.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.033903604880399674, 0.04308026706205004, 0.031921107135486015, 0.15314954882690557, 0.16610614381970956, 0.1613230020327221, 0.08799406734109871, 0.07940004781166177, 0.06859009348116418]}}
{"id": "9551faf7-0a49-4d0f-a3cb-8716d4732805", "fitness": 0.09088199550104185, "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with Adaptive Parameters and Dynamic Population Resizing for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.initial_pop_size = self.pop_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * np.random.rand())\n                    self.CR = min(1.0, self.CR + 0.1 * np.random.rand())\n                else:\n                    self.F = max(0.1, self.F - 0.1 * np.random.rand())\n                    self.CR = max(0.1, self.CR - 0.1 * np.random.rand())\n\n            # Dynamic Population Resizing\n            if eval_count < self.budget / 2 and self.pop_size > self.dim:\n                self.pop_size = max(self.dim, int(self.pop_size * 0.9))\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09088 with standard deviation 0.04726.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.04050156365716695, 0.05802914836968709, 0.0351777823325129, 0.15252102178226656, 0.16610614381970956, 0.14253324368743914, 0.08594193586186327, 0.07940004781166177, 0.057727072187069406]}}
{"id": "8c25dc17-e29b-4044-a04c-ab3a8d21c248", "fitness": 0.09351010980816216, "name": "AdaptiveMemoryDifferentialEvolution", "description": "Introducing Adaptive Memory to Differential Evolution enhancing diversity and convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveMemoryDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.memory_size = 5  # Memory size for storing successful F and CR\n        self.memory_F = [self.F] * self.memory_size\n        self.memory_CR = [self.CR] * self.memory_size\n        self.memory_index = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    # Update memory with successful F and CR\n                    self.memory_F[self.memory_index] = self.F\n                    self.memory_CR[self.memory_index] = self.CR\n                    self.memory_index = (self.memory_index + 1) % self.memory_size\n                \n                # Adaptive F and CR using memory\n                if trial_fitness < fitness[i]:\n                    self.F = np.random.choice(self.memory_F) + 0.1 * (np.random.rand() - 0.5)\n                    self.CR = np.random.choice(self.memory_CR) + 0.1 * (np.random.rand() - 0.5)\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveMemoryDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09351 with standard deviation 0.04738.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.046237004238184665, 0.04493781356099191, 0.03689394615581332, 0.1591587936815846, 0.16610614381970956, 0.1418670970708269, 0.08704279199273524, 0.08524887259905167, 0.07409852515456161]}}
{"id": "e67e2b84-8ca4-409a-ab92-9e2ffd76cbfb", "fitness": 0.09479803128035784, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Population Resizing and Success History for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.success_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    self.success_history.append((self.F, self.CR))\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n\n            # Update F and CR based on success history\n            if len(self.success_history) > 0:\n                mean_F = np.mean([s[0] for s in self.success_history])\n                mean_CR = np.mean([s[1] for s in self.success_history])\n                self.F = np.clip(mean_F + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n                self.CR = np.clip(mean_CR + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n\n            # Dynamic Population Resizing\n            if eval_count < self.budget and len(self.success_history) > self.pop_size / 2:\n                self.pop_size = max(4, int(self.pop_size * 0.9))  # Reduce population size by 10%\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09480 with standard deviation 0.04724.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.04858666981226811, 0.04835046585952463, 0.04033817826846997, 0.1557935912695273, 0.16610614381970956, 0.15259149618224965, 0.08594193586186327, 0.08090624651888245, 0.07456755393072556]}}
{"id": "8783dfcf-e05f-4026-aef1-b031ecd2b079", "fitness": 0.09272364996967464, "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic adjustment to the mutation factor `F` for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Change: Dynamic F\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09272 with standard deviation 0.04860.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.043641066430180286, 0.03543885313776762, 0.05079851842314409, 0.15313720028578404, 0.16610614381970956, 0.1544841893172032, 0.08594193586186327, 0.07940004781166177, 0.0655648946397579]}}
{"id": "41695465-8e90-4f11-aa19-b1c21a1c4892", "fitness": 0.09639848870694351, "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution by refining mutation strategy and adaptive parameters for improved black box optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + 0.001 * (best_individual - pop[i]), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.05 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.05 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.05 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.05 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09640 with standard deviation 0.04608.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.036504657073538005, 0.07046905117274838, 0.04244069945882567, 0.15817630607684652, 0.16610614381970956, 0.14765723195659541, 0.08594193586186327, 0.08092813015643763, 0.07936224278592707]}}
{"id": "3c8b5131-6bdc-4942-b56e-5df4b55943eb", "fitness": 0.09056572184060835, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution incorporating Self-Adaptive Mutation and Crossover Strategies for Robust Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        # Self-adaptive parameters\n        F_mutate_rate = np.ones(self.pop_size) * self.F\n        CR_mutate_rate = np.ones(self.pop_size) * self.CR\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F = F_mutate_rate[i]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                \n                CR = CR_mutate_rate[i]\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    # Adjust F and CR towards successful values\n                    F_mutate_rate[i] = min(1.0, F + 0.1 * np.random.rand() * (1 - F))\n                    CR_mutate_rate[i] = min(1.0, CR + 0.1 * np.random.rand() * (1 - CR))\n                else:\n                    # Adjust F and CR towards exploration\n                    F_mutate_rate[i] = max(0.1, F - 0.1 * np.random.rand() * F)\n                    CR_mutate_rate[i] = max(0.1, CR - 0.1 * np.random.rand() * CR)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09057 with standard deviation 0.04775.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.035846529191830734, 0.04229172874117926, 0.03997475565382458, 0.1503720898352029, 0.16610614381970956, 0.14381789488286612, 0.08594193586186327, 0.07940004781166177, 0.0713403707673369]}}
{"id": "82f4bfb7-142f-469a-a94f-0a16c06f2fdc", "fitness": 0.104660485120025, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with self-adaptive population size and dynamic strategy selection for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.strategy_prob = [0.5, 0.5]  # Probability for DE/rand/1 and DE/best/1\n        self.success_rate = [0, 0]  # Success rate for each strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Choose strategy based on probability\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                # Mutation \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:  # DE/rand/1\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:  # DE/best/1\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n               \n                # Update success rate\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            # Update population and fitness\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n            \n            # Self-adaptive F and CR\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            # Adapt strategy probabilities\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [rate / total_success for rate in self.success_rate]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10466 with standard deviation 0.04156.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.0794255988337399, 0.07696443410708131, 0.07801380741839425, 0.15465606716069136, 0.18600457548251292, 0.14134439455330872, 0.08594193586186327, 0.07940004781166177, 0.060193504850971524]}}
{"id": "885a8205-612e-4de5-80ba-ab1cc5522e2b", "fitness": 0.10319216285999334, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic scaling factor and crossover adjustment based on population diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.strategy_prob = [0.5, 0.5]  # Probability for DE/rand/1 and DE/best/1\n        self.success_rate = [0, 0]  # Success rate for each strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Choose strategy based on probability\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                # Mutation \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:  # DE/rand/1\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:  # DE/best/1\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n               \n                # Update success rate\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            # Update population and fitness\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n            \n            # Self-adaptive F and CR\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            # Adapt strategy probabilities\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [rate / total_success for rate in self.success_rate]\n\n            # Adjust F and CR based on population diversity\n            diversity = np.mean(np.std(pop, axis=0))\n            self.F = np.clip(self.F + 0.1 * (0.5 - diversity), 0.1, 1.0)  # Adjust F\n            self.CR = np.clip(self.CR + 0.1 * (0.5 - diversity), 0.1, 1.0)  # Adjust CR\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10319 with standard deviation 0.04730.", "error": "", "parent_ids": ["82f4bfb7-142f-469a-a94f-0a16c06f2fdc"], "operator": null, "metadata": {"aucs": [0.0591642957728693, 0.06842963014856307, 0.05669283655338242, 0.16185918591680382, 0.18600457548251292, 0.15459732959873895, 0.08598993891774298, 0.09067077712711336, 0.06532089622221326]}}
{"id": "623d4c02-1e26-48f4-8779-8bacac646e84", "fitness": 0.10588529526355533, "name": "ImprovedSelfAdaptiveDifferentialEvolution", "description": "Improved Self-Adaptive Differential Evolution utilizing dynamic parameter adjustment with learning for strategy selection to enhance convergence efficiency.", "code": "import numpy as np\n\nclass ImprovedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 13, "feedback": "The algorithm ImprovedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10589 with standard deviation 0.04278.", "error": "", "parent_ids": ["82f4bfb7-142f-469a-a94f-0a16c06f2fdc"], "operator": null, "metadata": {"aucs": [0.0887586817904652, 0.06445179687244695, 0.07481395249369927, 0.1576658860669169, 0.18600457548251292, 0.14851570889203336, 0.08594193586186327, 0.07940004781166177, 0.06741507210039832]}}
{"id": "ef3eef7d-884a-4fc5-86de-da5dc28d85a1", "fitness": 0.10113078934252256, "name": "EnhancedSelfAdaptiveDE", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and dynamic strategy adaptation based on success history to improve convergence.  ", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                elif strategy == 1:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            if eval_count % (self.budget // 10) == 0:\n                pop_size = max(5, int(pop_size * 0.9))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedSelfAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10113 with standard deviation 0.04505.", "error": "", "parent_ids": ["623d4c02-1e26-48f4-8779-8bacac646e84"], "operator": null, "metadata": {"aucs": [0.07017790023839754, 0.04928232826591439, 0.06887708971196982, 0.1503720898352029, 0.18600457548251292, 0.1493034377542557, 0.08594193586186327, 0.0796858407745058, 0.0705319061580808]}}
{"id": "95bdc8b5-dfd0-4609-9bc6-641b1ac87ab5", "fitness": 0.10750269125000449, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and mutation strategies to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Adaptive shrinkage\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10750 with standard deviation 0.04148.", "error": "", "parent_ids": ["623d4c02-1e26-48f4-8779-8bacac646e84"], "operator": null, "metadata": {"aucs": [0.07989224812701479, 0.09776099551309358, 0.07050194697536527, 0.15044229742028137, 0.18600457548251292, 0.15312867567064348, 0.08594193586186327, 0.08133081442158308, 0.06252073177768258]}}
{"id": "09b55d0c-de1a-41d0-9d08-f1fd7baa4246", "fitness": 0.1067192784827629, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with a dynamic mutation factor and crossover rate based on historical successes for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    F_dynamic = self.F + self.learning_rate * (np.random.rand() - 0.5)\n                    mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    F_dynamic = self.F + self.learning_rate * (np.random.rand() - 0.5)\n                    mutant = np.clip(best_individual + F_dynamic * (b - c), lb, ub)\n                \n                CR_dynamic = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Adaptive shrinkage\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10672 with standard deviation 0.03773.", "error": "", "parent_ids": ["95bdc8b5-dfd0-4609-9bc6-641b1ac87ab5"], "operator": null, "metadata": {"aucs": [0.07678259333463, 0.09700450421116591, 0.05797374874447436, 0.15645572308248268, 0.16842573557404583, 0.14701023867380458, 0.08594193586186327, 0.09543655352013347, 0.07544247334226595]}}
{"id": "7275ea3c-5d30-4c27-bfb6-c94bf2055386", "fitness": 0.11129737825908956, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with randomized adaptive mutation factor to improve exploration.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)  # Change: Randomized adaptive mutation factor\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Adaptive shrinkage\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11130 with standard deviation 0.03681.", "error": "", "parent_ids": ["95bdc8b5-dfd0-4609-9bc6-641b1ac87ab5"], "operator": null, "metadata": {"aucs": [0.09056998575478781, 0.12371571101380574, 0.07304798403722024, 0.150711282750438, 0.16610614381970956, 0.1601185648665332, 0.08613864171616836, 0.07940004781166177, 0.07186804256148138]}}
{"id": "14bcd0d9-bfb0-4a6c-9c9e-d89bff1891b6", "fitness": 0.1009728885164793, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dual mutation strategies and dynamic crossover control for improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c, d = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) + randomized_F * (d - best_individual), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10097 with standard deviation 0.04192.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.05947221894274368, 0.08355545939600839, 0.05434862796707929, 0.1503720898352029, 0.17509686316531858, 0.14782167387778644, 0.08594193586186327, 0.07940004781166177, 0.07274707979064943]}}
{"id": "41e4e133-5d85-462b-9465-3504b4caebc9", "fitness": 0.11094988897814603, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic learning rates and diversity preservation for robust exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            pop_diversity = np.std(pop, axis=0).mean()\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adaptive F and CR based on diversity\n            if pop_diversity < self.diversity_threshold:\n                self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n                self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11095 with standard deviation 0.03723.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.08975401165775032, 0.12253089469177625, 0.07167524572249817, 0.15191738886107842, 0.16610614381970956, 0.1601185648665332, 0.08594193586186327, 0.07940004781166177, 0.07110476751044337]}}
{"id": "ff2b08b3-321c-407e-afc8-f5e6de0a1cb1", "fitness": 0.11129737825908956, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Differential Evolution with Dynamic Population Adaptation and Diversity Maintenance to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            # Diversity maintenance\n            diversity = np.mean(np.std(pop, axis=0))\n            if diversity < self.diversity_threshold:\n                pop = np.vstack((pop, np.random.uniform(lb, ub, (self.dim, self.dim))))\n                fitness = np.hstack((fitness, [func(ind) for ind in pop[-self.dim:]]))\n                eval_count += self.dim\n            \n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11130 with standard deviation 0.03681.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.09056998575478781, 0.12371571101380574, 0.07304798403722024, 0.150711282750438, 0.16610614381970956, 0.1601185648665332, 0.08613864171616836, 0.07940004781166177, 0.07186804256148138]}}
{"id": "227d8b52-e9b8-4c2b-80e6-5d7ae0612f93", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and dynamic crossover rate adjustment for improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.95  # Slightly more aggressive shrinkage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            # Adjust population size dynamically based on budget\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop) * (1 - (eval_count / self.budget))))\n            \n            # Dynamic adjustment of CR based on success rate\n            self.CR = np.clip(self.CR + self.learning_rate * (self.success_rate[0] - self.success_rate[1]) / total_success if total_success > 0 else 0, 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 21, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'total_success' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'total_success' referenced before assignment\")", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {}}
{"id": "a88d97eb-f433-4a50-9e36-be508b83442e", "fitness": 0.12695441049483783, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive crossover rate based on success rate to improve performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12695 with standard deviation 0.05842.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.25456901648531827, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "bf572fc9-ee5d-4791-b554-4ac6c32be585", "fitness": 0.11529946689588774, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and learning rates for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.95  # Adjusted shrink factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            # Adapt learning rate based on success rate\n            self.learning_rate = np.clip(0.1 * (1 + 0.5 * (self.success_rate[1] / max(1, total_success))), 0.05, 0.2)\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11530 with standard deviation 0.03894.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.15132296540324708, 0.11433024107341283, 0.06084258829141598, 0.1503720898352029, 0.16610614381970956, 0.15605035462682482, 0.08594193586186327, 0.07940004781166177, 0.07332883533965162]}}
{"id": "492d8a7a-4c0f-44fe-9d8e-151d37e9ee1d", "fitness": 0.10721455773769968, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution with dynamic control of mutation factor and crossover rate based on historical performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Dynamic adaptation of F and CR based on success rate\n            success_ratio = self.success_rate[1] / max(1, sum(self.success_rate))\n            self.F = np.clip(0.4 + 0.6 * success_ratio, 0.1, 0.9)\n            self.CR = np.clip(0.5 + 0.4 * success_ratio, 0.1, 0.9)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10721 with standard deviation 0.03498.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08616885977427358, 0.0998677489808325, 0.0646518956215747, 0.1503720898352029, 0.16610614381970956, 0.14774686608301224, 0.08594193586186327, 0.08013868389178247, 0.08393679577104596]}}
{"id": "4de7cad9-02d0-4e16-9cf0-00e54324c4ca", "fitness": 0.11184345375996946, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population and adaptive F & CR adjustment for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * pop_size))\n            \n            # Adaptive F and CR adjustments\n            self.F = np.clip(self.F + self.learning_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) \n                                      for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11184 with standard deviation 0.03637.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08058955744416763, 0.12627125903728798, 0.07750080448521446, 0.1503720898352029, 0.16610614381970956, 0.1601185648665332, 0.08594193586186327, 0.0855771042880441, 0.07411362420170198]}}
{"id": "1e528ac3-a8d2-4896-9fce-3f8fa3438c5a", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive F factor based on recent improvement history.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * np.sign(fitness.mean() - best_fitness), 0.1, 1.0)  # Updated F factor\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "79255a80-8a54-4dc5-aed1-7c5846d8b0e8", "fitness": 0.10295060875375105, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution incorporating adaptive mutation and diversity maintenance to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.mutation_rate = 0.1\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0) * (1 + self.mutation_rate * np.random.rand())\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            # Adaptive Mutation Rate\n            self.mutation_rate = min(1.0, max(0.1, np.std(pop) / np.std([func(ind) for ind in pop])))\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 27, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10295 with standard deviation 0.04150.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07645041196401814, 0.08234673327793784, 0.054283801573095425, 0.15103450541485464, 0.16610614381970956, 0.16281690025775286, 0.08594193586186327, 0.08174646720028134, 0.06582857941424636]}}
{"id": "846eacef-88e4-42a2-aee1-3ba14e946c86", "fitness": 0.1088198777231501, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive scaling factor based on success rate to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                # Change: Adaptive scaling factor based on success rate\n                randomized_F = np.clip(0.1 + 0.9 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10882 with standard deviation 0.03824.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.0624933188383453, 0.10121547070599834, 0.08282954311370372, 0.1551800663208942, 0.16610614381970956, 0.16069151505998414, 0.09157435936863567, 0.0886520522539258, 0.07063643002715414]}}
{"id": "f693a468-915b-40a8-9f48-fa2c26f5def1", "fitness": 0.12211774582829836, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic mutation factor based on population diversity to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    # Change: Dynamic mutation factor based on population diversity\n                    population_diversity = np.std(pop, axis=0).mean()\n                    dynamic_F = 0.1 + 0.9 * (population_diversity / (ub - lb).mean())\n                    mutant = np.clip(best_individual + dynamic_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12212 with standard deviation 0.03829.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.17191162061165344, 0.131915505881523, 0.0958342152787528, 0.1503720898352029, 0.16610614381970956, 0.15184997736513517, 0.08594193586186327, 0.07940004781166177, 0.06572817598918346]}}
{"id": "4bc7d0df-701a-4009-92c4-92ce193280e9", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size adjustment based on convergence speed to improve performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            # Change: Dynamically adjust population size based on convergence behavior\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop) * (1 + 0.1 * (1 - np.std(fitness)))))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 30, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {}}
{"id": "fcacf852-b6e2-48e0-be86-8ffd7de0d968", "fitness": 0.12242548390612623, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduced a dynamic crossover rate adjustment based on both success rate and fitness improvement for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on success rate and improvement in fitness\n            self.CR = np.clip(0.5 + 0.5 * ((self.success_rate[1] / max(1, sum(self.success_rate))) + (np.min(fitness) - best_fitness) / abs(np.min(fitness) - best_fitness)), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12243 with standard deviation 0.06345.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.26209187439794923, 0.08638563849023073, 0.05003459609297023, 0.15695122962784613, 0.16610614381970956, 0.14883425134528028, 0.0866132054780081, 0.07940004781166177, 0.06541236809147999]}}
{"id": "307587ec-23c7-444c-8f7b-d9d1da9bc5eb", "fitness": 0.10943764808223193, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introducing Dynamic Strategy Rate Adjustment to Enhanced Self-Adaptive Differential Evolution for adaptive exploitation-exploration balance and improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_rate_factor = 0.05  # Newly added parameter for dynamic adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n                # New addition: Dynamically adjust strategy probabilities based on success rate\n                exploitation_rate = self.success_rate[1] / max(1, total_success)\n                exploration_rate = self.success_rate[0] / max(1, total_success)\n                dynamic_adjustment = exploitation_rate - exploration_rate\n                self.strategy_prob[0] = np.clip(self.strategy_prob[0] - self.dynamic_rate_factor * dynamic_adjustment, 0.1, 0.9)\n                self.strategy_prob[1] = np.clip(self.strategy_prob[1] + self.dynamic_rate_factor * dynamic_adjustment, 0.1, 0.9)\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10944 with standard deviation 0.03803.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07820586090534709, 0.12690371095154962, 0.07046563970040698, 0.1503720898352029, 0.16970995232264974, 0.15344624205373192, 0.08594193586186327, 0.07957208791813342, 0.07032131319120238]}}
{"id": "c7c27816-7a4a-44e7-ace1-c376a16b4232", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduced an adaptive scaling factor `F` based on the recent success rate to refine convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Adaptive scaling factor F based on success rate\n            self.F = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "302d2785-2cd5-4754-bedb-0cd1b2d4496a", "fitness": 0.11208202298355394, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with dynamic mutation factor adjustment and adaptive population size for enhanced convergence.  ", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            # Dynamic mutation factor adjustment\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n\n            # Adaptive crossover rate based on success rate and continual adjustment of population size\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n                self.pop_shrink_factor = max(0.95, self.pop_shrink_factor - 0.001)  # Gradually decreasing shrink factor for diversity\n\n        return best_individual, best_fitness", "configspace": "", "generation": 34, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11208 with standard deviation 0.03745.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.12988554817455233, 0.1123665161035271, 0.06958509219945963, 0.15095314366421586, 0.16610614381970956, 0.15345100261616074, 0.08594193586186327, 0.07940004781166177, 0.0610487766008353]}}
{"id": "2218244b-5e3f-4d18-8a90-a5d7fe26e21c", "fitness": 0.10853029121665825, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population resizing and adaptive learning rates for improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adaptive learning rate based on the success rate\n            self.learning_rate = np.clip(0.1 + 0.9 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.01, 0.5)\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10853 with standard deviation 0.03794.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07612364080913536, 0.12718969187555085, 0.06831413499408667, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06987869388898194]}}
{"id": "60f7424f-bba9-4ed4-b45a-8a5f3141ba4d", "fitness": 0.11094988897814603, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution with dynamic population size and adaptive mutation factor for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F_min, self.F_max = 0.1, 1.0  # Bounds for mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_shrink_threshold = 0.2  # Threshold to trigger dynamic pop shrink\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = self.F_min + np.random.rand() * (self.F_max - self.F_min)\n\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n\n            # Dynamic population size shrinkage\n            avg_fitness_improvement = np.mean(fitness) - np.mean(new_fitness)\n            if avg_fitness_improvement < self.dynamic_shrink_threshold:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n                pop = pop[:pop_size]\n                fitness = fitness[:pop_size]\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + \n                                      self.learning_rate * (rate / total_success) \n                                      for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 36, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11095 with standard deviation 0.03723.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08975401165775032, 0.12253089469177625, 0.07167524572249817, 0.15191738886107842, 0.16610614381970956, 0.1601185648665332, 0.08594193586186327, 0.07940004781166177, 0.07110476751044337]}}
{"id": "133ac65e-e561-4c8f-b0c0-609aa6c011cf", "fitness": 0.10959225669355423, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic mutation factor and adaptive population size to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_F_bounds = (0.1, 0.9)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                dynamic_F = np.clip(np.random.uniform(*self.dynamic_F_bounds), 0.1, 1.0)\n\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + dynamic_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10959 with standard deviation 0.03680.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.09489893113023329, 0.11581329337392066, 0.06961334136178932, 0.15965074231985021, 0.16610614381970956, 0.14677994589494825, 0.08751725852902836, 0.07940004781166177, 0.06655060600084661]}}
{"id": "75b3c31a-69bb-4467-9759-31457d819b5b", "fitness": 0.10690038063129693, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Adjusted the population shrink factor to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.995  # Adjusted shrink factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "ee9e8953-5927-48d4-8926-cbe79b417b75", "fitness": 0.10677685535654352, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with improved mutation vector calculation for better performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) + 0.1 * (best_individual - a), lb, ub)  # Modified line\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10678 with standard deviation 0.03695.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07862698670754775, 0.12350939034994646, 0.06315816673071728, 0.15315663293903914, 0.16610614381970956, 0.1405664172302683, 0.08594193586186327, 0.07940004781166177, 0.07052597675813821]}}
{"id": "1b4ed526-dfdf-4548-98ed-0bcc18367065", "fitness": 0.11814121281553398, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population resizing and adaptive mutation to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_F_range = (0.1, 0.9)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(*self.dynamic_F_range)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adjust F dynamically based on success rate\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.dynamic_F_range = (0.1, 0.9 - 0.8 * (self.success_rate[1] / total_success))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, total_success)), 0.1, 1.0)\n            \n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11814 with standard deviation 0.03911.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.14035248217855623, 0.1314846775520213, 0.07623440649532975, 0.15325559595733895, 0.16737083018302323, 0.16522484183942532, 0.08594193586186327, 0.07940004781166177, 0.06400609746058594]}}
{"id": "b1db0f49-249e-4194-98ad-62137c29687c", "fitness": 0.10690038063129693, "name": "AdaptiveDynamicDifferentialEvolution", "description": "Adaptive Dynamic Differential Evolution with multi-strategy adaptation and convergence acceleration using adaptive randomization.", "code": "import numpy as np\n\nclass AdaptiveDynamicDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.rand_adapt = True  # New adaptive randomization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                F_adapt = np.random.uniform(0.1, 1.0) if self.rand_adapt else self.F\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F_adapt * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + F_adapt * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveDynamicDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "88e4cb66-1b5d-43ee-b56b-edc64077759d", "fitness": 0.10638005548297351, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Minor refinement in the mutation process to increase diversity by altering the randomized_F range.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.2, 0.9)  # Change: Alter the range of randomized_F\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10638 with standard deviation 0.04011.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.06493900276675502, 0.12618857275088124, 0.0669986789958592, 0.15914285722534582, 0.16610614381970956, 0.14473844039328498, 0.08594193586186327, 0.08092117024379464, 0.0624436972892678]}}
{"id": "b82deb4c-97b1-49f5-9dee-653c92a26a31", "fitness": 0.09259227990713387, "name": "AdaptiveDifferentialEvolutionWithEntropyCrossover", "description": "Adaptive Differential Evolution with dynamic scaling factor and entropy-based crossover to enhance exploration and exploitation balance. ", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionWithEntropyCrossover:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F_lb = 0.1\n        self.F_ub = 0.9\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            F = np.random.uniform(self.F_lb, self.F_ub)\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + F * (b - c), lb, ub)\n                \n                entropy = -np.sum(pop * np.log(pop + 1e-10), axis=1)\n                cross_points = np.random.rand(self.dim) < (self.CR * (1 + entropy[i] / np.log(self.dim)))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveDifferentialEvolutionWithEntropyCrossover got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09259 with standard deviation 0.05000.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.052564678900557604, 0.04293403279350272, 0.03258813912756664, 0.1571815883155414, 0.17148638889071344, 0.14962925243428005, 0.08594193586186327, 0.07940004781166177, 0.06160445502851786]}}
{"id": "d16588a0-90db-44f5-ac89-706b2c5e44ce", "fitness": 0.10120602085255688, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution with dynamic adaptation of both F and CR using success history and periodic reinitialization to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.reinit_threshold = 100  # New threshold for reinitialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            if eval_count % self.reinit_threshold == 0:\n                pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                fitness = np.array([func(ind) for ind in pop])\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 44, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10121 with standard deviation 0.03962.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.05746652719554923, 0.09285686335424337, 0.06963917149370613, 0.1503720898352029, 0.1672011532085278, 0.14673647587945404, 0.08594193586186327, 0.07940004781166177, 0.061239923032803456]}}
{"id": "0dd7fcbd-b40c-4e6b-942a-6501454aaad0", "fitness": 0.10690038063129693, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population resizing and adaptive mutation based on convergence rate.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.convergence_threshold = 1e-8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = a + randomized_F * (b - c)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = best_individual + randomized_F * (b - c)\n                \n                mutant = np.clip(mutant, lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i] - self.convergence_threshold:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "911da725-4538-4f62-814a-523c1aa1bbf5", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive mutation factor based on success rate to further improve performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Updating F based on the success rate of strategies\n            self.F = np.clip(0.5 + 0.5 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "bf6fc2fa-b457-49fd-bb5d-10eaeeddcb8e", "fitness": 0.10830868603881122, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Self-Adaptive Differential Evolution with dynamic F and CR adaptation based on success history and diversity to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1\n\n    def diversity_measure(self, pop):\n        return np.mean([np.linalg.norm(ind - pop.mean(axis=0)) for ind in pop])\n\n    def adjust_parameters(self, diversity):\n        if diversity < self.diversity_threshold:\n            self.F = np.clip(self.F * 1.1, 0.1, 1.0)\n            self.CR = np.clip(self.CR * 0.9, 0.1, 1.0)\n        else:\n            self.F = np.clip(self.F * 0.9, 0.1, 1.0)\n            self.CR = np.clip(self.CR * 1.1, 0.1, 1.0)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            diversity = self.diversity_measure(pop)\n            self.adjust_parameters(diversity)\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10831 with standard deviation 0.03640.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10308062336946633, 0.08451764645479576, 0.0710262655219539, 0.15134479129972678, 0.16610614381970956, 0.15707013666664038, 0.08594193586186327, 0.0803014087290489, 0.07538922262609615]}}
