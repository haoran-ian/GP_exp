{"id": "8f119e0f-3441-4769-9eda-b086c2c281e8", "fitness": 0.0964061092475403, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Success-Based Parameter Adaptation for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09641 with standard deviation 0.04671.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.03956263908255797, 0.07334194258700255, 0.03689394615581332, 0.16473332300368138, 0.16610614381970956, 0.1418670970708269, 0.08594193586186327, 0.08510943049184616, 0.07409852515456161]}}
{"id": "d58d8ab5-3968-4ab2-adcf-bd6a8e99676d", "fitness": 0.09119599210511951, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Gaussian Mutation and Dynamic Population Resizing for Improved Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        while self.eval_count < self.budget:\n            new_pop = []\n            for i in range(self.pop_size):\n                if self.eval_count >= self.budget:\n                    break\n                # Mutation with Gaussian component\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.1, self.dim), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                else:\n                    new_pop.append(pop[i])\n\n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.05 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.05 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.05 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.05 * (np.random.rand() - 0.5))\n            \n            # Dynamic population resizing\n            if self.eval_count % (self.budget // 10) == 0:\n                self.pop_size = max(5, int(self.pop_size * 0.9))\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n\n            pop = np.array(new_pop)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09120 with standard deviation 0.04992.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.04688401036754153, 0.033340354351690804, 0.03494987458259369, 0.1509833625328072, 0.16610614381970956, 0.15495966281052065, 0.08622627788804083, 0.07940004781166177, 0.06791419478150962]}}
{"id": "e2c0dde1-29c1-417b-99ae-1e49054cf9b4", "fitness": 0.09339357958914947, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Opposition-Based Learning and Dynamic Populations for Improved Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.opposition_probability = 0.3  # Probability to perform opposition-based learning\n        self.dynamic_pop_adaptation_rate = 0.1  # Rate at which the population size can adapt\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Opposition-based learning\n                if np.random.rand() < self.opposition_probability:\n                    opposition_candidate = lb + ub - pop[i]\n                    opposition_fitness = func(opposition_candidate)\n                    eval_count += 1\n                    if opposition_fitness < fitness[i]:\n                        pop[i] = opposition_candidate\n                        fitness[i] = opposition_fitness\n\n                # Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n            # Dynamic population adaptation\n            if eval_count < self.budget:\n                fitness_std = np.std(fitness)\n                if fitness_std < 0.01:\n                    pop_size = max(4, int(pop_size * (1 - self.dynamic_pop_adaptation_rate)))\n                    pop = pop[:pop_size]\n                    fitness = fitness[:pop_size]\n                elif fitness_std > 0.05:\n                    new_individuals = np.random.uniform(lb, ub, (int(pop_size * self.dynamic_pop_adaptation_rate), self.dim))\n                    pop = np.vstack((pop, new_individuals))\n                    fitness = np.append(fitness, [func(ind) for ind in new_individuals])\n                    pop_size = len(pop)\n                    eval_count += len(new_individuals)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09339 with standard deviation 0.04588.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.046008959303123875, 0.04966395913230304, 0.04516611857750952, 0.15042610833428838, 0.16610614381970956, 0.14771773406478073, 0.08594193586186327, 0.08530525119982613, 0.06420600600894077]}}
{"id": "0d0000a8-12c8-4560-9822-533fe1cb90b8", "fitness": 0.09244763224599215, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Memory Mechanism for Improved Adaptation and Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.memory_size = 5\n        self.F_memory = np.full(self.memory_size, self.F)\n        self.CR_memory = np.full(self.memory_size, self.CR)\n        self.success_mem_index = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Update F and CR from memory\n                self.F = self.F_memory[np.random.randint(self.memory_size)]\n                self.CR = self.CR_memory[np.random.randint(self.memory_size)]\n\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    \n                    # Store successful F and CR\n                    self.F_memory[self.success_mem_index] = self.F\n                    self.CR_memory[self.success_mem_index] = self.CR\n                    self.success_mem_index = (self.success_mem_index + 1) % self.memory_size\n\n                # Adaptive F and CR based on success\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09245 with standard deviation 0.05006.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.0607670880936837, 0.030843380479890103, 0.03415278095689711, 0.16148065693299907, 0.16610614381970956, 0.1487896001481146, 0.08594193586186327, 0.07940004781166177, 0.06454705610911016]}}
{"id": "d90837ef-e58f-4651-9713-9bdf92615391", "fitness": 0.09171865359902195, "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with Adaptive Scaling Factor and Dynamic Population Sizing for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.dynamic_pop_size = True # Enable dynamic population sizing\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            if self.dynamic_pop_size:\n                self.pop_size = max(4, int(0.9 * self.pop_size)) # Dynamic resizing\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n                \n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_dynamic = self.F + 0.3 * np.sin(eval_count / self.budget * np.pi) # Adaptive F\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09172 with standard deviation 0.05179.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.033903604880399674, 0.04308026706205004, 0.031921107135486015, 0.15314954882690557, 0.16610614381970956, 0.1613230020327221, 0.08799406734109871, 0.07940004781166177, 0.06859009348116418]}}
{"id": "9551faf7-0a49-4d0f-a3cb-8716d4732805", "fitness": 0.09088199550104185, "name": "EnhancedDifferentialEvolution", "description": "Enhanced Differential Evolution with Adaptive Parameters and Dynamic Population Resizing for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.initial_pop_size = self.pop_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * np.random.rand())\n                    self.CR = min(1.0, self.CR + 0.1 * np.random.rand())\n                else:\n                    self.F = max(0.1, self.F - 0.1 * np.random.rand())\n                    self.CR = max(0.1, self.CR - 0.1 * np.random.rand())\n\n            # Dynamic Population Resizing\n            if eval_count < self.budget / 2 and self.pop_size > self.dim:\n                self.pop_size = max(self.dim, int(self.pop_size * 0.9))\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09088 with standard deviation 0.04726.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.04050156365716695, 0.05802914836968709, 0.0351777823325129, 0.15252102178226656, 0.16610614381970956, 0.14253324368743914, 0.08594193586186327, 0.07940004781166177, 0.057727072187069406]}}
{"id": "8c25dc17-e29b-4044-a04c-ab3a8d21c248", "fitness": 0.09351010980816216, "name": "AdaptiveMemoryDifferentialEvolution", "description": "Introducing Adaptive Memory to Differential Evolution enhancing diversity and convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveMemoryDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.memory_size = 5  # Memory size for storing successful F and CR\n        self.memory_F = [self.F] * self.memory_size\n        self.memory_CR = [self.CR] * self.memory_size\n        self.memory_index = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    # Update memory with successful F and CR\n                    self.memory_F[self.memory_index] = self.F\n                    self.memory_CR[self.memory_index] = self.CR\n                    self.memory_index = (self.memory_index + 1) % self.memory_size\n                \n                # Adaptive F and CR using memory\n                if trial_fitness < fitness[i]:\n                    self.F = np.random.choice(self.memory_F) + 0.1 * (np.random.rand() - 0.5)\n                    self.CR = np.random.choice(self.memory_CR) + 0.1 * (np.random.rand() - 0.5)\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n                self.F = np.clip(self.F, 0.1, 1.0)\n                self.CR = np.clip(self.CR, 0.1, 1.0)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveMemoryDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09351 with standard deviation 0.04738.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.046237004238184665, 0.04493781356099191, 0.03689394615581332, 0.1591587936815846, 0.16610614381970956, 0.1418670970708269, 0.08704279199273524, 0.08524887259905167, 0.07409852515456161]}}
{"id": "e67e2b84-8ca4-409a-ab92-9e2ffd76cbfb", "fitness": 0.09479803128035784, "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Population Resizing and Success History for Efficient Black Box Optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.success_history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    self.success_history.append((self.F, self.CR))\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n\n            # Update F and CR based on success history\n            if len(self.success_history) > 0:\n                mean_F = np.mean([s[0] for s in self.success_history])\n                mean_CR = np.mean([s[1] for s in self.success_history])\n                self.F = np.clip(mean_F + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n                self.CR = np.clip(mean_CR + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n\n            # Dynamic Population Resizing\n            if eval_count < self.budget and len(self.success_history) > self.pop_size / 2:\n                self.pop_size = max(4, int(self.pop_size * 0.9))  # Reduce population size by 10%\n                pop = pop[:self.pop_size]\n                fitness = fitness[:self.pop_size]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09480 with standard deviation 0.04724.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.04858666981226811, 0.04835046585952463, 0.04033817826846997, 0.1557935912695273, 0.16610614381970956, 0.15259149618224965, 0.08594193586186327, 0.08090624651888245, 0.07456755393072556]}}
{"id": "8783dfcf-e05f-4026-aef1-b031ecd2b079", "fitness": 0.09272364996967464, "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic adjustment to the mutation factor `F` for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                self.F = 0.5 + 0.5 * np.random.rand()  # Change: Dynamic F\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.1 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.1 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.1 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.1 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09272 with standard deviation 0.04860.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.043641066430180286, 0.03543885313776762, 0.05079851842314409, 0.15313720028578404, 0.16610614381970956, 0.1544841893172032, 0.08594193586186327, 0.07940004781166177, 0.0655648946397579]}}
{"id": "41695465-8e90-4f11-aa19-b1c21a1c4892", "fitness": 0.09639848870694351, "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution by refining mutation strategy and adaptive parameters for improved black box optimization.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                # Mutation\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c) + 0.001 * (best_individual - pop[i]), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                \n                # Adaptive F and CR\n                if trial_fitness < fitness[i]:\n                    self.F = min(1.0, self.F + 0.05 * (np.random.rand() - 0.5))\n                    self.CR = min(1.0, self.CR + 0.05 * (np.random.rand() - 0.5))\n                else:\n                    self.F = max(0.1, self.F - 0.05 * (np.random.rand() - 0.5))\n                    self.CR = max(0.1, self.CR - 0.05 * (np.random.rand() - 0.5))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09640 with standard deviation 0.04608.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.036504657073538005, 0.07046905117274838, 0.04244069945882567, 0.15817630607684652, 0.16610614381970956, 0.14765723195659541, 0.08594193586186327, 0.08092813015643763, 0.07936224278592707]}}
{"id": "3c8b5131-6bdc-4942-b56e-5df4b55943eb", "fitness": 0.09056572184060835, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution incorporating Self-Adaptive Mutation and Crossover Strategies for Robust Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = self.pop_size\n        \n        # Self-adaptive parameters\n        F_mutate_rate = np.ones(self.pop_size) * self.F\n        CR_mutate_rate = np.ones(self.pop_size) * self.CR\n\n        while eval_count < self.budget:\n            for i in range(self.pop_size):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F = F_mutate_rate[i]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                \n                CR = CR_mutate_rate[i]\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    # Adjust F and CR towards successful values\n                    F_mutate_rate[i] = min(1.0, F + 0.1 * np.random.rand() * (1 - F))\n                    CR_mutate_rate[i] = min(1.0, CR + 0.1 * np.random.rand() * (1 - CR))\n                else:\n                    # Adjust F and CR towards exploration\n                    F_mutate_rate[i] = max(0.1, F - 0.1 * np.random.rand() * F)\n                    CR_mutate_rate[i] = max(0.1, CR - 0.1 * np.random.rand() * CR)\n\n        return best_individual, best_fitness", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09057 with standard deviation 0.04775.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.035846529191830734, 0.04229172874117926, 0.03997475565382458, 0.1503720898352029, 0.16610614381970956, 0.14381789488286612, 0.08594193586186327, 0.07940004781166177, 0.0713403707673369]}}
{"id": "82f4bfb7-142f-469a-a94f-0a16c06f2fdc", "fitness": 0.104660485120025, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with self-adaptive population size and dynamic strategy selection for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.strategy_prob = [0.5, 0.5]  # Probability for DE/rand/1 and DE/best/1\n        self.success_rate = [0, 0]  # Success rate for each strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Choose strategy based on probability\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                # Mutation \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:  # DE/rand/1\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:  # DE/best/1\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n               \n                # Update success rate\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            # Update population and fitness\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n            \n            # Self-adaptive F and CR\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            # Adapt strategy probabilities\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [rate / total_success for rate in self.success_rate]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10466 with standard deviation 0.04156.", "error": "", "parent_ids": ["8f119e0f-3441-4769-9eda-b086c2c281e8"], "operator": null, "metadata": {"aucs": [0.0794255988337399, 0.07696443410708131, 0.07801380741839425, 0.15465606716069136, 0.18600457548251292, 0.14134439455330872, 0.08594193586186327, 0.07940004781166177, 0.060193504850971524]}}
{"id": "885a8205-612e-4de5-80ba-ab1cc5522e2b", "fitness": 0.10319216285999334, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic scaling factor and crossover adjustment based on population diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.strategy_prob = [0.5, 0.5]  # Probability for DE/rand/1 and DE/best/1\n        self.success_rate = [0, 0]  # Success rate for each strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                # Choose strategy based on probability\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                # Mutation \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:  # DE/rand/1\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:  # DE/best/1\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                eval_count += 1\n               \n                # Update success rate\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            # Update population and fitness\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n            \n            # Self-adaptive F and CR\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            # Adapt strategy probabilities\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [rate / total_success for rate in self.success_rate]\n\n            # Adjust F and CR based on population diversity\n            diversity = np.mean(np.std(pop, axis=0))\n            self.F = np.clip(self.F + 0.1 * (0.5 - diversity), 0.1, 1.0)  # Adjust F\n            self.CR = np.clip(self.CR + 0.1 * (0.5 - diversity), 0.1, 1.0)  # Adjust CR\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10319 with standard deviation 0.04730.", "error": "", "parent_ids": ["82f4bfb7-142f-469a-a94f-0a16c06f2fdc"], "operator": null, "metadata": {"aucs": [0.0591642957728693, 0.06842963014856307, 0.05669283655338242, 0.16185918591680382, 0.18600457548251292, 0.15459732959873895, 0.08598993891774298, 0.09067077712711336, 0.06532089622221326]}}
{"id": "623d4c02-1e26-48f4-8779-8bacac646e84", "fitness": 0.10588529526355533, "name": "ImprovedSelfAdaptiveDifferentialEvolution", "description": "Improved Self-Adaptive Differential Evolution utilizing dynamic parameter adjustment with learning for strategy selection to enhance convergence efficiency.", "code": "import numpy as np\n\nclass ImprovedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 13, "feedback": "The algorithm ImprovedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10589 with standard deviation 0.04278.", "error": "", "parent_ids": ["82f4bfb7-142f-469a-a94f-0a16c06f2fdc"], "operator": null, "metadata": {"aucs": [0.0887586817904652, 0.06445179687244695, 0.07481395249369927, 0.1576658860669169, 0.18600457548251292, 0.14851570889203336, 0.08594193586186327, 0.07940004781166177, 0.06741507210039832]}}
{"id": "ef3eef7d-884a-4fc5-86de-da5dc28d85a1", "fitness": 0.10113078934252256, "name": "EnhancedSelfAdaptiveDE", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and dynamic strategy adaptation based on success history to improve convergence.  ", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                elif strategy == 1:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = len(pop)\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            if eval_count % (self.budget // 10) == 0:\n                pop_size = max(5, int(pop_size * 0.9))\n\n        return best_individual, best_fitness", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedSelfAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10113 with standard deviation 0.04505.", "error": "", "parent_ids": ["623d4c02-1e26-48f4-8779-8bacac646e84"], "operator": null, "metadata": {"aucs": [0.07017790023839754, 0.04928232826591439, 0.06887708971196982, 0.1503720898352029, 0.18600457548251292, 0.1493034377542557, 0.08594193586186327, 0.0796858407745058, 0.0705319061580808]}}
{"id": "95bdc8b5-dfd0-4609-9bc6-641b1ac87ab5", "fitness": 0.10750269125000449, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and mutation strategies to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + self.F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Adaptive shrinkage\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10750 with standard deviation 0.04148.", "error": "", "parent_ids": ["623d4c02-1e26-48f4-8779-8bacac646e84"], "operator": null, "metadata": {"aucs": [0.07989224812701479, 0.09776099551309358, 0.07050194697536527, 0.15044229742028137, 0.18600457548251292, 0.15312867567064348, 0.08594193586186327, 0.08133081442158308, 0.06252073177768258]}}
{"id": "09b55d0c-de1a-41d0-9d08-f1fd7baa4246", "fitness": 0.1067192784827629, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with a dynamic mutation factor and crossover rate based on historical successes for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    F_dynamic = self.F + self.learning_rate * (np.random.rand() - 0.5)\n                    mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    F_dynamic = self.F + self.learning_rate * (np.random.rand() - 0.5)\n                    mutant = np.clip(best_individual + F_dynamic * (b - c), lb, ub)\n                \n                CR_dynamic = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Adaptive shrinkage\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10672 with standard deviation 0.03773.", "error": "", "parent_ids": ["95bdc8b5-dfd0-4609-9bc6-641b1ac87ab5"], "operator": null, "metadata": {"aucs": [0.07678259333463, 0.09700450421116591, 0.05797374874447436, 0.15645572308248268, 0.16842573557404583, 0.14701023867380458, 0.08594193586186327, 0.09543655352013347, 0.07544247334226595]}}
{"id": "7275ea3c-5d30-4c27-bfb6-c94bf2055386", "fitness": 0.11129737825908956, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with randomized adaptive mutation factor to improve exploration.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)  # Change: Randomized adaptive mutation factor\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Adaptive shrinkage\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11130 with standard deviation 0.03681.", "error": "", "parent_ids": ["95bdc8b5-dfd0-4609-9bc6-641b1ac87ab5"], "operator": null, "metadata": {"aucs": [0.09056998575478781, 0.12371571101380574, 0.07304798403722024, 0.150711282750438, 0.16610614381970956, 0.1601185648665332, 0.08613864171616836, 0.07940004781166177, 0.07186804256148138]}}
{"id": "14bcd0d9-bfb0-4a6c-9c9e-d89bff1891b6", "fitness": 0.1009728885164793, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dual mutation strategies and dynamic crossover control for improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c, d = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) + randomized_F * (d - best_individual), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10097 with standard deviation 0.04192.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.05947221894274368, 0.08355545939600839, 0.05434862796707929, 0.1503720898352029, 0.17509686316531858, 0.14782167387778644, 0.08594193586186327, 0.07940004781166177, 0.07274707979064943]}}
{"id": "41e4e133-5d85-462b-9465-3504b4caebc9", "fitness": 0.11094988897814603, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic learning rates and diversity preservation for robust exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            pop_diversity = np.std(pop, axis=0).mean()\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adaptive F and CR based on diversity\n            if pop_diversity < self.diversity_threshold:\n                self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n                self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11095 with standard deviation 0.03723.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.08975401165775032, 0.12253089469177625, 0.07167524572249817, 0.15191738886107842, 0.16610614381970956, 0.1601185648665332, 0.08594193586186327, 0.07940004781166177, 0.07110476751044337]}}
{"id": "ff2b08b3-321c-407e-afc8-f5e6de0a1cb1", "fitness": 0.11129737825908956, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Differential Evolution with Dynamic Population Adaptation and Diversity Maintenance to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            # Diversity maintenance\n            diversity = np.mean(np.std(pop, axis=0))\n            if diversity < self.diversity_threshold:\n                pop = np.vstack((pop, np.random.uniform(lb, ub, (self.dim, self.dim))))\n                fitness = np.hstack((fitness, [func(ind) for ind in pop[-self.dim:]]))\n                eval_count += self.dim\n            \n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11130 with standard deviation 0.03681.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.09056998575478781, 0.12371571101380574, 0.07304798403722024, 0.150711282750438, 0.16610614381970956, 0.1601185648665332, 0.08613864171616836, 0.07940004781166177, 0.07186804256148138]}}
{"id": "227d8b52-e9b8-4c2b-80e6-5d7ae0612f93", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and dynamic crossover rate adjustment for improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.95  # Slightly more aggressive shrinkage\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            # Adjust population size dynamically based on budget\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop) * (1 - (eval_count / self.budget))))\n            \n            # Dynamic adjustment of CR based on success rate\n            self.CR = np.clip(self.CR + self.learning_rate * (self.success_rate[0] - self.success_rate[1]) / total_success if total_success > 0 else 0, 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 21, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'total_success' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'total_success' referenced before assignment\")", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {}}
{"id": "a88d97eb-f433-4a50-9e36-be508b83442e", "fitness": 0.12695441049483783, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive crossover rate based on success rate to improve performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12695 with standard deviation 0.05842.", "error": "", "parent_ids": ["7275ea3c-5d30-4c27-bfb6-c94bf2055386"], "operator": null, "metadata": {"aucs": [0.25456901648531827, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "bf572fc9-ee5d-4791-b554-4ac6c32be585", "fitness": 0.11529946689588774, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size and learning rates for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.95  # Adjusted shrink factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            # Adapt learning rate based on success rate\n            self.learning_rate = np.clip(0.1 * (1 + 0.5 * (self.success_rate[1] / max(1, total_success))), 0.05, 0.2)\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11530 with standard deviation 0.03894.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.15132296540324708, 0.11433024107341283, 0.06084258829141598, 0.1503720898352029, 0.16610614381970956, 0.15605035462682482, 0.08594193586186327, 0.07940004781166177, 0.07332883533965162]}}
{"id": "492d8a7a-4c0f-44fe-9d8e-151d37e9ee1d", "fitness": 0.10721455773769968, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution with dynamic control of mutation factor and crossover rate based on historical performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Dynamic adaptation of F and CR based on success rate\n            success_ratio = self.success_rate[1] / max(1, sum(self.success_rate))\n            self.F = np.clip(0.4 + 0.6 * success_ratio, 0.1, 0.9)\n            self.CR = np.clip(0.5 + 0.4 * success_ratio, 0.1, 0.9)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10721 with standard deviation 0.03498.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08616885977427358, 0.0998677489808325, 0.0646518956215747, 0.1503720898352029, 0.16610614381970956, 0.14774686608301224, 0.08594193586186327, 0.08013868389178247, 0.08393679577104596]}}
{"id": "4de7cad9-02d0-4e16-9cf0-00e54324c4ca", "fitness": 0.11184345375996946, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population and adaptive F & CR adjustment for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * pop_size))\n            \n            # Adaptive F and CR adjustments\n            self.F = np.clip(self.F + self.learning_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * np.random.normal(0, 0.1), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) \n                                      for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11184 with standard deviation 0.03637.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08058955744416763, 0.12627125903728798, 0.07750080448521446, 0.1503720898352029, 0.16610614381970956, 0.1601185648665332, 0.08594193586186327, 0.0855771042880441, 0.07411362420170198]}}
{"id": "1e528ac3-a8d2-4896-9fce-3f8fa3438c5a", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive F factor based on recent improvement history.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * np.sign(fitness.mean() - best_fitness), 0.1, 1.0)  # Updated F factor\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "79255a80-8a54-4dc5-aed1-7c5846d8b0e8", "fitness": 0.10295060875375105, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution incorporating adaptive mutation and diversity maintenance to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.mutation_rate = 0.1\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0) * (1 + self.mutation_rate * np.random.rand())\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            # Adaptive Mutation Rate\n            self.mutation_rate = min(1.0, max(0.1, np.std(pop) / np.std([func(ind) for ind in pop])))\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 27, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10295 with standard deviation 0.04150.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07645041196401814, 0.08234673327793784, 0.054283801573095425, 0.15103450541485464, 0.16610614381970956, 0.16281690025775286, 0.08594193586186327, 0.08174646720028134, 0.06582857941424636]}}
{"id": "846eacef-88e4-42a2-aee1-3ba14e946c86", "fitness": 0.1088198777231501, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive scaling factor based on success rate to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                # Change: Adaptive scaling factor based on success rate\n                randomized_F = np.clip(0.1 + 0.9 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10882 with standard deviation 0.03824.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.0624933188383453, 0.10121547070599834, 0.08282954311370372, 0.1551800663208942, 0.16610614381970956, 0.16069151505998414, 0.09157435936863567, 0.0886520522539258, 0.07063643002715414]}}
{"id": "f693a468-915b-40a8-9f48-fa2c26f5def1", "fitness": 0.12211774582829836, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic mutation factor based on population diversity to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    # Change: Dynamic mutation factor based on population diversity\n                    population_diversity = np.std(pop, axis=0).mean()\n                    dynamic_F = 0.1 + 0.9 * (population_diversity / (ub - lb).mean())\n                    mutant = np.clip(best_individual + dynamic_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12212 with standard deviation 0.03829.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.17191162061165344, 0.131915505881523, 0.0958342152787528, 0.1503720898352029, 0.16610614381970956, 0.15184997736513517, 0.08594193586186327, 0.07940004781166177, 0.06572817598918346]}}
{"id": "4bc7d0df-701a-4009-92c4-92ce193280e9", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive population size adjustment based on convergence speed to improve performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            # Change: Dynamically adjust population size based on convergence behavior\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop) * (1 + 0.1 * (1 - np.std(fitness)))))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 30, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {}}
{"id": "fcacf852-b6e2-48e0-be86-8ffd7de0d968", "fitness": 0.12242548390612623, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduced a dynamic crossover rate adjustment based on both success rate and fitness improvement for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on success rate and improvement in fitness\n            self.CR = np.clip(0.5 + 0.5 * ((self.success_rate[1] / max(1, sum(self.success_rate))) + (np.min(fitness) - best_fitness) / abs(np.min(fitness) - best_fitness)), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12243 with standard deviation 0.06345.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.26209187439794923, 0.08638563849023073, 0.05003459609297023, 0.15695122962784613, 0.16610614381970956, 0.14883425134528028, 0.0866132054780081, 0.07940004781166177, 0.06541236809147999]}}
{"id": "307587ec-23c7-444c-8f7b-d9d1da9bc5eb", "fitness": 0.10943764808223193, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introducing Dynamic Strategy Rate Adjustment to Enhanced Self-Adaptive Differential Evolution for adaptive exploitation-exploration balance and improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_rate_factor = 0.05  # Newly added parameter for dynamic adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n                # New addition: Dynamically adjust strategy probabilities based on success rate\n                exploitation_rate = self.success_rate[1] / max(1, total_success)\n                exploration_rate = self.success_rate[0] / max(1, total_success)\n                dynamic_adjustment = exploitation_rate - exploration_rate\n                self.strategy_prob[0] = np.clip(self.strategy_prob[0] - self.dynamic_rate_factor * dynamic_adjustment, 0.1, 0.9)\n                self.strategy_prob[1] = np.clip(self.strategy_prob[1] + self.dynamic_rate_factor * dynamic_adjustment, 0.1, 0.9)\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10944 with standard deviation 0.03803.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07820586090534709, 0.12690371095154962, 0.07046563970040698, 0.1503720898352029, 0.16970995232264974, 0.15344624205373192, 0.08594193586186327, 0.07957208791813342, 0.07032131319120238]}}
{"id": "c7c27816-7a4a-44e7-ace1-c376a16b4232", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduced an adaptive scaling factor `F` based on the recent success rate to refine convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Adaptive scaling factor F based on success rate\n            self.F = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "302d2785-2cd5-4754-bedb-0cd1b2d4496a", "fitness": 0.11208202298355394, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with dynamic mutation factor adjustment and adaptive population size for enhanced convergence.  ", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            # Dynamic mutation factor adjustment\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n\n            # Adaptive crossover rate based on success rate and continual adjustment of population size\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n                self.pop_shrink_factor = max(0.95, self.pop_shrink_factor - 0.001)  # Gradually decreasing shrink factor for diversity\n\n        return best_individual, best_fitness", "configspace": "", "generation": 34, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11208 with standard deviation 0.03745.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.12988554817455233, 0.1123665161035271, 0.06958509219945963, 0.15095314366421586, 0.16610614381970956, 0.15345100261616074, 0.08594193586186327, 0.07940004781166177, 0.0610487766008353]}}
{"id": "2218244b-5e3f-4d18-8a90-a5d7fe26e21c", "fitness": 0.10853029121665825, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population resizing and adaptive learning rates for improved convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adaptive learning rate based on the success rate\n            self.learning_rate = np.clip(0.1 + 0.9 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.01, 0.5)\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10853 with standard deviation 0.03794.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07612364080913536, 0.12718969187555085, 0.06831413499408667, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06987869388898194]}}
{"id": "60f7424f-bba9-4ed4-b45a-8a5f3141ba4d", "fitness": 0.11094988897814603, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution with dynamic population size and adaptive mutation factor for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F_min, self.F_max = 0.1, 1.0  # Bounds for mutation factor\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_shrink_threshold = 0.2  # Threshold to trigger dynamic pop shrink\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = self.F_min + np.random.rand() * (self.F_max - self.F_min)\n\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n\n            # Dynamic population size shrinkage\n            avg_fitness_improvement = np.mean(fitness) - np.mean(new_fitness)\n            if avg_fitness_improvement < self.dynamic_shrink_threshold:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n                pop = pop[:pop_size]\n                fitness = fitness[:pop_size]\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + \n                                      self.learning_rate * (rate / total_success) \n                                      for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 36, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11095 with standard deviation 0.03723.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08975401165775032, 0.12253089469177625, 0.07167524572249817, 0.15191738886107842, 0.16610614381970956, 0.1601185648665332, 0.08594193586186327, 0.07940004781166177, 0.07110476751044337]}}
{"id": "133ac65e-e561-4c8f-b0c0-609aa6c011cf", "fitness": 0.10959225669355423, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic mutation factor and adaptive population size to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_F_bounds = (0.1, 0.9)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                dynamic_F = np.clip(np.random.uniform(*self.dynamic_F_bounds), 0.1, 1.0)\n\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + dynamic_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10959 with standard deviation 0.03680.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.09489893113023329, 0.11581329337392066, 0.06961334136178932, 0.15965074231985021, 0.16610614381970956, 0.14677994589494825, 0.08751725852902836, 0.07940004781166177, 0.06655060600084661]}}
{"id": "75b3c31a-69bb-4467-9759-31457d819b5b", "fitness": 0.10690038063129693, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Adjusted the population shrink factor to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.995  # Adjusted shrink factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "ee9e8953-5927-48d4-8926-cbe79b417b75", "fitness": 0.10677685535654352, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with improved mutation vector calculation for better performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) + 0.1 * (best_individual - a), lb, ub)  # Modified line\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10678 with standard deviation 0.03695.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07862698670754775, 0.12350939034994646, 0.06315816673071728, 0.15315663293903914, 0.16610614381970956, 0.1405664172302683, 0.08594193586186327, 0.07940004781166177, 0.07052597675813821]}}
{"id": "1b4ed526-dfdf-4548-98ed-0bcc18367065", "fitness": 0.11814121281553398, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population resizing and adaptive mutation to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_F_range = (0.1, 0.9)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(*self.dynamic_F_range)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adjust F dynamically based on success rate\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.dynamic_F_range = (0.1, 0.9 - 0.8 * (self.success_rate[1] / total_success))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, total_success)), 0.1, 1.0)\n            \n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11814 with standard deviation 0.03911.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.14035248217855623, 0.1314846775520213, 0.07623440649532975, 0.15325559595733895, 0.16737083018302323, 0.16522484183942532, 0.08594193586186327, 0.07940004781166177, 0.06400609746058594]}}
{"id": "b1db0f49-249e-4194-98ad-62137c29687c", "fitness": 0.10690038063129693, "name": "AdaptiveDynamicDifferentialEvolution", "description": "Adaptive Dynamic Differential Evolution with multi-strategy adaptation and convergence acceleration using adaptive randomization.", "code": "import numpy as np\n\nclass AdaptiveDynamicDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.rand_adapt = True  # New adaptive randomization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                F_adapt = np.random.uniform(0.1, 1.0) if self.rand_adapt else self.F\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F_adapt * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + F_adapt * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveDynamicDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "88e4cb66-1b5d-43ee-b56b-edc64077759d", "fitness": 0.10638005548297351, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Minor refinement in the mutation process to increase diversity by altering the randomized_F range.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.2, 0.9)  # Change: Alter the range of randomized_F\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10638 with standard deviation 0.04011.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.06493900276675502, 0.12618857275088124, 0.0669986789958592, 0.15914285722534582, 0.16610614381970956, 0.14473844039328498, 0.08594193586186327, 0.08092117024379464, 0.0624436972892678]}}
{"id": "b82deb4c-97b1-49f5-9dee-653c92a26a31", "fitness": 0.09259227990713387, "name": "AdaptiveDifferentialEvolutionWithEntropyCrossover", "description": "Adaptive Differential Evolution with dynamic scaling factor and entropy-based crossover to enhance exploration and exploitation balance. ", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolutionWithEntropyCrossover:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F_lb = 0.1\n        self.F_ub = 0.9\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            F = np.random.uniform(self.F_lb, self.F_ub)\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + F * (b - c), lb, ub)\n                \n                entropy = -np.sum(pop * np.log(pop + 1e-10), axis=1)\n                cross_points = np.random.rand(self.dim) < (self.CR * (1 + entropy[i] / np.log(self.dim)))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveDifferentialEvolutionWithEntropyCrossover got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09259 with standard deviation 0.05000.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.052564678900557604, 0.04293403279350272, 0.03258813912756664, 0.1571815883155414, 0.17148638889071344, 0.14962925243428005, 0.08594193586186327, 0.07940004781166177, 0.06160445502851786]}}
{"id": "d16588a0-90db-44f5-ac89-706b2c5e44ce", "fitness": 0.10120602085255688, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution with dynamic adaptation of both F and CR using success history and periodic reinitialization to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.reinit_threshold = 100  # New threshold for reinitialization\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            if eval_count % self.reinit_threshold == 0:\n                pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                fitness = np.array([func(ind) for ind in pop])\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 44, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10121 with standard deviation 0.03962.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.05746652719554923, 0.09285686335424337, 0.06963917149370613, 0.1503720898352029, 0.1672011532085278, 0.14673647587945404, 0.08594193586186327, 0.07940004781166177, 0.061239923032803456]}}
{"id": "0dd7fcbd-b40c-4e6b-942a-6501454aaad0", "fitness": 0.10690038063129693, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population resizing and adaptive mutation based on convergence rate.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.convergence_threshold = 1e-8\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = a + randomized_F * (b - c)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = best_individual + randomized_F * (b - c)\n                \n                mutant = np.clip(mutant, lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i] - self.convergence_threshold:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "911da725-4538-4f62-814a-523c1aa1bbf5", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive mutation factor based on success rate to further improve performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Updating F based on the success rate of strategies\n            self.F = np.clip(0.5 + 0.5 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "bf6fc2fa-b457-49fd-bb5d-10eaeeddcb8e", "fitness": 0.10830868603881122, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Self-Adaptive Differential Evolution with dynamic F and CR adaptation based on success history and diversity to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1\n\n    def diversity_measure(self, pop):\n        return np.mean([np.linalg.norm(ind - pop.mean(axis=0)) for ind in pop])\n\n    def adjust_parameters(self, diversity):\n        if diversity < self.diversity_threshold:\n            self.F = np.clip(self.F * 1.1, 0.1, 1.0)\n            self.CR = np.clip(self.CR * 0.9, 0.1, 1.0)\n        else:\n            self.F = np.clip(self.F * 0.9, 0.1, 1.0)\n            self.CR = np.clip(self.CR * 1.1, 0.1, 1.0)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            diversity = self.diversity_measure(pop)\n            self.adjust_parameters(diversity)\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10831 with standard deviation 0.03640.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10308062336946633, 0.08451764645479576, 0.0710262655219539, 0.15134479129972678, 0.16610614381970956, 0.15707013666664038, 0.08594193586186327, 0.0803014087290489, 0.07538922262609615]}}
{"id": "c87105c7-50bb-4c08-af53-2ee734fa104a", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Integrate dynamic population resizing and adaptive learning in Enhanced Self-Adaptive Differential Evolution to improve convergence on diverse problem landscapes.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.adaptive_learning = 0.5  # New adaptive learning rate parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Dynamic adjustment of F based on fitness improvements\n            improv_factor = np.mean((fitness - best_fitness) / (fitness + 1e-12))\n            self.F = np.clip(self.F + self.adaptive_learning * improv_factor, 0.1, 1.0)\n            \n            # Updating CR based on the success rate of strategies\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [\n                    (1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success)\n                    for prob, rate in zip(self.strategy_prob, self.success_rate)\n                ]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "b227536d-7d84-4921-8adc-a86fd45809dd", "fitness": 0.1110396387821494, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with dynamic mutation factor adjustment for enhanced convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.2, 0.8)  # Change: narrowed range for F\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.2, 0.8)  # Change: adjusted F range\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11104 with standard deviation 0.04323.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08169297431501721, 0.11736136085366433, 0.07024944725786875, 0.1766479234681272, 0.16610614381970956, 0.15966764512738285, 0.0944462145936702, 0.07940004781166177, 0.05378499179224272]}}
{"id": "1a2501e2-ee7b-44c8-9a2c-cba2bceae956", "fitness": 0.11488380915999365, "name": "HybridEvolutionarySwarmDifferentialEvolution", "description": "Hybrid Evolutionary Approach integrating Swarm Intelligence with Self-Adaptive Differential Evolution to dynamically adjust control parameters for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridEvolutionarySwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.swarm_influence = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                \n                global_best_contribution = self.swarm_influence * (best_individual - pop[i])\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) + global_best_contribution, lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) + global_best_contribution, lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 50, "feedback": "The algorithm HybridEvolutionarySwarmDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11488 with standard deviation 0.04026.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10749808847772291, 0.1191637648262216, 0.07551922228803121, 0.15257911410476155, 0.19231002565797395, 0.15213173148806536, 0.08594193586186327, 0.07940004781166177, 0.0694103519236412]}}
{"id": "6ed87051-9b42-4d9a-80da-efbdfa28c85b", "fitness": 0.10791433598512144, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population size adjustment based on diversity to maintain exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversity_threshold = 0.1  # Threshold for dynamic population adjustment\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            # Calculate diversity\n            centroid = np.mean(pop, axis=0)\n            diversity = np.mean(np.linalg.norm(pop - centroid, axis=1))\n            \n            # Adjust population size based on diversity\n            if diversity < self.diversity_threshold:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            else:\n                pop_size = min(self.initial_pop_size, len(pop) + 1)\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) \n                                      for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10791 with standard deviation 0.03564.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.08462966481910816, 0.10875387738500941, 0.0769838863337865, 0.1503720898352029, 0.16610614381970956, 0.15102391858839992, 0.08594193586186327, 0.07940004781166177, 0.06801745941135151]}}
{"id": "d956d439-4901-4025-a750-5774e049f652", "fitness": 0.10690038063129693, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with adaptive mutation factor and elitist selection to improve convergence. ", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adaptive mutation factor\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n            \n            # Elitist selection: keep the best individual in the population\n            if best_individual not in pop:\n                worst_idx = np.argmax(fitness)\n                pop[worst_idx] = best_individual\n                fitness[worst_idx] = best_fitness\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10690 with standard deviation 0.03889.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.07408274771345003, 0.11710587699261454, 0.06227282079657914, 0.1503720898352029, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.07957208791813342, 0.06987869388898194]}}
{"id": "7e9fedb9-dc5e-4e75-b6db-e57f5e0c22a4", "fitness": 0.0979414144793794, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population size and adaptive mutation strategy for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.5, 1.0)  # Adaptive F range\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * pop_size))  # Dynamic population size reduction\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09794 with standard deviation 0.05146.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.040326023525867005, 0.049139860656279066, 0.027362694477956695, 0.15357746747724232, 0.16905187683956213, 0.15628114673855886, 0.09773577389597299, 0.12195802537803924, 0.06603986132493633]}}
{"id": "cac247d3-188a-4d05-b274-33ae78f8f3d7", "fitness": 0.11908394585108642, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic adjustment of the mutation factor based on fitness improvement rate to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                # Change: Dynamic adjustment of mutation factor F based on fitness improvement rate\n                randomized_F = np.random.uniform(0.1, 1.0) * (best_fitness / max(fitness[i], 1e-8))\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11908 with standard deviation 0.03765.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.132704537275385, 0.13789985551024353, 0.07487185515596151, 0.1649589748197704, 0.16863531343823057, 0.15213980860450327, 0.08594193586186327, 0.08051554079146639, 0.07408769120235381]}}
{"id": "3fa7759d-106a-4b2f-9ac3-afcb3bbb346e", "fitness": 0.10221915717931658, "name": "ImprovedEnhancedSelfAdaptiveDifferentialEvolution", "description": "Improved Enhanced Self-Adaptive Differential Evolution using dynamic scaling factor adjustment and adaptive population resizing for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.base_F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                dynamic_F = self.base_F * (1 - eval_count / self.budget) + 0.1\n                randomized_F = np.random.uniform(dynamic_F, 1.0)\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.base_F = np.clip(self.base_F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 55, "feedback": "The algorithm ImprovedEnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10222 with standard deviation 0.04998.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.054392254459954215, 0.057932789753679326, 0.0376832776866165, 0.16319928881308443, 0.16721874726288055, 0.16633346915800518, 0.08621297618891377, 0.1218533687410307, 0.0651462425496846]}}
{"id": "78c1ed27-70a2-4dc8-be54-ba468d5910ca", "fitness": 0.10928428953518478, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic mutation factor based on success rate to improve exploration.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Change: Updating F based on the success rate of strategies\n            self.F = np.clip(0.5 + 0.5 * (self.success_rate[0] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10928 with standard deviation 0.03753.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [0.10324556833144105, 0.11855268496909943, 0.06119563732268973, 0.1503720898352029, 0.16610614381970956, 0.15344624205373192, 0.08594193586186327, 0.07940004781166177, 0.06529825581126336]}}
{"id": "2aaa2bb7-8051-4b30-8b2a-3126e3cd798b", "fitness": -Infinity, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhanced Self-Adaptive Differential Evolution with dynamic population size adjustment based on fitness variance and diversity to improve exploration and exploitation.  ", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            # Change: Adjust population size based on fitness variance and diversity\n            fitness_variance = np.var(fitness)\n            diversity = np.mean([np.linalg.norm(pop[i] - pop[best_idx]) for i in range(pop_size)])\n            if fitness_variance < 1e-5 or diversity < 1e-5:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop) * 1.1))\n            else:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_success = sum(self.success_rate)\n            if total_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_success) for prob, rate in zip(self.strategy_prob, self.success_rate)]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 57, "feedback": "An exception occurred: IndexError('index 60 is out of bounds for axis 0 with size 36').", "error": "IndexError('index 60 is out of bounds for axis 0 with size 36')", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {}}
{"id": "1721dbcd-a890-438c-80b6-f7a78d3ecc6f", "fitness": 0.2074914802994142, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance diversity and exploration by introducing a dynamic scaling factor for the mutation strategy and updating strategy probabilities based on recent success.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20749 with standard deviation 0.28233.", "error": "", "parent_ids": ["a88d97eb-f433-4a50-9e36-be508b83442e"], "operator": null, "metadata": {"aucs": [1.0, 0.09488795427777175, 0.0679769154075398, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "b2582650-2db3-441d-83b9-16d1309f2780", "fitness": 0.08825168698362106, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance exploration by introducing adaptive scaling factor variance based on population diversity.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                diversity = np.std(pop, axis=0).mean()  # Change: Calculate diversity\n                randomized_F = np.random.uniform(0.1, 1.0) * diversity  # Change: Adaptive scaling factor variance\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08825 with standard deviation 0.05714.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.03242013403917121, 0.028322605369733633, 0.02212243530534108, 0.153100484721708, 0.18472058612173958, 0.1499920307633683, 0.08594193586186327, 0.07940004781166177, 0.058244922858002646]}}
{"id": "78a58443-cb75-4433-b3ff-acfca6ffc28c", "fitness": 0.1026178858907531, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rate based on past iteration performance to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            # Change: Introduce adaptive crossover rate\n            self.CR = np.clip(0.5 + self.learning_rate * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10262 with standard deviation 0.04365.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.08035926497680179, 0.07209985414377396, 0.049255684611468675, 0.17552796882248378, 0.16610614381970956, 0.14373751018794, 0.08594193586186327, 0.0807952664891286, 0.06973734410360832]}}
{"id": "fa704c34-963a-4f1d-8345-b2eb33e67a88", "fitness": 0.10967114156224175, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance convergence by introducing a dynamic crossover rate that adjusts based on the best individual's improvement rate.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))) * (best_fitness / max(fitness)), 0.1, 1.0)  # Change: Dynamic CR based on best fitness improvement\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10967 with standard deviation 0.04217.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12348444437926243, 0.0674361233149704, 0.06660436177908902, 0.17552796882248378, 0.16610614381970956, 0.15109779695773506, 0.08594193586186327, 0.07940004781166177, 0.07144145131340052]}}
{"id": "5bf715e9-66df-4562-98bd-27eee0d4da4f", "fitness": 0.10802570588853755, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance exploration and exploitation by introducing adaptive scaling, crossover rates, and a self-adaptive learning mechanism for dynamic strategy selection.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                dynamic_F = np.random.normal(0.5, 0.3)  # Adaptive scaling\n                dynamic_CR = np.clip(np.random.normal(self.CR, 0.1), 0.1, 1.0)  # Adaptive crossover\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + dynamic_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + dynamic_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < dynamic_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10803 with standard deviation 0.03722.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.10060217136155236, 0.0664171377461843, 0.08392848019155008, 0.1573208549078685, 0.16610614381970956, 0.15273673276277167, 0.09200676975222155, 0.08196581895582611, 0.0711472434991538]}}
{"id": "590a948d-6a96-481d-814f-0cd941f2b60b", "fitness": 0.11118133116201169, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rate adjustment using recent trial success to further enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n            self.CR = min(1.0, max(0.1, self.CR + 0.1 * (0.5 - np.random.rand())))  # Change: Adaptive CR adjustment\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11118 with standard deviation 0.03677.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.13105650530480462, 0.08699559976266436, 0.06877767934661472, 0.1542443857698098, 0.16670444376982418, 0.14942742598215752, 0.08594193586186327, 0.0898180361800569, 0.06766596848030981]}}
{"id": "59ef5de4-6a98-4255-9a35-59cdfffc7cad", "fitness": 0.10968556068497935, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce a self-adaptive mechanism for adjusting mutation and crossover rates using historical performance and dynamic population resizing based on convergence speed.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.convergence_threshold = 1e-6  # Added: Convergence threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        prev_best_fitness = best_fitness  # Added: Track previous best fitness\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            # Added: Dynamic population resizing based on convergence\n            if abs(prev_best_fitness - best_fitness) < self.convergence_threshold:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            prev_best_fitness = best_fitness\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10969 with standard deviation 0.03584.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12767385515980656, 0.09413986168058197, 0.06255896495821556, 0.15197868374418133, 0.16610614381970956, 0.14179741656283817, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "a7f738ec-08ca-4544-9fd6-d7211d95e73d", "fitness": 0.12600996088642363, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Improve selection pressure and adaptability by dynamically adjusting crossover rate and mutation factor based on population diversity and fitness improvement rates.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            diversity_measure = np.std(pop, axis=0).mean()  # Change: Compute population diversity\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (diversity_measure - 0.5), 0.1, 1.0)  # Change: Adjust F based on diversity\n            self.CR = np.clip(0.5 + 0.5 * (np.mean(fitness) - best_fitness) / np.std(fitness), 0.1, 1.0)  # Change: Adjust CR based on fitness improvement\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12601 with standard deviation 0.04048.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1955766577942729, 0.12768413783507782, 0.09335730628770422, 0.15240531262258983, 0.16610614381970956, 0.1500456460510824, 0.08700761112242728, 0.09468690921563838, 0.06721992322931014]}}
{"id": "e5c59bac-eaca-48a2-9f0a-8a65381d2570", "fitness": 0.11832669940180468, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Refine exploration and improve convergence by introducing adaptive crossover rates and enhanced selection pressure.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.adapt_CR_rate = 0.05  # Change: New parameter for adaptive CR\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.adapt_CR_rate * (np.random.rand() - 0.5), 0.1, 1.0)  # Change: Adaptive crossover rate\n\n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11833 with standard deviation 0.03878.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1725220685613862, 0.10845491322314516, 0.07265980750280654, 0.15048015941777038, 0.16610614381970956, 0.1487329478144176, 0.08594193586186327, 0.0898180361800569, 0.07022428223508648]}}
{"id": "589bc697-3b8f-4ac1-9f59-6f1f104f5598", "fitness": 0.1097977346435602, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Refine adaptive strategy control by incorporating diversity preservation, leveraging distance-based reinitialization to maintain a balanced exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            if np.std(fitness) < 1e-6:  # Change: Trigger reinitialization based on fitness diversity\n                pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                fitness = np.array([func(ind) for ind in pop])\n                eval_count += pop_size\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10980 with standard deviation 0.03492.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1207562890973144, 0.09488795427777175, 0.0679769154075398, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "1427955b-3dcc-4586-aace-7f5ef9e658fe", "fitness": 0.10074194524684739, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive population dynamics by adjusting population size based on fitness diversity and implement adaptive crossover and mutation strategies for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.min_pop_size = 4\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            fitness_diversity = np.std(fitness) / np.mean(fitness)\n            adaptive_pop_size = int(self.initial_pop_size * fitness_diversity)\n            adaptive_pop_size = np.clip(adaptive_pop_size, self.min_pop_size, self.initial_pop_size)\n            pop_size = min(pop_size, adaptive_pop_size)\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10074 with standard deviation 0.04481.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.08189595560630958, 0.06722971216015705, 0.028749991594065216, 0.15050228330954352, 0.17761499588052476, 0.14759766275851516, 0.08663115749917316, 0.08604561191531368, 0.08041013649802442]}}
{"id": "ba7e5965-62b6-4b49-97a0-f31d0ac675ec", "fitness": -Infinity, "name": "AdaptiveHistoricalDifferentialEvolution", "description": "Introduce adaptive population resizing and incorporate historical search information to dynamically adjust mutation and crossover strategies for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveHistoricalDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.history = []\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            if len(self.history) > 10:\n                self.history.pop(0)\n            self.history.append(best_fitness)\n            \n            if len(self.history) > 1:\n                improvement = self.history[-2] - self.history[-1]\n                pop_size = int(max(2, self.initial_pop_size * (1 + improvement)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 69, "feedback": "An exception occurred: IndexError('index 164 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 164 is out of bounds for axis 0 with size 100')", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {}}
{"id": "6604cf44-46b2-4f40-9c9d-2241b9712211", "fitness": 0.12934616359725182, "name": "AdaptivePopulationDifferentialEvolution", "description": "Introduce adaptive population resizing based on convergence rate and usage of elite solutions to guide exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePopulationDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            elite_size = max(1, int(self.elite_fraction * pop_size))\n            elite_indices = np.argsort(fitness)[:elite_size]\n            elite_pop = pop[elite_indices]\n            \n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    elite = elite_pop[np.random.randint(elite_size)]\n                    mutant = np.clip(elite + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 70, "feedback": "The algorithm AdaptivePopulationDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12935 with standard deviation 0.08844.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.34842782463307087, 0.05758206624481943, 0.03797436256834308, 0.1540536173797885, 0.16610614381970956, 0.15008803434128581, 0.09323680031479531, 0.07970215158240102, 0.07694447149105277]}}
{"id": "fb9bfc60-97b5-49d0-a8a9-63314a674cf9", "fitness": 0.11215669042668913, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Adjust crossover rate dynamically based on recent success in both mutation strategies to enhance adaptability.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.recent_success[1] / max(1, sum(self.recent_success))), 0.1, 1.0)  # Change: Adjust CR based on recent success\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11216 with standard deviation 0.03430.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12710294783724319, 0.09548040274194414, 0.07790838065395067, 0.1503720898352029, 0.16610614381970956, 0.14912414971299637, 0.08594193586186327, 0.0898180361800569, 0.06755612719723514]}}
{"id": "a8875134-7044-4cfe-af8d-cf5bf8c45cbd", "fitness": 0.09970785945881598, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance adaptation by introducing a dynamic crossover rate influenced by recent success rates.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n            \n            # Change: Adjust CR based on recent success\n            self.CR = 0.9 * (self.recent_success[0] / max(1, total_recent_success)) + 0.1 * (self.recent_success[1] / max(1, total_recent_success))\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09971 with standard deviation 0.04317.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.07419925653789872, 0.05796438353865141, 0.04957013618185058, 0.15584735741036193, 0.16610614381970956, 0.15352881419712638, 0.09155547739822545, 0.07940004781166177, 0.06919911823385805]}}
{"id": "a8b39d6e-029d-48da-bdab-9720a66fbdd0", "fitness": 0.1096769037904293, "name": "AdaptiveSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive population resizing and feedback-driven parameter control to enhance convergence speed and accuracy across diverse problem landscapes.", "code": "import numpy as np\n\nclass AdaptiveSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_pop_resize = True\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        last_best_update = 0\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                        last_best_update = eval_count\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            # Dynamically adjust population size\n            if self.dynamic_pop_resize and eval_count > last_best_update + self.dim:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            # Adapt parameters based on recent successes\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10968 with standard deviation 0.03485.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.11950127864809279, 0.09488795427777175, 0.06814444817858323, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "d821c2f1-214f-4725-84c3-7643cdf8496e", "fitness": 0.10591446739445942, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Improve exploration and exploitation balance using adaptive crossover rates and dynamically adjusting mutation strategies based on historical performance.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR_min, self.CR_max = 0.1, 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 74, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10591 with standard deviation 0.03603.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.08910464479231728, 0.08559495748857782, 0.07659605304298489, 0.1553657947899092, 0.1679188629962658, 0.14364681272415725, 0.08594193586186327, 0.07940004781166177, 0.06966109704239754]}}
{"id": "d0274d65-a339-41ef-978a-e418adc2ca29", "fitness": 0.10968556068497935, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive population resizing based on convergence rate and incorporate a competitive selection mechanism for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.adaptive_pop_shrink = 0.99\n        self.min_pop_size = 4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        improvement_rate_threshold = 1e-5\n        last_best_fitness = best_fitness\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            \n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            improvement_rate = (last_best_fitness - best_fitness) / max(1.0, abs(last_best_fitness))\n            if improvement_rate < improvement_rate_threshold:\n                pop_size = max(self.min_pop_size, int(self.adaptive_pop_shrink * len(pop)))\n            last_best_fitness = best_fitness\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10969 with standard deviation 0.03584.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12767385515980656, 0.09413986168058197, 0.06255896495821556, 0.15197868374418133, 0.16610614381970956, 0.14179741656283817, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "2701da0e-460b-45d0-a9e0-18ac991ca3eb", "fitness": -Infinity, "name": "AdaptiveHybridDifferentialEvolution", "description": "Introduce adaptive population size and hybrid mutation strategies to improve convergence speed and diversity.", "code": "import numpy as np\n\nclass AdaptiveHybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.dynamic_pop_factor = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            success_ratio = sum(self.success_rate) / max(1, pop_size)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop) * (1 + self.dynamic_pop_factor * success_ratio)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 76, "feedback": "An exception occurred: IndexError('index 102 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 102 is out of bounds for axis 0 with size 100')", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {}}
{"id": "2ea3cb54-4adc-46d5-8d7c-87b07f176683", "fitness": 0.12819688400819348, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Refine exploration and exploitation balance by adaptive population resizing and dynamic mutation strategies based on success history.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.adaptive_resizing = True  # New: Adaptive resizing flag\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            if self.adaptive_resizing:\n                pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12820 with standard deviation 0.06193.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.26914278939182934, 0.11710587699261454, 0.062056751676697886, 0.1503720898352029, 0.16610614381970956, 0.15376762679518008, 0.08594193586186327, 0.07940004781166177, 0.06987869388898194]}}
{"id": "fa687934-6742-4715-960c-3beaba8f17fd", "fitness": 0.1081946626594337, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance adaptability by integrating a feedback mechanism for dynamic parameter adjustment based on historical performance and success within subpopulations.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.param_history = []\n        self.subpop_count = 5  # New: Number of subpopulations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            subpop_indices = np.array_split(np.arange(pop_size), self.subpop_count)  # New: Split into subpopulations\n            \n            for subpop_idx in subpop_indices:\n                for i in subpop_idx:\n                    if eval_count >= self.budget:\n                        break\n\n                    strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                    \n                    idxs = np.array([idx for idx in subpop_idx if idx != i])\n                    randomized_F = np.random.uniform(0.1, 1.0)\n                    if strategy == 0:\n                        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                        mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                    else:\n                        b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                        mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                    \n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    eval_count += 1\n                    \n                    if trial_fitness < fitness[i]:\n                        new_pop.append(trial)\n                        new_fitness.append(trial_fitness)\n                        if trial_fitness < best_fitness:\n                            best_fitness = trial_fitness\n                            best_individual = trial\n                        self.success_rate[strategy] += 1\n                        self.recent_success[strategy] += 1\n                    else:\n                        new_pop.append(pop[i])\n                        new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10819 with standard deviation 0.03894.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.134892269052161, 0.08357122415636631, 0.0633693883809674, 0.1560647117776368, 0.16610614381970956, 0.14245726487300858, 0.08594193586186327, 0.08037016468401137, 0.06097886132917896]}}
{"id": "4f9e0408-b8f3-42dc-95cc-e2408687c78e", "fitness": 0.10510406367485096, "name": "EnhancedSelfAdaptiveDifferentialEvolutionV2", "description": "Introduce an adaptive crossover rate dynamically adjusted based on the diversity in population to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            \n            # Dynamic adjustment of crossover rate based on population diversity\n            diversity = np.std(pop, axis=0).mean() / (ub - lb).mean()\n            self.CR = np.clip(0.5 + 0.5 * diversity, 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10510 with standard deviation 0.03975.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12348444437926243, 0.07451590810288922, 0.04703424873711459, 0.1540739105953597, 0.16610614381970956, 0.1424465520944821, 0.08594193586186327, 0.07940004781166177, 0.07293338167131602]}}
{"id": "59b1e018-7707-4a41-af85-4c974484cf86", "fitness": 0.11073369121792055, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive population resizing and dynamic crossover, enhancing adaptability and convergence speed by adjusting parameters based on success metrics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.95  # Change: More aggressive shrink factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))  # Change: More dynamic population resizing\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)  # Change: Dynamic CR adjustment\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11073 with standard deviation 0.03790.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1346559106453924, 0.10465723740133603, 0.05440390027135067, 0.1503720898352029, 0.16610614381970956, 0.14864666707118412, 0.08594193586186327, 0.07978592232857573, 0.07203341372667027]}}
{"id": "dcdc9dbf-0569-4853-868a-dfcd06fb9142", "fitness": -Infinity, "name": "AdaptiveGroupLearningDifferentialEvolution", "description": "Introduce adaptive group learning by dynamically adjusting group sizes and leveraging historical data to enhance both exploitation and exploration in differential evolution.", "code": "import numpy as np\n\nclass AdaptiveGroupLearningDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.group_size = 3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        historical_data = []\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                group = np.random.choice(idxs, self.group_size, replace=False)\n\n                if strategy == 0:\n                    a, b, c = pop[group]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[group[:2]]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                    historical_data.append((trial, trial_fitness))\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            self.group_size = max(3, int(pop_size / 10))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [\n                    (1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success)\n                    for prob, rate in zip(self.strategy_prob, self.recent_success)\n                ]\n                self.recent_success = [0, 0]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 81, "feedback": "An exception occurred: ValueError('too many values to unpack (expected 3)').", "error": "ValueError('too many values to unpack (expected 3)')", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {}}
{"id": "a0d339e8-578b-4df5-8807-5b006989d6ca", "fitness": 0.13725693224025634, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rates based on fitness improvements and integrate a memory mechanism to enhance strategy selection based on recent and historical success rates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9 \n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.memory_rate = [0.5, 0.5]  # New: Memory mechanism for strategy selection\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                adaptive_CR = self.CR * (1 + (fitness[i] - best_fitness) / max(fitness[i], 1e-10))\n                adaptive_CR = np.clip(adaptive_CR, 0.1, 0.9)\n                cross_points = np.random.rand(self.dim) < adaptive_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.memory_rate = [(1 - self.learning_rate) * mem + self.learning_rate * (rate / total_recent_success) for mem, rate in zip(self.memory_rate, self.recent_success)]\n                self.strategy_prob = self.memory_rate\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13726 with standard deviation 0.07312.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.31987304691231977, 0.11140738201764466, 0.07991699268831931, 0.1503720898352029, 0.17071743604246814, 0.15558636441459794, 0.08594193586186327, 0.08997350361106804, 0.07152363877882295]}}
{"id": "fe4905b4-b5a9-4735-b175-b904d8cd0b09", "fitness": -Infinity, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate adaptive population resizing and a success-history-based mutation strategy to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.adaptive_pop_scale = 1.0  # New: Adaptive population control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = int(self.initial_pop_size * self.adaptive_pop_scale)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    success_based_F = randomized_F * (self.success_rate[1] / max(1, sum(self.success_rate)))  # New: Success-history-based scaling\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + success_based_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            \n            # Adaptive population resizing based on success\n            if sum(self.recent_success) > 0:\n                self.adaptive_pop_scale += self.learning_rate * (np.random.rand() - 0.5)\n                pop_size = max(2, int(self.initial_pop_size * self.adaptive_pop_scale))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n\n        return best_individual, best_fitness", "configspace": "", "generation": 83, "feedback": "An exception occurred: IndexError('index 101 is out of bounds for axis 0 with size 99').", "error": "IndexError('index 101 is out of bounds for axis 0 with size 99')", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {}}
{"id": "0d682e72-bb71-4db2-935a-9b738c4ba4b4", "fitness": 0.14085561213532324, "name": "AdaptiveRestartDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Strategy Adjustment and Population Restart Strategy for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass AdaptiveRestartDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.no_improvement_limit = 150  # New: Limit for no improvement\n        self.no_improvement_counter = 0  # New: Counter for no improvement\n        self.best_fitness = float('inf')  # Track best fitness\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        self.best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            improvement_made = False\n\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    improvement_made = True\n                    if trial_fitness < self.best_fitness:\n                        self.best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            if not improvement_made:\n                self.no_improvement_counter += 1\n            else:\n                self.no_improvement_counter = 0\n            \n            if self.no_improvement_counter > self.no_improvement_limit:\n                pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                fitness = np.array([func(ind) for ind in pop])\n                self.no_improvement_counter = 0\n                continue  # Restart population\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, self.best_fitness", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveRestartDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14086 with standard deviation 0.09807.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.4002771865231819, 0.09488795427777175, 0.0679769154075398, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "a8320b15-f9f5-4eb2-a5a6-a362e92c97f6", "fitness": 0.0987007628670123, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance mutation diversity by incorporating adaptive scaling based on the best individual's improvement rate.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0 + (best_fitness / max(fitness)))  # Change: Adaptive scaling based on improvement rate\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09870 with standard deviation 0.04683.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.05981891221096047, 0.057625384860301554, 0.05049558874034521, 0.1548405628657581, 0.17741532315903086, 0.1561642148094884, 0.08594193586186327, 0.07940004781166177, 0.06660489548370119]}}
{"id": "317070a9-d80f-466a-9aca-5881ba0b1665", "fitness": 0.11385808615652193, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance strategy by dynamically adjusting the mutation factor based on a success-driven adaptive mechanism.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * (1 + self.success_rate[strategy] - self.success_rate[1-strategy]), lb, ub)  # Change: Adaptive scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11386 with standard deviation 0.04207.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.14131988061286527, 0.08039564706650149, 0.0778945258444581, 0.1743354947283815, 0.16610614381970956, 0.15641573359323113, 0.08594193586186327, 0.07940004781166177, 0.06291336607002529]}}
{"id": "a2e4dcd8-dadb-4338-93a8-d146635598ee", "fitness": 0.11140924222122955, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Refine strategy by adding adaptive mutation scaling, learning adaptive crossover rates, and utilizing a memory of past successful mutations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.memory = []  # Change: Memory to store successful mutations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutation_factor = np.mean(self.memory[-5:]) if len(self.memory) >= 5 else randomized_F  # Change: Use memory for mutation factor\n                    mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                    self.memory.append(randomized_F)  # Change: Store successful mutation factor\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11141 with standard deviation 0.03764.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.09846960421710349, 0.1337650959606702, 0.06932933317709433, 0.16079468591044432, 0.16610614381970956, 0.14386458047024875, 0.08594193586186327, 0.07940004781166177, 0.06501175276227034]}}
{"id": "7f5f5bf3-e45c-45fd-8890-5e7b25611887", "fitness": 0.1097977346435602, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance the convergence by dynamically adjusting the population size reduction factor based on performance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            self.pop_shrink_factor = 0.98 if np.mean(fitness) < np.mean(new_fitness) else 0.99  # Change: Dynamically adjust pop_shrink_factor\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10980 with standard deviation 0.03492.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1207562890973144, 0.09488795427777175, 0.0679769154075398, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "2b7006e8-00af-4270-b2f5-8267a5a8115b", "fitness": 0.10433835234972731, "name": "ImprovedDifferentialEvolution", "description": "Improved diversity and convergence by incorporating adaptive learning rates for scaling and crossover, alongside random local searches to escape local optima.", "code": "import numpy as np\n\nclass ImprovedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n                    if np.random.rand() < 0.05:  # Add random perturbation\n                        local_search = pop[i] + np.random.normal(0, 0.1, self.dim)\n                        local_search = np.clip(local_search, lb, ub)\n                        local_fitness = func(local_search)\n                        eval_count += 1\n\n                        if local_fitness < fitness[i]:\n                            new_pop[-1] = local_search\n                            new_fitness[-1] = local_fitness\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 89, "feedback": "The algorithm ImprovedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10434 with standard deviation 0.03778.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.08780072643821857, 0.06516911675972714, 0.07359120275512399, 0.15417885297272693, 0.16610614381970956, 0.14783562318316035, 0.08594193586186327, 0.091458399908529, 0.06696316944848701]}}
{"id": "b7a904bc-80f9-45b3-a994-70b60cbc6d4d", "fitness": 0.11444512822000125, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation and crossover rates guided by success over recent generations to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * ((self.success_rate[0] - self.success_rate[1]) / max(1, sum(self.success_rate))), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * ((self.success_rate[1] - self.success_rate[0]) / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11445 with standard deviation 0.03624.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.10733796122181116, 0.12806982174671722, 0.08105067775147046, 0.15191738886107842, 0.16737792301334886, 0.1601185648665332, 0.08594193586186327, 0.08135897469713427, 0.0668329059600542]}}
{"id": "e62d89da-47e0-4094-b803-dc93012fcaf6", "fitness": 0.09031212115514677, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Implement an adaptive mutation strategy and dynamically adjust the scaling factor and crossover rate based on population diversity to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n\n            diversity = np.std(pop, axis=0).mean()\n            adapt_F = np.clip(self.F + self.learning_rate * (diversity - 0.5), 0.1, 1.0)\n            adapt_CR = np.clip(self.CR + self.learning_rate * (0.5 - diversity), 0.1, 1.0)\n            \n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                \n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + adapt_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + adapt_F * (b - c), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < adapt_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09031 with standard deviation 0.04719.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.036024888908208874, 0.05062126416973878, 0.03831424675985162, 0.1503720898352029, 0.16610614381970956, 0.1417780835694996, 0.08594193586186327, 0.07940004781166177, 0.0642503896605845]}}
{"id": "8471fb13-0f06-47e3-95a8-dc9bd9c2b4d4", "fitness": 0.09460307417965086, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation factors and a selective crossover rate update to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                adaptive_F = np.random.uniform(0.5, 0.9)  # Change: Adaptive mutation factor range\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + adaptive_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Adaptive mutation factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + adaptive_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Adaptive mutation factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.3 + 0.7 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)  # Change: Selective crossover rate update\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09460 with standard deviation 0.04739.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.05428456962958572, 0.04825345095677247, 0.046060418141361414, 0.1606607313355638, 0.17297276788886817, 0.14170910868475106, 0.08594193586186327, 0.07940004781166177, 0.06214463730643005]}}
{"id": "9161ab4c-4827-4e50-8cd6-758a6413b77f", "fitness": 0.10983207110598532, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Implement a dynamic crossover rate strategy that adapts based on the success of recent generations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0 + self.learning_rate * (np.random.rand() - 0.5))  # Change: Dynamic crossover rate\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10983 with standard deviation 0.03418.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12020712456244353, 0.09381691719384344, 0.07193415398179648, 0.1503720898352029, 0.16610614381970956, 0.1431264846634176, 0.0861029585256392, 0.0898180361800569, 0.06700473119175832]}}
{"id": "97eb07a1-fbc2-4a0d-a2df-88f637837605", "fitness": 0.10311732111999884, "name": "EnhancedSelfAdaptiveDifferentialEvolutionV2", "description": "Enhance exploration by incorporating a diversity-preserving mechanism, adaptive mutation strategies, and dynamically adjusted crossover rates based on evolving landscape features.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.diversification_factor = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                diversification = self.diversification_factor * np.random.normal(size=self.dim)\n                mutant = np.clip(mutant + diversification, lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR_base\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F_base = np.clip(self.F_base + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR_base = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10312 with standard deviation 0.03997.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.07267251908377304, 0.07324308867543738, 0.0722115914248701, 0.16093182702102726, 0.16610614381970956, 0.14984664818552362, 0.08594193586186327, 0.07940004781166177, 0.06770208819612356]}}
{"id": "626cb20b-4a4f-46c2-9a61-fd3125939ec9", "fitness": 0.11244637388682893, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Improve adaptive mutation by introducing a dynamic crossover rate adjustment based on success rate changes.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(self.CR + self.learning_rate * (self.recent_success[0] - self.recent_success[1]) / max(1, sum(self.recent_success)), 0.1, 1.0)  # Change: Dynamic CR adjustment\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11245 with standard deviation 0.03759.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.12980080435679442, 0.08990126978417845, 0.06571068169825423, 0.1552135820935644, 0.16852105181332777, 0.15558636441459794, 0.08594193586186327, 0.0898180361800569, 0.07152363877882295]}}
{"id": "55972c72-1764-495c-8e84-967b2e9fe351", "fitness": 0.1097977346435602, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Enhance convergence by adding adaptive mutation rate based on fitness improvement.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]  # Change: Track recent success\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)  # Change: Dynamic scaling factor\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1  # Change: Track recent success\n                    self.F = np.clip(self.F + 0.1 * (fitness[i] - trial_fitness) / max(1, fitness[i]), 0.1, 1.0)  # Change: Adaptive mutation rate\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)  # Change: Use recent success for strategy probability\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]  # Change: Reset recent success\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10980 with standard deviation 0.03492.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1207562890973144, 0.09488795427777175, 0.0679769154075398, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "beb80cb8-1402-48e8-b421-8e4eed78edf4", "fitness": 0.10911544218378917, "name": "EnhancedSelfAdaptiveDifferentialEvolutionV2", "description": "Introduce local search intensification using Gaussian perturbations and adaptive strategy selection based on performance variance.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Initial crossover rate\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.local_search_prob = 0.2  # Probability of local search\n        self.local_search_radius = 0.05  # Radius for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                if np.random.rand() < self.local_search_prob:\n                    trial = np.clip(pop[i] + np.random.normal(0, self.local_search_radius, self.dim), lb, ub)\n                else:\n                    strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                    idxs = [idx for idx in range(pop_size) if idx != i]\n                    randomized_F = np.random.uniform(0.1, 1.0)\n                    if strategy == 0:\n                        a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                        mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                    else:\n                        b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                        mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                    \n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    if 'strategy' in locals():\n                        self.success_rate[strategy] += 1\n                        self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                strategy_var = np.var(self.recent_success)\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.strategy_prob = np.clip(self.strategy_prob, 0.1, 0.9)  # Avoid extreme probabilities\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10912 with standard deviation 0.03743.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.10214653881446878, 0.10919759987214206, 0.06070754855471494, 0.1625678206478458, 0.16610614381970956, 0.14463969709970614, 0.08594193586186327, 0.07940004781166177, 0.07133164717199025]}}
{"id": "2be35ad4-85a1-44f8-a875-f4398df4228d", "fitness": 0.1097977346435602, "name": "EnhancedSelfAdaptiveDifferentialEvolution", "description": "Introduce adaptive population resizing and parameter self-tuning to balance exploration and exploitation dynamically during the optimization process.", "code": "import numpy as np\n\nclass EnhancedSelfAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n        self.min_pop_size = 4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n        \n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n                \n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n                \n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c) * np.random.uniform(0.9, 1.1), lb, ub)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n            \n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(self.min_pop_size, int(self.pop_shrink_factor * len(pop)))\n            \n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n            \n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n        \n        return best_individual, best_fitness", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedSelfAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10980 with standard deviation 0.03492.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.1207562890973144, 0.09488795427777175, 0.0679769154075398, 0.15197868374418133, 0.16610614381970956, 0.14355850520604396, 0.0861029585256392, 0.0898180361800569, 0.06699412553378492]}}
{"id": "1ea71c20-5a9a-4b26-9dbd-37830a2372ce", "fitness": 0.10778823011589996, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Improve diversity and convergence by using adaptive step size scaling, elitist selection, and random walk exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.strategy_prob = [0.5, 0.5]\n        self.success_rate = [0, 0]\n        self.recent_success = [0, 0]\n        self.learning_rate = 0.1\n        self.pop_shrink_factor = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_individual = pop[best_idx]\n        best_fitness = fitness[best_idx]\n        eval_count = pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            new_fitness = []\n            for i in range(pop_size):\n                if eval_count >= self.budget:\n                    break\n\n                strategy = np.random.choice([0, 1], p=self.strategy_prob)\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                randomized_F = np.random.uniform(0.1, 1.0)\n                if strategy == 0:\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + randomized_F * (b - c), lb, ub)\n                else:\n                    b, c = pop[np.random.choice(idxs, 2, replace=False)]\n                    mutant = np.clip(best_individual + randomized_F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop.append(trial)\n                    new_fitness.append(trial_fitness)\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_individual = trial\n                    self.success_rate[strategy] += 1\n                    self.recent_success[strategy] += 1\n                else:\n                    new_pop.append(pop[i])\n                    new_fitness.append(fitness[i])\n\n            pop = np.array(new_pop)\n            fitness = np.array(new_fitness)\n            pop_size = max(2, int(self.pop_shrink_factor * len(pop)))\n\n            self.F = np.clip(self.F + self.learning_rate * (np.random.rand() - 0.5), 0.1, 1.0)\n            self.CR = np.clip(0.5 + 0.5 * (self.success_rate[1] / max(1, sum(self.success_rate))), 0.1, 1.0)\n\n            total_recent_success = sum(self.recent_success)\n            if total_recent_success > 0:\n                self.strategy_prob = [(1 - self.learning_rate) * prob + self.learning_rate * (rate / total_recent_success) for prob, rate in zip(self.strategy_prob, self.recent_success)]\n                self.recent_success = [0, 0]\n\n            # Random walk exploitation: Introduce a small chance to explore around the best solution found\n            if np.random.rand() < 0.05:\n                perturb = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                candidate = np.clip(best_individual + perturb, lb, ub)\n                candidate_fitness = func(candidate)\n                eval_count += 1\n                if candidate_fitness < best_fitness:\n                    best_fitness = candidate_fitness\n                    best_individual = candidate\n\n        return best_individual, best_fitness", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10779 with standard deviation 0.03907.", "error": "", "parent_ids": ["1721dbcd-a890-438c-80b6-f7a78d3ecc6f"], "operator": null, "metadata": {"aucs": [0.07865431234813303, 0.11850634227587309, 0.06339625027995244, 0.15360206774405571, 0.16610614381970956, 0.1567710288551376, 0.08594193586186327, 0.08004639346698927, 0.06706959639138566]}}
