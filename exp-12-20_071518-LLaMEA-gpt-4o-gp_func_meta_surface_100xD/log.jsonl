{"id": "c0e9127a-a6a4-496d-9410-ab609eb28b43", "fitness": 0.062476849847734925, "name": "HybridDEPSO", "description": "A hybrid evolutionary algorithm combining differential evolution and particle swarm optimization for robust black-box optimization across diverse problem landscapes.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 1.5       # Cognitive weight\n        self.c2 = 1.5       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06247338899532795, 0.06247292011508743, 0.06248423685912696, 0.06247339255981088, 0.062472923679745995, 0.06248424042435097, 0.06247338900416899, 0.06247292012405481, 0.06248423686794036]}}
{"id": "b0c3d1dd-2761-4cdd-915f-f27badfdec16", "fitness": 0.06247699949066584, "name": "HybridDEPSO", "description": "Enhanced the exploration capability of HybridDEPSO by adjusting the velocity update in PSO with dynamic weights to improve global search efficiency.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocity[i] = (0.7 * self.w * velocity[i] +  # Changed line\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["c0e9127a-a6a4-496d-9410-ab609eb28b43"], "operator": null, "metadata": {"aucs": [0.06247435978957383, 0.06247267759275743, 0.06248395751599389, 0.06247436335414791, 0.06247268115743265, 0.06248396108113874, 0.062474359798410095, 0.0624726776016139, 0.06248395752492408]}}
{"id": "30ab163c-b749-4c98-b394-d468e14a2f9d", "fitness": 0.0624765388274401, "name": "HybridDEPSO", "description": "Improved HybridDEPSO by implementing adaptive mutation factor in DE for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                adaptive_F = 0.5 + 0.1 * np.random.rand()  # Changed line\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)  # Changed line\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocity[i] = (0.7 * self.w * velocity[i] +  # Changed line\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["b0c3d1dd-2761-4cdd-915f-f27badfdec16"], "operator": null, "metadata": {"aucs": [0.06247278889335761, 0.06247255784050887, 0.06248426617460301, 0.062472792457986204, 0.06247256140519353, 0.06248426973996779, 0.06247278890232644, 0.06247255784942818, 0.062484266183589265]}}
{"id": "4477d5e2-10ca-46d8-8835-efa79ebac187", "fitness": 0.06247700482472075, "name": "HybridDEPSO", "description": "Refined HybridDEPSO by dynamically adjusting the inertia weight `w` to enhance convergence speed while maintaining exploration capability.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))  # Dynamically adjust inertia weight\n                velocity[i] = (self.w * velocity[i] +  # Adjusted line\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["b0c3d1dd-2761-4cdd-915f-f27badfdec16"], "operator": null, "metadata": {"aucs": [0.06247432935824726, 0.062472360795367, 0.06248432074670096, 0.06247433292285898, 0.062472364360028676, 0.06248432431212736, 0.06247432936715125, 0.06247236080432106, 0.06248432075568422]}}
{"id": "558c6431-1471-440e-972b-1c33f1060fcb", "fitness": 0.06247638702162393, "name": "AdaptiveHybridDEPSO", "description": "Enhance HybridDEPSO with adaptive parameter control for F and CR based on population diversity to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min, self.F_max = 0.4, 0.9  # Adaptive Differential evolution scale factor range\n        self.CR_min, self.CR_max = 0.1, 0.9  # Adaptive Crossover probability range\n        self.w_min, self.w_max = 0.4, 0.9  # Inertia weight range\n        self.c1 = 2.0  # Cognitive weight\n        self.c2 = 2.0  # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Evaluate population diversity\n            diversity = np.mean(np.std(pop, axis=0))\n            adapt_ratio = (diversity - np.min(diversity)) / (np.max(diversity) - np.min(diversity) + 1e-9)\n            \n            # Adaptive parameters\n            F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n            CR = self.CR_min + adapt_ratio * (self.CR_max - self.CR_min)\n            w = self.w_max - adapt_ratio * (self.w_max - self.w_min)\n            \n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocity[i] = (w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.062475524681192995, 0.062469500987247906, 0.06248413182276147, 0.06247552824580638, 0.06246950455170308, 0.062484135388130135, 0.062475524689955764, 0.0624695009960714, 0.06248413183174628]}}
{"id": "07e39d85-cb39-49a3-989c-3889238629e8", "fitness": 0.06247613538759514, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO by introducing adaptive mutation strategies and chaotic maps to improve exploration and convergence in dynamic environments.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  \n        self.F = 0.5        \n        self.CR = 0.9       \n        self.w = 0.5        \n        self.c1 = 2.0       \n        self.c2 = 2.0       \n        self.eval_count = 0\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # Logistic map\n\n    def adaptive_mutation(self, F, budget_ratio):\n        return F * (1 + 0.5 * np.sin(np.pi * budget_ratio))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        current_chaos = np.random.rand()\n\n        while self.eval_count < self.budget:\n            budget_ratio = self.eval_count / self.budget\n            self.F = self.adaptive_mutation(self.F, budget_ratio)\n            current_chaos = self.chaotic_map(current_chaos)\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * budget_ratio) * current_chaos\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.062472463542514456, 0.062471720893109595, 0.0624842181535088, 0.0624724671069119, 0.06247172445765414, 0.06248422171884482, 0.06247246355150793, 0.062471720901869254, 0.06248421816243532]}}
{"id": "400f1c9a-d32b-4a4a-a1f6-71af6497e82f", "fitness": 0.0624752966716893, "name": "HybridDEPSO", "description": "Introduce adaptive parameter control for the crossover probability `CR` and differential evolution scale factor `F` in HybridDEPSO, improving exploration-exploitation balance through the optimization process.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.w = 0.5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Adjust CR and F dynamically based on progress\n            progress_ratio = self.eval_count / self.budget\n            self.CR = 0.9 - 0.5 * progress_ratio\n            self.F = 0.5 + 0.5 * progress_ratio\n            \n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * progress_ratio)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.06247146360196287, 0.06247021505399686, 0.06248420778555697, 0.06247146716628882, 0.06247021861855828, 0.0624842113507077, 0.06247146361083222, 0.062470215062978895, 0.06248420779432107]}}
{"id": "86533899-df93-4d5c-a805-0fc39251a113", "fitness": 0.06247697388247978, "name": "HybridDEPSO", "description": "Enhanced HybridDEPSO by introducing adaptive crossover probability to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))  # Dynamically adjust inertia weight\n                self.CR = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))  # Adapt crossover probability\n                velocity[i] = (self.w * velocity[i] +  # Adjusted line\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.06247426347555729, 0.06247263472661835, 0.062484019871494545, 0.06247426704004666, 0.062472638291447447, 0.062484023436815805, 0.06247426348437346, 0.0624726347355985, 0.062484019880366004]}}
{"id": "778b08d3-bfd5-47a3-829b-24a69bec4c82", "fitness": 0.062476453782334386, "name": "HybridDEPSO", "description": "Enhanced HybridDEPSO by integrating adaptive crossover probability to further balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = 0.9 - (0.5 * (self.eval_count / self.budget))  # Dynamically adjust CR\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))  # Dynamically adjust inertia weight\n                velocity[i] = (self.w * velocity[i] + \n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.062473740102103936, 0.062471263641003416, 0.0624843540301212, 0.06247374366673708, 0.06247126720578444, 0.06248435759533055, 0.06247374011106033, 0.06247126364998323, 0.062484354038885304]}}
{"id": "8d1bf2b2-8bd9-497c-a66d-ed84b3bd3384", "fitness": -Infinity, "name": "HybridDEPSO", "description": "Incorporating a dynamic population size adjustment mechanism in HybridDEPSO to enhance exploration and exploitation balance throughout optimization.", "code": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 50  # Initial population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (current_pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += current_pop_size\n\n        velocity = np.random.uniform(-1, 1, (current_pop_size, self.dim))\n\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            new_pop_size = self.initial_pop_size + int((self.budget - self.eval_count) / self.budget * self.initial_pop_size)\n            if new_pop_size != current_pop_size:\n                pop = np.resize(pop, (new_pop_size, self.dim))\n                velocity = np.resize(velocity, (new_pop_size, self.dim))\n                personal_best = np.resize(personal_best, (new_pop_size, self.dim))\n                personal_best_fitness = np.resize(personal_best_fitness, new_pop_size)\n                current_pop_size = new_pop_size\n\n            for i in range(current_pop_size):\n                idxs = np.random.choice(np.delete(np.arange(current_pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            for i in range(current_pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 9, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {}}
{"id": "5aa5bfb7-206f-45ab-91bd-5bcb7ff20b6e", "fitness": 0.06247697414654579, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO by integrating adaptive mutation scaling based on convergence progress to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Initial Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive F\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                F = 0.5 + 0.5 * (1 - self.eval_count / self.budget)  # Adaptive mutation scaling\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))  # Dynamically adjust inertia weight\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.062475209606982385, 0.06247149119989892, 0.06248421805917048, 0.0624752131715931, 0.06247149476445302, 0.06248422162431899, 0.06247520961579678, 0.062471491208671015, 0.0624842180680274]}}
{"id": "c9eb1a7b-b8de-417d-a635-715dc753933f", "fitness": 0.062475685967403286, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO by implementing adaptive mutation strategies and adaptive crossover rates to boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Adaptive Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                adaptive_F = self.F + np.random.normal(0, 0.1)  # Adaptive mutation strategy\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n                adaptive_CR = self.CR * (1 - self.eval_count / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.062473864233586696, 0.062469115325576086, 0.06248407476949458, 0.062473867798085614, 0.062469118890020714, 0.062484078334704485, 0.06247386424237389, 0.062469115334344516, 0.06248407477844298]}}
{"id": "44092814-4fd6-4282-b698-be3b09000df0", "fitness": 0.062476325309073606, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO by introducing an adaptive mutation strategy in DE and utilizing a convergence-enhancing local search operator in PSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F = 0.5        # Initial DE scale factor\n        self.CR = 0.9       # Crossover probability\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Adaptive Differential Evolution step\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                F_adaptive = 0.5 + 0.3 * (1 - (self.eval_count / self.budget))  # Adaptive scale factor\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization with local search step\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))  # Dynamically adjust inertia weight\n                velocity[i] = (w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                # Local search operator\n                local_step = np.random.uniform(-0.1, 0.1, self.dim)\n                pop[i] = np.clip(pop[i] + local_step, lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.06247484987529828, 0.06247010588120494, 0.06248401659702418, 0.062474853439869804, 0.06247010944585718, 0.06248402016217369, 0.062474849884254224, 0.06247010589019186, 0.062484016605788284]}}
{"id": "005b28ef-3e26-4757-a4e7-fc72c4e946e3", "fitness": 0.062474448462371664, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO by incorporating adaptive differential evolution parameters and a local search mechanism to improve exploitation abilities.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.4    # Min DE scale factor\n        self.F_max = 0.9    # Max DE scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w = 0.5        # Inertia weight for PSO\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            for i in range(self.pop_size):\n                adaptive_F = self.F_min + (self.F_max - self.F_min) * (self.eval_count / self.budget)\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * (self.eval_count / self.budget))\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                local_search = pop[i] + 0.01 * np.random.randn(self.dim)\n                local_search = np.clip(local_search, lb, ub)\n                current_fitness = func(local_search)\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop[i] = local_search\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06247 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.06246767185644908, 0.062471392719745666, 0.062484277237402575, 0.06246767542068299, 0.06247139628431164, 0.062484280802632464, 0.06246767186540336, 0.06247139272855362, 0.062484277246163566]}}
{"id": "e5de2b3e-4650-44f2-9fa6-83cba213e083", "fitness": 0.06247703646506023, "name": "EnhancedHybridDEPSO", "description": "Enhanced HybridDEPSO by incorporating adaptive mutation scaling in DE and learning-based inertia weight adjustments in PSO for balanced exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.8    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Learning-based adjustment\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["4477d5e2-10ca-46d8-8835-efa79ebac187"], "operator": null, "metadata": {"aucs": [0.0624739410331816, 0.06247289931688549, 0.062484265471335676, 0.062473944597682074, 0.06247290288161278, 0.06248426903675697, 0.06247394104200654, 0.06247289932574962, 0.06248426548033137]}}
{"id": "8466c7c4-e41b-4cbc-b9ec-2fdc8761b049", "fitness": 0.06247723663847698, "name": "EnhancedHybridDEPSO", "description": "Introduce diversity by adding a random perturbation in the PSO velocity update to escape local optima.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.8    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Learning-based adjustment\n                random_perturbation = np.random.normal(0, 0.1, self.dim)  # New line for diversity\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation  # Modified line with perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["e5de2b3e-4650-44f2-9fa6-83cba213e083"], "operator": null, "metadata": {"aucs": [0.06247413851533867, 0.06247317964291199, 0.06248438818340318, 0.062474142080027995, 0.06247318320760742, 0.06248439174861453, 0.062474138524277856, 0.06247317965172661, 0.062484388192384555]}}
{"id": "a58fc0d7-9b42-437b-b84d-22042539f375", "fitness": 0.06247718076710981, "name": "EnhancedHybridDEPSO", "description": "Add a dynamic random perturbation factor to enhance exploration as the budget progresses.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.8    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Learning-based adjustment\n                random_perturbation = np.random.normal(0, 0.1 * (1 - self.eval_count / self.budget), self.dim)  # Dynamic perturbation\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation  # Modified line with perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["8466c7c4-e41b-4cbc-b9ec-2fdc8761b049"], "operator": null, "metadata": {"aucs": [0.06247434288938769, 0.06247311666512667, 0.06248407917303944, 0.06247434645391492, 0.062473120229984525, 0.06248408273823225, 0.06247434289816056, 0.06247311667410582, 0.06248407918203647]}}
{"id": "e31e452e-1f9a-4622-bce4-60c898d70eba", "fitness": 0.062476109650622585, "name": "DynamicEnhancedHybridDEPSO", "description": "Enhance convergence by integrating a dynamic population size and adaptive mutation step in the hybrid DE-PSO algorithm to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicEnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_pop_size = 50  # Initial population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop_size = self.init_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Dynamic population adjustment based on convergence\n            if self.eval_count > self.budget / 2:\n                pop_size = self.init_pop_size // 2\n                pop = pop[:pop_size]\n                velocity = velocity[:pop_size]\n                personal_best = personal_best[:pop_size]\n                personal_best_fitness = personal_best_fitness[:pop_size]\n            \n            # Differential Evolution step with adaptive scaling\n            F = self.F_min + (self.F_max - self.F_min) * np.exp(-self.eval_count / self.budget)\n            for i in range(pop_size):\n                idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Learning-based adjustment\n                random_perturbation = np.random.normal(0, 0.1, self.dim)  # Diversity\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation  # Modified line with perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 17, "feedback": "The algorithm DynamicEnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8466c7c4-e41b-4cbc-b9ec-2fdc8761b049"], "operator": null, "metadata": {"aucs": [0.062472037004384307, 0.06247195254478255, 0.062484335828933646, 0.0624720405687218, 0.062471956109572124, 0.06248433939436571, 0.06247203701315185, 0.06247195255377602, 0.06248433583791524]}}
{"id": "6657c4b5-c02e-4fb7-94c5-0ec324afe208", "fitness": 0.06247730057092815, "name": "RefinedHybridDEPSO", "description": "Introduce adaptive mutation strategies in DE and integrate an elite preservation mechanism to enhance exploration and exploitation balance in DEPSO.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 18, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8466c7c4-e41b-4cbc-b9ec-2fdc8761b049"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.0624720596941285, 0.062484404895829404, 0.062475437113867716, 0.06247206325871735, 0.06248440846099945, 0.06247543355808194, 0.06247205970303693, 0.06248440490459006]}}
{"id": "3882820a-ddaf-497a-83b9-fd6d22421cb9", "fitness": 0.062476017935988636, "name": "EnhancedHybridDEPSO", "description": "Incorporate a dynamic balance between exploration and exploitation by adjusting crossover probability and cognitive-social weights based on population diversity in RefinedHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR_min = 0.5\n        self.CR_max = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_min = 1.5\n        self.c1_max = 2.5\n        self.c2_min = 1.5\n        self.c2_max = 2.5\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Dynamic adaptation of parameters\n            diversity = np.std(pop, axis=0).mean()\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - (diversity / (ub - lb).mean()))\n            c1 = self.c1_min + (self.c1_max - self.c1_min) * (diversity / (ub - lb).mean())\n            c2 = self.c2_min + (self.c2_max - self.c2_min) * (diversity / (ub - lb).mean())\n            \n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               c1 * r1 * (personal_best[i] - pop[i]) +\n                               c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["6657c4b5-c02e-4fb7-94c5-0ec324afe208"], "operator": null, "metadata": {"aucs": [0.06247460672930494, 0.06246906228772742, 0.062484381217201124, 0.06247461029402035, 0.062469065852094996, 0.062484384782577784, 0.0624746067382983, 0.06246906229648974, 0.06248438122618305]}}
{"id": "6ab521ad-8c8c-4a6b-8b9f-93d05b9b6e30", "fitness": 0.06247671026384871, "name": "RefinedHybridDEPSO", "description": "Improve stability by adding a small perturbation to the global best update.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial + np.random.normal(0, 1e-5, global_best.shape)\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 20, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["6657c4b5-c02e-4fb7-94c5-0ec324afe208"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06247028877295657, 0.062484404895829404, 0.062475437113867716, 0.06247029233744894, 0.06248440846099945, 0.06247543355808194, 0.062470288781762306, 0.06248440490459006]}}
{"id": "faa996de-3a51-48fa-8446-4a243f04383b", "fitness": 0.062477132601537616, "name": "RefinedHybridDEPSO", "description": "Refine the velocity update in PSO by introducing a random perturbation scaled by the current inertia weight.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))\n                random_perturbation = np.random.normal(0, self.w, self.dim)  # Refined line\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 21, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["6657c4b5-c02e-4fb7-94c5-0ec324afe208"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06247177178509811, 0.06248418889669305, 0.062475437113867716, 0.06247177534966597, 0.06248419246188863, 0.06247543355808194, 0.06247177179385832, 0.06248418890558283]}}
{"id": "850c3250-4920-494e-a638-5d3fb816763f", "fitness": 0.06247733644786825, "name": "RefinedHybridDEPSO", "description": "Introduce non-linear scaling of inertia weight to improve convergence speed and balance exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min) # Non-linear scaling of inertia weight\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 22, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["6657c4b5-c02e-4fb7-94c5-0ec324afe208"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06247238544008926, 0.06248418678056866, 0.062475437113867716, 0.062472389004755935, 0.06248419034590347, 0.06247543355808194, 0.06247238544890388, 0.062484186789541374]}}
{"id": "0d9b82ee-586a-4c3b-a1f9-fd812f7ff4a3", "fitness": 0.06247677516310232, "name": "RefinedHybridDEPSO", "description": "Introduce dynamic crossover probability adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR_max = 0.9   # Maximum Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            CR = self.CR_max * (1 - (self.eval_count / self.budget))  # Dynamic crossover probability\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR  # Adjusted crossover points\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min) # Non-linear scaling of inertia weight\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 23, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06247055459157069, 0.06248433377498486, 0.062475437113867716, 0.06247055815605662, 0.06248433734016501, 0.06247543355808194, 0.062470554600332684, 0.062484333783759394]}}
{"id": "f216c860-b775-4758-b1e4-5d64b6d557bf", "fitness": 0.06247661259640295, "name": "EnhancedAdaptiveDEPSO", "description": "Integrate an adaptive learning strategy in PSO for dynamic adjustment of cognitive and social weights to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1_min = 1.5   # Minimum cognitive weight\n        self.c1_max = 2.5   # Maximum cognitive weight\n        self.c2_min = 1.5   # Minimum social weight\n        self.c2_max = 2.5   # Maximum social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Adaptive PSO step with dynamic cognitive and social weights\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                c1 = self.c1_min + (self.c1_max - self.c1_min) * (global_best_fitness - personal_best_fitness[i]) / (global_best_fitness + 1e-10)\n                c2 = self.c2_min + (self.c2_max - self.c2_min) * (global_best_fitness - pop_fitness[i]) / (global_best_fitness + 1e-10)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               c1 * r1 * (personal_best[i] - pop[i]) +\n                               c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06246996293145879, 0.06248441699141827, 0.06247543711780901, 0.06247002846992589, 0.06248442053533776, 0.06247543355808194, 0.062469963214150215, 0.062484417000342685]}}
{"id": "8d62c981-6c64-4f0b-aa86-3a4f87000dfb", "fitness": 0.062476252129099574, "name": "EnhancedStochasticHybridDEPSO", "description": "Introduce stochastic parameter adaptation to further enhance exploration and exploitation balance in hybrid DE-PSO.", "code": "import numpy as np\n\nclass EnhancedStochasticHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.2\n        self.F_max = 0.8\n        self.CR_base = 0.8\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + np.random.rand() * (self.F_max - self.F_min)\n            CR = self.CR_base + np.random.normal(0, 0.1) * (1 - (self.eval_count / self.budget))\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_min + (self.w_max - self.w_min) * np.exp(-5 * self.eval_count / self.budget)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedStochasticHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247205121922217, 0.06247286250236028, 0.06248383909206756, 0.062472054783615394, 0.06247286606703728, 0.06248384265720053, 0.06247205122820543, 0.06247286251135398, 0.06248383910083355]}}
{"id": "a65a0612-ab16-4953-8efc-f3f4c0ffb9d6", "fitness": 0.06247713877716816, "name": "EnhancedHybridDEPSO", "description": "Introducing adaptive learning rates for Differential Evolution and PSO to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum DE scale factor\n        self.F_max = 0.9    # Maximum DE scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Adaptive Differential Evolution step\n            F = self.F_min + (self.F_max - self.F_min) * np.exp(-(self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Adaptive PSO step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = (self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * self.eval_count / self.budget)) # Adaptive inertia weight\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.0624754335239498, 0.062471659005790325, 0.06248432022806161, 0.06247543708855319, 0.06247166257038028, 0.06248432379326918, 0.0624754335329063, 0.0624716590145854, 0.06248432023701733]}}
{"id": "fed5ee3b-5abf-43a0-9886-b18d7d185379", "fitness": 0.062476783135741405, "name": "EnhancedHybridDEPSO", "description": "Introduce a convergence-driven adaptive mutation strategy to enhance both local exploitation and global exploration.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eps = 1e-8     # Small constant to avoid division by zero\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with convergence-driven adaptive mutation\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (global_best_fitness / (np.min(pop_fitness) + self.eps)))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min) # Non-linear scaling of inertia weight\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247385890611801, 0.062472421854568694, 0.06248406507274129, 0.0624738624707869, 0.06247242541925013, 0.06248406863807621, 0.06247385891510848, 0.062472421863315586, 0.06248406508170734]}}
{"id": "016f86e7-7c56-453f-b9b9-18e0aa890d32", "fitness": 0.06247677471292317, "name": "RefinedHybridDEPSO", "description": "Introduce random initial inertia weights to further balance exploration and exploitation in the early stages.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50  # Population size\n        self.F_min = 0.3    # Minimum Differential evolution scale factor\n        self.F_max = 0.9    # Maximum Differential evolution scale factor\n        self.CR = 0.9       # Crossover probability\n        self.w_max = 0.9    # Maximum inertia weight\n        self.w_min = 0.4    # Minimum inertia weight\n        self.c1 = 2.0       # Cognitive weight\n        self.c2 = 2.0       # Social weight\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize population\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        # Initialize velocity for PSO\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        \n        # Track personal bests for PSO\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        # Track global best\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Differential Evolution step with adaptive amplitude scaling\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            # Particle Swarm Optimization step with learning-based inertia\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = (np.random.uniform(self.w_min, self.w_max) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min) # Random initial inertia weight\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 28, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06247058807023553, 0.062484298945778116, 0.062475437113867716, 0.06247059163472213, 0.06248430251098358, 0.06247543355808194, 0.06247058807899819, 0.06248429895453933]}}
{"id": "7f0097de-ff26-477a-ac3a-2febf0bfcd5f", "fitness": 0.06247717508668165, "name": "EnhancedHybridDEPSO", "description": "Introduce a population diversity measure and adaptive mutation strategy to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        def population_diversity():\n            mean_pop = np.mean(pop, axis=0)\n            return np.mean(np.sqrt(np.sum((pop - mean_pop) ** 2, axis=1)))\n        \n        while self.eval_count < self.budget:\n            diversity = population_diversity()\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget)) * (1 + diversity)\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247456004915919, 0.06247268982152243, 0.0624842718155908, 0.06247456361372461, 0.06247269338635553, 0.06248427538077439, 0.06247456005797358, 0.06247268983048504, 0.0624842718245493]}}
{"id": "91c13d20-2fde-4290-b481-b12bd2043fb6", "fitness": 0.0624772535792365, "name": "AdaptiveHybridDEPSO", "description": "Introduce adaptive learning rates based on feedback from convergence trends to dynamically balance exploration and exploitation in the optimization process.", "code": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.eval_count = 0\n        self.previous_best_fitness = None\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_index = np.argmin(pop_fitness)\n            elite = np.copy(pop[elite_index])\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c) + 0.5 * (elite - a), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n                            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n            \n            # Adaptive learning rate adjustment\n            if self.previous_best_fitness is not None:\n                fitness_improvement = self.previous_best_fitness - global_best_fitness\n                if fitness_improvement < 1e-6:  # Threshold to detect stagnation\n                    self.c1 *= 0.95  # Decrease cognitive component\n                    self.c2 *= 1.05  # Increase social component\n                else:\n                    self.c1 *= 1.05  # Increase cognitive component\n                    self.c2 *= 0.95  # Decrease social component\n            \n            self.previous_best_fitness = global_best_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.06247543354910201, 0.06247238544008926, 0.06248393817466924, 0.062475437113867716, 0.062472389004755935, 0.06248394174002958, 0.06247543355808194, 0.06247238544890388, 0.06248393818362896]}}
{"id": "8aeddd81-450b-4eec-a569-5b4f4b428e93", "fitness": 0.062477428960369515, "name": "EnhancedHybridDEPSO", "description": "Introduce adaptive random search and elitism in RefinedHybridDEPSO to enhance exploration and maintain diversity while improving convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["850c3250-4920-494e-a638-5d3fb816763f"], "operator": null, "metadata": {"aucs": [0.062475365669532046, 0.06247272673469606, 0.062484190903251524, 0.06247536923407604, 0.062472730299360735, 0.06248419446843356, 0.062475365678295924, 0.06247272674365256, 0.06248419091202717]}}
{"id": "4efcb957-8afb-410b-bf99-898a73215312", "fitness": 0.062477036455287176, "name": "EnhancedAdaptiveDEPSO", "description": "Utilize adaptive inertia weight and mutation factor tuning alongside a dynamic elite mechanism to improve convergence and diversity in HybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.2\n        self.F_max = 0.8\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n            self.elite_fraction = 0.05 + 0.15 * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.06247422825036386, 0.06247295070147463, 0.06248392684035953, 0.06247423181487832, 0.06247295426621979, 0.06248393040558098, 0.062474228259126297, 0.062472950710355635, 0.062483926849225546]}}
{"id": "ae570bf6-963d-49af-b734-2102557af24d", "fitness": 0.062477164567671876, "name": "EnhancedHybridDEPSO", "description": "Introduce adaptive inertia weights and dynamic crossover rates to further enhance exploration and exploitation balance in EnhancedHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR_min = 0.5  # Changed from static to dynamic\n        self.CR_max = 0.9  # Added for dynamic crossover rate\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (self.eval_count / self.budget)  # Dynamic CR\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.06247530168630244, 0.0624720838878956, 0.0624841045551463, 0.06247530525101219, 0.06247208745255983, 0.062484108120302695, 0.06247530169515225, 0.06247208389675751, 0.062484104563918064]}}
{"id": "2ed1deab-8be5-4ea8-911f-3b554377f753", "fitness": 0.06247629266181823, "name": "EnhancedHybridDEPSO", "description": "Integrate adaptive inertia weight and self-adaptive DE mutation strategies in EnhancedHybridDEPSO to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        F = np.full(self.pop_size, self.F_min)\n        \n        while self.eval_count < self.budget:\n            self.w = self.w_min + (self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget)\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    F[i] = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n                    mutant = np.clip(a + F[i] * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < np.random.rand()\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.06247285070930697, 0.06247173594165689, 0.06248428776077308, 0.06247285427381999, 0.06247173950624452, 0.06248429132613309, 0.06247285071821351, 0.06247173595045796, 0.06248428776975801]}}
{"id": "d5f7f35c-bea7-4cc2-ba3d-f16991b37b30", "fitness": 0.0624770739155749, "name": "EnhancedHybridDEPSO", "description": "Enhance the exploration-exploitation balance in EnhancedHybridDEPSO by integrating a dynamic population size and a self-adaptive crossover strategy.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 50\n        self.min_pop_size = 20\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR_max = 0.9\n        self.CR_min = 0.1\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += pop_size\n\n        velocity = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n\n            for i in range(pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n\n            if pop_size > self.min_pop_size and self.eval_count % (self.budget // 10) == 0:\n                pop_size = max(self.min_pop_size, int(pop_size * 0.9))\n                pop = pop[:pop_size]\n                pop_fitness = pop_fitness[:pop_size]\n                velocity = velocity[:pop_size]\n                personal_best = personal_best[:pop_size]\n                personal_best_fitness = personal_best_fitness[:pop_size]\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.06247450657145337, 0.06247259426994867, 0.062484117331599864, 0.06247451013600547, 0.06247259783458847, 0.06248412089694544, 0.0624745065804192, 0.06247259427871843, 0.06248411734049519]}}
{"id": "43065f59-c128-4f85-b6c6-cd34867ba9c6", "fitness": 0.062477428960369515, "name": "EnhancedHybridDEPSO", "description": "Introduce adaptive inertia weight adjustment to balance exploration and exploitation in EnhancedHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((1 - self.eval_count / self.budget) ** 2) + self.w_min)  # Changed the inertia weight adjustment\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.062475365669532046, 0.06247272673469606, 0.062484190903251524, 0.06247536923407604, 0.062472730299360735, 0.06248419446843356, 0.062475365678295924, 0.06247272674365256, 0.06248419091202717]}}
{"id": "1848a3e2-5f83-484b-8a70-4051c9c710af", "fitness": 0.062475975915004485, "name": "RefinedEnhancedHybridDEPSO", "description": "Introduce adaptive differential mutation and crowding distance sorting to EnhancedHybridDEPSO for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            \n            sorted_indices = np.argsort(pop_fitness)\n            sorted_pop = pop[sorted_indices]\n            sorted_pop_fitness = pop_fitness[sorted_indices]\n            \n            for i in range(self.pop_size):\n                idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < pop_fitness[i]:\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < global_best_fitness:\n                            global_best = trial\n                            global_best_fitness = trial_fitness\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) + self.w_min)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]))\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n            \n            # Crowding Distance Calculation and Replacement\n            distances = np.zeros(self.pop_size)\n            for i in range(self.dim):\n                sorted_indices = np.argsort(pop[:, i])\n                distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n                for j in range(1, self.pop_size - 1):\n                    distances[sorted_indices[j]] += (pop[sorted_indices[j + 1], i] - pop[sorted_indices[j - 1], i])\n\n            sorted_indices = np.argsort(distances)[::-1]\n            pop = pop[sorted_indices[:self.pop_size]]\n            pop_fitness = pop_fitness[sorted_indices[:self.pop_size]]\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 37, "feedback": "The algorithm RefinedEnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.0624729918012652, 0.062471242994046605, 0.06248368937600024, 0.06247299536570161, 0.06247124655858294, 0.06248369294127887, 0.0624729918102187, 0.0624712430030363, 0.06248368938490989]}}
{"id": "d87af5ac-b70e-445d-9c88-872a80c5ea54", "fitness": 0.062477298368606604, "name": "RefinedEnhancedHybridDEPSO", "description": "Incorporate dynamic local search intensification and adaptive mutation scaling to boost exploitation and accelerate convergence in EnhancedHybridDEPSO.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n\n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    dynamic_mutation_factor = F * (0.5 + np.linalg.norm(global_best - pop[i]) / (ub - lb))\n                    mutant = np.clip(a + dynamic_mutation_factor * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 38, "feedback": "The algorithm RefinedEnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.06247537512925094, 0.0624723169049074, 0.062484199497750526, 0.062475378693907846, 0.062472320469761033, 0.06248420306311664, 0.062475375138109746, 0.06247231691391997, 0.06248419950673534]}}
{"id": "6bb5515e-8bae-4e0e-a62a-f36fcd7f66ab", "fitness": 0.062477424154597734, "name": "RefinedHybridDEPSO", "description": "Integrate a dynamic learning factor and opposition-based learning in EnhancedHybridDEPSO to enhance adaptability and improve convergence precision.", "code": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_max = 2.5\n        self.c1_min = 1.0\n        self.c2_max = 2.5\n        self.c2_min = 1.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n\n    def opposition_based_learning(self, pop, lb, ub):\n        return lb + ub - pop\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n\n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = ((self.w_max - self.w_min) * ((self.budget - self.eval_count) / self.budget) ** 2 + self.w_min)\n                c1 = self.c1_min + (self.c1_max - self.c1_min) * (self.eval_count / self.budget)\n                c2 = self.c2_min + (self.c2_max - self.c2_min) * (self.eval_count / self.budget)\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               c1 * r1 * (personal_best[i] - pop[i]) +\n                               c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n\n            # Apply opposition-based learning\n            opposite_pop = self.opposition_based_learning(pop, lb, ub)\n            opposite_fitness = np.array([func(ind) for ind in opposite_pop])\n            self.eval_count += self.pop_size\n            for i in range(self.pop_size):\n                if opposite_fitness[i] < pop_fitness[i]:\n                    pop[i] = opposite_pop[i]\n                    pop_fitness[i] = opposite_fitness[i]\n                    if opposite_fitness[i] < personal_best_fitness[i]:\n                        personal_best[i] = opposite_pop[i]\n                        personal_best_fitness[i] = opposite_fitness[i]\n                        if opposite_fitness[i] < global_best_fitness:\n                            global_best = opposite_pop[i]\n                            global_best_fitness = opposite_fitness[i]\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 39, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.0624753567521521, 0.06247263574094786, 0.06248427639696519, 0.062475360316773476, 0.06247263930557634, 0.062484279962332745, 0.062475356760966716, 0.06247263574971518, 0.06248427640595]}}
{"id": "0e0f4f50-7b01-44a7-bc7e-e879ac488651", "fitness": 0.062477478240769595, "name": "EnhancedHybridDEPSO", "description": "Introduce exponential decay to inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Changed to exponential decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["8aeddd81-450b-4eec-a569-5b4f4b428e93"], "operator": null, "metadata": {"aucs": [0.0624753567521521, 0.062472797632896926, 0.06248427676348345, 0.062475360316773476, 0.06247280119773391, 0.06248428032868869, 0.062475356760966716, 0.062472797641880295, 0.0624842767723508]}}
{"id": "ff4d2a69-a5ae-480e-a38e-5260120e0438", "fitness": 0.06247684825035411, "name": "EnhancedHybridDEPSO_V2", "description": "Adaptive elite selection and diversity preservation for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - np.exp(-5 * self.eval_count / self.budget))\n            elite_size = max(1, int(self.pop_size * self.elite_fraction * np.cos(np.pi * self.eval_count / self.budget)))\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.95 ** (self.eval_count / self.budget))  # Adjusted exponential decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHybridDEPSO_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.0624745284832221, 0.06247191634319749, 0.06248409635087415, 0.06247453204782405, 0.062471919908028584, 0.062484099916018554, 0.06247452849220303, 0.062471916352180856, 0.06248409635963814]}}
{"id": "1fe40b42-1100-4e34-a0c8-610a96f56560", "fitness": 0.06247731844921853, "name": "EnhancedHybridDEPSO", "description": "Incorporate adaptive mutation scaling and dynamic population size to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 50\n        self.final_pop_size = 20\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_pop_size\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += pop_size\n\n        velocity = np.random.uniform(-1, 1, (pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * np.sin(0.5 * np.pi * (1 - (self.eval_count / self.budget)))\n            elite_size = int(pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n\n            for i in range(pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Exponential decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n\n            # Dynamically adjust population size\n            new_pop_size = int(self.initial_pop_size - ((self.initial_pop_size - self.final_pop_size) * (self.eval_count / self.budget)))\n            if new_pop_size < pop_size:\n                sorted_indices = np.argsort(pop_fitness)\n                pop = pop[sorted_indices[:new_pop_size]]\n                pop_fitness = pop_fitness[sorted_indices[:new_pop_size]]\n                personal_best = personal_best[sorted_indices[:new_pop_size]]\n                personal_best_fitness = personal_best_fitness[sorted_indices[:new_pop_size]]\n                velocity = velocity[sorted_indices[:new_pop_size]]\n                pop_size = new_pop_size\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.062475360543272074, 0.06247248018253859, 0.06248411104817386, 0.062475364107867026, 0.0624724837471925, 0.062484114613373665, 0.06247536055208147, 0.06247248019129925, 0.062484111057168334]}}
{"id": "c021124d-afe2-4a8d-aad7-753ee8a30d2b", "fitness": 0.062477290811111676, "name": "EnhancedAdaptiveDEPSO", "description": "Incorporate adaptive mutation scaling and neighborhood-based selection to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * np.exp(-5 * (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n\n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    neighborhood_indices = np.random.choice(self.pop_size, 5, replace=False)\n                    best_neighbor_idx = neighborhood_indices[np.argmin(pop_fitness[neighborhood_indices])]\n                    a, b, c = pop[best_neighbor_idx], pop[np.random.choice(neighborhood_indices)], pop[np.random.choice(neighborhood_indices)]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Adaptive inertia weight\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.062475321977051634, 0.06247222482440218, 0.06248432205805243, 0.06247532554164781, 0.06247222838920785, 0.06248432562342976, 0.06247532198581085, 0.062472224833368784, 0.062484322067033804]}}
{"id": "8603e5fb-1ccd-49ce-b1a9-f5b4b03c481b", "fitness": 0.062476824420716434, "name": "EnhancedHybridDEPSO", "description": "Incorporate adaptive mutation based on population diversity to enhance exploration in EnhancedHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            diversity_factor = np.std(pop, axis=0).mean() / (ub - lb)  # Line 1: Calculate diversity factor\n            F *= (1 + diversity_factor)  # Line 2: Adjust F by diversity factor\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):  # Line 3-5: Modify lines related to velocity and exploration\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  \n                random_perturbation = np.random.normal(0, 0.1, self.dim) * diversity_factor  # Line 6\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.06247389366571687, 0.0624727656862516, 0.06248381033656958, 0.06247389723027719, 0.062472769250892735, 0.06248381390175828, 0.06247389367459655, 0.06247276569502214, 0.06248381034536299]}}
{"id": "c7e3f824-905f-43ca-8bcd-f0daacbbb373", "fitness": 0.06247614055356505, "name": "EnhancedHybridDEPSO", "description": "Introduce a non-uniform mutation mechanism based on function evaluation progress to enhance global search capability.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    T = self.eval_count / self.budget\n                    non_uniform_mutation_factor = np.exp(-5 * T)  # Added line for non-uniform mutation\n                    mutant = np.clip(a + F * (b - c) * non_uniform_mutation_factor + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Changed to exponential decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.06247192346120012, 0.06247230155142092, 0.06248419307452768, 0.06247192702563675, 0.06247230511606583, 0.06248419663967075, 0.06247192347007591, 0.0624723015601919, 0.06248419308329556]}}
{"id": "2b65d952-ed31-4b60-8680-078988c52631", "fitness": 0.06247727512812608, "name": "EnhancedAdaptiveDEPSO", "description": "Introduce adaptive inertia weight and differential mutation scaling for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n\n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n\n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n\n        while self.eval_count < self.budget:\n            progress_ratio = self.eval_count / self.budget\n            F = self.F_min + (self.F_max - self.F_min) * np.exp(-progress_ratio)  # Adaptive mutation scaling\n            self.w = self.w_max - (self.w_max - self.w_min) * progress_ratio  # Adaptive inertia weight\n\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n\n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n\n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n\n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n\n        return global_best, global_best_fitness", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.0624753605515731, 0.06247218847915326, 0.06248427278004698, 0.06247536411616983, 0.06247219204376642, 0.062484276345235124, 0.06247536056033598, 0.06247218848800673, 0.06248427278884727]}}
{"id": "a8359fc3-6df8-4957-bf11-8f00741a62b7", "fitness": 0.062477176981753896, "name": "EnhancedHybridDEPSO", "description": "Integrate a piecewise linear decay for inertia weight to enhance convergence dynamics.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Changed to linear decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.0624753567521521, 0.06247220332697445, 0.0624839672925146, 0.062475360316773476, 0.062472206891596604, 0.06248397085766699, 0.062475356760966716, 0.06247220333573589, 0.062483967301404264]}}
{"id": "f4b47387-ea51-4eb5-9108-447c05f02990", "fitness": 0.062477267481767434, "name": "EnhancedHybridDEPSO", "description": "Adjusted elite fraction to enhance the algorithm's focus on top solutions.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.15  # Adjusted from 0.1 to 0.15\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Changed to exponential decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.062475093663028836, 0.06247275525661178, 0.06248394995199469, 0.06247509722760691, 0.06247275882125136, 0.06248395351717595, 0.06247509367206694, 0.06247275526537466, 0.06248394996079576]}}
{"id": "75f1751e-de64-407b-ba87-0d6b82a11b36", "fitness": 0.0624766092237749, "name": "EnhancedHybridDEPSOAdaptive", "description": "Introduce adaptive mutation factor and neighborhood learning mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSOAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            # Adaptive mutation factor based on diversity\n            diversity = np.mean(np.std(pop, axis=0))\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget)) * (diversity / (ub - lb).mean())\n            \n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Exponential decay\n                random_perturbation = np.random.normal(0, 0.1, self.dim)\n                # Enhanced velocity update using neighborhood learning\n                neighbors_idx = np.random.choice(np.delete(np.arange(self.pop_size), i), 2, replace=False)\n                neighbor_best = pop[np.argmin(pop_fitness[neighbors_idx])]\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i]) +\n                               0.5 * (neighbor_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridDEPSOAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.062475296138570724, 0.0624701493433949, 0.062484378615753955, 0.062475299703120823, 0.062470152907904586, 0.062484382180976294, 0.06247529614733338, 0.062470149352196636, 0.06248437862472278]}}
{"id": "237a79f8-a2c6-4f8f-8737-bf3e44f6f78e", "fitness": 0.062477489695164236, "name": "EnhancedHybridDEPSO", "description": "Adjust perturbation spread by modifying standard deviation based on convergence progress.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Changed to exponential decay\n                random_perturbation = np.random.normal(0, 0.1 * (1 - self.eval_count / self.budget), self.dim)  # Adjusted standard deviation\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00000.", "error": "", "parent_ids": ["0e0f4f50-7b01-44a7-bc7e-e879ac488651"], "operator": null, "metadata": {"aucs": [0.06247535683425243, 0.06247273751731641, 0.06248437116020733, 0.06247536039884738, 0.062472741082158945, 0.06248437472536328, 0.06247535684306704, 0.062472737526293676, 0.06248437116897165]}}
{"id": "844218e2-95df-4b09-babe-043136d54859", "fitness": 0.06247714118950191, "name": "EnhancedHybridDEPSO", "description": "Improved weight decay strategy for better convergence control in EnhancedHybridDEPSO.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - (self.w_max - self.w_min) * (self.eval_count / self.budget)  # Changed to linear decay\n                random_perturbation = np.random.normal(0, 0.1 * (1 - self.eval_count / self.budget), self.dim)  # Adjusted standard deviation\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["237a79f8-a2c6-4f8f-8737-bf3e44f6f78e"], "operator": null, "metadata": {"aucs": [0.0624753567521521, 0.06247190095225941, 0.06248416229037923, 0.062475360316773476, 0.06247190451704232, 0.06248416585553851, 0.062475356760966716, 0.062471900961222016, 0.06248416229918341]}}
{"id": "d7242076-1d72-4d33-9eb8-5f5eb54d14ff", "fitness": 0.062476309196505805, "name": "EnhancedHybridDEPSO", "description": "Introduce adaptive crossover probability to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < (self.CR * (1 - self.eval_count / self.budget))  # Adaptive CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Changed to exponential decay\n                random_perturbation = np.random.normal(0, 0.1 * (1 - self.eval_count / self.budget), self.dim)  # Adjusted standard deviation\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["237a79f8-a2c6-4f8f-8737-bf3e44f6f78e"], "operator": null, "metadata": {"aucs": [0.06247253993595847, 0.06247231600940417, 0.06248406807053186, 0.0624725435003608, 0.062472319574074064, 0.06248407163573699, 0.062472539944774086, 0.062472316018204466, 0.06248406807950735]}}
{"id": "7aaaf356-7a66-429f-905f-de4906fd84ab", "fitness": 0.062475601402741394, "name": "EnhancedHybridDEPSO", "description": "Introduce adaptive crossover rate by decreasing CR dynamically as the evaluation progresses to maintain diversity.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            self.CR = 0.9 * (1 - (self.eval_count / self.budget))  # Adaptive crossover rate\n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max * (0.99 ** self.eval_count)  # Changed to exponential decay\n                random_perturbation = np.random.normal(0, 0.1 * (1 - self.eval_count / self.budget), self.dim)  # Adjusted standard deviation\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["237a79f8-a2c6-4f8f-8737-bf3e44f6f78e"], "operator": null, "metadata": {"aucs": [0.062471588814975054, 0.062471012322317, 0.06248419949743589, 0.0624715923792577, 0.062471015886819914, 0.06248420306260127, 0.06247158882384474, 0.062471012331202, 0.062484199506218974]}}
{"id": "5d454166-0ab8-4915-9a29-61bbe6c568e9", "fitness": 0.062476973741785104, "name": "EnhancedHybridDEPSO", "description": "Incorporating adaptive inertia weight strategy and improved selection using crowding distance-based diversity preservation.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - (self.eval_count / self.budget) * (self.w_max - self.w_min)  # Adaptive inertia weight\n                random_perturbation = np.random.normal(0, 0.1 * (1 - self.eval_count / self.budget), self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + random_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["237a79f8-a2c6-4f8f-8737-bf3e44f6f78e"], "operator": null, "metadata": {"aucs": [0.06247404581704141, 0.06247282207913951, 0.06248404975560373, 0.06247404938149925, 0.062472825643777874, 0.06248405332081308, 0.062474045825888114, 0.06247282208788518, 0.06248404976441779]}}
{"id": "d1f1b386-3cc5-43f6-aa74-29a7a5d8cf54", "fitness": 0.06247714573426314, "name": "EnhancedHybridDEPSO", "description": "Implement a dynamic neighborhood search strategy to enhance exploration and exploitation phases.", "code": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 50\n        self.F_min = 0.3\n        self.F_max = 0.9\n        self.CR = 0.9\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.elite_fraction = 0.1\n        self.eval_count = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n        self.eval_count += self.pop_size\n        \n        velocity = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.copy(pop_fitness)\n        \n        global_best_idx = np.argmin(pop_fitness)\n        global_best = np.copy(pop[global_best_idx])\n        global_best_fitness = pop_fitness[global_best_idx]\n        \n        while self.eval_count < self.budget:\n            F = self.F_min + (self.F_max - self.F_min) * (1 - (self.eval_count / self.budget))\n            elite_size = int(self.pop_size * self.elite_fraction)\n            elite_indices = np.argsort(pop_fitness)[:elite_size]\n            elites = pop[elite_indices]\n            \n            for i in range(self.pop_size):\n                if i not in elite_indices:\n                    idxs = np.random.choice(np.delete(np.arange(self.pop_size), i), 3, replace=False)\n                    a, b, c = pop[idxs]\n                    mutant = np.clip(a + F * (b - c) + 0.5 * (elites[np.random.randint(elite_size)] - a), lb, ub)\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, pop[i])\n                    \n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < pop_fitness[i]:\n                        pop[i] = trial\n                        pop_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < global_best_fitness:\n                                global_best = trial\n                                global_best_fitness = trial_fitness\n            \n            for i in range(self.pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_max - ((self.w_max - self.w_min) * (self.eval_count / self.budget))  # Linear decay\n                dynamic_perturbation = np.random.normal(0, 0.1 * np.linalg.norm(global_best - pop[i]) / np.sqrt(self.dim), self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best[i] - pop[i]) +\n                               self.c2 * r2 * (global_best - pop[i])) + dynamic_perturbation\n                pop[i] = np.clip(pop[i] + velocity[i], lb, ub)\n                \n                current_fitness = func(pop[i])\n                self.eval_count += 1\n                if current_fitness < pop_fitness[i]:\n                    pop_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[i]:\n                        personal_best[i] = pop[i]\n                        personal_best_fitness[i] = current_fitness\n                        if current_fitness < global_best_fitness:\n                            global_best = pop[i]\n                            global_best_fitness = current_fitness\n        \n        return global_best, global_best_fitness", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06248 with standard deviation 0.00001.", "error": "", "parent_ids": ["237a79f8-a2c6-4f8f-8737-bf3e44f6f78e"], "operator": null, "metadata": {"aucs": [0.062475358580528106, 0.062471909355445554, 0.062484165692992755, 0.06247536214512728, 0.06247191292021692, 0.06248416925818834, 0.06247535858948605, 0.06247190936443159, 0.0624841657019517]}}
