{"id": "d1e4af54-6726-4910-9325-f1844c1f80cb", "fitness": 0.015967946579285783, "name": "HybridOptimizer", "description": "A hybrid metaheuristic combining differential evolution and simulated annealing to efficiently explore and exploit the search space in black box optimization.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial individual\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Simulated Annealing acceptance criterion\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Cooling\n                self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 0, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01597 with standard deviation 0.03163.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00220138388059099, 0.002600849944929151, 0.0004844090985521854, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.01841103586234727, 0.019750460529314284, 0.015088552075721795, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.038217998823837585, 0.04053208321684154, 0.03830551274434746, 0.08575267664542341, 0.08464980385597931, 0.08333530804756795, 0.02803552628352357, 0.02616144393161124, 0.026680595857971223, 0.06144519656583358, 0.058316405022125206, 0.05310226834018794, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.012239141199442471, 0.00981170136039955, 0.010097700075340388, 0.013936712199622558, 0.011594062276930162, 0.010096831784516147, 0.13457483298714756, 0.12708606545251966, 0.12718359564595172, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "caa7f1e8-ef0d-49d4-959e-a92ceaa3709f", "fitness": 0.017362079711653444, "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer with adaptive mutation factor and crossover probability for improved convergence and exploration.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5  # Adaptive mutation factor\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial individual\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Simulated Annealing acceptance criterion\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Cooling\n                self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 1, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01736 with standard deviation 0.03274.", "error": "", "parent_ids": ["d1e4af54-6726-4910-9325-f1844c1f80cb"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.001831579413644202, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0012875199431523487, 0.0003708563282691646, 0.000263899065327422, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.02464958319659516, 0.024894797982032757, 0.03242062836935822, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.04433483405959604, 0.05116247880808644, 0.03785152904710254, 0.084311804845554, 0.08570641013263713, 0.08840539653550006, 0.0303190876879188, 0.031709221908420404, 0.028841912712549544, 0.06269397705732183, 0.0660578209748176, 0.0672834807055579, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.010781042211426728, 0.014003211678079941, 0.01292010143405764, 0.016173809353315693, 0.013138873121235739, 0.0157729747983667, 0.13571051253124078, 0.1305463180049682, 0.12684829955513655, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "ccdae76d-ce18-4b8a-b1c0-e675f46cbeb4", "fitness": -Infinity, "name": "HybridOptimizer", "description": "Enhanced HybridOptimizer with dynamically adjusted population size for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.population_size = 50 + int(0.1 * evaluations)  # Dynamically adjust population size\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5  # Adaptive mutation factor\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial individual\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Simulated Annealing acceptance criterion\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Cooling\n                self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 2, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_ids": ["caa7f1e8-ef0d-49d4-959e-a92ceaa3709f"], "operator": null, "metadata": {}}
{"id": "ee283342-791b-45fd-8021-2357e6e14f84", "fitness": 0.016632960879856093, "name": "HybridOptimizer", "description": "Increased the population size for enhanced exploration and potentially better convergence in the optimization process.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 60  # Increased population size\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5  # Adaptive mutation factor\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial individual\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Simulated Annealing acceptance criterion\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Cooling\n                self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01663 with standard deviation 0.03200.", "error": "", "parent_ids": ["caa7f1e8-ef0d-49d4-959e-a92ceaa3709f"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.0002338682657548885, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.028181331030834644, 0.026532098683979877, 0.018237023526798013, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03648912680011662, 0.03790662299828207, 0.04244666717664869, 0.0858787883146993, 0.08565031583706328, 0.08588098270002975, 0.029111171995572227, 0.03200507741573766, 0.029955036089469256, 0.058696071462996935, 0.06371455093711864, 0.06007213445701831, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.011624190143967428, 0.015468256308961315, 0.010557586282557208, 0.012370347591083908, 0.014018458466723671, 0.013889972497097336, 0.12490698156224456, 0.13178461190184587, 0.13151746645859208, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "92e82550-f9eb-48a7-817f-e41d86b46c1f", "fitness": 0.017453922845584766, "name": "HybridOptimizer", "description": "Improved HybridOptimizer with dynamic population size adjustment for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05  # New: Dynamic population size adjustment\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adjust population size dynamically\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                # Differential Evolution mutation\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5  # Adaptive mutation factor\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Evaluate trial individual\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Simulated Annealing acceptance criterion\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n                # Cooling\n                self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01745 with standard deviation 0.03261.", "error": "", "parent_ids": ["caa7f1e8-ef0d-49d4-959e-a92ceaa3709f"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.0013009680781091992, 0.0007087963117705653, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0011786861095713919, 0.0005298335782056851, 0.002082018499474869, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.024199366236775544, 0.028697977879665326, 0.03030781388774384, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03931326389518697, 0.05116247880808644, 0.03831775578055685, 0.08499301091720712, 0.08500948727098978, 0.08823871996027244, 0.029165327445403233, 0.03218817518080641, 0.029273337967814617, 0.061698575347770346, 0.06748502182517946, 0.0671862750167177, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.011033661935555661, 0.01783168613759456, 0.013138961342339273, 0.02012614391370393, 0.01309605507114997, 0.017270309933369088, 0.13571051253124078, 0.13125260819001883, 0.12463006027426715, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "ba8e6929-b3dd-4b4f-b885-389586bd2850", "fitness": 0.017473053458727586, "name": "HybridOptimizer", "description": "Improved HybridOptimizer using adaptive cooling rate for better convergence speed.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Adapt cooling rate\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 5, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01747 with standard deviation 0.03261.", "error": "", "parent_ids": ["92e82550-f9eb-48a7-817f-e41d86b46c1f"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.0013009680781091992, 0.0007087963117705653, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0011786861095713919, 0.0005298335782056851, 0.0021674046672809366, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.024199366236775544, 0.028697977879665326, 0.030656695998599215, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03931326389518697, 0.05116247880808644, 0.03831775578055685, 0.08493090831497685, 0.08947942153390209, 0.0876627826465477, 0.029165327445403233, 0.03218817518080641, 0.029273337967814617, 0.061698575347770346, 0.06748502182517946, 0.0671862750167177, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.01106232001983376, 0.013023243825732056, 0.015768277636470485, 0.01603122005886204, 0.015812437508318067, 0.020086051294825435, 0.12447825593616335, 0.1305463180049682, 0.13439311656472996, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "299d0a11-069c-4bcb-a1fc-6653fdaacb5f", "fitness": 0.0175472640018919, "name": "HybridOptimizer", "description": "Enhanced mutation strategy by incorporating adaptive mutation scaling based on fitness variance to improve robustness.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9))  # Enhanced mutation strategy\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Adapt cooling rate\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 6, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01755 with standard deviation 0.03349.", "error": "", "parent_ids": ["ba8e6929-b3dd-4b4f-b885-389586bd2850"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.002033675733582596, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.004656915288604013, 0.006982294427617997, 0.0035493201740894875, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0398409897002685, 0.03832728545721287, 0.041611465567955586, 0.09606516964844403, 0.09802634738028293, 0.09262901378319788, 0.02149967714623946, 0.01972014335201333, 0.01871204513478364, 0.06486461539144472, 0.059200213552810355, 0.06328288445147456, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03609770785744226, 0.0354182887368758, 0.03533816123750588, 0.029182609538650817, 0.02007613265510433, 0.032828485114413275, 0.1276532473711437, 0.12633855993686927, 0.13902331505374466, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "c3c20d95-2d5e-4cea-9aac-2e36b802da80", "fitness": 0.016815364958822344, "name": "HybridOptimizer", "description": "Introduced dynamic crossover probability scaling based on fitness improvement rate to enhance exploration.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9))  # Enhanced mutation strategy\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                improvement_rate = (1 - fitness[i] / (np.mean(fitness) + 1e-9))  # Line modified\n                self.crossover_probability = 0.6 + improvement_rate * 0.4  # Line modified\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))  # Line modified\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 7, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01682 with standard deviation 0.03206.", "error": "", "parent_ids": ["299d0a11-069c-4bcb-a1fc-6653fdaacb5f"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.009564980965527048, 0.007824365868543737, 0.010293333877147481, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0042027077697514015, 0.0028173344091501074, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.037889963697684714, 0.03870684901273069, 0.041264542744082644, 0.09204731446228687, 0.08693183405537297, 0.08521772236344849, 0.017343567788910108, 0.012531115193610387, 0.01586984587748619, 0.05749841493760688, 0.062241149091126435, 0.05731334683194833, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03339270389321325, 0.021316836827137142, 0.028432924936346082, 0.03158490859757679, 0.027890046186582418, 0.03173314786253123, 0.1289627221635018, 0.13005375370586847, 0.12755862169381438, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "4e46fcde-e9ad-42a7-a634-e18361461000", "fitness": 0.017170450295706328, "name": "HybridOptimizer", "description": "Increased dynamic population size adjustment factor to enhance exploration in early stages of optimization.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.1  # Increased from 0.05 to 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9))  # Enhanced mutation strategy\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Adapt cooling rate\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 8, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01717 with standard deviation 0.03313.", "error": "", "parent_ids": ["299d0a11-069c-4bcb-a1fc-6653fdaacb5f"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00347487456619211, 0.0007351757504429068, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.005092138050711625, 0.005632341378786765, 0.0030349070194835015, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03853961830135677, 0.03854218242577856, 0.04099613520356937, 0.10123201072560772, 0.09882336683163706, 0.0900324853308414, 0.019491815277659197, 0.022740132083225895, 0.018240951810439943, 0.06376288542811237, 0.06229537194285495, 0.06806239876647324, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.023326113031740925, 0.03188925224441708, 0.021786463941029233, 0.0368140393752443, 0.02002166996670085, 0.028137332799337944, 0.1309982615427241, 0.12638997832512855, 0.12595829694913652, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "eb52edf2-c0d8-4132-b26b-e602fb233b2d", "fitness": 0.018371109435266555, "name": "HybridOptimizer", "description": "Refined mutation factor calculation by including best fitness ratio to enhance convergence speed.  ", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))  # Refined mutation factor\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Adapt cooling rate\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 9, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01837 with standard deviation 0.03337.", "error": "", "parent_ids": ["299d0a11-069c-4bcb-a1fc-6653fdaacb5f"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.001716036098923901, 0.0005941339471866591, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.011905659828588933, 0.015571666891029734, 0.010298033407196483, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.037404036889633674, 0.03656403566651534, 0.04292575799264986, 0.08624471414982471, 0.09337246575039404, 0.08737806519629476, 0.028858857556890993, 0.03010304703287714, 0.03057210246171682, 0.06873064078596591, 0.07261716782667083, 0.0751072659974652, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03789087307906691, 0.03504701128310561, 0.035764574490702805, 0.032498629798201395, 0.020936583678321963, 0.029252834972650188, 0.12650423251022724, 0.13433325693959308, 0.13030597288527512, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "71ec9c19-7736-45f7-8f69-0078f7dc32f1", "fitness": 0.01823738917068317, "name": "HybridOptimizer", "description": "Enhanced exploration with adaptive dynamic population size based on evaluation distance to budget.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * (self.budget - evaluations) / self.budget))  # Change made here\n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))  # Refined mutation factor\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Adapt cooling rate\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 10, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01824 with standard deviation 0.03366.", "error": "", "parent_ids": ["eb52edf2-c0d8-4132-b26b-e602fb233b2d"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.020280789747684436, 0.008101768299537904, 0.007929604049870198, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03990259354561876, 0.039926186298631205, 0.03986371490559293, 0.09691198520001254, 0.09254263091652681, 0.09047436367494699, 0.024039235298505268, 0.023317608799746203, 0.02995794140239927, 0.0675267420064597, 0.07128712128328052, 0.06923440792399738, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.031501924738062015, 0.032406839706372925, 0.03056038523705784, 0.02396022708059109, 0.034578204882733, 0.03445151618335007, 0.12738285864374022, 0.1308621088769376, 0.13542459492086611, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "903ff80a-bf70-4d52-a05f-147cd8cdfbec", "fitness": 0.024583576995957115, "name": "HybridOptimizer", "description": "Incorporate adaptive dynamic scaling and diversity preservation to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0  # New parameter for dynamic scaling\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)  # Modified mutation with scale factor\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0  # Reset scale factor on improvement\n                else:\n                    self.scale_factor *= 1.05  # Increase scale factor to enhance exploration\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 11, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02458 with standard deviation 0.05973.", "error": "", "parent_ids": ["eb52edf2-c0d8-4132-b26b-e602fb233b2d"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.2619997690270901, 0.3279839058024271, 0.20903397292192094, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0022126546311004303, 0.0009939843541819648, 0.0008284844804321567, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0405582345981339, 0.036477306241787466, 0.041258012907377184, 0.0694168952180797, 0.0742950467574166, 0.07299262674410223, 0.01096166021840106, 0.011915773956698295, 0.010451033363510609, 0.05030916325665724, 0.04715615583885202, 0.05202529789776544, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007312679243876574, 0.007523975568181185, 0.0075237183545272535, 0.007064974091471332, 0.007088770087542384, 0.007973667418823327, 0.1286456802142495, 0.13301208901606232, 0.13300201149824342, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "74e598d3-3a72-4778-a207-772359f50bd2", "fitness": 0.013575931207728677, "name": "HybridOptimizer", "description": "Enhance diversity by incorporating a noise factor in the mutation process.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0  # New parameter for dynamic scaling\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                self.mutation_factor = 0.5 + np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                noise_factor = np.random.normal(0, 0.1, self.dim)  # Added noise factor for diversity\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c) + noise_factor, self.lower_bound, self.upper_bound)  # Modified mutation with noise\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0  # Reset scale factor on improvement\n                else:\n                    self.scale_factor *= 1.05  # Increase scale factor to enhance exploration\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 12, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01358 with standard deviation 0.03098.", "error": "", "parent_ids": ["903ff80a-bf70-4d52-a05f-147cd8cdfbec"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0007611478211151379, 0.00023378611656843518, 0.003300670525422711, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.039040328333078356, 0.039478428207758265, 0.0384641881877027, 0.0744036503773976, 0.07384466047327587, 0.07415905235657672, 0.009767815417470294, 0.012208075699851606, 0.008583748026479543, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007333746821217013, 0.007523975568181185, 0.0075237183545272535, 0.006945606096194323, 0.007088770087542384, 0.007603384082002118, 0.12882006881175478, 0.14067867424478042, 0.12979854899492682, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "786ca3d2-d2f7-4bf1-8d89-3f4d32b2801a", "fitness": 0.026151412170384195, "name": "HybridOptimizer", "description": "Introduce dynamic mutation factor decay to enhance local exploitation as budget depletes.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 13, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02615 with standard deviation 0.06625.", "error": "", "parent_ids": ["903ff80a-bf70-4d52-a05f-147cd8cdfbec"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.35392886284107483, 0.31914554653648175, 0.24543342615775676, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0022126546311004303, 0.0034222337304561368, 0.0016266113082989975, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03658800242247218, 0.04213479184373703, 0.03634099263082535, 0.06943679291844762, 0.07288500411231957, 0.06998241160003738, 0.012414141024458814, 0.013727718643550268, 0.011926006045813398, 0.05030916325665724, 0.04715615583885202, 0.05202529789776544, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007312682305703366, 0.007523975568181185, 0.0075237183545272535, 0.007064977395744965, 0.007088770087542384, 0.00797387924299231, 0.13152171464345697, 0.1285639370285243, 0.1276322082008836, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "d136c695-7beb-42bc-a018-dd1136a5d5d7", "fitness": 0.022773953614050397, "name": "HybridOptimizer", "description": "Integrate adaptive crossover probability based on fitness variance to enhance exploration capabilities.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4 * (np.std(fitness) / (np.mean(fitness) + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 14, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02277 with standard deviation 0.05211.", "error": "", "parent_ids": ["786ca3d2-d2f7-4bf1-8d89-3f4d32b2801a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.20216646761116874, 0.2586004817160672, 0.2143431751937287, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03978375787556132, 0.03870784237809555, 0.041283911601341594, 0.07234759840002958, 0.07606413717183713, 0.0732233386848895, 0.008732557621547676, 0.013263334935183169, 0.010419828731190739, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007286936012244283, 0.007523975568181185, 0.0075237183545272535, 0.0069484667840792325, 0.007796486242821032, 0.007102675436246653, 0.13028470317951946, 0.12697843333787473, 0.12943783102285267, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "4b5c6da1-f423-406d-98cf-7aa04bd33e56", "fitness": 0.026151412170384195, "name": "HybridOptimizer", "description": "Increase the cooling rate slightly to improve convergence speed in the later stages of optimization.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.995  # Changed from 0.99 to 0.995\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.random.rand() * 0.4\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 15, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02615 with standard deviation 0.06625.", "error": "", "parent_ids": ["786ca3d2-d2f7-4bf1-8d89-3f4d32b2801a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.35392886284107483, 0.31914554653648175, 0.24543342615775676, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0022126546311004303, 0.0034222337304561368, 0.0016266113082989975, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03658800242247218, 0.04213479184373703, 0.03634099263082535, 0.06943679291844762, 0.07288500411231957, 0.06998241160003738, 0.012414141024458814, 0.013727718643550268, 0.011926006045813398, 0.05030916325665724, 0.04715615583885202, 0.05202529789776544, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007312682305703366, 0.007523975568181185, 0.0075237183545272535, 0.007064977395744965, 0.007088770087542384, 0.00797387924299231, 0.13152171464345697, 0.1285639370285243, 0.1276322082008836, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "ac9708dd-b02c-4f3b-a55f-72d78510c099", "fitness": 0.027744205820971767, "name": "HybridOptimizer", "description": "Utilize adaptive crossover probability decay to enhance exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 16, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02774 with standard deviation 0.07379.", "error": "", "parent_ids": ["786ca3d2-d2f7-4bf1-8d89-3f4d32b2801a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.30468263049571154, 0.3460410644365498, 0.3982934543700507, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.040837520542913675, 0.03791052110656523, 0.03945101653626848, 0.07015165840654058, 0.07299141486325322, 0.06993278628953337, 0.011333241545923078, 0.008530342353552323, 0.012031024455584793, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007747884262735427, 0.007523975568181185, 0.0075237183545272535, 0.007418868366239173, 0.007088770087542384, 0.007481197414783702, 0.124405143635406, 0.1261773320081, 0.13012425165736408, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "69a2dda6-8509-4259-8dfc-0991da68d3b1", "fitness": 0.018035022703785573, "name": "HybridOptimizer", "description": "Introduce adaptive scaling to mutation factor for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9)) * np.sqrt(evaluations / self.budget)\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 17, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01804 with standard deviation 0.03918.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.21242391128297466, 0.03721685067236746, 0.10352952722195785, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03673189266950028, 0.037211159078852196, 0.03571264472482916, 0.07328479883303285, 0.07003296785039548, 0.07131184907633825, 0.01184611090585208, 0.010115415030771624, 0.010360420602266052, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007747936314912884, 0.007523975568181185, 0.0075237183545272535, 0.007418839994390525, 0.007088770087542384, 0.0074811630011827335, 0.1270529767415094, 0.13313553410145917, 0.12386617020707658, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "b0e88d75-7e6c-4346-b614-8d366b5ad676", "fitness": 0.01985464071606924, "name": "HybridOptimizer", "description": "Introduce a dynamic adjustment to the mutation factor to improve convergence efficiency.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = np.clip(0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9)), 0.1, 1.0)  # Adjusted for stability\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 18, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01985 with standard deviation 0.04250.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.1587523672228578, 0.217528535706755, 0.090901137689967, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.005385148473084023, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.040837520542913675, 0.037777894905761666, 0.038198608311006965, 0.07596268033688625, 0.074307400344791, 0.07308623861547736, 0.009991933068544734, 0.010569083373628274, 0.011061661480013085, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007747884262735427, 0.007523975568181185, 0.0075237183545272535, 0.007418868366239173, 0.007088770087542384, 0.007481197414783702, 0.124405143635406, 0.1261773320081, 0.13012425165736408, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "50e794f7-19e2-4fd4-b0f3-93ce20e23402", "fitness": 0.02390920603516889, "name": "HybridOptimizer", "description": "Incorporate a dynamic scale factor adjustment to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.07  # Slightly increasing dynamic scale factor adjustment\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 19, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02391 with standard deviation 0.05966.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.3841066779091993, 0.1570765229004205, 0.21768984350811726, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.004378871496298564, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03964271891227955, 0.040447553721421725, 0.042235024359974394, 0.074613852089503, 0.07161012583962512, 0.06865984232172373, 0.01089431315883893, 0.010612755732970602, 0.010868106010312517, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007271226842566536, 0.007523975568181185, 0.007884064629499976, 0.007145807347540889, 0.007204078785692736, 0.007480465109044543, 0.12954954792041895, 0.12579737768854238, 0.1290873025495688, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "428c212c-c175-420e-8ed2-f0b8e6c3d2e4", "fitness": 0.026001306821734255, "name": "HybridOptimizer", "description": "Enhance exploration by varying the dynamic crossover probability range.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.5 + decay * np.random.rand() * 0.5  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 20, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02600 with standard deviation 0.06521.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.34262279820658736, 0.26054286718769026, 0.29778362396050007, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00023498804563215625, 0.0002584560823549742, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.037595071631134847, 0.042952390356421066, 0.035563812133549866, 0.07424342395430072, 0.07135105821545484, 0.07210708766644247, 0.00892924632848735, 0.014670245926092562, 0.011172305272698857, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00748541154633775, 0.007544930130976124, 0.0075237183545272535, 0.008221471008628578, 0.007332335728366113, 0.007999880575833673, 0.13225183459091094, 0.1333274177221837, 0.130919158631558, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "b4e70749-a70e-4993-aedd-475db4d5b7b2", "fitness": 0.022943062763927265, "name": "HybridOptimizer", "description": "Introduce a stochastic element to the mutation factor to enhance exploration.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9)) * np.random.uniform(0.9, 1.1)\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 21, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02294 with standard deviation 0.05288.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.21986191007247102, 0.27282107348590123, 0.19256829547770316, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00026750252507112826, 0.00022222222222223476, 0.0022192975325960873, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.040265809258845486, 0.036166561773063655, 0.04105252114626856, 0.07282126627292562, 0.0729305493382465, 0.06723262932312724, 0.012384688154631007, 0.012601579945384245, 0.011853556151478428, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007269743895771952, 0.007529314193745806, 0.007574359631437488, 0.007129674483283277, 0.007726820695620251, 0.007520544723145006, 0.1291927753121812, 0.13078011086721764, 0.13266937683445035, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "c0238eed-5c3e-43a1-b06f-493bda0d2666", "fitness": 0.02585731775962666, "name": "HybridOptimizer", "description": "Utilize adaptive crossover probability decay to enhance exploration and exploitation balance dynamically with improved mutation factor scaling.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.1  # Adjusted scale factor increment\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 22, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02586 with standard deviation 0.06646.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.335451853117522, 0.37274626889612017, 0.18593424767382305, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03870951381716259, 0.0394986683696128, 0.0386679265156985, 0.07123594214419915, 0.07151182185926863, 0.0697827596267756, 0.012361499652801866, 0.014764963683651655, 0.01143238508306299, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007287568433040237, 0.007523975568181185, 0.007660077853419378, 0.00695389159652704, 0.007127471201178626, 0.0071489997329168276, 0.13422633382765292, 0.1310824800642474, 0.1307132276236158, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "1e9b5927-bca8-4a28-aa3b-73450b7bd0b5", "fitness": 0.02486235029279564, "name": "HybridOptimizer", "description": "Adjust exploration-exploitation balance with dynamic crossover probability and mutation factor influenced by cooling rate.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.mean(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4 * self.cooling_rate  # Adaptive crossover probability decay influenced by cooling rate\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 23, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02486 with standard deviation 0.06086.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.2757667316931861, 0.24144771405043752, 0.3126187321370123, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03929341285332766, 0.03826470648275038, 0.03825477167909308, 0.0704033903963518, 0.07048275667660997, 0.07185882484994688, 0.01423035405209283, 0.008530342353552323, 0.010480641245263933, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007743054451613274, 0.007523975568181185, 0.0075237183545272535, 0.007418868039281379, 0.008250681791697079, 0.007481197414783702, 0.12791507225836152, 0.13376364728438417, 0.1309316250961905, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "604aa14f-7f51-4249-bfac-959bc3aec5be", "fitness": 0.02880260322872992, "name": "HybridOptimizer", "description": "Enhance convergence speed by adjusting mutation factor scaling based on a new variance formula.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 24, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02880 with standard deviation 0.07789.", "error": "", "parent_ids": ["ac9708dd-b02c-4f3b-a55f-72d78510c099"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.34935894968231085, 0.41621160753189435, 0.3523701188371918, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.038305771707835445, 0.03677853152366761, 0.04737917817544679, 0.07049940961612078, 0.07055724429172738, 0.06977639995133866, 0.010647641116026452, 0.011750457242440504, 0.01194934825778693, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007269551457368961, 0.007523975568181185, 0.0075237183545272535, 0.006933324215903536, 0.007286125215848038, 0.007992587470931567, 0.1297550911344285, 0.12771293831823616, 0.12630046044670007, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "53b661ff-7463-4ab3-a851-c74925b22cbd", "fitness": 0.028462493715508456, "name": "HybridOptimizer", "description": "Introduce adaptive scaling of the mutation factor to harness diversity in the population's fitness variance.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.8 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 25, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02846 with standard deviation 0.07621.", "error": "", "parent_ids": ["604aa14f-7f51-4249-bfac-959bc3aec5be"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.4042164638929815, 0.3619386160336986, 0.3214047031972358, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03985503940180146, 0.0435829639485128, 0.03669495791590993, 0.06966462581157817, 0.07003296785039548, 0.07079420993423446, 0.009039358288119193, 0.012373856850014353, 0.014970825606089644, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007298761581673419, 0.007523975568181185, 0.0075527013111016394, 0.006779283111834733, 0.007088770087542384, 0.007347592097424971, 0.13348523516181254, 0.12805461531666762, 0.1296950221971579, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "f45886d9-8edc-44d6-9ed4-2535a83ebdb9", "fitness": 0.02874393727382868, "name": "HybridOptimizer", "description": "Introduce dynamic adjustment of the crossover probability to enhance exploration and diversity.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.5 + decay * np.random.rand() * 0.5  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 26, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02874 with standard deviation 0.07795.", "error": "", "parent_ids": ["604aa14f-7f51-4249-bfac-959bc3aec5be"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.3560323170226728, 0.43203715939863296, 0.3251456979827382, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0421416836957611, 0.040739141076802765, 0.03840719103893209, 0.0697283425684404, 0.07329306297049476, 0.06796622396293461, 0.01180528470533504, 0.008976241375867944, 0.011076982865403928, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00787606335365576, 0.007523975568181185, 0.007568237480328532, 0.00739363986517616, 0.0071691838570328015, 0.007780559998825209, 0.1300111943902671, 0.12621436555483123, 0.1307719326307093, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "795fb05e-0bf7-4888-8c6c-27dcdef83a11", "fitness": 0.030555568970180746, "name": "HybridOptimizer", "description": "Enhance convergence speed by dynamically adjusting scale_factor based on fitness variance and trial success.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (best_fitness / (1 + abs(best_fitness)))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 27, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03056 with standard deviation 0.08557.", "error": "", "parent_ids": ["604aa14f-7f51-4249-bfac-959bc3aec5be"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.44536667847869027, 0.40484931893770837, 0.39075848269273483, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03972815332100299, 0.03890430727335514, 0.03704614139904738, 0.07161213034233127, 0.07058148907871753, 0.06862795728601123, 0.010317410306100228, 0.012304046663077717, 0.010905331978148358, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00734768798098917, 0.007523975568181185, 0.0075237183545272535, 0.007047219380954428, 0.007088770087542384, 0.00762903265376913, 0.1339420126261457, 0.12608326235308287, 0.1349088367382546, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "07bd972e-c9de-4d4f-a28c-cb0affa1319a", "fitness": 0.030563089198399243, "name": "HybridOptimizer", "description": "Improves exploitation by adjusting the cooling rate based on the variance of fitness, helping maintain diversity.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (np.var(fitness) / (1 + abs(np.var(fitness))))  # Changed line\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 28, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03056 with standard deviation 0.08560.", "error": "", "parent_ids": ["795fb05e-0bf7-4888-8c6c-27dcdef83a11"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.44536667847869027, 0.40484931893770837, 0.39075848269273483, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03972815332100299, 0.03890430727335514, 0.03704614139904738, 0.07010286889574047, 0.07079630030810524, 0.06862795728601123, 0.010317410306100228, 0.012304046663077717, 0.010905331978148358, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007269551457368961, 0.007523975568181185, 0.0075237183545272535, 0.007016766048888012, 0.007088770087542384, 0.007183646984943004, 0.12739687105522712, 0.13501828609744926, 0.1349088367382546, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "997b62c4-82f2-445c-89fa-c8ffdf009796", "fitness": 0.013126759691080283, "name": "HybridOptimizer", "description": "Enhances exploration by dynamically adjusting the crossover probability based on the diversity of the population.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + np.var(population) / (np.std(population) + 1e-9)  # Adaptive crossover probability based on diversity\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (np.var(fitness) / (1 + abs(np.var(fitness))))  # Changed line\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 29, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01313 with standard deviation 0.03010.", "error": "", "parent_ids": ["07bd972e-c9de-4d4f-a28c-cb0affa1319a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00037691860125921295, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03892579917541483, 0.03546895666749861, 0.03836381755262741, 0.08111169844167265, 0.07383052161962045, 0.06458727388658536, 0.005627800681589301, 0.009892470113859075, 0.007356065727861294, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007274152400777667, 0.007523975568181185, 0.0075237183545272535, 0.0067801241996963135, 0.007088770087542384, 0.008814094451910504, 0.12959354937512013, 0.1259489913792181, 0.12868855267573287, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "f924a039-7e13-4eae-94d2-25224df208f9", "fitness": 0.014002760859850798, "name": "HybridOptimizer", "description": "Enhances adaptive crossover probability by incorporating variance of fitness, further balancing exploration and exploitation.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                # Updated line below\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4 * (1 + np.var(fitness) / (np.std(fitness) + 1e-9))  # Adaptive crossover probability with fitness variance\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (np.var(fitness) / (1 + abs(np.var(fitness))))\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 30, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01400 with standard deviation 0.03037.", "error": "", "parent_ids": ["07bd972e-c9de-4d4f-a28c-cb0affa1319a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00467250091924587, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.008892359459281796, 0.006611865096890268, 0.009403766850400896, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.04025040090876675, 0.03828339466509434, 0.03604404154453311, 0.07896404921075006, 0.07892614170026857, 0.06996612678277714, 0.012772677548126832, 0.016388985158926506, 0.015658071006590002, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007269551457368961, 0.007523975568181185, 0.0075237183545272535, 0.007535314127349091, 0.007088770087542384, 0.007095849008219579, 0.12895121484515382, 0.13081253419305539, 0.12788069328578855, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "675cbbde-d1a3-4f53-9182-b1681543b54c", "fitness": 0.014009784045845778, "name": "HybridOptimizer", "description": "Improves exploitation by dynamically adapting the crossover probability based on the fitness variance, enhancing convergence speed.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4 * (np.var(fitness) / (np.std(fitness) + 1e-9))  # Adaptive crossover probability decay based on variance\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (np.var(fitness) / (1 + abs(np.var(fitness))))  # Changed line\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 31, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01401 with standard deviation 0.02983.", "error": "", "parent_ids": ["07bd972e-c9de-4d4f-a28c-cb0affa1319a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.016239641667009197, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0049942262631236245, 0.00022222222222223476, 0.010663405104801238, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.04236737201724017, 0.035464165137471526, 0.036262408889549014, 0.07602565174436471, 0.08210694723595369, 0.07116802811337986, 0.01605042967751691, 0.018784353429411538, 0.019294121543490195, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007269551457368961, 0.007523975568181185, 0.0075237183545272535, 0.006994682710545264, 0.007094919852003501, 0.007132220946310719, 0.12430276130653495, 0.12767537780791138, 0.12386149012156, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "31149209-efda-4024-82c2-28f4d6158126", "fitness": 0.030563089198399243, "name": "HybridOptimizer", "description": "Enhance mutation strategy by dynamically adjusting mutation factor based on fitness variance and a new scaling factor.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (np.var(fitness) / (1 + abs(np.var(fitness))))  # Changed line\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 32, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03056 with standard deviation 0.08560.", "error": "", "parent_ids": ["07bd972e-c9de-4d4f-a28c-cb0affa1319a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.44536667847869027, 0.40484931893770837, 0.39075848269273483, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.03972815332100299, 0.03890430727335514, 0.03704614139904738, 0.07010286889574047, 0.07079630030810524, 0.06862795728601123, 0.010317410306100228, 0.012304046663077717, 0.010905331978148358, 0.05030916325665724, 0.04715615583885202, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.007269551457368961, 0.007523975568181185, 0.0075237183545272535, 0.007016766048888012, 0.007088770087542384, 0.007183646984943004, 0.12739687105522712, 0.13501828609744926, 0.1349088367382546, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
{"id": "eeb5ed9d-2d88-4639-b459-34d9c71effcc", "fitness": 0.01759186907142138, "name": "HybridOptimizer", "description": "Enhances exploration by adapting dynamic population size based on early performance, steering convergence.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.dynamic_pop_size_factor = 0.05\n        self.scale_factor = 1.0\n\n    def __call__(self, func):\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations < self.budget // 2:  # Change line: Adapt population size based on early evaluations\n                self.dynamic_pop_size_factor *= 1.1\n            current_pop_size = int(self.population_size * (1 + self.dynamic_pop_size_factor * evaluations / self.budget))  \n            population = np.resize(population, (current_pop_size, self.dim))\n            fitness = np.resize(fitness, current_pop_size)\n\n            for i in range(current_pop_size):\n                decay = (self.budget - evaluations) / self.budget  # Dynamic mutation factor decay\n                self.mutation_factor = 0.5 + decay * np.random.rand() * 0.5 * (np.var(fitness) / (np.std(fitness) + 1e-9)) * (best_fitness / (np.mean(fitness) + 1e-9))\n                indices = [idx for idx in range(current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * self.scale_factor * (b - c), self.lower_bound, self.upper_bound)\n\n                self.crossover_probability = 0.6 + decay * np.random.rand() * 0.4  # Adaptive crossover probability decay\n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness or np.exp((best_fitness - trial_fitness) / self.temperature) > np.random.rand():\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        self.scale_factor = 1.0 + np.var(fitness) / (np.std(fitness) + 1e-9)  # Modified scale factor\n                else:\n                    self.scale_factor *= 1.05\n\n            self.cooling_rate = 0.99 + 0.01 * (np.var(fitness) / (1 + abs(np.var(fitness))))  # Changed line\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 33, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01759 with standard deviation 0.03653.", "error": "", "parent_ids": ["07bd972e-c9de-4d4f-a28c-cb0affa1319a"], "operator": null, "metadata": {"aucs": [0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.05289427350666054, 0.05793734536148132, 0.17646989483526876, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0009159349702579922, 0.00022222222222223476, 0.0034679138597701886, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.040968414257377184, 0.03661598160783519, 0.039964999671066814, 0.07374888025599347, 0.07155370009409245, 0.06770285180432678, 0.012242811933386166, 0.009613967355466269, 0.012399146603344402, 0.0513744964417171, 0.05631396008854128, 0.05177301659046474, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476, 0.0075477012729490145, 0.007704551580860808, 0.007902814441385964, 0.00739123694355559, 0.0076518493207577976, 0.008085496157497651, 0.12204944725913613, 0.1277464729048291, 0.14435519180209377, 0.00022222222222223476, 0.00022222222222223476, 0.00022222222222223476]}}
