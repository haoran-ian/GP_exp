{"id": "e65f3f83-4d3f-44ee-a06d-a0eb7ec3a2c1", "fitness": 0.16188521943570763, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) to efficiently explore and exploit the search space in black box optimization.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16189 with standard deviation 0.01183.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14807666833769983, 0.16060823997290197, 0.17697074999652107]}}
{"id": "c6c2fb28-30cf-4e9a-95f9-de845108ce84", "fitness": 0.09030509301769356, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining PSO and DE with improved velocity update for efficient optimization.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            velocity = np.clip(velocity, -0.1, 0.1)  # Added velocity clamping\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09031 with standard deviation 0.00661.", "error": "", "parent_ids": ["e65f3f83-4d3f-44ee-a06d-a0eb7ec3a2c1"], "operator": null, "metadata": {"aucs": [0.08173766063597898, 0.09784052267425714, 0.09133709574284454]}}
{"id": "a423ea4f-e2fe-4ad6-acf0-ef8204806729", "fitness": 0.1357996159129681, "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight in PSO to improve convergence in the hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.9 - (0.9 - 0.4) * (evaluations / self.budget)  # Adaptive inertia\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13580 with standard deviation 0.01493.", "error": "", "parent_ids": ["e65f3f83-4d3f-44ee-a06d-a0eb7ec3a2c1"], "operator": null, "metadata": {"aucs": [0.11471794331802443, 0.1473723450903205, 0.14530855933055942]}}
{"id": "2f9ed38b-372e-4091-b7cd-2eaaf560c6df", "fitness": 0.13882948653092794, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameter control to improve exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_init = 0.9  # initial inertia weight for PSO\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.F_init = 0.8  # initial scaling factor for DE\n        self.CR = 0.9  # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.full(self.population_size, float('inf'))\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        w = self.w_init\n        F = self.F_init\n\n        while evaluations < self.budget:\n            w = (self.w_init - self.w_min) * (1 - evaluations / self.budget) + self.w_min\n            F = self.F_init * (1 - evaluations / self.budget)\n\n            r1, r2 = np.random.rand(2)\n            velocity = (w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13883 with standard deviation 0.01427.", "error": "", "parent_ids": ["e65f3f83-4d3f-44ee-a06d-a0eb7ec3a2c1"], "operator": null, "metadata": {"aucs": [0.12572562965554335, 0.13209023358815175, 0.1586725963490887]}}
{"id": "527f3940-381f-4c39-a3df-dc5aa0f3ecec", "fitness": 0.1357996159129681, "name": "HybridPSO_DE", "description": "A refined hybrid algorithm combining PSO and DE with adaptive inertia weight for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            self.w = 0.9 - evaluations / (2 * self.budget) # Adaptive inertia weight\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13580 with standard deviation 0.01493.", "error": "", "parent_ids": ["e65f3f83-4d3f-44ee-a06d-a0eb7ec3a2c1"], "operator": null, "metadata": {"aucs": [0.11471794331802443, 0.1473723450903205, 0.14530855933055942]}}
{"id": "bd89df3f-a679-41f2-b92b-e6bee5064421", "fitness": 0.16706757289207907, "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with an improved inertia weight update strategy for enhanced exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16707 with standard deviation 0.01020.", "error": "", "parent_ids": ["e65f3f83-4d3f-44ee-a06d-a0eb7ec3a2c1"], "operator": null, "metadata": {"aucs": [0.1568147301791034, 0.18097373973484154, 0.16341424876229227]}}
{"id": "ef6a1d53-2ea0-4852-afc7-9e2536399683", "fitness": 0.12541685041224304, "name": "EnhancedHybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameters and a dynamic selection strategy to enhance convergence and solution quality in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_w = 0.9  # starting inertia weight\n        self.final_w = 0.4    # ending inertia weight\n        self.c1 = 1.5         # cognitive coefficient for PSO\n        self.c2 = 1.5         # social coefficient for PSO\n        self.F = 0.8          # scaling factor for DE\n        self.CR = 0.9         # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.full(self.population_size, float('inf'))\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight update\n            self.w = self.initial_w - (self.initial_w - self.final_w) * (iteration / max_iterations)\n            \n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                # Adaptive selection strategy\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            iteration += 1\n\n        return g_best", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12542 with standard deviation 0.00759.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.11490628906678291, 0.13257703245537888, 0.12876722971456733]}}
{"id": "33490d48-9890-46d3-bdf6-22671db1b438", "fitness": 0.13775902505291585, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive parameters and dynamic learning strategies for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.7\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                # Introduce a dynamic scaling factor\n                F_dynamic = self.F * (1 - evaluations / self.budget)\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            iteration += 1\n\n        return g_best", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13776 with standard deviation 0.01867.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.11856204738353082, 0.16305501808115896, 0.13166000969405778]}}
{"id": "26db5b3b-8204-4b47-8963-ae2ce1800dc7", "fitness": 0.16264980006506033, "name": "HybridPSO_DE", "description": "A refined hybrid PSO and DE algorithm with dynamic cognitive and social coefficients for better convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            self.c1 = 1.5 + np.random.rand() * 0.5  # Dynamic cognitive coefficient update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16265 with standard deviation 0.01011.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.15653705178926114, 0.15451422770247036, 0.17689812070344946]}}
{"id": "500afb2a-717a-4f29-923a-b9646c5b8fa9", "fitness": 0.1656679256208916, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive crossover probability to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            self.CR = 0.5 + 0.4 * np.random.rand()  # Adaptive crossover probability\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16567 with standard deviation 0.01527.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.1592541150560387, 0.15102069064034018, 0.18672897116629594]}}
{"id": "819c9202-a1bd-4f92-ab61-35fb5423391b", "fitness": 0.1357996159129681, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO), Differential Evolution (DE), and adaptive parameter tuning to improve exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_w = 0.9  # initial inertia weight\n        self.final_w = 0.4    # final inertia weight\n        self.c1 = 1.5         # cognitive coefficient for PSO\n        self.c2 = 1.5         # social coefficient for PSO\n        self.F = 0.8          # scaling factor for DE\n        self.CR = 0.9         # crossover probability for DE\n        self.population_size = 20\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight for PSO\n            self.w = self.final_w + (self.initial_w - self.final_w) * (self.budget - evaluations) / self.budget\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13580 with standard deviation 0.01493.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.11471794331802443, 0.1473723450903205, 0.14530855933055942]}}
{"id": "5f177a58-b03b-4282-93db-b416240ad79b", "fitness": 0.12541685041224304, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid metaheuristic combining PSO and DE, integrating adaptive strategies for inertia weight and mutation to improve convergence speed and solution quality in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_max = 0.9  # maximum inertia weight for PSO\n        self.w_min = 0.4  # minimum inertia weight for PSO\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9  # crossover probability for DE\n        self.evaluations = 0\n\n    def adaptive_inertia_weight(self):\n        \"\"\"Adaptive inertia weight based on the number of evaluations.\"\"\"\n        return self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        while self.evaluations < self.budget:\n            # Update PSO parameters\n            self.w = self.adaptive_inertia_weight()\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                self.evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if self.evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12542 with standard deviation 0.00759.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.11490628906678291, 0.13257703245537888, 0.12876722971456733]}}
{"id": "590beb76-17b7-46ad-8d88-df2721a13ecc", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid optimization algorithm integrating Adaptive Particle Swarm Optimization (PSO) with Dynamic Differential Evolution (DE) leveraging elite population strategies for improved convergence in black box optimization problems.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n        self.elite_fraction = 0.2  # fraction of elite population to maintain diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.w = 0.5 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover with elite strategy\n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(p_best_scores)[:elite_size]\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                elite_indices = [idx for idx in elite_indices if idx != i]\n                partners = np.random.choice(elite_indices if elite_indices else indices, 2, replace=False)\n                a, b, c = population[i], population[partners[0]], population[partners[1]]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n        return g_best", "configspace": "", "generation": 12, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {}}
{"id": "40275735-80a9-4d97-a21d-de0390812d27", "fitness": 0.10998185586539459, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE: Incorporates adaptive parameter tuning and elitism to improve convergence speed and solution quality in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.1  # minimum inertia weight for PSO\n        self.w_max = 0.9  # maximum inertia weight for PSO\n        self.c1 = 2.0     # cognitive coefficient for PSO\n        self.c2 = 2.0     # social coefficient for PSO\n        self.F_min = 0.5  # minimum scaling factor for DE\n        self.F_max = 1.0  # maximum scaling factor for DE\n        self.CR = 0.9     # crossover probability for DE\n        self.elite_rate = 0.2  # proportion of elite individuals retained\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update adaptive parameters\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            F = self.F_max - (self.F_max - self.F_min) * (evaluations / self.budget)\n\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            velocity = (w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                \n                # Selection with Elitism\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Elitism: Retain a proportion of the best solutions\n            elite_count = int(self.elite_rate * self.population_size)\n            elite_indices = np.argsort(p_best_scores)[:elite_count]\n            population[:elite_count] = p_best[elite_indices]\n\n        return g_best", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10998 with standard deviation 0.01579.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.09752479959178528, 0.13225462429700352, 0.10016614370739496]}}
{"id": "1b9933d0-648a-4a6b-a4e8-8b0551bf9e9c", "fitness": 0.14409606130027244, "name": "RefinedHybridPSO_DE", "description": "A refined hybrid metaheuristic algorithm combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive inertia weight and self-adaptive control parameters to enhance convergence and robustness in black box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4  # minimum inertia weight for PSO\n        self.w_max = 0.9  # maximum inertia weight for PSO\n        self.c1 = 1.5     # cognitive coefficient for PSO\n        self.c2 = 1.5     # social coefficient for PSO\n        self.F = 0.8      # scaling factor for DE\n        self.CR = 0.9     # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight based on convergence\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n            r1, r2 = np.random.rand(2)\n            \n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Self-adaptive DE parameters\n            self.F = 0.5 + 0.3 * np.random.rand()\n            self.CR = 0.6 + 0.3 * np.random.rand()\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 14, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14410 with standard deviation 0.02833.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.11371761589089868, 0.1366655219751347, 0.18190504603478397]}}
{"id": "ca5a919a-64cd-426f-b7f9-b6738c6bc255", "fitness": 0.13224185369114985, "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid PSO-DE algorithm with adaptive control parameters and a restart mechanism for improved global convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_w = 0.9  # initial inertia weight for PSO\n        self.final_w = 0.4   # final inertia weight for PSO\n        self.c1 = 1.5        # cognitive coefficient for PSO\n        self.c2 = 1.5        # social coefficient for PSO\n        self.F = 0.8         # scaling factor for DE\n        self.CR = 0.9        # crossover probability for DE\n        self.restart_threshold = 5  # restarts if no improvement in this many generations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n        evaluations = self.population_size\n        generations_without_improvement = 0\n\n        while evaluations < self.budget:\n            # Dynamic inertia weight update\n            self.w = self.initial_w - ((self.initial_w - self.final_w) * (evaluations / self.budget))\n\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                # Selection and best-known update\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                        generations_without_improvement = 0\n                else:\n                    generations_without_improvement += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Restart mechanism\n            if generations_without_improvement >= self.restart_threshold:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                generations_without_improvement = 0\n\n        return g_best", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13224 with standard deviation 0.02065.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.10391279195083591, 0.15254460249867774, 0.14026816662393593]}}
{"id": "a86aa837-3cd7-46a1-926e-80979e9afe20", "fitness": 0.17457500204594065, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive DE scaling factor for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.3 * np.random.rand()  \n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17458 with standard deviation 0.03161.", "error": "", "parent_ids": ["bd89df3f-a679-41f2-b92b-e6bee5064421"], "operator": null, "metadata": {"aucs": [0.13013947232115908, 0.19253197651717802, 0.20105355729948482]}}
{"id": "58a06dbb-52c6-4501-8430-6c9abfd6e870", "fitness": 0.1612095461241585, "name": "EnhancedHybridPSO_DE", "description": "Introducing stochastic adaptive parameters in HybridPSO_DE for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.base_w = 0.5  # base inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.base_F = 0.8  # base scaling factor\n        self.base_CR = 0.9  # base crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adapt inertia weight dynamically\n            dynamic_w = self.base_w + 0.1 * np.random.rand()\n            # Use stochastic c1 and c2 to adjust exploration/exploitation balance\n            stochastic_c1 = self.c1 * (0.5 + np.random.rand())\n            stochastic_c2 = self.c2 * (0.5 + np.random.rand())\n\n            r1, r2 = np.random.rand(2)\n            velocity = (dynamic_w * velocity +\n                        stochastic_c1 * r1 * (p_best - population) +\n                        stochastic_c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                adaptive_F = self.base_F + 0.3 * np.random.rand()\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n                # Adaptive crossover probability\n                adaptive_CR = self.base_CR * (0.5 + np.random.rand())\n                cross_points = np.random.rand(self.dim) < adaptive_CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16121 with standard deviation 0.02616.", "error": "", "parent_ids": ["a86aa837-3cd7-46a1-926e-80979e9afe20"], "operator": null, "metadata": {"aucs": [0.141524809480159, 0.14392137072313538, 0.19818245816918112]}}
{"id": "ebc223ba-371f-41d0-b61c-8d85146534f5", "fitness": 0.18191511200778843, "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE with adaptive population size and dynamic crossover probability for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.3 * np.random.rand()  \n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                # Dynamic crossover probability\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9)) \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18192 with standard deviation 0.02142.", "error": "", "parent_ids": ["a86aa837-3cd7-46a1-926e-80979e9afe20"], "operator": null, "metadata": {"aucs": [0.1532531408735065, 0.2047292215788289, 0.1877629735710299]}}
{"id": "29082a4a-5971-4f48-91d0-f38cc9413bfc", "fitness": 0.1478883141087123, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive inertia, scaling factor, and population size for improved convergence rate balancing exploration-exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.population_size = self.initial_population_size\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_max = 0.9\n        self.F_min = 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            self.w = self.w_max - (self.w_max - self.w_min) * progress_ratio\n            self.F = self.F_max - (self.F_max - self.F_min) * progress_ratio\n            \n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(self.min_population_size, int(self.initial_population_size * (1 - progress_ratio)))\n\n        return g_best", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14789 with standard deviation 0.02077.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.12256913514038414, 0.17344414136874364, 0.14765166581700917]}}
{"id": "e09654ed-3591-4103-8a22-e1914fecc103", "fitness": 0.16064325064723947, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with time-varying parameters and local search refinement for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.min_population_size = 10\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.5  # cognitive coefficient for PSO\n        self.c2 = 1.5  # social coefficient for PSO\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.5\n        self.CR_max = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.full(self.population_size, float('inf'))\n        \n        evaluations = 0\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n            evaluations += 1\n            \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            F = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - g_best_score / (min(p_best_scores) + 1e-9))\n            \n            r1, r2 = np.random.rand(2)\n            velocity = (w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(self.min_population_size, int(self.initial_population_size * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16064 with standard deviation 0.01899.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.14887181097584423, 0.18742963742259844, 0.14562830354327572]}}
{"id": "09e0fb68-0f95-4891-90c2-885d8b39896d", "fitness": 0.18191511200778843, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with dynamic topology adaptation and leader selection for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.3 * np.random.rand()  \n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                # Dynamic crossover probability\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9)) \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n            \n            # Dynamic topology adaptation: periodically shuffle population\n            if evaluations % (self.budget // 4) == 0:\n                np.random.shuffle(population)\n\n            # Leader selection: periodically replace g_best with a random p_best\n            if evaluations % (self.budget // 10) == 0:\n                if np.random.rand() < 0.1:\n                    random_leader = np.random.choice(self.population_size)\n                    g_best = p_best[random_leader]\n                    g_best_score = p_best_scores[random_leader]\n\n        return g_best", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18192 with standard deviation 0.02142.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.1532531408735065, 0.2047292215788289, 0.1877629735710299]}}
{"id": "deda2dff-2abe-4060-b47a-000bf58115c7", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive turbulence-induced diversification for increased exploration in high-dimensional spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n        self.turbulence_factor = 0.1\n    \n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            \n            # Introduce turbulence to increase exploration in high-dimensional spaces\n            turbulence = self.turbulence_factor * np.random.randn(self.population_size, self.dim)\n            population = np.clip(population + velocity + turbulence, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.3 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 22, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,20) (19,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,20) (19,20) ')", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {}}
{"id": "c43b2714-e395-464c-ba2b-019f9f0e0c0f", "fitness": 0.1680884660888354, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive mutation strategy and stochastic velocity initialization for improved convergence and solution quality.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.normal(0, 0.1, (self.population_size, self.dim))  # Stochastic initialization\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.3 * np.random.rand()  \n                mutant = np.clip(a + self.F * ((b - c) + (g_best - population[i])), lb, ub)  # Enhanced mutation strategy\n                # Dynamic crossover probability\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9)) \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 23, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16809 with standard deviation 0.02022.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.1647405796673469, 0.19435724780399288, 0.1451675707951664]}}
{"id": "398d71a6-ff18-4e99-bb63-42e6312f5e21", "fitness": 0.1708262404707552, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by introducing a stochastic element in inertia weight update for better adaptability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.3 + 0.2 * np.random.rand()  # Dynamic inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.3 * np.random.rand()  \n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                # Dynamic crossover probability\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9)) \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17083 with standard deviation 0.02818.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.13432514464996848, 0.202921726415754, 0.1752318503465431]}}
{"id": "b580196a-1f92-43ea-8bf9-b49d430107a4", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE using Fuzzy Logic for adaptive parameter tuning to improve convergence speed and solution accuracy.", "code": "import numpy as np\nimport skfuzzy as fuzz\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_population_size = self.population_size\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def fuzzy_logic(self, g_best_score, evaluations_ratio):\n        # Fuzzy logic system to adjust parameters\n        x_range = np.arange(0, 1.1, 0.1)\n        g_score = fuzz.trapmf(x_range, [0, 0, 0.5, 0.7])\n        eval_ratio = fuzz.trapmf(x_range, [0.3, 0.5, 0.7, 1])\n        \n        rule1 = np.fmin(g_score, eval_ratio)\n        rule2 = np.fmin(g_score, np.fmax(np.ones_like(eval_ratio) - eval_ratio, 0))\n        \n        # Aggregate the two rules\n        aggregated = np.fmax(rule1, rule2)\n\n        # Defuzzify the aggregated output\n        parameter_adjustment = fuzz.defuzz(x_range, aggregated, 'centroid')\n        \n        return parameter_adjustment\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            evaluations_ratio = evaluations / self.budget\n            adjustment = self.fuzzy_logic(g_best_score / (np.min(p_best_scores) + 1e-9), evaluations_ratio)\n\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.3 * adjustment\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = 0.5 + 0.3 * adjustment\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = 0.5 + 0.4 * adjustment * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adjust population size using fuzzy logic\n            self.population_size = max(10, int(self.initial_population_size * (1 - evaluations_ratio)))\n        \n        return g_best", "configspace": "", "generation": 25, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'skfuzzy'\").", "error": "ModuleNotFoundError(\"No module named 'skfuzzy'\")", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {}}
{"id": "4c91f46d-e3a0-4d78-830f-04723cd79e00", "fitness": 0.1681787950785605, "name": "HybridPSO_DE", "description": "Introducing dynamic cognitive and social coefficients in HybridPSO_DE to enhance convergence precision.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.1 * np.random.rand()  # Dynamic inertia weight update\n            self.c1 = 1.0 + 0.5 * np.random.rand()  # Dynamic cognitive coefficient update\n            self.c2 = 1.0 + 0.5 * np.random.rand()  # Dynamic social coefficient update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.3 * np.random.rand()  \n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                # Dynamic crossover probability\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9)) \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16818 with standard deviation 0.01529.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.1568245196516772, 0.18979161559115088, 0.15792024999285348]}}
{"id": "00515aca-f3d5-4fa2-b8fa-ad6c50158dee", "fitness": 0.15626791215106214, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with improved velocity update using nonlinear inertia weight and adaptive differential mutation to refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5 # cognitive coefficient for PSO\n        self.c2 = 1.5 # social coefficient for PSO\n        self.F = 0.8  # scaling factor for DE\n        self.CR = 0.9 # crossover probability for DE\n\n    def __call__(self, func):\n        # Initialize the population\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        # Evaluate initial population\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocity and position for PSO\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.3 * (1 - evaluations / self.budget)  # Nonlinear inertia weight update\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adaptive scaling factor for DE\n                self.F = 0.5 + 0.5 * np.random.rand()  # Slightly adjusted adaptive scaling factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                # Dynamic crossover probability\n                self.CR = 0.5 + 0.4 * (g_best_score / (p_best_scores[i] + 1e-9)) \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                # Selection\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive population size adjustment\n            self.population_size = max(10, int(20 * (1 - (evaluations / self.budget))))\n\n        return g_best", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15627 with standard deviation 0.00474.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.15368681786564786, 0.15219475369482438, 0.16292216489271416]}}
{"id": "12a3650c-6069-4be5-baa3-8653af0cee50", "fitness": 0.18864717183345148, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with stochastic inertia and adaptive selection pressure for improved convergence through dynamic control of exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3  # minimum inertia weight\n        self.w_max = 0.7  # maximum inertia weight\n        self.c1 = 1.5     # cognitive coefficient\n        self.c2 = 1.5     # social coefficient\n        self.F_base = 0.5 # base scaling factor for DE\n        self.CR_base = 0.5 # base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.2 * np.random.rand() * dynamic_pressure\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n\n        return g_best", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18865 with standard deviation 0.00279.", "error": "", "parent_ids": ["ebc223ba-371f-41d0-b61c-8d85146534f5"], "operator": null, "metadata": {"aucs": [0.19237721757711657, 0.18565285750098703, 0.18791144042225083]}}
{"id": "457427b6-41c7-46df-8efe-bc4836d5d2df", "fitness": 0.16109610564625557, "name": "AdaptiveHybridPSO_DE", "description": "Adaptive HybridPSO_DE with dynamic multi-phase exploration-exploitation and parameter coordination to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([func(ind) for ind in population])\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            phase_ratio = evaluations / self.budget\n            self.w = self.w_max - (self.w_max - self.w_min) * phase_ratio\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.5 * np.random.rand() * phase_ratio\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = self.CR_base + 0.4 * np.random.rand() * (1 - phase_ratio)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * (1 - phase_ratio)))\n\n        return g_best", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16110 with standard deviation 0.03096.", "error": "", "parent_ids": ["12a3650c-6069-4be5-baa3-8653af0cee50"], "operator": null, "metadata": {"aucs": [0.11753250122218761, 0.18672365024515725, 0.17903216547142187]}}
{"id": "e0b342d9-9f1b-4d75-abce-41706f4b421f", "fitness": 0.1818557866423778, "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with dynamic inertia and pressure, improved balance of exploration and exploitation via adaptive mutation scaling and crossover.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3  # minimum inertia weight\n        self.w_max = 0.7  # maximum inertia weight\n        self.c1 = 1.5     # cognitive coefficient\n        self.c2 = 1.5     # social coefficient\n        self.F_base = 0.5 # base scaling factor for DE\n        self.CR_base = 0.5 # base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.3 * np.random.rand() * dynamic_pressure  # Changed from 0.2 to 0.3\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = self.CR_base + 0.4 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9))  # Changed from 0.3 to 0.4\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n\n        return g_best", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18186 with standard deviation 0.00633.", "error": "", "parent_ids": ["12a3650c-6069-4be5-baa3-8653af0cee50"], "operator": null, "metadata": {"aucs": [0.17296334363715216, 0.18542253703906741, 0.18718147925091388]}}
{"id": "42fb0979-2341-4601-90d1-a1072746e70b", "fitness": 0.18045593000458446, "name": "EnhancedHybridPSO_DE", "description": "Adaptive Hybrid PSO-DE with dynamic population control and elite archive strategy for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.elite_archive_size = 5\n        self.w_min = 0.3  \n        self.w_max = 0.7  \n        self.c1 = 1.7     \n        self.c2 = 1.7     \n        self.F_base = 0.5 \n        self.CR_base = 0.5 \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        elite_archive = np.zeros((self.elite_archive_size, self.dim))\n        elite_scores = np.array([float('inf')]*self.elite_archive_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.2 * np.random.rand() * dynamic_pressure\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n            sorted_indices = np.argsort(p_best_scores)\n            for j in range(self.elite_archive_size):\n                elite_archive[j] = p_best[sorted_indices[j]]\n                elite_scores[j] = p_best_scores[sorted_indices[j]]\n            if evaluations >= self.budget:\n                break\n\n        return g_best", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18046 with standard deviation 0.02318.", "error": "", "parent_ids": ["12a3650c-6069-4be5-baa3-8653af0cee50"], "operator": null, "metadata": {"aucs": [0.19124352825445956, 0.14824860169001064, 0.20187566006928315]}}
{"id": "1896d36a-b9cb-46ad-8dfb-d2333597a8fd", "fitness": 0.17061308163953556, "name": "EnhancedHybridPSO_DE", "description": "Introduce a multi-phase adaptive inertia and crossover strategy to EnhancedHybridPSO_DE for better handling of diverse search spaces and improved convergence balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2  # minimum inertia weight\n        self.w_max = 0.9  # maximum inertia weight\n        self.c1 = 1.5     # cognitive coefficient\n        self.c2 = 1.5     # social coefficient\n        self.F_base = 0.5 # base scaling factor for DE\n        self.CR_base = 0.5 # base crossover probability for DE\n        self.phase_split = [0.3, 0.7]  # defines budget split for different phases\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')]*self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_phase = 0 if evaluations < self.budget * self.phase_split[0] else (\n                            1 if evaluations < self.budget * self.phase_split[1] else 2)\n\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            if current_phase == 0:\n                self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / (self.budget * self.phase_split[0]))\n            elif current_phase == 1:\n                self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            else:\n                self.w = self.w_min\n            \n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.2 * np.random.rand() * dynamic_pressure\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n\n        return g_best", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17061 with standard deviation 0.03166.", "error": "", "parent_ids": ["12a3650c-6069-4be5-baa3-8653af0cee50"], "operator": null, "metadata": {"aucs": [0.12605313166363197, 0.1890478660998618, 0.1967382471551129]}}
{"id": "f07df4f3-48e2-4de0-9e57-41ff10336f6f", "fitness": 0.18526181889480933, "name": "AdaptiveLevyPSO_DE", "description": "Adaptive Hybrid PSO-DE with Levy flight-based perturbation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n\n    def levy_flight(self, size, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        return u / np.abs(v) ** (1 / beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.2 * np.random.rand() * dynamic_pressure\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Levy flight perturbation\n                if np.random.rand() < 0.1:\n                    trial += self.levy_flight(trial.shape)\n                    trial = np.clip(trial, lb, ub)\n                \n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n\n        return g_best", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveLevyPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18526 with standard deviation 0.01138.", "error": "", "parent_ids": ["12a3650c-6069-4be5-baa3-8653af0cee50"], "operator": null, "metadata": {"aucs": [0.17390683836314025, 0.18106694721382988, 0.2008116711074579]}}
{"id": "121d6015-9b39-4859-8456-31d83f02d6d8", "fitness": 0.19527302856872134, "name": "AdaptiveQuantumHybridPSO_DE", "description": "Adaptive Quantum-Inspired HybridPSO_DE enhances convergence by using quantum superposition for particle initialization and adaptive parameter tuning based on historical performance.", "code": "import numpy as np\n\nclass AdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3  # minimum inertia weight\n        self.w_max = 0.7  # maximum inertia weight\n        self.c1 = 1.5     # cognitive coefficient\n        self.c2 = 1.5     # social coefficient\n        self.F_base = 0.5 # base scaling factor for DE\n        self.CR_base = 0.5 # base crossover probability for DE\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.F = self.F_base + 0.2 * np.random.rand() * dynamic_pressure\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19527 with standard deviation 0.00290.", "error": "", "parent_ids": ["12a3650c-6069-4be5-baa3-8653af0cee50"], "operator": null, "metadata": {"aucs": [0.1961959371262486, 0.19134812254172462, 0.1982750260381908]}}
{"id": "6a9fc8ea-f08d-4248-956c-af9c7b1e0cde", "fitness": 0.20118076922070402, "name": "AdaptiveQuantumHybridPSO_DE", "description": "Quantum-Inspired HybridPSO_DE with Adaptive Dynamic Scaling refines search efficiency by introducing dynamic scaling of DE parameters based on real-time convergence metrics.", "code": "import numpy as np\n\nclass AdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Dynamic scaling based on convergence metrics\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20118 with standard deviation 0.00932.", "error": "", "parent_ids": ["121d6015-9b39-4859-8456-31d83f02d6d8"], "operator": null, "metadata": {"aucs": [0.212878187425105, 0.19008361262294637, 0.20058050761406065]}}
{"id": "0a593f4a-8540-4ce8-bc93-e8607902c6f1", "fitness": 0.12140264711502002, "name": "AdaptiveQuantumHybridPSO_DE", "description": "Quantum-Inspired HybridPSO_DE with Adaptive Environmental Pressure optimizes search by dynamically adjusting exploration and exploitation based on fitness variance and diversity metrics.", "code": "import numpy as np\n\nclass AdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2  # Lowered to balance exploration\n        self.w_max = 0.9  # Increased for greater search space coverage\n        self.c1 = 1.8  # Increased cognitive component\n        self.c2 = 1.8  # Increased social component\n        self.F_base = 0.4  # Adjusted differential weight\n        self.CR_base = 0.9  # Increased crossover rate\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand()\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                fitness_variance = np.var(p_best_scores)\n                diversity_factor = np.mean(np.std(population, axis=0))\n                \n                # Adaptive scaling with fitness variance and diversity factor\n                self.F = self.F_base + 0.5 * np.exp(-fitness_variance) * diversity_factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12140 with standard deviation 0.02793.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.09300512291724905, 0.15938431682265197, 0.11181850160515905]}}
{"id": "7f435d9f-ea2b-40d0-a6ab-bf99493a3f6e", "fitness": 0.1912971830697073, "name": "EnhancedQuantumHybridPSO_DE", "description": "Enhanced Quantum-Inspired HybridPSO_DE introduces adaptive inertia and diversity preservation to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            diversity = np.std(population.flatten())\n            self.w = self.w_min + (self.w_max - self.w_min) * (1 - np.tanh(diversity))\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * (1 - np.tanh(diversity))))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19130 with standard deviation 0.00674.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.1834344212574327, 0.1999042679958365, 0.1905528599558527]}}
{"id": "f1e4415f-315d-4c80-84ec-1177bceda58a", "fitness": 0.2002572714503067, "name": "EnhancedAdaptativeQuantumPSO_DE", "description": "EnhancedAdaptativeQuantumPSO_DE introduces adaptive exploration-exploitation balance through dynamic weight and crossover adjustments based on population diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptativeQuantumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.6\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            population_mean = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - population_mean, axis=1))\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * (1 - np.exp(-diversity)) * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Dynamic scaling based on convergence metrics and diversity\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score) / diversity) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)) * (1 - np.exp(-diversity)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptativeQuantumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20026 with standard deviation 0.00673.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.1914637924984487, 0.2077951900484747, 0.2015128318039967]}}
{"id": "40820d0a-7306-40bd-8292-f06af7fa4b08", "fitness": 0.19425082363688181, "name": "AdaptiveQuantumHybridPSO_DE", "description": "Quantum-Inspired HybridPSO_DE with Adaptive Convergence Pressure adjusts convergence pressure dynamically based on recent improvement history to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            recent_improvement = np.mean(np.diff(historical_scores[-5:])) if len(historical_scores) > 5 else 0\n            convergence_pressure = max(0.1, min(1.0, 0.5 + recent_improvement))\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * convergence_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Dynamic scaling based on convergence metrics\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * convergence_pressure))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19425 with standard deviation 0.00591.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.2011757271470611, 0.1867265568476798, 0.1948501869159045]}}
{"id": "80e8431b-2484-4ef7-91b8-38736e2a312b", "fitness": 0.19467297809605486, "name": "AdaptiveQuantumHybridPSO_DE", "description": "Improved Adaptive Scaling of CR Parameter for Better Convergence Control.", "code": "import numpy as np\n\nclass AdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Dynamic scaling based on convergence metrics\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.05 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * dynamic_pressure))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19467 with standard deviation 0.01041.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.20918677152211151, 0.1895754568001734, 0.18525670596587962]}}
{"id": "027c5edb-b8bb-4b9d-927f-609a7f257d98", "fitness": 0.08854435927941184, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Enhanced Adaptive Quantum-Inspired Hybrid PSO-DE optimizes convergence by integrating dynamic inertia weight adjustment and adaptive crossover based on swarm diversity metrics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n        \n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n            \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n        \n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            diversity = np.std(population, axis=0).mean()\n            self.w = self.w_min + (self.w_max - self.w_min) * (1 - diversity)\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (diversity / (1 + p_best_scores[i])), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(20 * (1 - diversity)))\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08854 with standard deviation 0.00784.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.07757027412407469, 0.09536119005917298, 0.09270161365498786]}}
{"id": "04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4", "fitness": 0.2085131630483139, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Enhanced Adaptive Quantum Hybrid PSO-DE integrates a momentum term to refine convergence speed and stability by dynamically adjusting based on historical improvement trends.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # New momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20851 with standard deviation 0.00489.", "error": "", "parent_ids": ["6a9fc8ea-f08d-4248-956c-af9c7b1e0cde"], "operator": null, "metadata": {"aucs": [0.20202756841539005, 0.21383267541941609, 0.2096792453101356]}}
{"id": "00979dcb-b4b6-49b3-a3e9-fbca99e48997", "fitness": 0.16893374549622017, "name": "QuantumInspiredAdaptiveGradientPSO_DE", "description": "Quantum-Inspired Adaptive Gradient PSO-DE leverages quantum-inspired state transitions combined with adaptive learning rates driven by gradient approximations to enhance convergence precision and efficiency.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveGradientPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2\n        self.w_max = 0.6\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        gradient_approx = np.zeros(self.dim)\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n\n            for i in range(self.population_size):\n                # Gradient approximation\n                grad_steps = np.clip(np.random.normal(0, 1, self.dim), -1, 1)\n                gradient_approx += grad_steps * (func(population[i] + grad_steps) - p_best_scores[i])\n\n                velocity[i] = (self.momentum_factor * velocity[i] + self.w * (self.c1 * r1 * (p_best[i] - population[i]) +\n                                self.c2 * r2 * (g_best - population[i])) + gradient_approx)\n                population[i] = np.clip(population[i] + velocity[i], lb, ub)\n\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.mean(np.abs(gradient_approx)) < 0.0001:\n                self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n            gradient_approx *= 0.9  # Decay factor for gradient approximation\n\n        return g_best", "configspace": "", "generation": 43, "feedback": "The algorithm QuantumInspiredAdaptiveGradientPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16893 with standard deviation 0.01203.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.17351926429639697, 0.15245474168625162, 0.1808272305060119]}}
{"id": "f004f83c-b5c5-4370-9a70-95c0b6858609", "fitness": 0.2085131630483139, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Refined Enhanced Adaptive Quantum Hybrid PSO-DE implements an adaptive learning rate for the momentum term to enhance convergence and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  \n        self.learning_rate = 0.1  # New adaptive learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n                \n            # Adaptive learning rate adjustment\n            if len(historical_improvements) > 5 and evaluations % 10 == 0:\n                self.learning_rate = min(1.0, self.learning_rate + 0.05)\n\n        return g_best", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20851 with standard deviation 0.00489.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20202756841539005, 0.21383267541941609, 0.2096792453101356]}}
{"id": "3b75a081-56ff-48a0-9bc7-9366736aa7ce", "fitness": 0.20216654919618424, "name": "OptimizedHybridPSO_DE", "description": "Optimized Hybrid PSO-DE using Adaptive Quantum Tunneling and Dynamic Strategy Adjustment to Boost Convergence.", "code": "import numpy as np\n\nclass OptimizedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2  # Adjusted\n        self.w_max = 0.6  # Adjusted\n        self.c1 = 1.6  # Adjusted\n        self.c2 = 1.4  # Adjusted\n        self.F_base = 0.6  # Adjusted\n        self.CR_base = 0.6  # Adjusted\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.85  # Adjusted\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 45, "feedback": "The algorithm OptimizedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20217 with standard deviation 0.00857.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.1900949704759124, 0.20912892915237946, 0.20727574796026083]}}
{"id": "e2372844-1c05-42d5-9301-4e937291d827", "fitness": 0.19845558958251386, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Improved Enhanced Adaptive Quantum Hybrid PSO-DE by introducing an adaptive learning rate for faster convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.05)  # Adjusted rate\n                    self.w_min = max(0.1, self.w_min - 0.05)  # Adjusted rate\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.03)\n\n        return g_best", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19846 with standard deviation 0.00712.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.1901636897858171, 0.2075567397429363, 0.19764633921878816]}}
{"id": "5f7e0729-6b4e-471d-8c44-cf330a57d796", "fitness": 0.18345031377181711, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Further Refined Adaptive Quantum Hybrid PSO-DE incorporates environmental and self-adaptive mutation and crossover strategies to enhance convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                \n                # Self-adaptive mutation factor\n                self.F = self.F_base + np.random.rand() * abs(np.tanh(np.mean(p_best_scores) - g_best_score))\n\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Environmental and self-adaptive crossover rate\n                self.CR = max(self.CR_base + np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18345 with standard deviation 0.02585.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.1480335488358252, 0.20901659709025378, 0.1933007953893724]}}
{"id": "65330df6-111f-404a-937a-004227602610", "fitness": 0.2085131630483139, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Introduced self-adaptive parameters for CR and F to enhance exploration and exploitation balance throughout the optimization process.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # New momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20851 with standard deviation 0.00489.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20202756841539005, 0.21383267541941609, 0.2096792453101356]}}
{"id": "f2b56605-7ca0-44c6-9058-91a28707a413", "fitness": -Infinity, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Improved Adaptive Quantum Hybrid PSO-DE with adaptive population size and directionally aware velocity updates to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population) * np.sign(g_best - p_best)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n                elif avg_improvement > 0.01 and self.population_size < 30:\n                    self.population_size += 1\n                    \n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 49, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {}}
{"id": "fbe75567-ef34-49a8-bedd-78aa4b154962", "fitness": 0.20687829388359788, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Enhanced Adaptive Quantum Hybrid PSO-DE now refines its convergence by dynamically altering the crossover rate based on variance in historical improvements.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # New momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Modified line: dynamically adjust CR based on variance in historical improvements\n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (np.var(historical_improvements[-5:]) / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20688 with standard deviation 0.00429.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20881006647266676, 0.21089263668078584, 0.20093217849734102]}}
{"id": "1587d992-7b70-4ccb-88af-9cc010209b15", "fitness": 0.07874635286325977, "name": "QuantumInspiredDynamicPSO", "description": "Quantum-Inspired Dynamic Particle Swarm Optimization incorporates adaptive learning factors based on population diversity and convergence speed for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumInspiredDynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1_base = 1.5\n        self.c2_base = 1.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([func(ind) for ind in population])\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = np.min(p_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(population)\n            c1 = self.c1_base + 0.5 * (1 - diversity)\n            c2 = self.c2_base + 0.5 * diversity\n\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        w * (c1 * r1 * (p_best - population) +\n                             c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                trial_score = func(population[i])\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = population[i]\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = population[i]\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 51, "feedback": "The algorithm QuantumInspiredDynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07875 with standard deviation 0.01200.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.07344126197273104, 0.09536119005917298, 0.06743660655787531]}}
{"id": "420ad5b3-fd46-41af-a2fb-fb6b40c6669d", "fitness": 0.17775344658250836, "name": "MultiStrategyQuantumHybridPSO_DE", "description": "The Multi-Strategy Quantum Hybrid PSO-DE introduces adaptive strategy selection based on population diversity to dynamically switch between exploration and exploitation.", "code": "import numpy as np\n\nclass MultiStrategyQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity = np.std(population, axis=0).mean()\n            adaptive_strategy = 'exploration' if diversity > self.diversity_threshold else 'exploitation'\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                if adaptive_strategy == 'exploration':\n                    self.F = self.F_base + np.random.rand() * 0.5\n                else:\n                    avg_population_score = np.mean(p_best_scores)\n                    self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                \n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 52, "feedback": "The algorithm MultiStrategyQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17775 with standard deviation 0.00965.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.16993220000819387, 0.19134588564954402, 0.17198225408978718]}}
{"id": "2c89dba0-aa06-4b8e-851d-edfa7d0dbc9d", "fitness": 0.2085131630483139, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Enhanced Adaptive Quantum Hybrid PSO-DE with learning and adaptive mutation strategies for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n            # New adaptive mutation strategy\n            diversity = np.std(p_best, axis=0)\n            if np.mean(diversity) < 0.01:\n                self.F_base = min(self.F_base + 0.1, 1.0)  # Encourage diversity\n\n        return g_best", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20851 with standard deviation 0.00489.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20202756841539005, 0.21383267541941609, 0.2096792453101356]}}
{"id": "d9c6fe11-09ba-4d42-b0c4-c31f0ab29a6f", "fitness": -Infinity, "name": "EnhancedAdaptiveQuantumHybridPSO_DE_DNI", "description": "Enhanced Adaptive Quantum Hybrid PSO-DE with Dynamic Neighborhood Integration (PSO-DE-DNI) incorporates dynamic neighborhood information to enhance exploration and convergence by leveraging local optima insights within a versatile population framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE_DNI:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # Momentum term\n        self.local_influence = 0.1  # New local neighborhood influence factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            \n            # Integrating local neighborhood information\n            for i in range(self.population_size):\n                local_best_score = float('inf')\n                local_best = population[i]\n                for j in range(self.population_size):\n                    if i != j:\n                        distance = np.linalg.norm(population[i] - population[j])\n                        if distance < (ub - lb) / 4 and p_best_scores[j] < local_best_score:\n                            local_best_score = p_best_scores[j]\n                            local_best = population[j]\n                velocity[i] += self.local_influence * (local_best - population[i])\n                \n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 54, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {}}
{"id": "73842764-da29-480d-8c91-ec909ca42c24", "fitness": 0.20678432490429502, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Quantum-Inspired Adaptive Momentum PSO-DE refines convergence by dynamically adjusting both momentum and crossover rates based on particle diversity and historical improvements.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Adjust CR based on population diversity\n                diversity_factor = np.std(population, axis=0).mean()\n                self.CR = max(self.CR_base + 0.3 * diversity_factor * np.random.rand(), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 55, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20678 with standard deviation 0.00119.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20742488517206026, 0.20511430882349757, 0.20781378071732726]}}
{"id": "0681828e-2995-4342-8afe-d7c7a0c1998d", "fitness": 0.19378488229252913, "name": "BalancedAdaptiveHybridPSO_DE", "description": "The BalancedAdaptiveHybridPSO_DE incorporates dynamic learning rates and adaptive neighborhood strategies to optimize exploration and exploitation, enhancing convergence and solution quality.", "code": "import numpy as np\n\nclass BalancedAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1_min = 1.0  # Dynamic learning rate for personal best\n        self.c1_max = 2.5\n        self.c2_min = 1.0  # Dynamic learning rate for global best\n        self.c2_max = 2.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            self.c1 = self.c1_min + (self.c1_max - self.c1_min) * dynamic_pressure\n            self.c2 = self.c2_min + (self.c2_max - self.c2_min) * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 56, "feedback": "The algorithm BalancedAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19378 with standard deviation 0.00971.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20112795971720954, 0.18006133482500142, 0.20016535233537647]}}
{"id": "42aadbad-4eb5-4245-b83a-36ec2e314544", "fitness": 0.2074646848679578, "name": "AdaptiveQuantumEnhancedPSO_DE", "description": "Adaptive Quantum-Enhanced PSO-DE introduces a non-linear control mechanism for exploration-exploitation balance and adaptive mutation based on success rate to improve convergence stability and solution quality.", "code": "import numpy as np\n\nclass AdaptiveQuantumEnhancedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.4\n        self.c2 = 1.4\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.success_threshold = 0.1  # New parameter for success-based adaptation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        success_counter = 0\n\n        while evaluations < self.budget:\n            dynamic_pressure = np.sin(np.pi * evaluations / self.budget)\n            self.w = self.w_min + (self.w_max - self.w_min) * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.w * velocity +\n                        self.c1 * r1 * (p_best - population) +\n                        self.c2 * r2 * (g_best - population))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                self.F = self.F_base + 0.5 * np.random.rand() * (1 - dynamic_pressure)\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base * (1 - dynamic_pressure), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    success_counter += 1\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if success_counter / self.population_size > self.success_threshold:\n                self.w_max = min(1.0, self.w_max + 0.05)\n                self.CR_base = max(0.3, self.CR_base - 0.05)\n                success_counter = 0\n\n        return g_best", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveQuantumEnhancedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20746 with standard deviation 0.00708.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.21579267579655104, 0.20811112272734045, 0.19849025607998194]}}
{"id": "0bf7f7f3-9e86-475b-8b5e-3af1530d192d", "fitness": 0.07783115909189779, "name": "ImprovedEnhancedAdaptiveQuantumHybridPSO_DE", "description": "Improved Enhanced Adaptive Quantum Hybrid PSO-DE incorporates adaptive learning rates and diversity preservation techniques to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass ImprovedEnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            \n            diversity_factor = np.std(population, axis=0).mean()\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population) * diversity_factor))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 58, "feedback": "The algorithm ImprovedEnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07783 with standard deviation 0.01313.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.07438548569642223, 0.09536119005917298, 0.06374680152009815]}}
{"id": "aeced910-3ecd-4a1c-9767-f17632ad518c", "fitness": 0.20124109825914627, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Modified Hybrid PSO-DE with Adaptive Differential Evolution scaling and crossover for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                # Modified scaling factor using sigmoid function\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.random.rand() / (1 + np.exp(g_best_score - avg_population_score))\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Modified crossover rate\n                self.CR = max(self.CR_base + 0.1 * np.random.rand() * np.abs(avg_population_score - g_best_score), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20124 with standard deviation 0.00208.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.19970604393023406, 0.20417453435765598, 0.19984271648954877]}}
{"id": "45eb75a9-08ac-4655-afb0-463483b8514c", "fitness": 0.19036330213712485, "name": "QuantumInspiredAdaptiveDE", "description": "Quantum-Inspired Adaptive Differential Evolution incorporates adaptive learning rates and momentum with perturbative Gaussian noise to enhance exploration and convergence.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.7\n        self.c2 = 1.7\n        self.F_base = 0.6\n        self.CR_base = 0.6\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.85\n        self.noise_std = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity + np.random.normal(0, self.noise_std, population.shape), lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 60, "feedback": "The algorithm QuantumInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19036 with standard deviation 0.00424.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.1900740730635292, 0.1853235114424815, 0.1956923219053639]}}
{"id": "07938376-3f71-4d1e-a83a-d7fe5262247a", "fitness": 0.20776241992730257, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Enhanced Adaptive Quantum Hybrid PSO-DE with a refined momentum update strategy for improved performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # New momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.02)  # Adjusted decrement\n\n        return g_best", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20776 with standard deviation 0.00531.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20471628422177102, 0.21523106041576434, 0.20333991514437233]}}
{"id": "c9c13798-ab65-46bb-8e76-dc171d2d4b4f", "fitness": 0.20030086118544066, "name": "AdaptiveQuantumHybridPSO_DE_DynamicFeedback", "description": "Adaptive Quantum Hybrid PSO-DE with Dynamic Feedback introduces a feedback-based parameter adjustment mechanism to enhance exploration and exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumHybridPSO_DE_DynamicFeedback:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # Momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        feedback_window = 10  # Window size for dynamic feedback\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > feedback_window:\n                recent_scores = historical_scores[-feedback_window:]\n                improvement_rate = np.mean(np.diff(recent_scores))\n                self.w_max = max(0.5, self.w_max - 0.1 * (improvement_rate < 0.001))\n                self.momentum_factor = max(0.7, self.momentum_factor - 0.05 * (improvement_rate < 0.001))\n\n        return g_best", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveQuantumHybridPSO_DE_DynamicFeedback got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20030 with standard deviation 0.00948.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.19070292197121264, 0.21320015382746793, 0.1969995077576414]}}
{"id": "906b519b-9255-40b8-bf89-6a21e23bb075", "fitness": 0.20792171849144506, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Refined Enhanced Adaptive Quantum Hybrid PSO-DE with improved adaptive mechanisms for F and CR, leveraging recent performance metrics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        recent_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores[-5:])  # Changed to use recent scores\n                self.F = self.F_base + 0.3 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()  # Adjusted factor\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.25 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)  # Adjusted factor\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    recent_improvements.append(p_best_scores[i] - trial_score)  # Renamed variable\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(recent_improvements) > 5:  # Renamed condition check\n                momentum_improvement = np.mean(recent_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20792 with standard deviation 0.00629.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20431306739559407, 0.21676253159950354, 0.2026895564792376]}}
{"id": "e397cfd9-b5b3-48d9-9e66-3d4a3299e22b", "fitness": 0.1771047083352204, "name": "QuantumInspiredDualGuidedPSO_DE", "description": "Quantum-Inspired Dual-Guided PSO-DE introduces a dual-guided mechanism enhancing particle exploration and convergence using adaptive learning probabilities and hybrid crossover strategies.", "code": "import numpy as np\n\nclass QuantumInspiredDualGuidedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([func(ind) for ind in population])\n        scores = np.copy(p_best_scores)\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = self.F_base + 0.4 * np.random.rand() * (1 - g_best_score / (p_best_scores[i] + 1e-9))\n                mutant = np.clip(a + F_dynamic * (b - c), lb, ub)\n                \n                crossover_prob = self.CR_base + 0.3 * np.random.rand() * ((p_best_scores[i] - g_best_score) / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < crossover_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n\n        return g_best", "configspace": "", "generation": 64, "feedback": "The algorithm QuantumInspiredDualGuidedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17710 with standard deviation 0.01092.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.16179592881713334, 0.18304415491295245, 0.18647404127557543]}}
{"id": "8e3a4ff5-79a0-4593-88a5-fb1ac335c5ff", "fitness": 0.19640094508213224, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Introduced adaptive learning rates and improved diversity through Gaussian mutation for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.1, self.dim), lb, ub)  # Gaussian mutation\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19640 with standard deviation 0.00779.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.2063260620881393, 0.18729818414415422, 0.1955785890141032]}}
{"id": "f7578118-b257-4fa5-a002-6aa7cf0bfe4e", "fitness": 0.1892111388462467, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "The Momentum-Enhanced Adaptive Quantum Hybrid PSO-DE introduces adaptive scaling and crossover strategies to further refine search efficiency and stability by leveraging historical population diversity metrics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        diversity_history = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                diversity = np.std(population, axis=0).mean()\n                diversity_history.append(diversity)\n                avg_diversity = np.mean(diversity_history[-10:])\n                \n                self.F = self.F_base + 0.4 * np.exp(-avg_diversity) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18921 with standard deviation 0.01229.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.17599799222543844, 0.20559328040899105, 0.18604214390431062]}}
{"id": "1735c19d-b2f9-40fa-af85-324f5de4ba55", "fitness": 0.07751641785066739, "name": "DiversifiedVelocityQuantumHybridPSO_DE", "description": "The DiversifiedVelocityQuantumHybridPSO-DE uses variance-based velocity scaling and multi-stage adaptive parameters to enhance exploration and exploitation balance for better convergence.", "code": "import numpy as np\n\nclass DiversifiedVelocityQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.7\n        self.c2 = 1.7\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n        velocity_scaling = np.ones((self.population_size, self.dim))\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            variance = np.var(population, axis=0)\n            velocity_scaling = 1 + variance * np.random.rand(self.population_size, self.dim)\n            velocity *= velocity_scaling\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 67, "feedback": "The algorithm DiversifiedVelocityQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07752 with standard deviation 0.01322.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.07344126197273104, 0.09536119005917298, 0.06374680152009815]}}
{"id": "0521e829-1563-4884-b9e6-7c402904a121", "fitness": 0.12906943389896497, "name": "QuantumInspiredAdaptiveHybridPSO_DE", "description": "Quantum-Inspired Adaptive Hybrid PSO-DE refines exploration and exploitation balance using adaptive quantum potential and differential evolution crossover strategies.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F_base = 0.4\n        self.CR_base = 0.6\n        self.q_min = -np.pi\n        self.q_max = np.pi\n        self.momentum_factor = 0.85\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.sin(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.5 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 68, "feedback": "The algorithm QuantumInspiredAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12907 with standard deviation 0.01651.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.1271623228718446, 0.10987344352962802, 0.1501725352954223]}}
{"id": "60069456-66f3-4809-bc1e-d04ead6dd5b3", "fitness": 0.18589649456289667, "name": "QuantumInspiredAdaptiveHybridPSO_DE", "description": "Quantum-Inspired Adaptive Hybrid PSO-DE integrates adaptive parameter control with a quantum-inspired population update mechanism to enhance exploration and exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.7\n        self.c2 = 1.7\n        self.F_base = 0.5\n        self.CR_base = 0.7\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.85\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.5 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.6, self.w_max - 0.1)\n                    self.momentum_factor = max(0.75, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 69, "feedback": "The algorithm QuantumInspiredAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18590 with standard deviation 0.01193.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.18465842782483766, 0.1719414113648774, 0.20108964449897493]}}
{"id": "2176ca6c-f6ef-4e19-aca4-114c5dfd0974", "fitness": 0.18239368393448543, "name": "AdvancedQuantumHybridPSO_DE", "description": "Advanced Quantum Hybrid PSO-DE with Adaptive Quantum Variance for Enhanced Exploration and Convergence.", "code": "import numpy as np\n\nclass AdvancedQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        quantum_variance = np.var(qubits, axis=0)\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand() * (1 + quantum_variance[i])\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            quantum_variance = np.var(qubits, axis=0)\n\n        return g_best", "configspace": "", "generation": 70, "feedback": "The algorithm AdvancedQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18239 with standard deviation 0.01791.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.16825974076864725, 0.2076688029355228, 0.17125250809928627]}}
{"id": "60095579-cef8-4166-b37a-57a78a7e9711", "fitness": 0.19896165274621702, "name": "EnhancedAdaptiveQuantumHybridPSO_DE_Obl", "description": "The algorithm employs a dynamic opposition-based learning strategy to enhance exploration and overcome early convergence by strategically reinitializing half the population with opposite vectors.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE_Obl:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # New momentum term for velocity\n        self.obl_factor = 0.2  # Opposition-based learning factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            # Opposition-based learning\n            opposite_population = lb + ub - population\n            opposite_scores = np.array([func(ind) for ind in opposite_population])\n            evaluations += self.population_size\n            for i in range(self.population_size):\n                if opposite_scores[i] < p_best_scores[i]:\n                    population[i], p_best_scores[i] = opposite_population[i], opposite_scores[i]\n                    p_best[i] = opposite_population[i]\n                    if opposite_scores[i] < g_best_score:\n                        g_best = opposite_population[i]\n                        g_best_score = opposite_scores[i]\n\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE_Obl got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19896 with standard deviation 0.00484.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.1923033419765624, 0.20091444267089476, 0.2036671735911939]}}
{"id": "5a7e9c57-d953-4fe8-9d1d-bef54f3b5b6b", "fitness": 0.12031987255877878, "name": "EnhancedAdaptiveQuantumHybridPSO_DE", "description": "Enhanced Adaptive Quantum Hybrid PSO-DE improves exploration by adjusting the velocity calculation using a Gaussian-distributed random factor.", "code": "import numpy as np\n\nclass EnhancedAdaptiveQuantumHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9  # New momentum term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.randn(2)  # Changed from rand() to randn() for Gaussian distribution\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveQuantumHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12032 with standard deviation 0.02091.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.14895284998782432, 0.11237972016646236, 0.09962704752204965]}}
{"id": "b59d92f0-d5a1-4934-b9ba-7923df02f351", "fitness": 0.17795698766350768, "name": "QuantumEnhancedAdaptivePSODE", "description": "Quantum-Enhanced Adaptive PSO-DE with Dynamic Learning Rates optimizes convergence by incorporating adaptive learning rates alongside quantum-inspired position updates.", "code": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.alpha = 0.1  # Learning rate factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + self.alpha * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                self.CR = max(self.CR_base + self.alpha * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n        return g_best", "configspace": "", "generation": 73, "feedback": "The algorithm QuantumEnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17796 with standard deviation 0.00536.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.18234466783465342, 0.17041166820826914, 0.1811146269476005]}}
{"id": "debaf8e4-9dad-45e8-b3f1-9457b8fc1438", "fitness": 0.1744492814873381, "name": "AdaptiveMomentumInspiredQuantumPSO_DE", "description": "Adaptive Momentum-Inspired Quantum PSO-DE enhances convergence by incorporating adaptive crossover and mutation controls based on diversity and success history.", "code": "import numpy as np\n\nclass AdaptiveMomentumInspiredQuantumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        success_history = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                diversity_factor = np.std(p_best_scores) / (np.mean(p_best_scores) + 1e-9)\n                self.F = self.F_base + 0.4 * (1 - np.exp(-diversity_factor)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9))\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    success_history.append(1)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                else:\n                    success_history.append(0)\n\n                if evaluations >= self.budget:\n                    break\n\n            if len(success_history) > 10:\n                success_rate = sum(success_history[-10:]) / 10.0\n                if success_rate < 0.2:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n                elif success_rate > 0.8:\n                    self.momentum_factor = min(1.0, self.momentum_factor + 0.05)\n\n        return g_best", "configspace": "", "generation": 74, "feedback": "The algorithm AdaptiveMomentumInspiredQuantumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17445 with standard deviation 0.00630.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.16669156782973915, 0.17452314589205975, 0.18213313074021542]}}
{"id": "b69918e8-c611-423f-bf0a-6c92c801f691", "fitness": 0.20866558219801198, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Quantum-Inspired Adaptive Momentum PSO-DE with Dynamic Diversity Control, enhancing convergence by dynamically adjusting diversity and momentum for balanced exploration-exploitation.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 75, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20867 with standard deviation 0.00482.", "error": "", "parent_ids": ["04fbfffc-f31d-46bf-9d87-2c6ff68e8fd4"], "operator": null, "metadata": {"aucs": [0.20339989227337774, 0.2150561679168893, 0.20754068640376888]}}
{"id": "19970deb-7dd4-4e82-b753-8b531603f4e4", "fitness": -Infinity, "name": "EnhancedQuantumInspiredPSO_DE", "description": "Enhanced Quantum-Inspired PSO-DE with Adaptive Parametric Feedback and Memory Replay, leveraging historical patterns and adaptive parameters to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.memory_replay_factor = 0.1\n        self.adaptive_threshold = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n        memory = [(p_best.copy(), p_best_scores.copy())]\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure * (1 - self.memory_replay_factor)\n\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < self.adaptive_threshold:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < self.adaptive_threshold:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n            if np.random.rand() < self.memory_replay_factor and len(memory) > 1:\n                memory_choice = np.random.choice(memory)\n                p_best, p_best_scores = memory_choice\n\n            memory.append((p_best.copy(), p_best_scores.copy()))\n            if len(memory) > 10:\n                memory.pop(0)\n\n        return g_best", "configspace": "", "generation": 76, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (7, 2, 20) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (7, 2, 20) + inhomogeneous part.')", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {}}
{"id": "e673e745-5e5d-4f39-ad1f-9cabb16c9271", "fitness": 0.077054986368713, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhance convergence by refining mutation strategy with adaptive scaling based on historical improvements.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                self.F *= 1 + np.tanh(np.mean(historical_improvements[-5:]))  # Adjust F adaptively\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 77, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07705 with standard deviation 0.01323.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.07297777647157999, 0.09490864438139401, 0.06327853825316498]}}
{"id": "da0d6b48-5971-4fa6-9986-f6e279f95cf4", "fitness": 0.20726838828210323, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired Adaptive Momentum PSO-DE with Gradient-Based Learning Rate Adjustment and Adaptive Mutation Strategy for improved convergence.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n                if avg_improvement > 0.01:  # Newly added: Increase learning rate if improving\n                    self.w_max = min(0.9, self.w_max + 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n                if momentum_improvement > 0.005:  # Newly added: Adaptive mutation strategy\n                    self.CR_base = min(0.8, self.CR_base + 0.1)\n\n        return g_best", "configspace": "", "generation": 78, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20727 with standard deviation 0.00300.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.20582265381920506, 0.2114417202811245, 0.20454079074598008]}}
{"id": "b33910b8-a54e-4fc0-93ad-819c5a151bda", "fitness": -Infinity, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired PSO-DE with Adaptive Population Size and Stochastic Mutation Control to bolster exploration and convergence efficiency.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        qubits = np.random.uniform(self.q_min, self.q_max, (population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * population_size)\n\n        for i in range(population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(population_size):\n                indices = [idx for idx in range(population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.random.rand() * np.exp(-abs(g_best_score - avg_population_score))\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n            if evaluations < 0.5 * self.budget:\n                population_size = min(40, population_size + 2)\n\n        return g_best", "configspace": "", "generation": 79, "feedback": "An exception occurred: IndexError('index 21 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 21 is out of bounds for axis 0 with size 20')", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {}}
{"id": "59d7e7a1-b977-4cd7-83be-6cd94e6b21f5", "fitness": 0.20665851079318942, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Refined adaptive momentum adjustment based on diversity factor to enhance convergence speed and stability.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.95 * (1 - diversity_factor)  # Changed from 0.9 to 0.95\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 80, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20666 with standard deviation 0.00498.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.2027677824444124, 0.2136878372482025, 0.20351991268695335]}}
{"id": "c0887a6e-ddff-4d41-9faa-674baa456705", "fitness": 0.20457420700166437, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired Adaptive Momentum PSO-DE with Adaptive Control Mechanism, improving convergence by dynamically adjusting exploration-exploitation balance and mutation strategies.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            self.c1 = 1.5 + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)  # Adaptive c1 based on evaluations\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                self.CR = min(max(self.CR, 0.2), 0.9)  # Ensure CR stays within reasonable bounds\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 81, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20457 with standard deviation 0.00544.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.20209472143264873, 0.21211973973298492, 0.19950815983935943]}}
{"id": "b4e1a627-7a02-4c8b-9eb9-6539c31c80ba", "fitness": 0.19940723693874732, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired Adaptive Momentum PSO-DE with Improved Velocity Update and Dynamic CR for Robust Adaptability.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = self.CR_base + 0.3 * diversity_factor * (g_best_score / (p_best_scores[i] + 1e-9))\n                self.CR = np.clip(self.CR, 0.2, 0.9)\n                \n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 82, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19941 with standard deviation 0.00941.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.2059050386917416, 0.1861070555807568, 0.2062096165437436]}}
{"id": "210355ac-c3b7-43d9-ac9b-ae9f346f8b58", "fitness": 0.20797615200716568, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Introduced adaptive dynamic scaling for mutation factor (F) and accelerated convergence through improved historical improvement tracking.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * dynamic_pressure * np.random.rand()  # Adaptive dynamic scaling\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.0005:  # More sensitive threshold for momentum adjustment\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 83, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20798 with standard deviation 0.00556.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.2022144015124271, 0.2154843808167748, 0.20622967369229517]}}
{"id": "dd4131b2-0bea-4a9b-8c93-b7b36554cfe3", "fitness": 0.20749924344208803, "name": "EnhancedQuantumPSO_DE", "description": "Enhanced Quantum PSO-DE with Adaptive Neighborhood Learning and Momentum Adjustment, focusing on improved global exploration and adaptive local exploitation strategies to optimize convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedQuantumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                a, b, c = population[neighbors[:3]]\n\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedQuantumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20750 with standard deviation 0.00297.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.2095892934570045, 0.20960464255552302, 0.20330379431373657]}}
{"id": "248fcd27-83bb-4f9c-886b-602c86f697a9", "fitness": 0.203241997616556, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired Adaptive Momentum PSO-DE with Adaptive Parameters, improving convergence by dynamically adjusting both control and mutation parameters for adaptive exploration-exploitation balance.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                self.CR *= (0.5 + 0.5 * np.random.rand())  # Adaptive CR adjustment\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 85, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20324 with standard deviation 0.00762.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.2126871518735145, 0.194017782061345, 0.20302105891480848]}}
{"id": "bc6c6df4-66eb-4149-8d77-b8e705d38abb", "fitness": 0.20866558219801198, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhancing Quantum-Inspired Adaptive Momentum PSO-DE with Adaptive Boundary Constraints for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n        return g_best", "configspace": "", "generation": 86, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20867 with standard deviation 0.00482.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.20339989227337774, 0.2150561679168893, 0.20754068640376888]}}
{"id": "d0e02ee4-843d-4272-a285-3d83684c1bce", "fitness": 0.20867492906866014, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Adaptive Quantum-Inspired PSO-DE with Inertia Weight Tuning based on Historical Performance Trends, refining local searches and convergence by dynamically adapting strategy parameters.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:  # Tuning inertia based on std deviation\n                self.w_min = min(0.5, self.w_min + 0.05)  # Change 1\n\n        return g_best", "configspace": "", "generation": 87, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20867 with standard deviation 0.00481.", "error": "", "parent_ids": ["b69918e8-c611-423f-bf0a-6c92c801f691"], "operator": null, "metadata": {"aucs": [0.20345310641391623, 0.21505657585221216, 0.20751510493985204]}}
{"id": "99206eeb-acce-4ce5-9967-13da94e1d855", "fitness": 0.20443583402636167, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Quantum-Inspired Adaptive Momentum PSO-DE with Adaptive Learning Rates, enhancing convergence by dynamically adjusting exploration and exploitation based on real-time performance feedback.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1_base = 1.5\n        self.c2_base = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            \n            # Adaptive learning rates based on performance feedback\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.c1 = self.c1_base * (1 + diversity_factor)\n            self.c2 = self.c2_base * (1 + (1 - diversity_factor))\n            \n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 88, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20444 with standard deviation 0.00476.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.1991607777955352, 0.20345557769008227, 0.21069114659346755]}}
{"id": "40124b32-d4df-4dbd-b360-4a73df9579df", "fitness": 0.2039892430426554, "name": "EnhancedQuantumInspiredPSO_DE", "description": "Enhanced Quantum-Inspired PSO-DE with Adaptive Diversification and Convergence Strategies by incorporating dynamic adjustment of exploration-exploitation balance using historical gradients and maintaining diversity with controlled mutation rate.", "code": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        diversity_history = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            \n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n            diversity_history.append(diversity_factor)\n\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                delta_g_best = np.abs(g_best_score - np.min(p_best_scores))\n                self.F = self.F_base + 0.5 * np.exp(-delta_g_best) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                avg_score = np.mean(p_best_scores)\n                self.CR = max(self.CR_base + 0.2 * (1 - dynamic_pressure) * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if np.std(historical_scores[-5:]) < 0.01 and len(diversity_history) > 5:\n                self.F_base = min(0.7, self.F_base + 0.05)\n\n        return g_best", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedQuantumInspiredPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20399 with standard deviation 0.00813.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.19512187836271633, 0.21475876612854838, 0.20208708463670144]}}
{"id": "542928e3-26b8-4bb7-922e-ce35f0364d56", "fitness": 0.20867492906866014, "name": "QuantumAdaptiveHybridPSO_DE", "description": "Quantum Adaptive Hybrid PSO-DE with Stochastic Control Mechanisms enhancing exploration-exploitation balance via probabilistic parameter adjustments and diversity safeguarding.", "code": "import numpy as np\n\nclass QuantumAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3 and diversity_factor < self.diversity_threshold:\n                self.w_min = min(0.5, self.w_min + 0.05)  # Enhance exploration\n\n        return g_best", "configspace": "", "generation": 90, "feedback": "The algorithm QuantumAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20867 with standard deviation 0.00481.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.20345310641391623, 0.21505657585221216, 0.20751510493985204]}}
{"id": "f8dfcfa9-bb05-476b-9386-78763c28e8bc", "fitness": 0.20484597854304823, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Improved Quantum-Inspired PSO-DE by incorporating adaptive learning rates and diversity-based rejuvenation for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.learning_rate = 0.1  # Added learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < self.learning_rate:  # Adjusted learning rate evaluation\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < self.learning_rate:  # Adjusted learning rate evaluation\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n            if diversity_factor < 0.1:  # Diversity-based rejuvenation\n                velocity *= np.random.uniform(0.9, 1.1)\n                self.w_max = min(1.2, self.w_max + 0.05)\n\n        return g_best", "configspace": "", "generation": 91, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20485 with standard deviation 0.00805.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.204260933550249, 0.21498783987606518, 0.19528916220283055]}}
{"id": "08195315-8134-4820-b500-2acb34893246", "fitness": 0.19686805536263, "name": "QuantumInspiredDynamicPSO_DE", "description": "Quantum-Inspired Dynamic Exploration and Exploitation Balancing PSO-DE, enhancing convergence by adaptive diversity control and strategic parameter fine-tuning based on real-time population dynamics.", "code": "import numpy as np\n\nclass QuantumInspiredDynamicPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.7\n        self.c2 = 1.7\n        self.F_base = 0.6\n        self.CR_base = 0.6\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.5 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.25 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.75, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 92, "feedback": "The algorithm QuantumInspiredDynamicPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19687 with standard deviation 0.01062.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.20161206295362222, 0.18215177605334898, 0.20684032708091882]}}
{"id": "6dc6fd07-7d25-44e9-80d0-f23c45e73941", "fitness": 0.2054817583651437, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired PSO-DE with Adaptive Diversity Control and Gradient Estimation for Efficient Convergence.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                gradient_estimation = (p_best_scores[i] - g_best_score) / (np.linalg.norm(p_best[i] - g_best) + 1e-9)\n                self.F = self.F_base + 0.4 * np.exp(-abs(gradient_estimation)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 93, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20548 with standard deviation 0.00694.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.20152731028788284, 0.21523433608035758, 0.1996836287271907]}}
{"id": "672c6181-ee0e-4632-93af-74b72cfa421a", "fitness": -Infinity, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced Quantum-Inspired PSO-DE with Adaptive Mutation and Dynamic Population Size for Improved Diversity and Convergence. ", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n                if evaluations > self.budget * 0.5:  # Dynamic population size adjustment\n                    self.population_size = int(self.population_size * 1.2)\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 94, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {}}
{"id": "0d9f757f-fdf8-4e97-9afb-8b32752a307a", "fitness": 0.10027543369088106, "name": "AdaptiveQuantumInspiredPSO_DE", "description": "Adaptive Quantum-Inspired PSO-DE with Diversity-Driven Dual Strategy Tuning, enhancing exploration and exploitation based on population diversity metrics for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity = np.std(population, axis=0).mean()\n            self.momentum_factor = 0.9 * (1 - diversity)\n            \n            if diversity > 0.1:\n                self.F = self.F_base + 0.4 * np.random.rand()\n                self.CR = self.CR_base + 0.3 * np.random.rand()\n            else:\n                self.F = self.F_base * 0.5\n                self.CR = max(self.CR_base, 0.1 + 0.2 * np.random.rand())\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n        return g_best", "configspace": "", "generation": 95, "feedback": "The algorithm AdaptiveQuantumInspiredPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10028 with standard deviation 0.00915.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.09245385944341644, 0.11311274046696862, 0.09525970116225813]}}
{"id": "a0bce4c9-6fd3-460d-8b12-a59389d9c0db", "fitness": 0.20867492906866014, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Improved convergence by introducing adaptive control for the crossover rate based on historical improvements.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:  # Tuning inertia based on std deviation\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n            if len(historical_improvements) > 5 and np.mean(historical_improvements[-5:]) > 0.001:  # Change 1\n                self.CR_base = min(0.9, self.CR_base + 0.1)  # Change 2\n\n        return g_best", "configspace": "", "generation": 96, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20867 with standard deviation 0.00481.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.20345310641391623, 0.21505657585221216, 0.20751510493985204]}}
{"id": "8b95c985-3736-4e5e-b4df-547493886d1f", "fitness": 0.19860478742628976, "name": "EnhancedQuantumPSO_DE", "description": "Enhanced Quantum-Inspired PSO-DE with Adaptive Diversity Control and Continuous Learning from Historical Improvements to optimize exploration-exploitation balance and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedQuantumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 1.7\n        self.c2 = 1.7\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.diversity_threshold = 0.05  # New parameter for diversity control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.full(self.population_size, float('inf'))\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(population) / (np.abs(np.mean(population)) + 1e-9)\n            if diversity_factor < self.diversity_threshold:\n                self.momentum_factor = min(0.95, self.momentum_factor + 0.05)\n            else:\n                self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 10:\n                recent_scores = historical_scores[-10:]\n                avg_improvement = np.mean(np.diff(recent_scores))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n                if np.std(recent_scores) < 0.01:\n                    self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedQuantumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19860 with standard deviation 0.00492.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.19945035429866076, 0.1921949377173463, 0.20416907026286224]}}
{"id": "541f94c6-e3e4-4915-a571-f42553ce28a3", "fitness": 0.20860343267113554, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Symbiotic Quantum-Inspired Adaptive Momentum PSO-DE with Enhanced Diversity Control and Dynamic Mutation Strategy Tuning.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F_base = 0.5\n        self.CR_base = 0.5\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n        \n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            if evaluations > 0.5 * self.budget:  # Dynamic mutation strategy tuning\n                self.F_base = 0.6\n                self.CR_base = 0.7\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                \n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n            \n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 98, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20860 with standard deviation 0.00474.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.20344215508695318, 0.2148886403895235, 0.20747950253692993]}}
{"id": "a65ced92-1f65-457c-84f7-c781d21bbcc7", "fitness": 0.20174870726272498, "name": "QuantumInspiredAdaptiveMomentumPSO_DE", "description": "Enhanced PSO-DE with Dynamic Quantum Tunneling and Adaptive Diversity Control, improving exploration and convergence.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveMomentumPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w_min = 0.3\n        self.w_max = 0.9\n        self.c1 = 1.7  # Change 1\n        self.c2 = 1.7  # Change 2\n        self.F_base = 0.6  # Change 3\n        self.CR_base = 0.6  # Change 4\n        self.q_min = -1\n        self.q_max = 1\n        self.momentum_factor = 0.9\n        self.diversity_threshold = 0.05  # Change 5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        qubits = np.random.uniform(self.q_min, self.q_max, (self.population_size, self.dim))\n        population = lb + (ub - lb) / 2 * (1 + np.tanh(qubits))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = population.copy()\n        p_best_scores = np.array([float('inf')] * self.population_size)\n\n        for i in range(self.population_size):\n            score = func(population[i])\n            p_best_scores[i] = score\n\n        g_best = population[np.argmin(p_best_scores)]\n        g_best_score = min(p_best_scores)\n\n        evaluations = self.population_size\n        historical_scores = []\n        historical_improvements = []\n\n        while evaluations < self.budget:\n            dynamic_pressure = (self.budget - evaluations) / self.budget\n            self.w = self.w_min + (self.w_max - self.w_min) * np.random.rand() * dynamic_pressure\n            r1, r2 = np.random.rand(2)\n            velocity = (self.momentum_factor * velocity +\n                        self.w * (self.c1 * r1 * (p_best - population) +\n                                  self.c2 * r2 * (g_best - population)))\n            population = np.clip(population + velocity, lb, ub)\n\n            diversity_factor = np.std(p_best_scores) / (np.abs(np.mean(p_best_scores)) + 1e-9)\n            self.momentum_factor = 0.9 * (1 - diversity_factor)\n            \n            # Quantum tunneling mechanism\n            if np.std(p_best_scores) < self.diversity_threshold:  # Change 6\n                population += np.random.normal(0, 0.1, population.shape)  # Change 7\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n\n                avg_population_score = np.mean(p_best_scores)\n                self.F = self.F_base + 0.4 * np.exp(-abs(g_best_score - avg_population_score)) * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n\n                self.CR = max(self.CR_base + 0.3 * np.random.rand() * (g_best_score / (p_best_scores[i] + 1e-9)), 0.1)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_score = func(trial)\n                evaluations += 1\n                historical_scores.append(trial_score)\n                if trial_score < p_best_scores[i]:\n                    p_best[i] = trial\n                    p_best_scores[i] = trial_score\n                    historical_improvements.append(p_best_scores[i] - trial_score)\n                    if trial_score < g_best_score:\n                        g_best = trial\n                        g_best_score = trial_score\n                if evaluations >= self.budget:\n                    break\n\n            if len(historical_scores) > 5:\n                avg_improvement = np.mean(np.diff(historical_scores[-5:]))\n                if avg_improvement < 0.001:\n                    self.w_max = max(0.5, self.w_max - 0.1)\n\n            if len(historical_improvements) > 5:\n                momentum_improvement = np.mean(historical_improvements[-5:])\n                if momentum_improvement < 0.001:\n                    self.momentum_factor = max(0.7, self.momentum_factor - 0.05)\n\n            if np.std(historical_scores[-5:]) < 0.01 and dynamic_pressure < 0.3:\n                self.w_min = min(0.5, self.w_min + 0.05)\n\n        return g_best", "configspace": "", "generation": 99, "feedback": "The algorithm QuantumInspiredAdaptiveMomentumPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20175 with standard deviation 0.01157.", "error": "", "parent_ids": ["d0e02ee4-843d-4272-a285-3d83684c1bce"], "operator": null, "metadata": {"aucs": [0.20964525142018653, 0.18538800976830216, 0.21021286059968625]}}
