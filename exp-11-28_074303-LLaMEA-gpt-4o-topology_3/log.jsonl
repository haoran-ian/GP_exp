{"id": "3d2e1c63-9ea1-4d8d-85b9-90d75eba7710", "fitness": 0.3978444833208997, "name": "HybridPSO_DE", "description": "A novel hybrid particle swarm optimization and differential evolution algorithm, combining global and local search strategies to effectively explore and exploit the search space.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.34.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.14315014078853205, 0.11380693972780609, 0.11779729175354492, 0.11733776351732328, 0.13570841289951452, 0.8499789708696396, 0.6310667457779677, 0.8935906024035334, 0.517408364077873, 0.8189555582550438, 0.5565082843575573, 0.8222079597919004, 0.8443553063413572, 0.44548436148997317, 0.7817340694919604]}}
{"id": "7d70156b-8cc8-4be8-b1a5-513131abe5a5", "fitness": 0.26877229859952856, "name": "HybridPSO_DE", "description": "A refined hybrid algorithm using adaptive inertia weight for better convergence in variable dimensions.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w_init = 0.9  # initial inertia weight\n        self.w_end = 0.4   # final inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (eval_count / self.budget)\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.20.", "error": "", "parent_ids": ["3d2e1c63-9ea1-4d8d-85b9-90d75eba7710"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1493777059061554, 0.14560825820831946, 0.11965960670062203, 0.12529024963909507, 0.12435532610509281, 0.3543618128339632, 0.38965860759871773, 0.41713663773974596, 0.23892043524583606, 0.5445286766945097, 0.4349779282610666, 0.4786858312473917, 0.6681811122151993, 0.5305889919465772, 0.4863158967738125]}}
{"id": "ebf7a0c3-1e21-4f21-af95-6f025c066339", "fitness": 0.26877229859952856, "name": "HybridPSO_DE", "description": "Improved hybrid algorithm with adaptive inertia weight for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.20.", "error": "", "parent_ids": ["3d2e1c63-9ea1-4d8d-85b9-90d75eba7710"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1493777059061554, 0.14560825820831946, 0.11965960670062203, 0.12529024963909507, 0.12435532610509281, 0.3543618128339632, 0.38965860759871773, 0.41713663773974596, 0.23892043524583606, 0.5445286766945097, 0.4349779282610666, 0.4786858312473917, 0.6681811122151993, 0.5305889919465772, 0.4863158967738125]}}
{"id": "bcbf3c53-cf20-4e84-9c8a-16b54f5b6875", "fitness": 0.2687722985992298, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive inertia weight for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.9   # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Update inertia weight\n            self.w = self.w_min + (0.9 - self.w_min) * ((self.budget - eval_count) / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.20.", "error": "", "parent_ids": ["3d2e1c63-9ea1-4d8d-85b9-90d75eba7710"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.14937770590766453, 0.1456082582077063, 0.11965960670062203, 0.12529024963728408, 0.12435532610550148, 0.35436181283386325, 0.3896586075987265, 0.41713663774125376, 0.2389204352390445, 0.5445286766945199, 0.4349779282609515, 0.4786858312473913, 0.6681811122151993, 0.5305889919465874, 0.4863158967738125]}}
{"id": "ec1735df-999a-4de2-a833-386a8c5c0e73", "fitness": 0.42941048239564356, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by fine-tuning parameters for improved balance in exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.38.", "error": "", "parent_ids": ["3d2e1c63-9ea1-4d8d-85b9-90d75eba7710"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11966839684758646, 0.12109591225492566, 0.12671590893918117, 0.12288889534730951, 0.11782969083653072, 0.8408911569935467, 0.3245873288967538, 0.9138181698622504, 0.9240939587438686, 0.8968142568639185, 0.702492763866049, 0.7853621493311884, 0.906354068487809, 0.6075058149674064, 0.9102922808000818]}}
{"id": "ffbb5a6e-8c7c-4c62-8550-a463a5f11296", "fitness": 0.26237518969716317, "name": "HybridPSO_DE", "description": "Introducing adaptive coefficients for better balance in exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive PSO update\n            self.w = 0.4 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.20.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1372684410598899, 0.12153350918197248, 0.12105174968327848, 0.13312235018202667, 0.13360038937946073, 0.5696520674459911, 0.3245780965867987, 0.5367711873811339, 0.191863225409601, 0.48307905025905196, 0.4111900132841223, 0.41170833213628266, 0.578569467276943, 0.564864349119134, 0.36085267068311067]}}
{"id": "38ce761b-2fd2-4f45-a554-996d15515954", "fitness": 0.2604779672393226, "name": "HybridPSO_DE", "description": "HybridPSO_DE with Adaptive Parameters for Dynamic Balance in Exploration and Exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.4  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.8   # inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.30.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11722106454542947, 0.12295522371804313, 0.11446577808106762, 0.13576961151075917, 0.11989335086703334, 0.5692152594643589, 0.12058694860694819, 0.7621611395298171, 0.11219045626054769, 0.8138224724986209, 0.11291163602952703, 0.12462896419379799, 0.9362197731569071, 0.08832243860843692, 0.7913963328406912]}}
{"id": "e97005c4-6cde-460e-9fbd-1c2df46e3a0e", "fitness": 0.34168077657798024, "name": "HybridPSO_DE", "description": "Slightly refined HybridPSO_DE by adjusting parameters for better convergence under budget constraints.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient (changed from 1.7)\n        self.c2 = 1.5  # social coefficient (changed from 1.3)\n        self.w = 0.7   # inertia weight (changed from 0.6)\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.32.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1254149589324981, 0.14160713236844502, 0.12363048127014964, 0.1299198383456569, 0.127034700520267, 0.13572240700620908, 0.7807707237349916, 0.8980922543440344, 0.5976716315248074, 0.7093474187465714, 0.14955223003269513, 0.5958064097814073, 0.8789588451616401, 0.4087440571703629, 0.863543547745402]}}
{"id": "c8a8aa3e-0d8b-4539-9584-8b23e16d42e6", "fitness": 0.23115671359687368, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by incorporating adaptive inertia weight and dynamic crossover rate for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # start inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.1  # start DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = self.w_min + (0.9 - self.w_min) * ((self.budget - eval_count) / self.budget)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            self.CR = 0.9 * (1 - eval_count / self.budget)  # Dynamic DE crossover rate\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.16.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12321809875502432, 0.3336570965334201, 0.14065559944957773, 0.1241833301719869, 0.14161026622824535, 0.29244926757497147, 0.24847322585641485, 0.581101647409452, 0.3518488180860032, 0.3127649948553416, 0.37884966315740676, 0.22443805470243927, 0.45831310298583927, 0.40405761182931466, 0.33971459946756977]}}
{"id": "6f5f5fdd-a1de-4d23-828b-a706dc02c7d0", "fitness": 0.26237518969671464, "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight in HybridPSO_DE to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.9 - 0.5 * (eval_count / self.budget)  # Adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.20.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1372684410598899, 0.12153350918097694, 0.12105174968334098, 0.13312235018168816, 0.13360038937343277, 0.5696520674459911, 0.3245780965869316, 0.5367711873811427, 0.1918632254091429, 0.48307905025905196, 0.41119001328393, 0.4117083321352175, 0.578569467276943, 0.5648643491191331, 0.3608526706830132]}}
{"id": "2a3d66a1-c7fa-4171-8137-f679c7fdcb9e", "fitness": 0.39786945231193804, "name": "HybridPSO_DE", "description": "Improved exploration by dynamically adjusting cognitive and social coefficients in the HybridPSO_DE algorithm.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 2.0  # cognitive coefficient adjusted from 1.7\n        self.c2 = 1.0  # social coefficient adjusted from 1.3\n        self.w = 0.6   # inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.36.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11897242974991862, 0.11326327944416525, 0.13414590262718273, 0.12582221443350694, 0.13881681301073823, 0.8712520152895121, 0.16107162540300268, 0.8996324266987324, 0.5758607235216455, 0.8529183836427368, 0.8502595190221612, 0.5432869779101551, 0.925374480833396, 0.7925466618024527, 0.6863666979749898]}}
{"id": "b1a6c276-918c-445f-b81a-ad5112d5dc3d", "fitness": 0.2558850512134544, "name": "HybridPSO_DE", "description": "Improved control over exploration and exploitation balance by dynamically adjusting the inertia weight `w` and introducing perturbation in DE crossover.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # adjusted start inertia weight\n        self.F = 0.85  # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia weight adjustment\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                mutant_vector += np.random.normal(0, 0.01, self.dim)  # Perturbation in DE crossover\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.19.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.13667712622453476, 0.13002053822600312, 0.13154261856160043, 0.143663685003247, 0.15735802575224933, 0.28308723819114934, 0.3303041295321666, 0.6083491733286388, 0.6146185473765733, 0.3874398887951551, 0.3484306835479528, 0.28770007302600875, 0.5509697888566529, 0.3780789369126174, 0.4616616760600729]}}
{"id": "296eea29-f9d4-4409-ae30-e66482fd1e4b", "fitness": 0.4380380480105062, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by adjusting crossover rate and mutation factor for better exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 12, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.37.", "error": "", "parent_ids": ["ec1735df-999a-4de2-a833-386a8c5c0e73"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12601357631355892, 0.13791632761211026, 0.11542894877216914, 0.13804116613621864, 0.12010633590505704, 0.7536914605502898, 0.6006507305649736, 0.9303104788319043, 0.9240939587438686, 0.8035008578078209, 0.8013501054383024, 0.6315390938615133, 0.8816531647422458, 0.7929317906043373, 0.8357340694512887]}}
{"id": "63376a88-1161-468e-a95f-8ea0955a7961", "fitness": 0.27321681671752884, "name": "HybridPSO_DE", "description": "Refined HybridPSO_DE by dynamically adapting inertia weight and enhancing trial vector selection.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # initial inertia weight\n        self.w_min = 0.3  # minimum inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Update inertia weight dynamically\n            self.w = self.w_min + (0.9 - self.w_min) * (self.budget - eval_count) / self.budget\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.22.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1229758402022274, 0.11867264406022959, 0.13595263215637043, 0.12180596806094224, 0.1292917877873777, 0.43343838762667597, 0.1400594240630908, 0.7520901472496218, 0.45368875804805187, 0.49164431388618035, 0.5268247146052805, 0.3792235486932245, 0.6339110562258886, 0.4635494707289448, 0.39340874608200405]}}
{"id": "fc8421d5-170d-4217-b5f4-b35aa12953a7", "fitness": 0.21520677013761325, "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE by dynamically adjusting inertia weight and employing adaptive mutation to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # inertia weight (increased to enhance exploration)\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive mutation factor\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.19.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12412829136666204, 0.12870131051833955, 0.11737443339529774, 0.11618078278714905, 0.1195357259367994, 0.3232023816765319, 0.10799852173118918, 0.449489598437385, 0.6661843967407, 0.11618630896854898, 0.3851391326792869, 0.40578280585980253, 0.571421950867105, 0.34116696071558517, 0.1638439061974165]}}
{"id": "a71e3c20-b4eb-47dc-8feb-245f9548c4d8", "fitness": 0.22976970426062646, "name": "HybridPSO_DE", "description": "Enhance the balance between exploration and exploitation by dynamically adjusting parameters based on function evaluations.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adjust parameters dynamically\n            self.w = 0.9 - 0.5 * (eval_count / self.budget)\n            self.F = 0.8 + 0.2 * (eval_count / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.18.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12353367992982955, 0.1267455784070014, 0.12333514479029362, 0.1286299181083469, 0.13208558137010695, 0.2643587180576672, 0.19087036899126497, 0.5920927429980282, 0.4316724422022121, 0.2698097815439944, 0.23451875543835965, 0.3850762997628928, 0.5804987073202886, 0.4919148804795964, 0.35245259093818004]}}
{"id": "aba9782a-ba83-4767-a590-9096449724b4", "fitness": 0.43455121248179884, "name": "HybridPSO_DE", "description": "Introduced adaptive parameters for DE to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.9 - 0.5 * (eval_count / self.budget)  # Adaptive scaling factor\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 16, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.39.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1263651624593688, 0.12078326938400685, 0.136986068139483, 0.12982050461039274, 0.1202093798556948, 0.8917475339126039, 0.12105238355765713, 0.9138181698622504, 0.8966053815724291, 0.8283398866967256, 0.9205029295907725, 0.8731292447631027, 0.9137269466331923, 0.6695561980257874, 0.8605822956980429]}}
{"id": "847f2784-aa2c-4bc2-b1f5-92bdf10e4cc7", "fitness": 0.2308249751783605, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by incorporating adaptive inertia weight and mutation factor for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight and scaling factor\n            self.w = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            self.F = 0.5 + 0.4 * (1 - eval_count / self.budget)\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11956140781847102, 0.12296196135529369, 0.11932836204508723, 0.1288169010425665, 0.11979452704075055, 0.4678140100387277, 0.2304501150171374, 0.6562742318540612, 0.30673977835334787, 0.11875114458367375, 0.6892114662334936, 0.19806820150210136, 0.5372546263160066, 0.3672744483845618, 0.2663994271074638]}}
{"id": "96fce0e2-98f2-42b3-afe5-996df7d5fd7f", "fitness": 0.30282379890049804, "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE by fine-tuning inertia weight dynamically for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.9 - 0.7 * (eval_count / self.budget)  # Dynamic inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12399406125869417, 0.11641237300675189, 0.12960020983399512, 0.11878494702643605, 0.12177118418989263, 0.6693095296181206, 0.41608032118906557, 0.5177610342344954, 0.4251204096054946, 0.5012580209891959, 0.644687415800715, 0.5103107721436713, 0.6434177184887744, 0.46129229340823386, 0.4888767923419579]}}
{"id": "aafe1d34-a4e4-4f7a-ad1a-6261ea5e6a5a", "fitness": 0.23082497517730646, "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE by dynamically adjusting inertia weight and DE scaling factor for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w_start = 0.9   # initial inertia weight\n        self.w_end = 0.4     # final inertia weight\n        self.F_start = 0.9   # initial DE scaling factor\n        self.F_end = 0.5     # final DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            progress = eval_count / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start - progress * (self.F_start - self.F_end)\n            \n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 19, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11956140781794933, 0.12296196135482418, 0.11932836204510755, 0.12881690104266996, 0.1197945270403552, 0.4678140100389123, 0.23045011501648138, 0.6562742318540612, 0.30673977835323185, 0.11875114458420755, 0.6892114662334936, 0.19806820148267323, 0.5372546263160066, 0.3672744483842121, 0.26639942710747744]}}
{"id": "1ee784bb-9746-4b68-a5e0-af28d4e56384", "fitness": 0.22512639039227858, "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight and self-adaptive DE parameters for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptively adjust inertia weight\n            self.w = 0.9 - (0.5 * eval_count / self.budget)\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover with self-adaptive parameters\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                self.F = 0.5 + 0.5 * np.random.rand()  # self-adaptive DE scaling factor\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 20, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12160886272153881, 0.12702465692526899, 0.12219917241376244, 0.16269870652474883, 0.11880893376330504, 0.42771372399575014, 0.11126442256512525, 0.7651268708743789, 0.5667754199328052, 0.16146638810797764, 0.32386366998603244, 0.34184592409509207, 0.4188561666844848, 0.284960356639136, 0.28051563774169874]}}
{"id": "0c5794e2-fb46-4baa-bea3-c8c21ea30a7a", "fitness": 0.20019283356019169, "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE by dynamically adjusting inertia weight and incorporating adaptive DE parameters for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.F = 0.5 + np.random.rand() * 0.4  # Adaptive DE scaling factor\n        self.CR = 0.6 + np.random.rand() * 0.4  # Adaptive DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 21, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.17.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.13547075647104212, 0.11786210154995114, 0.11671962580205364, 0.16445463465130505, 0.13026629489907093, 0.17989932447858814, 0.12285581078376429, 0.30889545364563464, 0.30720900558508024, 0.6859539064153257, 0.3053251526289117, 0.11530229214649079, 0.40527688192571887, 0.38915274058349747, 0.35141379476293244]}}
{"id": "7c525184-a887-4e96-a048-381c858cae09", "fitness": 0.42819639256774106, "name": "HybridPSO_DE", "description": "Enhance exploration by dynamic adjustment of inertia weight and scaling factor based on evaluation progress.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adjust inertia weight and scaling factor dynamically\n            self.w = 0.4 + 0.2 * (self.budget - eval_count) / self.budget\n            self.F = 0.7 + 0.2 * eval_count / self.budget\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 22, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.36.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12819221031013073, 0.15707406180862205, 0.12941628462756172, 0.11825382283398422, 0.11722956645060723, 0.7390007683337634, 0.4947880959088332, 0.9412141267070867, 0.7773802480755823, 0.9268594794892153, 0.8204049131229315, 0.6702473550262937, 0.906410848208921, 0.814962100321177, 0.6546950752556446]}}
{"id": "f5477147-5977-4c88-aac1-c06e79f67366", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Improved particle swarm optimization by employing adaptive inertia weight and dynamic population size for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # inertia weight (changed from 0.6)\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n            # Adjust population size dynamically (added logic)\n            if eval_count < self.budget // 2:\n                self.pop_size = min(self.pop_size + 1, int(20 + 2 * dim))\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 23, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {}}
{"id": "815d8518-23bf-4f7b-a652-ef6218f8bae6", "fitness": 0.25317698559059365, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by dynamically adjusting the inertia weight for better adaptability.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # initial inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adjust inertia weight dynamically\n            self.w = 0.4 + 0.5 * ((self.budget - eval_count) / self.budget)\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.13309254155450834, 0.12266619333287221, 0.1267738559920072, 0.16025388616426994, 0.12706767837567723, 0.3926444314399432, 0.1274704659413458, 0.6797120931967361, 0.5131471164356143, 0.19988371193773347, 0.5759616082077256, 0.4296882360829283, 0.4978890546994884, 0.31978098860551263, 0.48970895497104416]}}
{"id": "b4f8be23-c53f-4643-be69-6f55e18fc934", "fitness": 0.11888560801941081, "name": "HybridPSO_DE", "description": "Introduced velocity adaptation and adaptive crossover rate in HybridPSO_DE for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # increased inertia weight for enhanced exploration\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Adjust crossover rate dynamically based on iteration\n                adaptive_CR = self.CR * (1 - eval_count / self.budget)\n                crossover = np.random.rand(self.dim) < adaptive_CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 25, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.12.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11426497058272556, 0.12449572625953487, 0.11280820960534421, 0.12204596742800322, 0.13363836529726858, 0.12051389728120543, 0.1001504988370513, 0.13732648340714115, 0.10300857394198626, 0.11194560223493677, 0.10791179821274777, 0.10382500172717779, 0.6020126166952229, 0.10740301526176965, 0.10856253874163446]}}
{"id": "9ef02d8f-d135-4656-832b-618e5548de85", "fitness": 0.3970215169789915, "name": "HybridPSO_DE", "description": "Introduced dynamic adjustment of DE parameters and elitism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.5   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            self.F = 0.5 + (eval_count / self.budget) * 0.4  # Dynamic adjustment of F\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.35.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12950720025490592, 0.13299835255272152, 0.13939351483906193, 0.12927968590277417, 0.12062241035578702, 0.8829439370062871, 0.5514089181216368, 0.7668432353529161, 0.9240939587438686, 0.278578956063087, 0.8772652321393384, 0.5295961902448703, 0.8751866773306494, 0.7242246341207308, 0.7106885416767281]}}
{"id": "11955d6d-4c43-4dc0-9873-1b3f330cd608", "fitness": 0.1860423357105205, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by dynamically adjusting inertia weight and introducing a re-evaluation strategy to improve exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.4 + 0.5 * np.exp(-eval_count / self.budget)  # Dynamically adjust inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n                # Re-evaluation strategy for refinement\n                if eval_count < self.budget and np.random.rand() < 0.1:  # Re-evaluate with a 10% chance\n                    re_eval_score = func(positions[i])\n                    eval_count += 1\n                    if re_eval_score < scores[i]:\n                        scores[i] = re_eval_score\n                        if re_eval_score < pbest_scores[i]:\n                            pbest_scores[i] = re_eval_score\n                            pbest_positions[i] = positions[i]\n                            if re_eval_score < gbest_score:\n                                gbest_position = positions[i]\n                                gbest_score = re_eval_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.16.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1213390307188712, 0.12667876641854514, 0.11887184209882706, 0.1232662448077061, 0.1343777167510256, 0.4484778097226799, 0.121843240211857, 0.24354028799834593, 0.17453580161844318, 0.11326893929387127, 0.2500746037431806, 0.7166255302047292, 0.3734349639443457, 0.23737813781270167, 0.24933490399081437]}}
{"id": "e28e1870-88d1-474a-b65e-95f263dcadf8", "fitness": 0.22512639039227858, "name": "HybridPSO_DE", "description": "Introduce adaptive parameters and neighborhood influence to enhance exploration and exploitation balance in the HybridPSO_DE algorithm.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n        # Adaptive parameters\n        w_min, w_max = 0.4, 0.9\n        F_min, F_max = 0.5, 1.0\n\n        while eval_count < self.budget:\n            # Update inertia weight\n            self.w = w_max - (w_max - w_min) * (eval_count / self.budget)\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adaptive DE factor\n                self.F = F_min + (F_max - F_min) * np.random.rand()\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 28, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12160886272153881, 0.12702465692526899, 0.12219917241376244, 0.16269870652474883, 0.11880893376330504, 0.42771372399575014, 0.11126442256512525, 0.7651268708743789, 0.5667754199328052, 0.16146638810797764, 0.32386366998603244, 0.34184592409509207, 0.4188561666844848, 0.284960356639136, 0.28051563774169874]}}
{"id": "28fddf43-cf83-4be2-8782-d9365675c918", "fitness": 0.24098853716539956, "name": "HybridPSO_DE", "description": "Enhanced exploration in HybridPSO_DE by introducing adaptive inertia weight and dynamic crossover rate for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # initial inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.w = 0.9 - 0.5 * (eval_count / self.budget)\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Dynamic crossover rate\n                self.CR = 0.85 + 0.1 * (eval_count / self.budget)\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 29, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11968893335053843, 0.13044821530158568, 0.115594215702021, 0.12200756642439137, 0.11822507004500349, 0.43362317741341794, 0.12036159728415474, 0.5862893620494986, 0.3099672592892524, 0.4228728755889234, 0.514804070294846, 0.2956114872855212, 0.67226342203154, 0.29075202615644624, 0.39946257021638465]}}
{"id": "57ad8fb2-5b41-4759-9383-b67387e3caab", "fitness": 0.15379378120458553, "name": "HybridPSO_DE", "description": "Enhance HybridPSO_DE by dynamic adjustment of inertia weight and improving DE mutation strategy for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9  # Initial inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Dynamic inertia weight adjustment\n            self.w = 0.4 + 0.5 * (1 - eval_count / self.budget)\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(pbest_positions[a] + self.F * (pbest_positions[b] - pbest_positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.12.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12557132382933478, 0.12538321928205087, 0.14164871574748406, 0.1259871025143413, 0.12372375964219084, 0.2616054965763457, 0.11805557157463453, 0.27446190896264366, 0.20574650370143865, 0.11439466497095074, 0.2931470345721683, 0.20941403651522106, 0.528596227790431, 0.15450430080368238, 0.1058368627343258]}}
{"id": "3bb7dd80-6500-42b9-be0f-13565bef459a", "fitness": 0.42021907135843756, "name": "HybridPSO_DE", "description": "Enhance the balance between exploration and exploitation by dynamically adjusting DE parameters based on iteration progress.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Dynamic adjustment of DE parameters\n                self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n                self.CR = 0.7 + 0.2 * eval_count / self.budget\n                \n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.38.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.13200550642789521, 0.12714863754605898, 0.135039624441727, 0.13480109644857075, 0.12631958051349912, 0.9236552860795965, 0.67946726057625, 0.9138181698622504, 0.8209362831651659, 0.9310041049495408, 0.9280464622310662, 0.19445041398513108, 0.9252986673781352, 0.5002518534042887, 0.7643395852851077]}}
{"id": "3c43cf18-bfa2-4095-a7a7-d946d5aeb99c", "fitness": 0.13424817817070672, "name": "HybridPSO_DE", "description": "Enhanced exploration by adaptive inertia weight and dynamic DE parameters adjustment.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # initial inertia weight modified for better exploration\n        self.F = 0.5   # DE scaling factor modified for better exploration\n        self.CR = 0.9  # DE crossover rate modified for better exploitation\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.14.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1191616555259789, 0.11763786509879492, 0.13235540641001942, 0.12217337501640801, 0.12945018436325684, 0.12390432674662222, 0.10054090333210541, 0.4593101802448283, 0.09071998388612079, 0.1056885496077089, 0.1020290515180422, 0.10118736609972678, 0.6020126166952229, 0.11044214104570871, 0.10055106294912419]}}
{"id": "b83b3a06-a22f-415d-a286-8d0c62d14d08", "fitness": 0.45900846645069865, "name": "HybridPSO_DE", "description": "Optimized HybridPSO_DE with dynamic adjustment of the DE scaling factor and crossover rate for enhanced convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 33, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.39.", "error": "", "parent_ids": ["296eea29-f9d4-4409-ae30-e66482fd1e4b"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12672899602587795, 0.12096944080478378, 0.1277058973060321, 0.1378534350923012, 0.12834409542158154, 0.8815286019283435, 0.8441382703330573, 0.9264699592216423, 0.9240939587438686, 0.8613727872408794, 0.8892000972022189, 0.5516670353105189, 0.9137269466331923, 0.7000692344592583, 0.8785016784159504]}}
{"id": "b20452ed-54f8-43ee-8e55-f513d464b808", "fitness": 0.43510803084582506, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by diversifying selection strategies and refining DE parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.8 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.39.", "error": "", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1268309588674268, 0.14109772093070827, 0.13485380044405115, 0.12261819183066358, 0.13664194945013763, 0.826033403735662, 0.14252698654637141, 0.9037113187967432, 0.7388359885394593, 0.8941594533199039, 0.8089600617263433, 0.8640706500396071, 0.931058210683266, 0.8922627092901282, 0.8707003178415633]}}
{"id": "9d89251c-7a7d-4278-b951-c0ceab2da8eb", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive inertia weight and targeted DE mutation to improve convergence performance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.9   # increased initial inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.9 * (1 - eval_count / self.budget) + 0.4 * (eval_count / self.budget)  # adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                # Select vectors closer to the global best for mutation\n                a, b, c = sorted(np.random.choice(indices, 3, replace=False, p=pbest_scores/pbest_scores.sum()))\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 35, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {}}
{"id": "1b4b3581-0d6d-46a3-8785-37fd4b18484a", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive population size for improved convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n            # Adjust population size\n            self.pop_size = max(4, int((10 + 2 * self.dim) * (self.budget - eval_count) / self.budget))\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 36, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (55,23) (56,23) ').", "error": "ValueError('operands could not be broadcast together with shapes (55,23) (56,23) ')", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {}}
{"id": "4aac32f3-1aac-4ebd-8618-14610d7fad04", "fitness": 0.45900846645069865, "name": "HybridPSO_DE", "description": "Introduced random restart to diversify the search space, enhancing exploration in HybridPSO_DE.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n            # Random restart to diversify search space\n            if eval_count % (self.budget // 10) == 0:\n                positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 37, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.39.", "error": "", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12672899602587795, 0.12096944080478378, 0.1277058973060321, 0.1378534350923012, 0.12834409542158154, 0.8815286019283435, 0.8441382703330573, 0.9264699592216423, 0.9240939587438686, 0.8613727872408794, 0.8892000972022189, 0.5516670353105189, 0.9137269466331923, 0.7000692344592583, 0.8785016784159504]}}
{"id": "ed683fd6-ad5e-43b5-b11f-6a5009813df0", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with chaotic initialization and adaptive population size for improved diversity and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n            # Chaotic initialization instead of random\n            positions = np.clip(positions + 0.01 * np.random.randn(self.pop_size, self.dim), self.lb, self.ub)\n            # Adaptive population size adjustment\n            self.pop_size = int((10 + 2 * self.dim) * (0.9 + 0.1 * (eval_count / self.budget)))\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 38, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (50,23) (56,23) ').", "error": "ValueError('operands could not be broadcast together with shapes (50,23) (56,23) ')", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {}}
{"id": "7fbde4ff-9252-4fe7-b5b3-93481771afd1", "fitness": 0.22077378003405856, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive inertia weight to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            self.w = 0.9 - 0.5 * eval_count / self.budget  # Changed line: adaptive inertia weight\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.18.", "error": "", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12566695623488888, 0.12488929671635307, 0.1263306099040764, 0.1470132547030285, 0.1417871639836067, 0.5623541535359582, 0.10178471019167301, 0.4942161455319005, 0.38785726175733237, 0.34848796926677195, 0.6131528686046681, 0.2053237364414009, 0.42884196666372043, 0.2835567138057967, 0.156413898465529]}}
{"id": "9516731e-04c0-4c61-88cf-5e2caba69087", "fitness": 0.35082307856163514, "name": "HybridPSO_DE", "description": "Enhanced velocity and mutation mechanisms to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.7   # inertia weight (changed)\n        self.F = 0.8   # DE scaling factor (changed)\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget  # Adjusted scaling factor update\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 40, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.34.", "error": "", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12622679004882864, 0.12684351512206515, 0.11777064663006087, 0.13755967981820483, 0.12670166712581543, 0.8531248223028679, 0.10791719764117791, 0.8600699896727089, 0.7748441247295295, 0.7646369839098444, 0.8091736533904159, 0.423780160467092, 0.8829123958723978, 0.11421642232968132, 0.6228846272975452]}}
{"id": "4cba7dcc-3695-4a88-bd45-cb56d1865225", "fitness": 0.47654743299505997, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by introducing adaptive inertia weight adjustment for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.4 + 0.2 * (self.budget - eval_count) / self.budget\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 41, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.39.", "error": "", "parent_ids": ["b83b3a06-a22f-415d-a286-8d0c62d14d08"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.12689964415341726, 0.11739000291445811, 0.18670942958401426, 0.1702088347852142, 0.13532306334834987, 0.9381477221107477, 0.7255885356053896, 0.9412141267070867, 0.893250890643572, 0.8401608327775155, 0.8857276086927061, 0.8237486921821298, 0.8688398376900495, 0.8400498941101141, 0.8698906497219683]}}
{"id": "dfff7a07-7004-4065-acd4-cc5ccfab29d0", "fitness": 0.44238744965437515, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by introducing a convergence-enhancing mutation strategy to improve solution diversity and exploitation capabilities.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.4 + 0.2 * (self.budget - eval_count) / self.budget\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n\n                # Convergence-enhancing mutation\n                if np.random.rand() < 0.2:\n                    random_drift = 0.1 * (self.ub - self.lb) * np.random.randn(self.dim)\n                    mutant_vector = np.clip(mutant_vector + random_drift, self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 42, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.37.", "error": "", "parent_ids": ["4cba7dcc-3695-4a88-bd45-cb56d1865225"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.13884212781986838, 0.12576761027274508, 0.13974387034097224, 0.12480430365972817, 0.13999241812655627, 0.8538375177761056, 0.994785368365699, 0.807701392266533, 0.6751503632007406, 0.7269999484585437, 0.8513034029015154, 0.6761447813578465, 0.7850125642901968, 0.7372306950161978, 0.9026337343597873]}}
{"id": "cb59b013-26af-41be-ab0b-102f17023c15", "fitness": 0.457815097392454, "name": "HybridPSO_DE", "description": "Introduced a chaotic map for adaptive parameter tuning to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        chaos_factor = 0.7  # Initial value for chaotic mapping\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment with chaotic map\n            chaos_factor = 4 * chaos_factor * (1 - chaos_factor)  # Logistic map\n            self.w = 0.4 + 0.3 * chaos_factor\n            \n            # PSO update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * chaos_factor\n            self.CR = 0.9 - 0.1 * chaos_factor\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 43, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.38.", "error": "", "parent_ids": ["4cba7dcc-3695-4a88-bd45-cb56d1865225"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.1243849734714072, 0.1455151192213947, 0.1363094733859942, 0.12617645306800696, 0.12865339917259855, 0.8717389892071408, 0.8684257392674812, 0.9355041376139641, 0.7878854377501054, 0.8965633347809384, 0.6665085945492124, 0.7750731078558791, 0.9490378625942715, 0.7555680148391001, 0.8211584161971197]}}
{"id": "8cf267a1-d03f-455e-a6c7-596caa9d1da4", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive population size for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.7\n        self.c2 = 1.3\n        self.w = 0.6\n        self.F = 0.9\n        self.CR = 0.85\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.2 * (self.budget - eval_count) / self.budget\n            # Adaptive population size adjustment\n            self.pop_size = int((10 + 2 * self.dim) * (self.budget - eval_count) / self.budget) + 1\n            \n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities \n                          + self.c1 * r1 * (pbest_positions - positions) \n                          + self.c2 * r2 * (gbest_position - positions))\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 44, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (55,23) (56,23) ').", "error": "ValueError('operands could not be broadcast together with shapes (55,23) (56,23) ')", "parent_ids": ["4cba7dcc-3695-4a88-bd45-cb56d1865225"], "operator": null, "metadata": {}}
{"id": "101b8d52-fa71-411b-ab36-6bbb87ff39e7", "fitness": 0.478007427828938, "name": "HybridPSO_DE", "description": "Enhanced diversity by dynamic adjustment of PSO velocity bounds for more robust exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.4 + 0.2 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.38.", "error": "", "parent_ids": ["4cba7dcc-3695-4a88-bd45-cb56d1865225"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.13827370813287765, 0.3046983257956446, 0.15584894116174064, 0.13035679910243225, 0.19184233030433795, 0.8668990132160287, 0.8007571818142116, 0.938251273723802, 0.8381017267553093, 0.7345019894655886, 0.8597255630532127, 0.7280703694741334, 0.9118601400452402, 0.971542597127958, 0.8216197025317754]}}
{"id": "bfc7f7be-5131-4993-ab23-f9d17faad3cf", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Enhanced exploration by adaptive population size adjustment in HybridPSO_DE.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.4 + 0.2 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n            # Adjust population size dynamically\n            if eval_count < self.budget / 2:\n                self.pop_size = min(100, self.pop_size + 1)\n            else:\n                self.pop_size = max(10, self.pop_size - 1)\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 46, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (57,23) (56,23) ').", "error": "ValueError('operands could not be broadcast together with shapes (57,23) (56,23) ')", "parent_ids": ["101b8d52-fa71-411b-ab36-6bbb87ff39e7"], "operator": null, "metadata": {}}
{"id": "fcc31719-e989-44fe-be39-08b6a4a46e74", "fitness": 0.428349155986692, "name": "HybridPSO_DE", "description": "Adjusted PSO and DE parameters dynamically based on relative position within budget for improved convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient\n        self.c2 = 1.3  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.9   # DE scaling factor\n        self.CR = 0.85 # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.4 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.5 + 0.4 * (self.budget - eval_count) / self.budget\n            self.CR = 0.9 - 0.1 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 47, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.33.", "error": "", "parent_ids": ["101b8d52-fa71-411b-ab36-6bbb87ff39e7"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.26934397459486636, 0.21553610382884292, 0.1553398178485882, 0.14478289495655627, 0.13876291260979046, 0.7547813505607693, 0.8282217831690487, 0.5941840291113181, 0.5419912319845759, 0.861417587610406, 0.9085910572349983, 0.7089757718138621, 0.7549055571185522, 0.6695945827385233, 0.8527555696786749]}}
{"id": "7c7cda9c-d42c-468a-a35f-722f7e9d5bac", "fitness": 0.5241625772757823, "name": "HybridPSO_DE", "description": "Enhanced exploration and exploitation balance by adjusting velocity and crossover parameters dynamically.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 48, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52 with standard deviation 0.40.", "error": "", "parent_ids": ["101b8d52-fa71-411b-ab36-6bbb87ff39e7"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.14501649482975665, 0.17638894551744022, 0.14873241652636404, 0.16033660912930736, 0.9754440551812363, 0.8080903623412359, 0.8618537114568472, 0.8973554618701048, 0.8704219356588825, 0.8719544054485453, 0.873659439412454, 0.8528231106843414, 0.9476636260243639, 0.8373141213605675, 0.8883979551997339]}}
{"id": "673dc0a6-4816-4881-af59-b9c24ce1a530", "fitness": 0.44324111768286334, "name": "HybridPSO_DE", "description": "Enhanced dynamic parameter adjustment for improved convergence in hybrid PSO-DE.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.7  # cognitive coefficient (changed)\n        self.c2 = 1.7  # social coefficient (changed)\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.4 * (self.budget - eval_count) / self.budget # changed\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.65 + 0.25 * (self.budget - eval_count) / self.budget # changed\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.33.", "error": "", "parent_ids": ["7c7cda9c-d42c-468a-a35f-722f7e9d5bac"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.14361811071163488, 0.1304061788150972, 0.68300889126822, 0.1470988980562049, 0.1899719799767775, 0.8128094134126759, 0.7451830990525032, 0.912464795197889, 0.7197847912852152, 0.6384945862329969, 0.6370112607902068, 0.6975464854004041, 0.8757546459411872, 0.7151091447271183, 0.64876117791467]}}
{"id": "ddcc0edf-4eca-48f7-9681-1f5bcca17335", "fitness": 0.4993795343841752, "name": "HybridPSO_DE", "description": "Introduced a random reinitialization of worst particles in PSO to enhance diversity and avoid local minima.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n            # Introduce reinitialization of worst particles\n            worst_indices = np.argsort(scores)[-3:]\n            positions[worst_indices] = np.random.uniform(self.lb, self.ub, (3, self.dim))\n            scores[worst_indices] = np.array([func(x) for x in positions[worst_indices]])\n            eval_count += 3\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.50 with standard deviation 0.38.", "error": "", "parent_ids": ["7c7cda9c-d42c-468a-a35f-722f7e9d5bac"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.16198341452812626, 0.18402140201282613, 0.14040413587628742, 0.20661167962389615, 0.941238732842561, 0.8906251062099417, 0.563284240965511, 0.788302100840327, 0.6285339291443386, 0.8368871429987976, 0.8812378176830229, 0.8734478184175011, 0.9558208892391664, 0.8437758851855904, 0.9236174972411436]}}
{"id": "52854c57-bad6-470d-81bf-7b0c81c1e172", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "Introduced a diversity preservation mechanism using crowding distance to maintain exploration in HybridPSO_DE.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        def crowding_distance(positions):\n            sorted_idx = np.argsort(positions, axis=0)\n            distances = np.zeros_like(positions)\n            distances[sorted_idx[0]] = np.inf\n            max_min_diff = np.max(positions, axis=0) - np.min(positions, axis=0)\n            for i in range(1, len(positions) - 1):\n                distances[sorted_idx[i]] += np.sum(\n                    (positions[sorted_idx[i+1]] - positions[sorted_idx[i-1]]) / max_min_diff\n                )\n            distances[sorted_idx[-1]] = np.inf\n            return distances\n        \n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n\n                if trial_score < scores[i] or (trial_score == scores[i] and crowding_distance([positions[i], trial_vector])[1] > crowding_distance([positions[i], trial_vector])[0]):\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 51, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["7c7cda9c-d42c-468a-a35f-722f7e9d5bac"], "operator": null, "metadata": {}}
{"id": "5237dc96-13d2-4cf2-bbc7-19e76a8b59a8", "fitness": 0.5874101490123766, "name": "HybridPSO_DE", "description": "Improved exploitation by modifying DE mutation strategy to use global best vector for better convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False) # Changed line 1\n                mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub) # Changed line 2\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 52, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.59 with standard deviation 0.37.", "error": "", "parent_ids": ["7c7cda9c-d42c-468a-a35f-722f7e9d5bac"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.6766281544823579, 0.15308306131077065, 0.4111800999379077, 0.6504472087883072, 0.6276955646332558, 0.8775923593729554, 0.9352636581890128, 0.9222266853245542, 0.8970111832103295, 0.8588575621256295, 0.9246463455774203, 0.8652112560544654, 0.9341926028899988, 0.8881902983349221, 0.9581780451411792]}}
{"id": "cf560c92-2f70-42fa-a83e-b8d9d28a7d19", "fitness": 0.4564661489324541, "name": "HybridPSO_DE", "description": "Enhanced local exploitation by introducing adaptive learning for personal best updates and dynamic crossover adjustments.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best with adaptive learning\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved] * 0.5 + pbest_positions[improved] * 0.5  # Changed line 1\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget + 0.1 * (1 - eval_count / self.budget)  # Changed line 2\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 53, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.36.", "error": "", "parent_ids": ["5237dc96-13d2-4cf2-bbc7-19e76a8b59a8"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.15408658501967099, 0.12678352396477688, 0.1678512862074376, 0.1407766590471079, 0.40824208665901174, 0.8828027664757193, 0.9197349335773612, 0.9542239058517146, 0.7006279567490366, 0.6813322080628271, 0.7067731791040643, 0.8934956051933378, 0.9452158588426847, 0.8149741845959755, 0.4646033444238905]}}
{"id": "233d0f0f-f759-47cf-94f2-b7ea8d7f8b7d", "fitness": 0.6237635798565511, "name": "HybridPSO_DE", "description": "Adaptive local search integrated with PSO-DE to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                # Introduce a new local search component\n                if np.random.rand() < 0.2:  # Changed line 1\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub) # Changed line 2\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 54, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.36.", "error": "", "parent_ids": ["5237dc96-13d2-4cf2-bbc7-19e76a8b59a8"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.5147580302171673, 0.5538076656103419, 0.7275642477373312, 0.7475109370546644, 0.705925630894926, 0.9651346487849308, 0.8348453520986099, 0.9287139055795091, 0.8957692921098857, 0.9057009522017827, 0.8922048193363687, 0.8684956331323743, 0.91929073775278, 0.9041572510804834, 0.9435935986653995]}}
{"id": "5100234a-e745-4879-a5d6-5d0b32c23125", "fitness": 0.6022878788381305, "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing a dynamic adaptive mutation strategy in PSO-DE to maintain diversity and convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = np.random.choice(indices, 3, replace=False)  # Changed line 1\n                # Introduce a new adaptive mutation strategy\n                if np.random.rand() < 0.2:  # Changed line 2\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                elif np.random.rand() < 0.5:  # Changed line 3\n                    mutant_vector = np.clip(positions[a] + self.F * (positions[b] - positions[c]), self.lb, self.ub)  # Changed line 4\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.37.", "error": "", "parent_ids": ["233d0f0f-f759-47cf-94f2-b7ea8d7f8b7d"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.6740988955805645, 0.5984443276302505, 0.684786246662239, 0.1457150700648676, 0.6609678519098521, 0.9570447267062487, 0.905116543459215, 0.8821357582688422, 0.9294928943134221, 0.8866610651014201, 0.9112505920657821, 0.9294539224392077, 0.9139760332247786, 0.9002180517344837, 0.8985967027269679]}}
{"id": "475fa22d-09ec-4c03-85fd-48fc0674c3fb", "fitness": 0.6116371546607569, "name": "HybridPSO_DE", "description": "Enhanced exploration by introducing stochastic perturbation in the DE mutation strategy.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                # Introduce a new local search component\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    # Apply stochastic perturbation\n                    rand_perturbation = np.random.normal(0, 0.05, self.dim)  # Changed line 1\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]) + rand_perturbation, self.lb, self.ub)  # Changed line 2\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61 with standard deviation 0.36.", "error": "", "parent_ids": ["233d0f0f-f759-47cf-94f2-b7ea8d7f8b7d"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.5475592722167726, 0.5085998151448317, 0.6527369111675618, 0.5828694093749386, 0.6846172241767103, 0.8615046886256386, 0.8837404019574191, 0.9194142589623275, 0.912644642646077, 0.9240199947779149, 0.9289200246970373, 0.9139511862872335, 0.8945588787765804, 0.8966691412673017, 0.9531383482623262]}}
{"id": "32ecfbc8-b732-412c-888a-1ffd1be26aa8", "fitness": -Infinity, "name": "HybridPSO_DE", "description": "HybridPSO_DE with Lvy Flight-based local search for enhanced exploration and diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return L * step\n    \n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.3:\n                    mutant_vector = np.clip(positions[i] + self.levy_flight(0.01), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["233d0f0f-f759-47cf-94f2-b7ea8d7f8b7d"], "operator": null, "metadata": {}}
{"id": "f27d3946-cb35-47cb-9cd3-f237410ca145", "fitness": 0.6466227991493794, "name": "HybridPSO_DE", "description": "Introduced dynamic adaptation of cognitive and social coefficients in PSO to enhance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            \n            # Adaptive cognitive and social coefficients\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)  # Changed line 1\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)  # Changed line 2\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                # Introduce a new local search component\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 58, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.37.", "error": "", "parent_ids": ["233d0f0f-f759-47cf-94f2-b7ea8d7f8b7d"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.7106044218223979, 0.7210415354014357, 0.7520455234130057, 0.6422325632668866, 0.6871510859113964, 0.9624492934767673, 0.9159814270478714, 0.9059271824926419, 0.9292273879078072, 0.9291493155049215, 0.9294292706714283, 0.9298817348630388, 0.9041950948384538, 0.9265194124703863, 0.9188218390246827]}}
{"id": "03cf5ab8-5302-4cd3-852b-da2fe29a57f9", "fitness": 0.6454081881960649, "name": "HybridPSO_DE", "description": "Enhanced local search with Gaussian perturbation and adapted DE mutation strategy for improved exploration.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim  # population size\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.6   # inertia weight\n        self.F = 0.8   # DE scaling factor\n        self.CR = 0.9  # DE crossover rate\n\n    def __call__(self, func):\n        # Initialize positions and velocities for PSO\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight adjustment\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            \n            # Adaptive cognitive and social coefficients\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)  # Changed line 1\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)  # Changed line 2\n\n            # PSO update with dynamic velocity bounds\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            # Evaluate the new positions\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            # Update personal best\n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            # Update global best\n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            # Dynamic scaling factor and crossover rate\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            # DE mutation and crossover\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                # Introduce a new local search component\n                if np.random.rand() < 0.25:  # Modified line 7\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.3, self.dim), self.lb, self.ub)  # Modified line 7\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]) + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)  # Modified line 7\n                \n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):  # Ensure at least one dimension is taken from mutant_vector\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                # Selection\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 59, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.37.", "error": "", "parent_ids": ["f27d3946-cb35-47cb-9cd3-f237410ca145"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8217145243517705, 0.5315770937408291, 0.7641050061378479, 0.7948797589347607, 0.6813960242985427, 0.9058585333420368, 0.8948441071850605, 0.8994915374361723, 0.9676214680252088, 0.9088645056829965, 0.8822456530359807, 0.9243423763531506, 0.9191487496347276, 0.9158015686489948, 0.9284739622387532]}}
{"id": "46e8a828-7ac5-4c15-9198-9f4f6d61c46e", "fitness": 0.656484936880867, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with adaptive diversity control and multi-population strategy for improved exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1  # Added line 1\n        self.extra_mutation_prob = 0.1  # Added line 2\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:  # Added line 27\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)  # Added line 28\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.37.", "error": "", "parent_ids": ["f27d3946-cb35-47cb-9cd3-f237410ca145"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.7788627170030405, 0.6636661799679849, 0.6285353743071553, 0.7479126869665549, 0.8748026843054795, 0.9098007192406166, 0.9367757250667451, 0.959793873524354, 0.8827645926788088, 0.9794970904245327, 0.9253416472561987, 0.924185624957758, 0.9552611155983779, 0.8972052381903945, 0.8974945732548726]}}
{"id": "2c4dc8b9-d9bc-4e3d-9037-0026d623a24c", "fitness": 0.6357668748050381, "name": "EnhancedHybridPSO_DE", "description": "Improved EnhancedHybridPSO_DE with enhanced adaptive parameters and refined diversity strategy for superior optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.7  # Modified line 1\n        self.c2 = 1.7  # Modified line 2\n        self.w = 0.5  # Modified line 3\n        self.F = 0.9  # Modified line 4\n        self.CR = 0.8  # Modified line 5\n        self.diversity_threshold = 0.15  # Modified line 6\n        self.extra_mutation_prob = 0.15  # Modified line 7\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.37.", "error": "", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.72518145154865, 0.7113264450824022, 0.5258820792016894, 0.6863441471392574, 0.6040257311140189, 0.9510443216074967, 0.8987442516524154, 0.9033476338495344, 0.9715867394822146, 0.9169402697740231, 0.9166994476230618, 0.9379106531492509, 0.9316574922641642, 0.9386177359702358, 0.9282302017678791]}}
{"id": "ec909eaf-7abb-4cbe-882b-4e1e93126cdb", "fitness": 0.15470776296471794, "name": "EnhancedHybridPSO_DE", "description": "Refinement of EnhancedHybridPSO_DE by integrating elite pooling and adaptive crossover for enhanced convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n        elite_pool = []\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.7 + 0.2 * (self.budget - eval_count) / self.budget  # Changed line 1\n            self.CR = 0.80 - 0.05 * (self.budget - eval_count) / self.budget  # Changed line 2\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                elite_pool.append(gbest_position)  # Changed line 3\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n                \n                if len(elite_pool) > 2:  # Changed line 4\n                    trial_vector = np.mean(elite_pool[-2:], axis=0)  # Changed line 5\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n                        elite_pool.append(trial_vector)  # Changed line 6\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.19.", "error": "", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.11576905182629893, 0.12963135222793487, 0.12363386832184853, 0.9572121672601611, 0.10399448108544851, 0.1367418311343671, 0.10275425209509492, 0.12245158900268749, 0.15179428743411638, 0.13109596374949373, 0.11527016251988986, 0.32132145846256543, 0.1312111604643339, 0.15623091381135001, 0.12724382502430176]}}
{"id": "1f6bd1d3-a343-49cd-9eb7-f7e006831df4", "fitness": 0.44849619516042327, "name": "EnhancedHybridPSO_DE", "description": "Incorporate dynamic inertia weight adjustment and stochastic perturbations for enhanced exploration and exploitation equilibrium.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.9 - 0.6 * (eval_count / self.budget)  # Changed line 1\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.7 + 0.2 * (self.budget - eval_count) / self.budget  # Changed line 2\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold * 0.5, self.dim)  # Changed line 3\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.29.", "error": "", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.3408843586053285, 0.511616889865941, 0.15943662817319648, 0.29620344561617706, 0.3752736358917719, 0.690289501061619, 0.7199150210646905, 0.7984536434566363, 0.6851652573267802, 0.7344426727943716, 0.7313355574150058, 0.5964135163040047, 0.8623885482561359, 0.6743679452410567, 0.6259383872612841]}}
{"id": "b1a4a767-4c54-4d5d-85b4-54f7a1d28089", "fitness": 0.5556146208594949, "name": "EnhancedHybridPSO_DE", "description": "Adaptive EnhancedHybridPSO_DE with dynamic inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.5 * np.exp(-3 * eval_count / self.budget)  # Changed line\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.56 with standard deviation 0.33.", "error": "", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.6026696718823217, 0.3840523850076323, 0.5737115356878911, 0.6416528214188766, 0.48760694464163534, 0.7914405471443088, 0.8226301833713754, 0.8211589205711719, 0.7971829512024251, 0.8576940903828782, 0.8515816685046204, 0.8400031843191781, 0.8232572769381824, 0.8256726140122612, 0.824178727230672]}}
{"id": "236ed1fd-92f5-4108-a1c7-023fe0d16baa", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Adaptive hybrid metaheuristic combining enhanced swarm intelligence and recombination strategies with fitness-based mutation control.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub) if np.random.rand() < 0.2 else np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    mutation_intensity = self.diversity_threshold * (gbest_score - scores[i]) / (gbest_score + 1e-10)  # Changed line 86\n                    trial_vector += np.random.normal(0, mutation_intensity, self.dim)  # Changed line 87\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 65, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {}}
{"id": "fcdf1ea7-a09b-4765-95fb-2dd64dc126ca", "fitness": 0.6343094714889586, "name": "EnhancedHybridPSO_DE", "description": "Enhance mutation strategy by dynamically adjusting `extra_mutation_prob` for better exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.5 + 0.5 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                self.extra_mutation_prob = 0.1 + 0.05 * (1 - eval_count / self.budget)  # Line changed\n                \n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.37.", "error": "", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.7084605197953888, 0.6217513005221946, 0.5443730513095242, 0.819455602204217, 0.6347528366248791, 0.9351930719209053, 0.8842241650593174, 0.9416487118673426, 0.9715867394822146, 0.903573420176575, 0.9141762791626364, 0.9089384698775622, 0.9198942757503272, 0.9267323429142799, 0.8836297482373416]}}
{"id": "fc538bd2-012e-4e53-90a9-754be2481b3a", "fitness": 0.6706479282543056, "name": "EnhancedHybridPSO_DE", "description": "Enhanced HybridPSO_DE with adjusted velocity scaling factor for improved convergence control.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget  # Adjusted line for velocity scaling factor\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.37.", "error": "", "parent_ids": ["46e8a828-7ac5-4c15-9198-9f4f6d61c46e"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.7413865617119506, 0.7638089991361748, 0.7558227388501758, 0.786401440610038, 0.905520543689835, 0.894077312808095, 0.9214844340314879, 0.959793873524354, 0.9035681578015453, 0.9794984138233941, 0.9225908794383006, 0.9453093087418191, 0.955314419386178, 0.9131910442891802, 0.8973915423691173]}}
{"id": "8cc9d58e-4f66-4600-a77c-4040c0391555", "fitness": 0.4344257336580209, "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive mutation rate and dynamic inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.5 * (self.budget - eval_count) / self.budget  # Adjusted line for dynamic inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n            \n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            adaptive_mutation_prob = 0.1 + 0.1 * (self.budget - eval_count) / self.budget  # Adaptive mutation rate\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < adaptive_mutation_prob:  # Use adaptive mutation rate\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.29.", "error": "", "parent_ids": ["fc538bd2-012e-4e53-90a9-754be2481b3a"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.21212807737419592, 0.34080668942214953, 0.25506856777666953, 0.4801086403518824, 0.21689219144894079, 0.7555963769494889, 0.7330096744277195, 0.8150641510601084, 0.6750261985654766, 0.6953270869253383, 0.6413924415200722, 0.6463780860470489, 0.6583926751728946, 0.6867770785888708, 0.7087478426550944]}}
{"id": "dea67653-3e11-447b-a7bb-e252eb78baef", "fitness": 0.6706479282543056, "name": "EnhancedHybridPSO_DE", "description": "Adjusted hybrid algorithm with dynamic parameter control for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget  # Adjusted line for velocity scaling factor\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * (self.budget - eval_count) / self.budget\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.37.", "error": "", "parent_ids": ["fc538bd2-012e-4e53-90a9-754be2481b3a"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.7413865617119506, 0.7638089991361748, 0.7558227388501758, 0.786401440610038, 0.905520543689835, 0.894077312808095, 0.9214844340314879, 0.959793873524354, 0.9035681578015453, 0.9794984138233941, 0.9225908794383006, 0.9453093087418191, 0.955314419386178, 0.9131910442891802, 0.8973915423691173]}}
{"id": "8579e74b-ea58-4a2e-859a-89cf40f75a42", "fitness": 0.6854437532568245, "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive mutation scaling and strategic velocity update for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.38.", "error": "", "parent_ids": ["fc538bd2-012e-4e53-90a9-754be2481b3a"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9230646987709299, 0.8283925687984651, 0.822729366537668, 0.8513868273966363, 0.7958709053030688, 0.9331274076708912, 0.9470617345269619, 0.9432883436594122, 0.9282912429850452, 0.9135699506371375, 0.904850267436236, 0.9326997432142805, 0.9589653248861747, 0.934498672558679, 0.9232791158804393]}}
{"id": "7cd760f8-f101-4b8a-a933-89694bb617f4", "fitness": 0.67451838585359, "name": "EnhancedHybridPSO_DE", "description": "Improved population diversity by adjusting the extra mutation probability.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.15\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.37.", "error": "", "parent_ids": ["8579e74b-ea58-4a2e-859a-89cf40f75a42"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8311814547661989, 0.7723244985194762, 0.8228076380919739, 0.8852597067045125, 0.7709545145590891, 0.9284041603820233, 0.9140882401630661, 0.9379635086525052, 0.9008330377212704, 0.9320230574234551, 0.9406806674233523, 0.8968082454007851, 0.9544065683699386, 0.9189347970134467, 0.9158987270062379]}}
{"id": "dcb997cf-7d42-4ba6-8f43-f2a958173d45", "fitness": -Infinity, "name": "EnhancedHybridPSO_DE", "description": "Enhanced diversity and convergence stability through gradient-informed trial selection and dynamic parameter tuning.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            gradient = np.zeros(self.dim)\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.25:  # Adjusted probability for gradient utilization\n                    gradient = np.gradient(func(positions[i]), positions[i])  # Calculate gradient\n                    mutant_vector = np.clip(positions[i] - 0.01 * gradient, self.lb, self.ub)  # Use gradient\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 72, "feedback": "An exception occurred: TypeError('invalid number of arguments').", "error": "TypeError('invalid number of arguments')", "parent_ids": ["8579e74b-ea58-4a2e-859a-89cf40f75a42"], "operator": null, "metadata": {}}
{"id": "535759fd-206e-4d1a-9603-0cba98680791", "fitness": 0.654337411080597, "name": "EnhancedHybridPSO_DE", "description": "Improved Exploration with Dynamic Mutation and Adaptive Learning Rates.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.3 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.9 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.25:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.37.", "error": "", "parent_ids": ["8579e74b-ea58-4a2e-859a-89cf40f75a42"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.7675607705460188, 0.7793551496338682, 0.5776974576045901, 0.7687763398675207, 0.7238017082247792, 0.9305153188060341, 0.9385273286819068, 0.9442431475228406, 0.9262343681927372, 0.9200320087842376, 0.9265089370871677, 0.9354328789237935, 0.8993439534646936, 0.9374869145308281, 0.943433044866458]}}
{"id": "6adc7d7e-863d-4eb0-9a5a-c16cd11b1570", "fitness": 0.6650077528912207, "name": "EnhancedHybridPSO_DE", "description": "Enhanced convergence speed by fine-tuning the adaptive mutation scaling factor.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.55 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.37.", "error": "", "parent_ids": ["8579e74b-ea58-4a2e-859a-89cf40f75a42"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8103998804856356, 0.7594212043918951, 0.783825778671235, 0.6808380711924424, 0.8201862459719558, 0.917753945665669, 0.9193309380704301, 0.9513297717396476, 0.9582329604575709, 0.9206412075299968, 0.9125447700989877, 0.9245987685552102, 0.9508816376581497, 0.9184275020026298, 0.9039434804584929]}}
{"id": "5f9bbb78-4575-42e0-a5ad-3ba4471848d6", "fitness": 0.6517245402970463, "name": "EnhancedHybridPSO_DE", "description": "Introduced minor refinement to adaptive mutation scaling for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (self.budget - eval_count) / self.budget\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.65 + 0.35 * np.random.rand()  # Adaptive mutation scaling modified slightly\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.37.", "error": "", "parent_ids": ["8579e74b-ea58-4a2e-859a-89cf40f75a42"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.63898066387487, 0.6912923811591324, 0.7534838797878173, 0.785614096477249, 0.7254561809297966, 0.9113359838662602, 0.9226711870480078, 0.9669010392252927, 0.9218494844025648, 0.9057655867932803, 0.9342331474890828, 0.9073590380335836, 0.9339533602366443, 0.9201341808598327, 0.9476617008830439]}}
{"id": "06f02b9c-94f8-46bc-83d9-7e7f3ea62620", "fitness": 0.7085789717974826, "name": "EnhancedHybridPSO_DE", "description": "Introduced a diversity-based adaptive inertia weight control to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["8579e74b-ea58-4a2e-859a-89cf40f75a42"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9038201385509906, 0.9018074705844383, 0.9085705394798624, 0.917128654107001, 0.7430117105696549, 0.9605571375800539, 0.9508701763491847, 0.9844374452930748, 0.9631423760530495, 0.9635796407396146, 0.9453600240403641, 0.9620735989701326, 0.9844272485785492, 0.9597119815516049, 0.9552823986276087]}}
{"id": "eb1bf712-778b-4471-8e13-697c6819473d", "fitness": 0.7045420199819696, "name": "EnhancedHybridPSO_DE", "description": "Introduced a higher adaptive mutation scaling factor to further enhance global search capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.6 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.39.", "error": "", "parent_ids": ["06f02b9c-94f8-46bc-83d9-7e7f3ea62620"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8864667437749417, 0.8390725551439255, 0.8423959680855315, 0.9252355802421756, 0.8582904676477794, 0.9653642233788696, 0.9385840032669795, 0.9604193005564995, 0.9660890698162616, 0.9468528037918731, 0.9814646793838812, 0.9615197064304424, 0.9619921367408683, 0.9407055535550685, 0.9485887129498306]}}
{"id": "1ab33a63-0280-4d5e-8ecb-daa1c3067329", "fitness": 0.6940870997866091, "name": "EnhancedHybridPSO_DE", "description": "Adjusted crossover probability to increase diversity in early iterations.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.4 + 0.6 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < (0.95 - 0.05 * eval_count / self.budget)  # Adjusted crossover probability\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.39.", "error": "", "parent_ids": ["06f02b9c-94f8-46bc-83d9-7e7f3ea62620"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8689818824961344, 0.8508933692027889, 0.8772051329537762, 0.8412978144785225, 0.6940894360571184, 0.9597982471658135, 0.9556307897618624, 0.9725915328371882, 0.9632355328093873, 0.960888151468497, 0.9473561833903092, 0.9478300519788744, 0.9649723772395681, 0.9495829121351923, 0.9595896868826833]}}
{"id": "57feb5a3-c162-4242-a8b5-466bf4290d43", "fitness": 0.7130877531177731, "name": "EnhancedHybridPSO_DE", "description": "Introduced adaptive velocity clamping based on the evaluation count to better control swarm dynamics.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.2 + 0.8 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["06f02b9c-94f8-46bc-83d9-7e7f3ea62620"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9037756744488225, 0.9039323183657788, 0.8749026410433077, 0.8760778828330541, 0.9205727496761786, 0.944096446246392, 0.9499409139923742, 0.9844374474343823, 0.9573687702589037, 0.963558334857612, 0.9422501394952078, 0.95406463488622, 0.9844272510450556, 0.9647553917040731, 0.9697955711936304]}}
{"id": "b33ac1b8-bf1c-4ade-b72e-bc779d4da70b", "fitness": 0.6900843828280714, "name": "EnhancedHybridPSO_DE", "description": "Introduced an adaptive boundary mechanism to dynamically adjust the search space.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.2 + 0.8 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb + (eval_count / self.budget) * (self.ub - self.lb) / 2, self.ub - (eval_count / self.budget) * (self.ub - self.lb) / 2)\n\n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.40.", "error": "", "parent_ids": ["57feb5a3-c162-4242-a8b5-466bf4290d43"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.44222786376303924, 0.890026360638465, 0.9112334317331595, 0.8660321963588392, 0.893370154494759, 0.9564485748784282, 0.9499045961511093, 0.9844374461261086, 0.9498127437968592, 0.9635583037816686, 0.9537934981581095, 0.9540651404785708, 0.9844272490718058, 0.9647556319123085, 0.9697955703437331]}}
{"id": "e5c23ea5-8e47-4957-8809-970abfe21545", "fitness": 0.7130877531177731, "name": "EnhancedHybridPSO_DE", "description": "Introduced dynamic inertia weight decay based on the evaluation budget to enhance exploitation capabilities as the search progresses.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.2 + 0.8 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["57feb5a3-c162-4242-a8b5-466bf4290d43"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9037756744488225, 0.9039323183657788, 0.8749026410433077, 0.8760778828330541, 0.9205727496761786, 0.944096446246392, 0.9499409139923742, 0.9844374474343823, 0.9573687702589037, 0.963558334857612, 0.9422501394952078, 0.95406463488622, 0.9844272510450556, 0.9647553917040731, 0.9697955711936304]}}
{"id": "12c65b05-0653-4e76-9908-bc6988f02885", "fitness": 0.7134196552644417, "name": "EnhancedHybridPSO_DE", "description": "Enhanced adaptive velocity clamping threshold to improve convergence consistency.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["57feb5a3-c162-4242-a8b5-466bf4290d43"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9091848872630376, 0.9045936095546631, 0.8963274783549849, 0.9142250945140431, 0.8398111276962015, 0.9667886891042075, 0.9387959641408766, 0.9844374463635828, 0.9631436155409743, 0.9635681969225259, 0.9439763940507387, 0.9595064481931901, 0.9844272498116299, 0.9620085362644775, 0.969799472639236]}}
{"id": "3309b521-5033-4b4f-beb4-1e511cdaca5f", "fitness": 0.7056260406886568, "name": "EnhancedHybridPSO_DE", "description": "Introduce adaptive crossover rate (CR) based on diversity to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.5 + 0.4 * (np.std(positions) / (self.ub - self.lb))  # Adaptive CR based on diversity\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob:\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["12c65b05-0653-4e76-9908-bc6988f02885"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8625090597862882, 0.9016147113534845, 0.8435233259147918, 0.9168948918133883, 0.8330097969082799, 0.9667560101400167, 0.9549170525277075, 0.9650602425535428, 0.9629634872212126, 0.9541419338748858, 0.9579146324867753, 0.9352968215214039, 0.9788159567470667, 0.9542013323035793, 0.9571026637462442]}}
{"id": "d0b3a567-d053-4ccb-a083-0335b469c2f9", "fitness": 0.7144282904390751, "name": "EnhancedHybridPSO_DE", "description": "Improved mutation diversity by increasing mutation probability threshold dynamically to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["12c65b05-0653-4e76-9908-bc6988f02885"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8439209176003641, 0.8978753418223275, 0.9004041628869234, 0.9202369542292672, 0.9157972935018182, 0.9634859240606446, 0.9387959641408766, 0.9844374463635828, 0.9625509104550147, 0.9596637088146265, 0.9601024815080385, 0.9595064481931901, 0.9844272498116299, 0.9597626378794966, 0.969799472639236]}}
{"id": "19fca100-4f44-4977-bddd-e461c0567a36", "fitness": 0.7101927112945278, "name": "EnhancedHybridPSO_DE", "description": "Enhanced convergence by incorporating adaptive crossover rate adjustment based on evaluation progress.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < (self.CR + 0.1 * (eval_count / self.budget))\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8512461822041365, 0.9101037454111658, 0.8645310450551429, 0.9235023124776229, 0.8743937798200345, 0.9609855919454267, 0.9446087237119977, 0.9844374459701608, 0.9625507179611765, 0.9596665020649982, 0.9600963589650469, 0.9499784417060781, 0.9844272498116299, 0.9621122938806308, 0.943414940030842]}}
{"id": "b00f110a-0d5b-4926-8ed2-b06329b3fd47", "fitness": 0.7062287818731953, "name": "EnhancedHybridPSO_DE", "description": "Enhanced convergence by slightly adjusting the adaptive mutation scaling factor range.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.55 + 0.35 * np.random.rand()  # Adaptive mutation scaling adjusted from 0.5-0.4 to 0.55-0.35\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.943009257914485, 0.8483860198652107, 0.7991672446798542, 0.818891528051293, 0.8875261159763985, 0.9570667288596268, 0.9632296270352215, 0.984437590114536, 0.9580670222413272, 0.9631847814871656, 0.9799998005098086, 0.9508025172564184, 0.9844262983460613, 0.9633778444825932, 0.9552043657694377]}}
{"id": "7092e86c-a256-4aa1-9bca-ec9a75956e47", "fitness": 0.7017236176887134, "name": "EnhancedHybridPSO_DE", "description": "Adjusted the velocity clamping function for more dynamic convergence control by incorporating dimension size.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            # Adjusted velocity clamping with dimension consideration\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / (self.budget * np.sqrt(self.dim))\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8843014591872915, 0.8376673353632718, 0.8979947928395869, 0.851042996499388, 0.9318291069545188, 0.9412429919710397, 0.9457772515204831, 0.9684910491153937, 0.9460211771541065, 0.9557451722531031, 0.9235461545119029, 0.9379342056898756, 0.9669469898363657, 0.9412831719345864, 0.9368496040688876]}}
{"id": "5fbf8bc9-190c-4d36-b1b6-2dc9fdf49acf", "fitness": 0.7144282904390751, "name": "EnhancedHybridPSO_DE", "description": "Enhanced exploitation by introducing a tunable dynamic mutation scaling factor to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8439209176003641, 0.8978753418223275, 0.9004041628869234, 0.9202369542292672, 0.9157972935018182, 0.9634859240606446, 0.9387959641408766, 0.9844374463635828, 0.9625509104550147, 0.9596637088146265, 0.9601024815080385, 0.9595064481931901, 0.9844272498116299, 0.9597626378794966, 0.969799472639236]}}
{"id": "186ad1d5-8345-4527-a276-5411c376e6bb", "fitness": 0.7072467564697253, "name": "EnhancedHybridPSO_DE", "description": "Introduced a mechanism to dynamically adjust the crossover rate based on population diversity for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            # Calculate diversity to adjust CR\n            population_diversity = np.std(positions) / (self.ub - self.lb)\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget + 0.1 * population_diversity\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8031277933681322, 0.9156927447406505, 0.8945676436076551, 0.859487906165998, 0.9104493150718073, 0.9593485479488468, 0.9496944561679952, 0.9844378413018244, 0.9510316078056669, 0.950816516428388, 0.9465906026991093, 0.9651936332908555, 0.9844273947309885, 0.9548326713023724, 0.9474375598897502]}}
{"id": "7a2b275d-5c1a-4ad2-b70b-fb2fd2d37f99", "fitness": 0.7058177035462074, "name": "EnhancedHybridPSO_DE", "description": "Refined mutation strategy by slightly increasing the mutation scaling factor for more aggressive exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.55 + 0.4 * np.random.rand()  # Slightly increased mutation scaling\n\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8912027830946456, 0.9071323713983299, 0.7893004241690432, 0.874797961640448, 0.9044395008560728, 0.9519160339467431, 0.9452246652321775, 0.9651518588935423, 0.953244057920193, 0.9717644239946447, 0.9758549117318669, 0.9568014102638003, 0.9663068966486723, 0.961257961612019, 0.9341599146474839]}}
{"id": "515ac039-8585-42a1-8095-217015ed9a6e", "fitness": 0.6904792804383995, "name": "EnhancedHybridPSO_DE", "description": "Enhanced adaptive parameters by increasing inertia weight range for better exploitation-exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.4 * (np.std(positions) / (self.ub - self.lb))  # Adjusted adaptive inertia weight range\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.38.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8671766989469955, 0.897681403400655, 0.7978216832815008, 0.8114984524359645, 0.814993759490434, 0.9392783782678673, 0.9578481021467177, 0.9515283103001613, 0.9223595378341218, 0.9409783379800207, 0.9500515472846305, 0.925523387489183, 0.9607174626236281, 0.9505096877224856, 0.9538199646891572]}}
{"id": "e575aa40-3095-4b0e-bf71-e90446db8e79", "fitness": 0.7070855653753261, "name": "EnhancedHybridPSO_DE", "description": "Enhanced exploitation by reducing velocity clamping as the evaluation progresses.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.1 + 0.5 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9368626381705314, 0.8601586307401232, 0.8972270775220841, 0.90097153468863, 0.8668755627324918, 0.940996448065359, 0.941427076431986, 0.9666193202926177, 0.9578203374702469, 0.9420013403078088, 0.961350800417903, 0.9630287804356165, 0.9506584247505367, 0.943532300143182, 0.9443821404629374]}}
{"id": "b58ae396-4f88-4bbf-a951-0dc8f33c53b8", "fitness": 0.6759189688030125, "name": "EnhancedHybridPSO_DE", "description": "Increase exploration by replacing the standard deviation-based weight adjustment with a more dynamic exploration factor.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (1 - (eval_count / self.budget))  # More dynamic exploration factor\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.38.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9408588931922981, 0.7148021202204565, 0.7739169470191788, 0.846146614568978, 0.7043528137394771, 0.9515505134630293, 0.9470692906952846, 0.9521602975035004, 0.9299649619598925, 0.9328124798936679, 0.9210697083931748, 0.9333030206364834, 0.9555179718157671, 0.9304042248970144, 0.9166506231875804]}}
{"id": "0f1e323d-770a-4964-a5e3-6b7b5e4665f5", "fitness": 0.7110292010497129, "name": "EnhancedHybridPSO_DE", "description": "Enhanced exploration by adapting velocity computation to incorporate diversity-based scaling.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                (1 - np.std(positions) / (self.ub - self.lb)) * self.w * velocities  # Modified line\n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.05 * (eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.9043114135219606, 0.8956193427785542, 0.8825996033913781, 0.9075422855867061, 0.8100397572380997, 0.9599955854112664, 0.9621491732381156, 0.9843546515269878, 0.9681027365696857, 0.9685230681587633, 0.9409138888594464, 0.9558448925142498, 0.9702389424172886, 0.9718944734138181, 0.9706553114934692]}}
{"id": "f9e1f98c-8ba8-44a5-9cac-490e1d51913b", "fitness": 0.6992491342641446, "name": "EnhancedHybridPSO_DE", "description": "Enhanced exploration by dynamically adjusting mutation probability based on convergence speed near the final stages.", "code": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.pop_size = 10 + 2 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.6\n        self.F = 0.8\n        self.CR = 0.9\n        self.diversity_threshold = 0.1\n        self.extra_mutation_prob = 0.1\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lb, self.ub, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        pbest_positions = np.copy(positions)\n        pbest_scores = np.array([func(x) for x in pbest_positions])\n        \n        gbest_idx = np.argmin(pbest_scores)\n        gbest_position = pbest_positions[gbest_idx]\n        gbest_score = pbest_scores[gbest_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            self.w = 0.3 + 0.3 * (np.std(positions) / (self.ub - self.lb))  # Diversity-based adaptive inertia weight\n            self.c1 = 1.0 + 0.5 * (eval_count / self.budget)\n            self.c2 = 2.0 - 0.5 * (eval_count / self.budget)\n\n            # Changed the lower limit of velocity_bound for improved convergence\n            velocity_bound = 0.3 + 0.7 * (self.budget - eval_count) / self.budget  # Adjusted velocity clamping\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = np.clip(\n                self.w * velocities \n                + self.c1 * r1 * (pbest_positions - positions) \n                + self.c2 * r2 * (gbest_position - positions), \n                -velocity_bound, velocity_bound\n            )\n            positions = np.clip(positions + velocities, self.lb, self.ub)\n            \n            scores = np.array([func(x) for x in positions])\n            eval_count += self.pop_size\n            \n            improved = scores < pbest_scores\n            pbest_scores[improved] = scores[improved]\n            pbest_positions[improved] = positions[improved]\n            \n            gbest_idx = np.argmin(pbest_scores)\n            if pbest_scores[gbest_idx] < gbest_score:\n                gbest_position = pbest_positions[gbest_idx]\n                gbest_score = pbest_scores[gbest_idx]\n\n            self.F = 0.5 + 0.4 * np.random.rand()  # Adaptive mutation scaling\n            self.CR = 0.85 - 0.05 * (self.budget - eval_count) / self.budget\n\n            for i in range(self.pop_size):\n                indices = [idx for idx in range(self.pop_size) if idx != i]\n                a, b = np.random.choice(indices, 2, replace=False)\n                if np.random.rand() < 0.2:\n                    mutant_vector = np.clip(positions[i] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                else:\n                    mutant_vector = np.clip(gbest_position + self.F * (positions[a] - positions[b]), self.lb, self.ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n                trial_vector = np.where(crossover, mutant_vector, positions[i])\n\n                if np.random.rand() < self.extra_mutation_prob + 0.1 * (1 - eval_count / self.budget):\n                    trial_vector += np.random.normal(0, self.diversity_threshold, self.dim)\n\n                trial_score = func(trial_vector)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < pbest_scores[i]:\n                        pbest_scores[i] = trial_score\n                        pbest_positions[i] = trial_vector\n                        if trial_score < gbest_score:\n                            gbest_position = trial_vector\n                            gbest_score = trial_score\n\n        return gbest_position, gbest_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.39.", "error": "", "parent_ids": ["d0b3a567-d053-4ccb-a083-0335b469c2f9"], "operator": null, "metadata": {"aucs": [0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.03355977897489326, 0.8024864134185847, 0.895679114135671, 0.8249900715261259, 0.9033078485466921, 0.8201264822277259, 0.9520535347540832, 0.9377527085580762, 0.9736512228568645, 0.9800733490476317, 0.95634790955644, 0.9495224844429173, 0.9544999385935521, 0.954294459860953, 0.9801448049139315, 0.9322534479691751]}}
