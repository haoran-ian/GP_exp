{"id": "7f5615ac-592d-47ed-bcbf-9ee0ff8e2390", "fitness": 0.17957916791783685, "name": "AdaptiveLevyPSO", "description": "Adaptive Particle Swarm Optimization with Lévy Flight for enhanced exploration and exploitation in dynamic search spaces.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.05  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.16.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1434650779666039, 0.0891203670679106, 0.2721504567363344, 0.09307915387159083, 0.11092685191320517, 0.07833005016730488, 0.1356853978820639, 0.5929762260884751, 0.10047892956704285]}}
{"id": "3ab271d6-f97e-42a2-bd86-290bba5d56aa", "fitness": 0.2446417624797177, "name": "AdaptiveLevyPSO", "description": "Improved the AdaptiveLevyPSO algorithm by reducing inertia weight to enhance convergence speed.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.05  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.16.", "error": "", "parent_ids": ["7f5615ac-592d-47ed-bcbf-9ee0ff8e2390"], "operator": null, "metadata": {"aucs": [0.13811429834327116, 0.4722261736577482, 0.11794467198934644, 0.18465091200628525, 0.10675106765207132, 0.1035335199713302, 0.44964988198105205, 0.4663310668825221, 0.16257426983383227]}}
{"id": "39bc12cd-dd22-422a-8f43-03d8f8e00215", "fitness": 0.26404496374070524, "name": "AdaptiveLevyPSO", "description": "Slightly decreased the social component to balance exploration and exploitation improving convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.21.", "error": "", "parent_ids": ["3ab271d6-f97e-42a2-bd86-290bba5d56aa"], "operator": null, "metadata": {"aucs": [0.11275196833430845, 0.13929898222315495, 0.2515067444153247, 0.0985745241040612, 0.11641395985365421, 0.09974184755237825, 0.37247891881067685, 0.7736712845443103, 0.41196644382847847]}}
{"id": "4f1ef02a-70ea-4a78-98e5-8a6d36668c04", "fitness": 0.08162032240462119, "name": "AdaptiveLevyPSO", "description": "Adjusted the inertia weight dynamically to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                # Change: Dynamically adjust the inertia weight\n                self.w = 0.9 - (self.evaluations / self.budget) * 0.5\n                \n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.08262413471622232, 0.0876814920990504, 0.07862175738316068, 0.07460105025472552, 0.07954224129287235, 0.06084330856595854, 0.09444997939214317, 0.10393856726353912, 0.07228037067391868]}}
{"id": "6afc512d-2baa-40c8-8298-692459be2476", "fitness": 0.07831368121346155, "name": "AdaptiveLevyPSO", "description": "Adjusted inertia weight dynamically based on evaluations to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.4 + 0.6 * (1 - self.evaluations / self.budget)  # Dynamically adjust inertia weight\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.0696557020795383, 0.07147465598274005, 0.08329425315970218, 0.06447797402184396, 0.07286335116311715, 0.0753592736214086, 0.07862380333417607, 0.09343695477747449, 0.09563716278115308]}}
{"id": "19a15460-d602-4a6e-9303-48e6cbe6c34a", "fitness": 0.217759300851655, "name": "AdaptiveLevyPSO", "description": "Introduced adaptive adjustment to inertia weight based on the number of evaluations to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.w = 0.4 + 0.1 * (1 - self.evaluations / self.budget)  # Adaptive adjustment to inertia weight\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.09044972480844793, 0.09934479358531756, 0.6163342328946103, 0.09070736281079717, 0.08117765926173237, 0.08423405285091123, 0.13183385395365177, 0.10692478985991016, 0.6588272376395166]}}
{"id": "053bb853-b3d6-4b8b-8787-35f0a0dc1233", "fitness": 0.08661049216853373, "name": "AdaptiveLevyPSO", "description": "Introduced adaptive inertia weight to improve convergence balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            self.w = 0.9 - (0.5 * (self.evaluations / self.budget))  # Changed line: adaptive inertia weight\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.0891651854915606, 0.07832195458002289, 0.08902500621032039, 0.08221288458421616, 0.06553846059718815, 0.08100040619937787, 0.10864276510721582, 0.0804078135992361, 0.1051799531476656]}}
{"id": "4d332dc3-dc76-418a-a8af-44ef37fdf9ce", "fitness": 0.0870015468208836, "name": "AdaptiveLevyPSO", "description": "Implement a dynamic inertia weight to enhance the balance between exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # Adjusted initial inertia weight for dynamic adjustment\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Dynamically adjust inertia weight based on progress\n            self.w = 0.9 - (0.5 * (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.0987540179023575, 0.08556027129782628, 0.0781732675693565, 0.07749489290657907, 0.07808832800261312, 0.07225184541873897, 0.10207335877056467, 0.10025473031676546, 0.09036320920315077]}}
{"id": "e856ce25-17a1-4e90-801e-dc964763cc05", "fitness": 0.1271285944620914, "name": "AdaptiveLevyPSO", "description": "Introduced stochastic inertia weight to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                # Change: Introduce stochastic inertia weight\n                self.velocities[i] = np.random.uniform(0.3, 0.5) * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.04.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.12474756746422444, 0.09785559003546807, 0.09994446814565416, 0.09675820131651824, 0.11254194436791753, 0.08947020820286489, 0.1445038761460845, 0.24099056751809667, 0.13734492696199418]}}
{"id": "31a8c962-7b55-4c4f-8e61-e7655ab53287", "fitness": 0.08162032240462119, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation balance by introducing adaptive inertia weight and dynamic velocity updates to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.08262413471622232, 0.0876814920990504, 0.07862175738316068, 0.07460105025472552, 0.07954224129287235, 0.06084330856595854, 0.09444997939214317, 0.10393856726353912, 0.07228037067391868]}}
{"id": "b9df43d8-8085-4e0e-a778-029dd55ef0d8", "fitness": 0.18569990848513113, "name": "AdaptiveLevyPSO", "description": "Introduced random restarts every 10% of evaluations to enhance escaping local optima.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            if self.evaluations > 0 and self.evaluations % (self.budget // 10) == 0:  # Change here\n                self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n            \n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.21.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.09689079837202985, 0.13929898222315495, 0.10774060781738248, 0.08815101929558611, 0.11641395985365421, 0.09424478983219142, 0.11873925134817886, 0.7736712845443103, 0.13614848307969207]}}
{"id": "6ad91604-17fa-477c-b09b-6519ba4d6a19", "fitness": 0.08517360588612603, "name": "AdaptiveLevyPSO", "description": "Incorporate a dynamic inertia weight and adaptive social component to enhance exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # Increased initial inertia weight for better exploration\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 1.5  # Decreased social component for better exploration balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Gradually decrease inertia weight to favor exploitation\n            self.w = 0.4 + (0.9 - 0.4) * (1 - self.evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.09382131567802388, 0.06828985107891661, 0.09222416530504907, 0.08296497368492273, 0.06324403096359632, 0.07983004552935102, 0.09852146013597873, 0.07693382338819432, 0.11073278721110158]}}
{"id": "765dc4ff-2540-403e-af73-a9f740342fde", "fitness": 0.22728278811765856, "name": "AdaptiveLevyPSO", "description": "Adjust inertia weight dynamically based on evaluation progress to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                self.w = 0.4 + 0.6 * (self.evaluations / self.budget)  # Dynamically adjust inertia weight\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.10194958731386361, 0.16851160668635612, 0.13599569840063908, 0.09436207338312785, 0.12649138945550342, 0.11593888697567101, 0.1343189100856097, 0.6418879672304542, 0.526088973527702]}}
{"id": "248c24b4-baa1-4b02-91b6-3498def0994e", "fitness": 0.32148675939334886, "name": "AdaptiveLevyPSO", "description": "Improved exploration by increasing the probability of performing a Lévy flight.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.10315347552682907, 0.10607660088037851, 0.2417008799963991, 0.6565217732010057, 0.10266466719966205, 0.12813549383940837, 0.7358976957095822, 0.29117640917730525, 0.5280538390095693]}}
{"id": "1ef26a40-dd3f-49cc-a415-d3b9cc7a8240", "fitness": 0.08714751836611084, "name": "AdaptiveLevyPSO", "description": "Advanced AdaptiveLevyPSO with dynamic parameter adjustment for improved convergence and exploration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.7  # increased inertia weight for better exploration initially\n        self.c1 = 1.5  # decreased cognitive component for more global search\n        self.c2 = 2.5  # increased social component for faster convergence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.initial_w = self.w\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for levy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Dynamically adjust the inertia weight for balance between exploration and exploitation\n            self.w = self.initial_w * (1 - self.evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10024457108683271, 0.07393374742796233, 0.07939559628883708, 0.08976690362783424, 0.06940798783543944, 0.06936609168008956, 0.12603745475519335, 0.0889168616590642, 0.08725845093374474]}}
{"id": "1db8d1c5-6d6e-4587-a186-fdf7176da187", "fitness": 0.08527220789381755, "name": "AdaptiveLevyPSO", "description": "Fine-tuned balance between exploration and exploitation by adjusting parameters.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # increased inertia weight from 0.4 to 0.5 for better exploration\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 1.95  # decreased social component from 2.0 to 1.95 to fine-tune balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09629603623499172, 0.06414256766912252, 0.08859181604796917, 0.08554010914723098, 0.05958696865017765, 0.0807440023256395, 0.116565608330496, 0.0716249752950412, 0.10435778734368917]}}
